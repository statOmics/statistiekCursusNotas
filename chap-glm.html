<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Hoofdstuk 10 Algemeen lineair model | Cursus Statistiek 2019-2020</title>
  <meta name="description" content="Basiscursus Statistiek voor de 2de Bachelor of Science in de Biologie, - in de Biochemie &amp; de Biotechnologie, - in de Biomedische Wetenschappen, en - in de Chemie" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Hoofdstuk 10 Algemeen lineair model | Cursus Statistiek 2019-2020" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Basiscursus Statistiek voor de 2de Bachelor of Science in de Biologie, - in de Biochemie &amp; de Biotechnologie, - in de Biomedische Wetenschappen, en - in de Chemie" />
  <meta name="github-repo" content="statOmics/statistiek2deBach" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Hoofdstuk 10 Algemeen lineair model | Cursus Statistiek 2019-2020" />
  
  <meta name="twitter:description" content="Basiscursus Statistiek voor de 2de Bachelor of Science in de Biologie, - in de Biochemie &amp; de Biotechnologie, - in de Biomedische Wetenschappen, en - in de Chemie" />
  

<meta name="author" content="Lieven Clement" />


<meta name="date" content="2019-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-categorisch.html">
<link rel="next" href="chap-modsel.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cursus Statistiek 2019-2020</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Woord vooraf</a></li>
<li class="chapter" data-level="" data-path="links.html"><a href="links.html"><i class="fa fa-check"></i>Links</a></li>
<li class="chapter" data-level="1" data-path="inleiding.html"><a href="inleiding.html"><i class="fa fa-check"></i><b>1</b> Inleiding</a><ul>
<li class="chapter" data-level="1.1" data-path="inleiding.html"><a href="inleiding.html#sec:wetMeth"><i class="fa fa-check"></i><b>1.1</b> De Wetenschappelijke Methode</a></li>
<li class="chapter" data-level="1.2" data-path="inleiding.html"><a href="inleiding.html#voorbeeld-horizon---homeopathy-the-test"><i class="fa fa-check"></i><b>1.2</b> Voorbeeld: Horizon - Homeopathy the test</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inleiding.html"><a href="inleiding.html#wetenschappelijke-hypothese-fragmenten-1-2-000-600-740-1130"><i class="fa fa-check"></i><b>1.2.1</b> Wetenschappelijke hypothese (fragmenten 1-2: 0’00’‘-6’00’‘&amp; 7’40’‘-11’30’’)</a></li>
<li class="chapter" data-level="1.2.2" data-path="inleiding.html"><a href="inleiding.html#onderzoek-dient-reproduceerbaar-te-zijn.-wat-ging-er-fout-fragment-1450-1856"><i class="fa fa-check"></i><b>1.2.2</b> Onderzoek dient reproduceerbaar te zijn. Wat ging er fout? (Fragment: 14’50”-18’56”)</a></li>
<li class="chapter" data-level="1.2.3" data-path="inleiding.html"><a href="inleiding.html#the-ultimate-test---proefopzet-fragment-3100-3930"><i class="fa fa-check"></i><b>1.2.3</b> The ultimate test - proefopzet (Fragment 31’00-39’30’’)</a></li>
<li class="chapter" data-level="1.2.4" data-path="inleiding.html"><a href="inleiding.html#the-ultimate-test---data-analyse-fragment-3930-4300"><i class="fa fa-check"></i><b>1.2.4</b> The ultimate test - data analyse (Fragment 39’30-43’00’’)</a></li>
<li class="chapter" data-level="1.2.5" data-path="inleiding.html"><a href="inleiding.html#mogelijke-fouten"><i class="fa fa-check"></i><b>1.2.5</b> Mogelijke fouten</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html"><i class="fa fa-check"></i><b>2</b> Belangrijke concepten &amp; conventies</a><ul>
<li class="chapter" data-level="2.1" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#variabelen"><i class="fa fa-check"></i><b>2.1</b> Variabelen</a></li>
<li class="chapter" data-level="2.2" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#subsec:pop"><i class="fa fa-check"></i><b>2.2</b> Populatie</a></li>
<li class="chapter" data-level="2.3" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#toevalsveranderlijken-of-toevallige-veranderlijken"><i class="fa fa-check"></i><b>2.3</b> Toevalsveranderlijken (of toevallige veranderlijken)</a></li>
<li class="chapter" data-level="2.4" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#beschrijven-van-de-populatie"><i class="fa fa-check"></i><b>2.4</b> Beschrijven van de populatie</a></li>
<li class="chapter" data-level="2.5" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#steekproef"><i class="fa fa-check"></i><b>2.5</b> Steekproef</a></li>
<li class="chapter" data-level="2.6" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#schatten-van-de-verdeling-in-de-populatie"><i class="fa fa-check"></i><b>2.6</b> Schatten van de verdeling in de populatie</a></li>
<li class="chapter" data-level="2.7" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#statistieken"><i class="fa fa-check"></i><b>2.7</b> Statistieken</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap-design.html"><a href="chap-design.html"><i class="fa fa-check"></i><b>3</b> Studiedesign</a><ul>
<li class="chapter" data-level="3.1" data-path="chap-design.html"><a href="chap-design.html#inleiding-1"><i class="fa fa-check"></i><b>3.1</b> Inleiding</a></li>
<li class="chapter" data-level="3.2" data-path="chap-design.html"><a href="chap-design.html#sec:steekproefdesigns"><i class="fa fa-check"></i><b>3.2</b> Steekproefdesigns</a><ul>
<li class="chapter" data-level="3.2.1" data-path="chap-design.html"><a href="chap-design.html#replicatie"><i class="fa fa-check"></i><b>3.2.1</b> Replicatie</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="chap-design.html"><a href="chap-design.html#experimentele-studies"><i class="fa fa-check"></i><b>3.3</b> Experimentele studies</a><ul>
<li class="chapter" data-level="3.3.1" data-path="chap-design.html"><a href="chap-design.html#de-salk-vaccin-veldstudie"><i class="fa fa-check"></i><b>3.3.1</b> De Salk Vaccin Veldstudie</a></li>
<li class="chapter" data-level="3.3.2" data-path="chap-design.html"><a href="chap-design.html#gerandomiseerd-gecontroleerde-studies"><i class="fa fa-check"></i><b>3.3.2</b> Gerandomiseerd gecontroleerde studies</a></li>
<li class="chapter" data-level="3.3.3" data-path="chap-design.html"><a href="chap-design.html#parallelle-designs"><i class="fa fa-check"></i><b>3.3.3</b> Parallelle designs</a></li>
<li class="chapter" data-level="3.3.4" data-path="chap-design.html"><a href="chap-design.html#cross-over-designs"><i class="fa fa-check"></i><b>3.3.4</b> Cross-over designs</a></li>
<li class="chapter" data-level="3.3.5" data-path="chap-design.html"><a href="chap-design.html#factoriele-designs"><i class="fa fa-check"></i><b>3.3.5</b> Factoriële designs</a></li>
<li class="chapter" data-level="3.3.6" data-path="chap-design.html"><a href="chap-design.html#quasi-experimentele-designs"><i class="fa fa-check"></i><b>3.3.6</b> Quasi-experimentele designs</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chap-design.html"><a href="chap-design.html#sec:observational"><i class="fa fa-check"></i><b>3.4</b> Observationele studies</a></li>
<li class="chapter" data-level="3.5" data-path="chap-design.html"><a href="chap-design.html#subsec:design:prosp"><i class="fa fa-check"></i><b>3.5</b> Prospectieve studies</a></li>
<li class="chapter" data-level="3.6" data-path="chap-design.html"><a href="chap-design.html#subsec:design:retro"><i class="fa fa-check"></i><b>3.6</b> Retrospectieve studies</a></li>
<li class="chapter" data-level="3.7" data-path="chap-design.html"><a href="chap-design.html#niet-gecontroleerde-studies"><i class="fa fa-check"></i><b>3.7</b> Niet-gecontroleerde studies</a><ul>
<li class="chapter" data-level="3.7.1" data-path="chap-design.html"><a href="chap-design.html#subsec:prepost"><i class="fa fa-check"></i><b>3.7.1</b> Pre-test/Post-test studies</a></li>
<li class="chapter" data-level="3.7.2" data-path="chap-design.html"><a href="chap-design.html#cross-sectionele-surveys"><i class="fa fa-check"></i><b>3.7.2</b> Cross-sectionele surveys</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap-describe.html"><a href="chap-describe.html"><i class="fa fa-check"></i><b>4</b> Data exploratie en beschrijvende statistiek</a><ul>
<li class="chapter" data-level="4.1" data-path="chap-describe.html"><a href="chap-describe.html#inleiding-2"><i class="fa fa-check"></i><b>4.1</b> Inleiding</a></li>
<li class="chapter" data-level="4.2" data-path="chap-describe.html"><a href="chap-describe.html#sec:univar"><i class="fa fa-check"></i><b>4.2</b> Univariate beschrijving van de variabelen</a></li>
<li class="chapter" data-level="4.3" data-path="chap-describe.html"><a href="chap-describe.html#sec:summarize"><i class="fa fa-check"></i><b>4.3</b> Samenvattingsmaten voor continue variabelen</a><ul>
<li class="chapter" data-level="4.3.1" data-path="chap-describe.html"><a href="chap-describe.html#maten-voor-de-centrale-ligging"><i class="fa fa-check"></i><b>4.3.1</b> Maten voor de centrale ligging</a></li>
<li class="chapter" data-level="4.3.2" data-path="chap-describe.html"><a href="chap-describe.html#subsec:spreiding"><i class="fa fa-check"></i><b>4.3.2</b> Spreidingsmaten</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chap-describe.html"><a href="chap-describe.html#sec:normal"><i class="fa fa-check"></i><b>4.4</b> De Normale benadering van gegevens</a><ul>
<li class="chapter" data-level="4.4.1" data-path="chap-describe.html"><a href="chap-describe.html#subsec:normalcalc"><i class="fa fa-check"></i><b>4.4.1</b> Bepalen van oppervlaktes onder de Normale curve</a></li>
<li class="chapter" data-level="4.4.2" data-path="chap-describe.html"><a href="chap-describe.html#sec:qq"><i class="fa fa-check"></i><b>4.4.2</b> QQ-plots</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chap-describe.html"><a href="chap-describe.html#sec:explCatVar"><i class="fa fa-check"></i><b>4.5</b> Samenvattingsmaten voor categorische variabelen</a><ul>
<li class="chapter" data-level="4.5.1" data-path="chap-describe.html"><a href="chap-describe.html#prospectieve-studies-en-lukrake-steekproeven"><i class="fa fa-check"></i><b>4.5.1</b> Prospectieve studies en lukrake steekproeven</a></li>
<li class="chapter" data-level="4.5.2" data-path="chap-describe.html"><a href="chap-describe.html#subsec:retrospect"><i class="fa fa-check"></i><b>4.5.2</b> Retrospectieve studies</a></li>
<li class="chapter" data-level="4.5.3" data-path="chap-describe.html"><a href="chap-describe.html#rates-versus-risicos"><i class="fa fa-check"></i><b>4.5.3</b> Rates versus risico’s</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="chap-describe.html"><a href="chap-describe.html#associaties-tussen-twee-variabelen"><i class="fa fa-check"></i><b>4.6</b> Associaties tussen twee variabelen</a><ul>
<li class="chapter" data-level="4.6.1" data-path="chap-describe.html"><a href="chap-describe.html#subsec:kruistabel"><i class="fa fa-check"></i><b>4.6.1</b> Associatie tussen twee kwalitatieve variabelen</a></li>
<li class="chapter" data-level="4.6.2" data-path="chap-describe.html"><a href="chap-describe.html#subsec:asskwalcont"><i class="fa fa-check"></i><b>4.6.2</b> Associatie tussen één kwalitatieve en één continue variabele</a></li>
<li class="chapter" data-level="4.6.3" data-path="chap-describe.html"><a href="chap-describe.html#sec:correlatie"><i class="fa fa-check"></i><b>4.6.3</b> Associatie tussen twee continue variabelen</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="chap-describe.html"><a href="chap-describe.html#sec:missing"><i class="fa fa-check"></i><b>4.7</b> Onvolledige gegevens</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap-besluit.html"><a href="chap-besluit.html"><i class="fa fa-check"></i><b>5</b> Statistische besluitvorming</a><ul>
<li class="chapter" data-level="5.1" data-path="chap-besluit.html"><a href="chap-besluit.html#inleiding-3"><i class="fa fa-check"></i><b>5.1</b> Inleiding</a></li>
<li class="chapter" data-level="5.2" data-path="chap-besluit.html"><a href="chap-besluit.html#captopril-voorbeeld"><i class="fa fa-check"></i><b>5.2</b> Captopril voorbeeld</a><ul>
<li class="chapter" data-level="5.2.1" data-path="chap-besluit.html"><a href="chap-besluit.html#proefopzet"><i class="fa fa-check"></i><b>5.2.1</b> Proefopzet</a></li>
<li class="chapter" data-level="5.2.2" data-path="chap-besluit.html"><a href="chap-besluit.html#data-exploratie-beschrijvende-statistiek"><i class="fa fa-check"></i><b>5.2.2</b> Data Exploratie &amp; Beschrijvende Statistiek</a></li>
<li class="chapter" data-level="5.2.3" data-path="chap-besluit.html"><a href="chap-besluit.html#schatten"><i class="fa fa-check"></i><b>5.2.3</b> Schatten</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chap-besluit.html"><a href="chap-besluit.html#puntschatters-het-steekproefgemiddelde"><i class="fa fa-check"></i><b>5.3</b> Puntschatters: het steekproefgemiddelde</a><ul>
<li class="chapter" data-level="5.3.1" data-path="chap-besluit.html"><a href="chap-besluit.html#het-steekproefgemiddelde-is-onvertekend"><i class="fa fa-check"></i><b>5.3.1</b> Het steekproefgemiddelde is onvertekend</a></li>
<li class="chapter" data-level="5.3.2" data-path="chap-besluit.html"><a href="chap-besluit.html#imprecisiestandard-error"><i class="fa fa-check"></i><b>5.3.2</b> Imprecisie/standard error</a></li>
<li class="chapter" data-level="5.3.3" data-path="chap-besluit.html"><a href="chap-besluit.html#subsec:verdelingXbar"><i class="fa fa-check"></i><b>5.3.3</b> Verdeling van het steekproefgemiddelde</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="chap-besluit.html"><a href="chap-besluit.html#intervalschatters"><i class="fa fa-check"></i><b>5.4</b> Intervalschatters</a><ul>
<li class="chapter" data-level="5.4.1" data-path="chap-besluit.html"><a href="chap-besluit.html#subsec:bigek"><i class="fa fa-check"></i><b>5.4.1</b> Gekende variantie op de metingen</a></li>
<li class="chapter" data-level="5.4.2" data-path="chap-besluit.html"><a href="chap-besluit.html#sec:tBI"><i class="fa fa-check"></i><b>5.4.2</b> Ongekende variantie op de metingen</a></li>
<li class="chapter" data-level="5.4.3" data-path="chap-besluit.html"><a href="chap-besluit.html#subsec:interpretBI"><i class="fa fa-check"></i><b>5.4.3</b> Interpretatie van betrouwbaarheidsintervallen</a></li>
<li class="chapter" data-level="5.4.4" data-path="chap-besluit.html"><a href="chap-besluit.html#wat-rapporteren"><i class="fa fa-check"></i><b>5.4.4</b> Wat rapporteren?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chap-besluit.html"><a href="chap-besluit.html#principe-van-hypothesetoetsen-via-one-sample-t-test"><i class="fa fa-check"></i><b>5.5</b> Principe van Hypothesetoetsen (via one sample t-test)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="chap-besluit.html"><a href="chap-besluit.html#hypotheses"><i class="fa fa-check"></i><b>5.5.1</b> Hypotheses</a></li>
<li class="chapter" data-level="5.5.2" data-path="chap-besluit.html"><a href="chap-besluit.html#test-statistiek"><i class="fa fa-check"></i><b>5.5.2</b> Test-statistiek</a></li>
<li class="chapter" data-level="5.5.3" data-path="chap-besluit.html"><a href="chap-besluit.html#de-p-waarde"><i class="fa fa-check"></i><b>5.5.3</b> De p-waarde</a></li>
<li class="chapter" data-level="5.5.4" data-path="chap-besluit.html"><a href="chap-besluit.html#kritieke-waarde"><i class="fa fa-check"></i><b>5.5.4</b> Kritieke waarde</a></li>
<li class="chapter" data-level="5.5.5" data-path="chap-besluit.html"><a href="chap-besluit.html#beslissingsfouten"><i class="fa fa-check"></i><b>5.5.5</b> Beslissingsfouten</a></li>
<li class="chapter" data-level="5.5.6" data-path="chap-besluit.html"><a href="chap-besluit.html#conclusies-captopril-voorbeeld."><i class="fa fa-check"></i><b>5.5.6</b> Conclusies Captopril voorbeeld.</a></li>
<li class="chapter" data-level="5.5.7" data-path="chap-besluit.html"><a href="chap-besluit.html#eenzijdig-of-tweezijdig-toetsen"><i class="fa fa-check"></i><b>5.5.7</b> Eenzijdig of tweezijdig toetsen?</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="chap-besluit.html"><a href="chap-besluit.html#two-sample-t-test"><i class="fa fa-check"></i><b>5.6</b> Two-sample t-test</a><ul>
<li class="chapter" data-level="5.6.1" data-path="chap-besluit.html"><a href="chap-besluit.html#oksel-voorbeeld"><i class="fa fa-check"></i><b>5.6.1</b> Oksel-voorbeeld</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="chap-besluit.html"><a href="chap-besluit.html#aannames"><i class="fa fa-check"></i><b>5.7</b> Aannames</a><ul>
<li class="chapter" data-level="5.7.1" data-path="chap-besluit.html"><a href="chap-besluit.html#nagaan-van-de-veronderstelling-van-normaliteit"><i class="fa fa-check"></i><b>5.7.1</b> Nagaan van de veronderstelling van Normaliteit</a></li>
<li class="chapter" data-level="5.7.2" data-path="chap-besluit.html"><a href="chap-besluit.html#nagaan-van-homoscedasticiteit"><i class="fa fa-check"></i><b>5.7.2</b> Nagaan van homoscedasticiteit</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="chap-besluit.html"><a href="chap-besluit.html#wat-rapporteren-1"><i class="fa fa-check"></i><b>5.8</b> Wat rapporteren?</a><ul>
<li class="chapter" data-level="5.8.1" data-path="chap-besluit.html"><a href="chap-besluit.html#reden-1-relatie-toetsen-en-betrouwbaarheidsintervallen"><i class="fa fa-check"></i><b>5.8.1</b> Reden 1: Relatie toetsen en betrouwbaarheidsintervallen</a></li>
<li class="chapter" data-level="5.8.2" data-path="chap-besluit.html"><a href="chap-besluit.html#reden-2-statistische-significantie-versus-wetenschappelijke-relevantie"><i class="fa fa-check"></i><b>5.8.2</b> Reden 2: Statistische significantie versus wetenschappelijke relevantie</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="chap-besluit.html"><a href="chap-besluit.html#equivalentie-intervallen"><i class="fa fa-check"></i><b>5.9</b> Equivalentie-intervallen</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap-linReg.html"><a href="chap-linReg.html"><i class="fa fa-check"></i><b>6</b> Enkelvoudige lineaire regressie</a><ul>
<li class="chapter" data-level="6.1" data-path="chap-linReg.html"><a href="chap-linReg.html#inleiding-4"><i class="fa fa-check"></i><b>6.1</b> Inleiding</a><ul>
<li class="chapter" data-level="6.1.1" data-path="chap-linReg.html"><a href="chap-linReg.html#borstkanker-dataset"><i class="fa fa-check"></i><b>6.1.1</b> Borstkanker dataset</a></li>
<li class="chapter" data-level="6.1.2" data-path="chap-linReg.html"><a href="chap-linReg.html#data-exploratie"><i class="fa fa-check"></i><b>6.1.2</b> Data exploratie</a></li>
<li class="chapter" data-level="6.1.3" data-path="chap-linReg.html"><a href="chap-linReg.html#model"><i class="fa fa-check"></i><b>6.1.3</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="chap-linReg.html"><a href="chap-linReg.html#lineaire-regressie"><i class="fa fa-check"></i><b>6.2</b> Lineaire regressie</a></li>
<li class="chapter" data-level="6.3" data-path="chap-linReg.html"><a href="chap-linReg.html#parameterschatting"><i class="fa fa-check"></i><b>6.3</b> Parameterschatting</a></li>
<li class="chapter" data-level="6.4" data-path="chap-linReg.html"><a href="chap-linReg.html#sec:linBesluit"><i class="fa fa-check"></i><b>6.4</b> Statistische besluitvorming</a></li>
<li class="chapter" data-level="6.5" data-path="chap-linReg.html"><a href="chap-linReg.html#nagaan-van-modelveronderstellingen"><i class="fa fa-check"></i><b>6.5</b> Nagaan van modelveronderstellingen</a><ul>
<li class="chapter" data-level="6.5.1" data-path="chap-linReg.html"><a href="chap-linReg.html#lineariteit"><i class="fa fa-check"></i><b>6.5.1</b> Lineariteit</a></li>
<li class="chapter" data-level="6.5.2" data-path="chap-linReg.html"><a href="chap-linReg.html#veronderstelling-van-homoscedasticiteit-gelijkheid-van-variantie"><i class="fa fa-check"></i><b>6.5.2</b> Veronderstelling van homoscedasticiteit (gelijkheid van variantie)</a></li>
<li class="chapter" data-level="6.5.3" data-path="chap-linReg.html"><a href="chap-linReg.html#veronderstelling-van-normaliteit"><i class="fa fa-check"></i><b>6.5.3</b> Veronderstelling van normaliteit</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="chap-linReg.html"><a href="chap-linReg.html#afwijkingen-van-modelveronderstellingen"><i class="fa fa-check"></i><b>6.6</b> Afwijkingen van Modelveronderstellingen</a></li>
<li class="chapter" data-level="6.7" data-path="chap-linReg.html"><a href="chap-linReg.html#besluitvorming-over-gemiddelde-uitkomst"><i class="fa fa-check"></i><b>6.7</b> Besluitvorming over gemiddelde uitkomst</a></li>
<li class="chapter" data-level="6.8" data-path="chap-linReg.html"><a href="chap-linReg.html#predictie-intervallen"><i class="fa fa-check"></i><b>6.8</b> Predictie-intervallen</a></li>
<li class="chapter" data-level="6.9" data-path="chap-linReg.html"><a href="chap-linReg.html#sec:linAnova"><i class="fa fa-check"></i><b>6.9</b> Kwadratensommen en Anova-tabel</a><ul>
<li class="chapter" data-level="6.9.1" data-path="chap-linReg.html"><a href="chap-linReg.html#determinatie-coefficient"><i class="fa fa-check"></i><b>6.9.1</b> Determinatie-coëfficiënt</a></li>
<li class="chapter" data-level="6.9.2" data-path="chap-linReg.html"><a href="chap-linReg.html#f-testen-in-het-enkelvoudig-lineair-regressiemodel"><i class="fa fa-check"></i><b>6.9.2</b> F-Testen in het enkelvoudig lineair regressiemodel</a></li>
<li class="chapter" data-level="6.9.3" data-path="chap-linReg.html"><a href="chap-linReg.html#anova-tabel"><i class="fa fa-check"></i><b>6.9.3</b> Anova Tabel</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="chap-linReg.html"><a href="chap-linReg.html#sec:linDummy"><i class="fa fa-check"></i><b>6.10</b> Dummy variabelen</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-anova.html"><a href="chap-anova.html"><i class="fa fa-check"></i><b>7</b> Variantie analyse</a><ul>
<li class="chapter" data-level="7.1" data-path="chap-anova.html"><a href="chap-anova.html#inleiding-5"><i class="fa fa-check"></i><b>7.1</b> Inleiding</a><ul>
<li class="chapter" data-level="7.1.1" data-path="chap-anova.html"><a href="chap-anova.html#prostacycline-voorbeeld"><i class="fa fa-check"></i><b>7.1.1</b> Prostacycline voorbeeld</a></li>
<li class="chapter" data-level="7.1.2" data-path="chap-anova.html"><a href="chap-anova.html#model-1"><i class="fa fa-check"></i><b>7.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chap-anova.html"><a href="chap-anova.html#variantie-analyse"><i class="fa fa-check"></i><b>7.2</b> Variantie-analyse</a><ul>
<li class="chapter" data-level="7.2.1" data-path="chap-anova.html"><a href="chap-anova.html#model-2"><i class="fa fa-check"></i><b>7.2.1</b> Model</a></li>
<li class="chapter" data-level="7.2.2" data-path="chap-anova.html"><a href="chap-anova.html#kwadratensommen-en-anova"><i class="fa fa-check"></i><b>7.2.2</b> Kwadratensommen en Anova</a></li>
<li class="chapter" data-level="7.2.3" data-path="chap-anova.html"><a href="chap-anova.html#anova-test"><i class="fa fa-check"></i><b>7.2.3</b> Anova-test</a></li>
<li class="chapter" data-level="7.2.4" data-path="chap-anova.html"><a href="chap-anova.html#anova-tabel-1"><i class="fa fa-check"></i><b>7.2.4</b> Anova Tabel</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="chap-anova.html"><a href="chap-anova.html#post-hoc-analyse-meervoudig-vergelijken-van-gemiddelden"><i class="fa fa-check"></i><b>7.3</b> Post hoc analyse: Meervoudig Vergelijken van Gemiddelden</a><ul>
<li class="chapter" data-level="7.3.1" data-path="chap-anova.html"><a href="chap-anova.html#naieve-methode"><i class="fa fa-check"></i><b>7.3.1</b> Naïeve methode</a></li>
<li class="chapter" data-level="7.3.2" data-path="chap-anova.html"><a href="chap-anova.html#family-wise-error-rate"><i class="fa fa-check"></i><b>7.3.2</b> Family-wise error rate</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="chap-anova.html"><a href="chap-anova.html#conclusies-prostacycline-voorbeeld"><i class="fa fa-check"></i><b>7.4</b> Conclusies: Prostacycline Voorbeeld</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html"><i class="fa fa-check"></i><b>8</b> Niet-parametrische statistiek</a><ul>
<li class="chapter" data-level="8.1" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#inleiding-6"><i class="fa fa-check"></i><b>8.1</b> Inleiding</a></li>
<li class="chapter" data-level="8.2" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#vergelijken-van-twee-groepen"><i class="fa fa-check"></i><b>8.2</b> Vergelijken van twee groepen</a><ul>
<li class="chapter" data-level="8.2.1" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#cholestorol-voorbeeld"><i class="fa fa-check"></i><b>8.2.1</b> Cholestorol voorbeeld</a></li>
<li class="chapter" data-level="8.2.2" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#permutatietesten"><i class="fa fa-check"></i><b>8.2.2</b> Permutatietesten</a></li>
<li class="chapter" data-level="8.2.3" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#rank-testen"><i class="fa fa-check"></i><b>8.2.3</b> Rank Testen</a></li>
<li class="chapter" data-level="8.2.4" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#wilcoxon-mann-whitney-test"><i class="fa fa-check"></i><b>8.2.4</b> Wilcoxon-Mann-Whitney Test</a></li>
<li class="chapter" data-level="8.2.5" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#conclusie-cholestorol-voorbeeld"><i class="fa fa-check"></i><b>8.2.5</b> Conclusie Cholestorol Voorbeeld</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#vergelijken-van-g-behandelingen"><i class="fa fa-check"></i><b>8.3</b> Vergelijken van <span class="math inline">\(g\)</span> Behandelingen</a><ul>
<li class="chapter" data-level="8.3.1" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#dmh-voorbeeld"><i class="fa fa-check"></i><b>8.3.1</b> DMH Voorbeeld</a></li>
<li class="chapter" data-level="8.3.2" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#permutatietest"><i class="fa fa-check"></i><b>8.3.2</b> Permutatietest</a></li>
<li class="chapter" data-level="8.3.3" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#kruskal-wallis-rank-test"><i class="fa fa-check"></i><b>8.3.3</b> Kruskal-Wallis Rank Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chap-categorisch.html"><a href="chap-categorisch.html"><i class="fa fa-check"></i><b>9</b> Categorische data analyse</a><ul>
<li class="chapter" data-level="9.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#inleiding-7"><i class="fa fa-check"></i><b>9.1</b> Inleiding</a></li>
<li class="chapter" data-level="9.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#toetsen-voor-een-proportie"><i class="fa fa-check"></i><b>9.2</b> Toetsen voor een proportie</a><ul>
<li class="chapter" data-level="9.2.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#subsec:binom"><i class="fa fa-check"></i><b>9.2.1</b> Binomiale test</a></li>
<li class="chapter" data-level="9.2.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#betrouwbaarheidsinterval-op-een-proportie"><i class="fa fa-check"></i><b>9.2.2</b> Betrouwbaarheidsinterval op een proportie</a></li>
<li class="chapter" data-level="9.2.3" data-path="chap-categorisch.html"><a href="chap-categorisch.html#conclusie"><i class="fa fa-check"></i><b>9.2.3</b> Conclusie</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="chap-categorisch.html"><a href="chap-categorisch.html#toets-voor-associatie-tussen-2-kwalitatieve-variabelen"><i class="fa fa-check"></i><b>9.3</b> Toets voor associatie tussen 2 kwalitatieve variabelen</a><ul>
<li class="chapter" data-level="9.3.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#gepaarde-gegevens"><i class="fa fa-check"></i><b>9.3.1</b> Gepaarde gegevens</a></li>
<li class="chapter" data-level="9.3.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#subsec:catOnPaired"><i class="fa fa-check"></i><b>9.3.2</b> Ongepaarde gegevens</a></li>
<li class="chapter" data-level="9.3.3" data-path="chap-categorisch.html"><a href="chap-categorisch.html#de-pearson-chi-kwadraat-test-voor-ongepaarde-gegevens"><i class="fa fa-check"></i><b>9.3.3</b> De Pearson Chi-kwadraat test voor ongepaarde gegevens</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chap-categorisch.html"><a href="chap-categorisch.html#logistische-regressie"><i class="fa fa-check"></i><b>9.4</b> Logistische regressie</a><ul>
<li class="chapter" data-level="9.4.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#categorische-predictor"><i class="fa fa-check"></i><b>9.4.1</b> Categorische predictor</a></li>
<li class="chapter" data-level="9.4.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#continue-predictor"><i class="fa fa-check"></i><b>9.4.2</b> Continue predictor</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap-glm.html"><a href="chap-glm.html"><i class="fa fa-check"></i><b>10</b> Algemeen lineair model</a><ul>
<li class="chapter" data-level="10.1" data-path="chap-glm.html"><a href="chap-glm.html#inleiding-8"><i class="fa fa-check"></i><b>10.1</b> Inleiding</a><ul>
<li class="chapter" data-level="10.1.1" data-path="chap-glm.html"><a href="chap-glm.html#sec:prostate"><i class="fa fa-check"></i><b>10.1.1</b> Prostaatkanker dataset</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="chap-glm.html"><a href="chap-glm.html#het-additieve-meervoudig-lineaire-regressie-model"><i class="fa fa-check"></i><b>10.2</b> Het additieve meervoudig lineaire regressie model</a><ul>
<li class="chapter" data-level="10.2.1" data-path="chap-glm.html"><a href="chap-glm.html#statistisch-model"><i class="fa fa-check"></i><b>10.2.1</b> Statistisch model</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chap-glm.html"><a href="chap-glm.html#besluitvorming-in-regressiemodellen"><i class="fa fa-check"></i><b>10.3</b> Besluitvorming in regressiemodellen</a></li>
<li class="chapter" data-level="10.4" data-path="chap-glm.html"><a href="chap-glm.html#nagaan-van-modelveronderstellingen-1"><i class="fa fa-check"></i><b>10.4</b> Nagaan van modelveronderstellingen</a><ul>
<li class="chapter" data-level="10.4.1" data-path="chap-glm.html"><a href="chap-glm.html#lineariteit-1"><i class="fa fa-check"></i><b>10.4.1</b> Lineariteit</a></li>
<li class="chapter" data-level="10.4.2" data-path="chap-glm.html"><a href="chap-glm.html#homoscedasticiteit"><i class="fa fa-check"></i><b>10.4.2</b> Homoscedasticiteit</a></li>
<li class="chapter" data-level="10.4.3" data-path="chap-glm.html"><a href="chap-glm.html#normaliteit"><i class="fa fa-check"></i><b>10.4.3</b> Normaliteit</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="chap-glm.html"><a href="chap-glm.html#het-niet-additieve-meervoudig-lineair-regressiemodel"><i class="fa fa-check"></i><b>10.5</b> Het niet-additieve meervoudig lineair regressiemodel</a><ul>
<li class="chapter" data-level="10.5.1" data-path="chap-glm.html"><a href="chap-glm.html#sec:intCont"><i class="fa fa-check"></i><b>10.5.1</b> Interactie tussen twee continue variabelen</a></li>
<li class="chapter" data-level="10.5.2" data-path="chap-glm.html"><a href="chap-glm.html#interactie-tussen-continue-variabele-en-factor-variabele"><i class="fa fa-check"></i><b>10.5.2</b> Interactie tussen continue variabele en factor variabele</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="chap-glm.html"><a href="chap-glm.html#anova-tabel-2"><i class="fa fa-check"></i><b>10.6</b> ANOVA Tabel</a><ul>
<li class="chapter" data-level="10.6.1" data-path="chap-glm.html"><a href="chap-glm.html#sstot-ssr-en-sse"><i class="fa fa-check"></i><b>10.6.1</b> SSTot, SSR en SSE</a></li>
<li class="chapter" data-level="10.6.2" data-path="chap-glm.html"><a href="chap-glm.html#extra-kwadratensommen"><i class="fa fa-check"></i><b>10.6.2</b> Extra Kwadratensommen</a></li>
<li class="chapter" data-level="10.6.3" data-path="chap-glm.html"><a href="chap-glm.html#type-i-kwadratensommen"><i class="fa fa-check"></i><b>10.6.3</b> Type I Kwadratensommen</a></li>
<li class="chapter" data-level="10.6.4" data-path="chap-glm.html"><a href="chap-glm.html#type-iii-kwadratensommen"><i class="fa fa-check"></i><b>10.6.4</b> Type III Kwadratensommen</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="chap-glm.html"><a href="chap-glm.html#regressiediagnostieken"><i class="fa fa-check"></i><b>10.7</b> Regressiediagnostieken</a><ul>
<li class="chapter" data-level="10.7.1" data-path="chap-glm.html"><a href="chap-glm.html#multicollineariteit"><i class="fa fa-check"></i><b>10.7.1</b> Multicollineariteit</a></li>
<li class="chapter" data-level="10.7.2" data-path="chap-glm.html"><a href="chap-glm.html#invloedrijke-observaties"><i class="fa fa-check"></i><b>10.7.2</b> Invloedrijke observaties</a></li>
<li class="chapter" data-level="10.7.3" data-path="chap-glm.html"><a href="chap-glm.html#cooks-distance"><i class="fa fa-check"></i><b>10.7.3</b> Cook’s distance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-modsel.html"><a href="chap-modsel.html"><i class="fa fa-check"></i><b>11</b> Modelselectie</a><ul>
<li class="chapter" data-level="11.1" data-path="chap-modsel.html"><a href="chap-modsel.html#inleiding-9"><i class="fa fa-check"></i><b>11.1</b> Inleiding</a></li>
<li class="chapter" data-level="11.2" data-path="chap-modsel.html"><a href="chap-modsel.html#modelselectie-op-basis-van-hypothesetesten"><i class="fa fa-check"></i><b>11.2</b> Modelselectie op basis van hypothesetesten</a><ul>
<li class="chapter" data-level="11.2.1" data-path="chap-modsel.html"><a href="chap-modsel.html#voorwaartse-modelselectie"><i class="fa fa-check"></i><b>11.2.1</b> Voorwaartse modelselectie</a></li>
<li class="chapter" data-level="11.2.2" data-path="chap-modsel.html"><a href="chap-modsel.html#achterwaartse-modelselectie"><i class="fa fa-check"></i><b>11.2.2</b> Achterwaartse modelselectie</a></li>
<li class="chapter" data-level="11.2.3" data-path="chap-modsel.html"><a href="chap-modsel.html#stapsgewijze-modelselectie"><i class="fa fa-check"></i><b>11.2.3</b> Stapsgewijze modelselectie</a></li>
<li class="chapter" data-level="11.2.4" data-path="chap-modsel.html"><a href="chap-modsel.html#opmerkingen"><i class="fa fa-check"></i><b>11.2.4</b> Opmerkingen</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chap-modsel.html"><a href="chap-modsel.html#modelselectie-voor-predictie"><i class="fa fa-check"></i><b>11.3</b> Modelselectie voor predictie</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chap-modsel.html"><a href="chap-modsel.html#inleiding-10"><i class="fa fa-check"></i><b>11.3.1</b> Inleiding</a></li>
<li class="chapter" data-level="11.3.2" data-path="chap-modsel.html"><a href="chap-modsel.html#selectie-criterium"><i class="fa fa-check"></i><b>11.3.2</b> Selectie-criterium</a></li>
<li class="chapter" data-level="11.3.3" data-path="chap-modsel.html"><a href="chap-modsel.html#alternatieve-criteria"><i class="fa fa-check"></i><b>11.3.3</b> Alternatieve criteria</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cursus Statistiek 2019-2020</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap:glm" class="section level1">
<h1><span class="header-section-number">Hoofdstuk 10</span> Algemeen lineair model</h1>
<div id="inleiding-8" class="section level2">
<h2><span class="header-section-number">10.1</span> Inleiding</h2>
<p>Tot nog toe hebben we ons geconcentreerd op het beschrijven van een associatie tussen een uitkomst <span class="math inline">\(Y\)</span> en één enkele predictor <span class="math inline">\(X\)</span>. Vaak is het echter nuttig om de gemiddelde uitkomst niet in termen van één, maar in termen van meerdere predictoren simultaan te beschrijven. De volgende voorbeelden illustreren waarom:</p>
<ol style="list-style-type: decimal">
<li><p>Vaak is de associatie tussen een verklarende variabele X en een uitkomst Y verstoord als gevolg van een confounder C. Bijvoorbeeld, bij het bepalen van het effect van de duur van blootstelling aan asbest (X) op de longfunctie (Y), is leeftijd (C) een confounder omdat het zowel de duur van blootstelling als de longfunctie beïnvloedt. Om hiervoor te corrigeren, is het noodzakelijk om de associatie tussen X en Y afzonderlijk te beschrijven voor mensen van dezelfde leeftijd (m.a.w. individuen met dezelfde waarde voor de confounder). Voor elke geobserveerde leeftijd (C=c) een aparte lineaire regressie uitvoeren onder mensen van die leeftijd (C=c), is weinig zinvol omdat er vaak weinig mensen met exact dezelfde leeftijd in de studie opgenomen zijn. Dit is in het bijzonder zo wanneer er meerdere confounders zijn. In deze sectie zullen we dit probleem oplossen door de confounder C als extra variabele in het lineaire model op te nemen.</p></li>
<li><p>In heel wat studies is men geïnteresseerd in welke van een groep variabelen een gegeven uitkomst het meest beïnvloedt. Bijvoorbeeld, het begrijpen van welke aspecten van habitat en menselijke activiteit een voorname impact hebben op de biodiversiteit in het regenwoud is een belangrijk streefdoel van de conservatie-biologie. Daartoe wil men niet alleen de grootte van het woud in rekening brengen, maar ook andere factoren, zoals de ouderdom en hoogteligging van het woud, de nabijheid van andere wouden, … Een studie van het simultane effect van die verschillende variabelen laat toe om beter inzicht te krijgen in de variatie in biodiversiteit tussen verschillende wouden. Door in het bijzonder wouden met hoge of lage biodiversiteit nader te bekijken, kan men nieuwe predictieve factoren voor biodiversiteit ontdekken.</p></li>
<li><p>Wanneer men een uitkomst wil voorspellen voor individuen, is het belangrijk om veel predictieve informatie voor hen beschikbaar te hebben en die informatie simultaan in een regressiemodel te kunnen gebruiken. Bijvoorbeeld, na behandeling van patiënten met gevorderde borstkanker is de prognose zeer onzeker. Op basis van gemeten predictoren voor en na de operatie kan men echter regressiemodellen opbouwen die toelaten om in de toekomst voor elke patiënt, op basis van zijn/haar karakteristieken, de prognose te voorspellen. Verwante predicties (maar dan voor het risico op sterfte) worden dagdagelijks gebruikt in eenheden intensieve zorgen om de ernst van de gezondheidstoestand van een patiënt uit te drukken. Het spreekt voor zich dat betere predicties kunnen gemaakt worden wanneer een groot aantal predictoren simultaan worden in rekening gebracht.</p></li>
</ol>
<p>In dit hoofdstuk breiden we daarom enkelvoudige lineaire regressie (Hoofdstuk <a href="chap-linReg.html#chap:linReg">6</a>) uit door meerdere predictoren toe te laten. We zullen dus de gemiddelde uitkomsten modelleren als een functie van meerdere predictoren. We illustreren meervoudige lineaire regressie aan de hand van de prostaatkanker dataset.</p>
<div id="sec:prostate" class="section level3">
<h3><span class="header-section-number">10.1.1</span> Prostaatkanker dataset</h3>
<p>Stamey et al., 1989, bestudeerden het niveau van het prostaat specific antigen (PSA) en een aantal klinische metingen bij 97 mannen waarvan de prostaat werd verwijderd. Het doel van de studie is om de associatie van de PSA te bestuderen in functie van het tumorvolume (lcavol), het gewicht van de prostaat (lweight), leeftijd (age), de goedaardige prostaathypertrofie hoeveelheid (lbph), een indicator voor de aantasting van de zaadblaasjes (svi), capsulaire penetratie (lcp), Gleason score (gleason) die de graad van kwaadaardigheid van de kanker weergeeft (hoe hoger de score hoe minder de kankercellen op normaal prostaatweefsel lijken), en, het precentage gleason score 4/5 (pgg45), die de proportie aangeeft van de tumor die ingenomen wordt door kankerweefsel van een hoge graad. De onderzoekers die de dataset verspreidden hebben het tumorvolume, het gewicht, de goedaardige prostraat hypertrofie hoeveelheid en de capsulaire penetratie reeds log-getransformeerd.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prostate&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;dataset/prostate.csv&quot;</span>)
<span class="kw">head</span>(prostate)</code></pre></div>
<pre><code>##       lcavol  lweight age      lbph     svi       lcp gleason   pgg45
## 1 -0.5798185 2.769459  50 -1.386294 healthy -1.386294       6 healthy
## 2 -0.9942523 3.319626  58 -1.386294 healthy -1.386294       6 healthy
## 3 -0.5108256 2.691243  74 -1.386294 healthy -1.386294       7      20
## 4 -1.2039728 3.282789  58 -1.386294 healthy -1.386294       6 healthy
## 5  0.7514161 3.432373  62 -1.386294 healthy -1.386294       6 healthy
## 6 -1.0498221 3.228826  50 -1.386294 healthy -1.386294       6 healthy
##         lpsa
## 1 -0.4307829
## 2 -0.1625189
## 3 -0.1625189
## 4 -0.1625189
## 5  0.3715636
## 6  0.7654678</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(prostate)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:lpsaAll"></span>
<img src="Statistiek_2019_2020_files/figure-html/lpsaAll-1.png" alt="Scatterplot matrix voor de observaties in de prostaat kanker dataset." width="100%" />
<p class="caption">
Figuur 10.1: Scatterplot matrix voor de observaties in de prostaat kanker dataset.
</p>
</div>
<p>Figuur <a href="chap-glm.html#fig:lpsaAll">10.1</a> toont de scatter matrix van de data en suggereert dat de lpsa sterk positief gecorreleerd is met het volume en svi. We zien verder dat lcp en lbph links-gecensureerd lijken te zijn. Er lijkt een ondergrens/detectielimiet te zijn voor deze metingen. Verder blijkt het merendeel van de gleason scores gelijk te zijn aan 6 of 7. We zullen de analyse in dit hoofdstuk beperken tot de associatie van lpsa met het log tumorvolume (lcavol), het log gewicht (lweight) en de aantasting van de zaadblaasjes (svi).</p>
</div>
</div>
<div id="het-additieve-meervoudig-lineaire-regressie-model" class="section level2">
<h2><span class="header-section-number">10.2</span> Het additieve meervoudig lineaire regressie model</h2>
<p>Afzonderlijke lineaire regressiemodellen, zoals</p>
<p><span class="math display">\[E(Y|X_v)=\alpha+\beta_v X_v\]</span></p>
<p>laten enkel toe om de associatie tussen de prostaat specifieke antigeen concentratie te evalueren op basis van 1 variabele, bijvoorbeeld het log-tumorvolume. Het spreekt voor zich dat meer accurate predicties kunnen bekomen worden door meerdere predictoren simultaan in rekening te brengen. Bovendien geeft de parameter <span class="math inline">\(\beta_v\)</span> in dit model mogelijks geen zuiver effect van het tumorvolume weer. Inderdaad, <span class="math inline">\(\beta_v\)</span> is het gemiddeld verschil in log-psa voor patiënten die 1 eenheid in het log tumorvolume (lcavol) verschillen. Zelfs als lcavol niet is geassocieerd met het lpsa, dan nog kunnen patiënten met een groter tumorvolume een hoger lpsa hebben omdat ze bijvoorbeeld een aantasting van de zaadblaasjes hebben (svi status 1). Dit is een probleem van confounding (nl. het effect van lcavol wordt verward met het effect van svi) dat kan verholpen worden door patiënten te vergelijken met verschillend log-tumorvolume, maar met dezelfde status voor svi. We zullen in dit hoofdstuk aantonen dat meervoudige lineaire regressiemodellen dit op een natuurlijke wijze mogelijk maken.</p>
<div id="statistisch-model" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Statistisch model</h3>
<p>De techniek die we hiertoe gaan gebruiken heet <em>meervoudige lineaire regressie</em>, in tegenstelling tot <em>enkelvoudige lineaire regressie</em> die we eerder gebruikt hebben. Stel dat we <span class="math inline">\(p-1\)</span> verklarende variabelen <span class="math inline">\(X_1,...,X_{p-1}\)</span> en een uitkomst <span class="math inline">\(Y\)</span> beschikbaar hebben voor <span class="math inline">\(n\)</span> subjecten. Stel bovendien dat de gemiddelde uitkomst lineair kan beschreven worden in functie van deze verklarende variabelen; d.w.z.</p>
<span class="math display">\[\begin{equation}  
Y_i =\beta_0 + \beta_1 X_{i1} + ... +\beta_{p-1} X_{ip-1} + \epsilon_i
\end{equation}\]</span>
<p>waarbij <span class="math inline">\(\beta_0,\beta_1,...,\beta_{p-1}\)</span> onbekende parameters zijn en <span class="math inline">\(\epsilon_i\)</span> de residuen die niet kunnen worden verklaard a.d.h.v. de predictoren. Het principe van de <em>kleinste kwadratenmethode</em> kan ook voor dit model worden gebruikt om schatters te bekomen voor de onbekende parameters <span class="math inline">\(\beta_0, \ldots, \beta_{p-1}\)</span>. De formules voor deze schattingen zijn nu een stuk complexer dan voorheen, maar worden door de software automatisch uitgerekend. Voor gegeven schattingen <span class="math inline">\(\hat{\beta}_0,\hat{\beta}_1,...,\hat{\beta}_{p-1}\)</span> laat het lineaire regressiemodel dan toe om:</p>
<ol style="list-style-type: decimal">
<li>de verwachte uitkomst te voorspellen voor subjecten met gegeven waarden <span class="math inline">\(x_1,...,x_{p-1}\)</span> voor de verklarende variabelen. Dit kan geschat worden als <span class="math inline">\(E[Y\vert X_1=x_1, \ldots X_{p-1}=x_{p-1}]=\hat{\beta}_0+\hat{\beta}_1x_1+...+\hat{\beta}_{p-1}x_{p-1}\)</span>.</li>
<li>na te gaan in welke mate de gemiddelde uitkomst verschilt tussen 2 groepen subjecten met <span class="math inline">\(\delta\)</span> eenheden verschil in een verklarende variabele <span class="math inline">\(X_j\)</span> met <span class="math inline">\(j=1,\ldots,p\)</span>, maar met dezelfde waarden voor alle andere variabelen <span class="math inline">\(\{X_k,k=1,...,p,k\ne j\}\)</span>. Namelijk: <span class="math display">\[
\begin{array}{l}
E(Y|X_1=x_1,...,X_j=x_j+\delta,...,X_{p-1}=x_{p-1}) - E(Y|X_1=x_1,...,X_j=x_j,...,X_{p-1}=x_{p-1}) \\
\quad =\beta_0 + \beta_1 x_1 + ... + \beta_j(x_j+\delta)+...+\beta_{p-1} x_{p-1} - \beta_0 - \beta_1 x_1 - ... - \beta_jx_j-...-\beta_{p-1} x_{p-1} \\
\quad= \beta_j\delta
\end{array}
\]</span></li>
</ol>
<p>In het bijzonder kan <span class="math inline">\(\beta_j\)</span> geïnterpreteerd worden als het verschil in gemiddelde uitkomst tussen subjecten die 1 eenheid verschillen in de waarde van <span class="math inline">\(X_j\)</span>, maar dezelfde waarde hebben van de overige verklarende variabelen in het model. Dit kan geschat worden als <span class="math inline">\(\hat{\beta}_j\)</span>.</p>
<p>Voor het prostaatkanker voorbeeld levert een analyse van het enkelvoudige lineaire regressiemodel <span class="math inline">\(E(Y|X_v)=\beta_0+\beta_v X_v\)</span> in R de volgende output.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmV &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa<span class="op">~</span>lcavol,prostate)
<span class="kw">summary</span>(lmV)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.67624 -0.41648  0.09859  0.50709  1.89672 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.50730    0.12194   12.36   &lt;2e-16 ***
## lcavol       0.71932    0.06819   10.55   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7875 on 95 degrees of freedom
## Multiple R-squared:  0.5394, Adjusted R-squared:  0.5346 
## F-statistic: 111.3 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We besluiten op basis van deze gegevens dat patiënten met een tumorvolume dat 1% hoger ligt, gemiddeld gezien een prostaat antigeen concentratie zullen hebben die ongeveer 0.72% hoger zal liggen. Merk op dat we voor deze interpretatie beroep hebben gedaan op het feit dat beide variabelen log getransformeerd zijn.</p>
<p>Een analyse van het meervoudige lineaire regressiemodel met de predictoren lcavol (index v), lweight (index w) en svi (index s) <span class="math display">\[E(Y|X_f,X_s,X_p,X_r)=\beta_0 +\beta_v X_v+\beta_w X_w+\beta_s X_s,\]</span></p>
<p>wijzigt dit resultaat vrij behoorlijk, zoals onderstaande output aangeeft.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmVWS &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa<span class="op">~</span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi ,prostate)
<span class="kw">summary</span>(lmVWS)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + svi, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.72966 -0.45767  0.02814  0.46404  1.57012 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.26807    0.54350  -0.493  0.62301    
## lcavol       0.55164    0.07467   7.388  6.3e-11 ***
## lweight      0.50854    0.15017   3.386  0.00104 ** 
## sviinvasion  0.66616    0.20978   3.176  0.00203 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7168 on 93 degrees of freedom
## Multiple R-squared:  0.6264, Adjusted R-squared:  0.6144 
## F-statistic: 51.99 on 3 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>De parameter bij lcavol geeft nu aan dat patiënten met een tumorvolume dat 1% hoger ligt, maar eenzelfde prostaat gewicht en svi status hebben, een prostaat antigeen concentratie zullen hebben dat gemiddeld slechts 0.55% hoger ligt. De reden dat we eerder een verschil van meer dan 0.7% vonden, kan worden verklaard doordat patiënten met een verschil in tumorvolume vaak ook verschillen in prostaat gewicht en svi status.</p>
<p>De parameter voor svi kunnen we als volgt interpreteren: de prostaat antigeen concentratie ligt gemiddeld een factor exp(0.666)=1.95 hoger voor patiënten met invasie van de zaadblaasjes dan voor patiënten zonder invasie van de zaadblaasjes na correctie voor het prostaat gewicht en het tumorvolume. De introductie van de factor svi in het additieve model zorgt ervoor dat we twee regressievlakken bekomen die evenwijdig zijn maar een verschillend intercept hebben (zie Figuur <a href="chap-glm.html#fig:prosAdditiveFit">10.2</a>).</p>
<p>De <span class="math inline">\(R^2\)</span>-waarde in bovenstaande analyse bedraagt 62.6% en geeft aan 62.6% in de variabiliteit van het log-PSA verklaard kan worden d.m.v. het tumorvolume, het prostaat gewicht en de status van de zaadblaasjes.</p>
<div class="figure" style="text-align: center"><span id="fig:prosAdditiveFit"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosAdditiveFit-1.png" alt="Fit van het additieve model met termen lcavol, lweight en svi. De figuur geeft duidelijk weer dat de gemiddelde lpsa toeneemt i.f.v. het log-tumorvolume, het log-prostaatgewicht en de invasie van de zaadblaasjes. Merk op dat de fit resulteert in twee parallele vlakken, een regressievlak voor patiënten zonder (blauw) en met invasie van de zaadblaasjes (oranje)." width="100%" />
<p class="caption">
Figuur 10.2: Fit van het additieve model met termen lcavol, lweight en svi. De figuur geeft duidelijk weer dat de gemiddelde lpsa toeneemt i.f.v. het log-tumorvolume, het log-prostaatgewicht en de invasie van de zaadblaasjes. Merk op dat de fit resulteert in twee parallele vlakken, een regressievlak voor patiënten zonder (blauw) en met invasie van de zaadblaasjes (oranje).
</p>
</div>
</div>
</div>
<div id="besluitvorming-in-regressiemodellen" class="section level2">
<h2><span class="header-section-number">10.3</span> Besluitvorming in regressiemodellen</h2>
<p>Als de gegevens representatief zijn voor de populatie kan men in de meervoudige lineaire regressiecontext eveneens aantonen dat de kleinste kwadraten schatters voor het intercept en de hellingen onvertekend zijn, m.a.w <span class="math display">\[E[\hat \beta_j]=\beta_j,\quad j=0,\ldots,p-1.\]</span></p>
<p>Het feit dat de schatters gemiddeld (over een groot aantal vergelijkbare studies) niet afwijken van de waarden in de populatie, impliceert niet dat ze niet rond die waarde variëren. Om inzicht te krijgen hoe dicht we de parameterschatters bij het werkelijke intercept <span class="math inline">\(\beta_0\)</span> en de werkelijke hellingen <span class="math inline">\(\beta_j\)</span> mogen verwachten, wensen we bijgevolg ook haar variabiliteit te kennen.</p>
<p>Net zoals in Hoofdstuk <a href="chap-linReg.html#chap:linReg">6</a> is het op basis van de puntschatters voor de hellingen niet duidelijk of de verbanden werkelijk voorkomen in de populatie of indien we de verbanden door toeval hebben geobserveerd in de dataset. De schatting van de hellingen is immers onnauwkeurig en zal variëren van steekproef tot steekproef. Zoals steeds is het resultaat van een data-analyse dus niet interpreteerbaar zonder die variabiliteit in kaart te brengen.</p>
<p>Om de resultaten uit de steekproef te kunnen veralgemenen naar de populatie zullen we in deze context eveneens inzicht nodig hebben op de verdeling van de parameterschatters. Om op basis van slechts één steekproef te kunnen voorspellen hoe de parameterschatters variëren van steekproef tot steekproef zullen we naast de onderstelling van</p>
<ol style="list-style-type: decimal">
<li><em>Lineariteit</em></li>
</ol>
<p>bijkomende aannames moeten maken over de verdeling van de gegevens, met name</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Onafhankelijkheid</em>: de metingen <span class="math inline">\((X_{11},\dots, X_{1p-1}, Y_1), ..., (X_{n1},\ldots,X_{np-1},Y_n)\)</span> werden gemaakt bij n onafhankelijke subjecten/observationele eenheden</li>
<li><em>Homoscedasticiteit</em> of <em>gelijkheid van variantie</em>: de observaties variëren met een gelijke variantie rond het regressievlak. De residuen <span class="math inline">\(\epsilon_i\)</span> hebben dus een gelijke variantie <span class="math inline">\(\sigma^2\)</span> voor elk covariaat patroon <span class="math inline">\((X_1=x_1, ..., X_{p-1}=x_{p-1})\)</span>. Dat impliceert ook dat de conditionele variantie van <span class="math inline">\(Y\)</span> gegeven <span class="math inline">\(X_1,\ldots,X_{p-1}\)</span>, <span class="math inline">\(\text{var}(Y\vert X_1,\ldots,X_{p-1})\)</span> dus gelijk is, met name <span class="math inline">\(\text{var}(Y\vert X_1,\ldots,X_{p-1}) = \sigma^2\)</span> voor elk covariaat patroon <span class="math inline">\((X_1=x_1, ..., X_{p-1}=x_{p-1})\)</span>. De constante <span class="math inline">\(\sigma\)</span> wordt opnieuw de <em>residuele standaarddeviatie</em> genoemd.</li>
<li><em>Normaliteit</em>: de residuen <span class="math inline">\(\epsilon_i\)</span> zijn normaal verdeeld.</li>
</ol>
<p>Uit aannames 2, 3 en 4 volgt dus dat de residuen <span class="math inline">\(\epsilon_i\)</span> onafhankelijk zijn en dat ze allen eenzelfde Normale verdeling volgen <span class="math display">\[\epsilon_i \sim N(0,\sigma^2).\]</span> Als we ook steunen op de veronderstelling van lineariteit weten we dat de originele observaties conditioneel op <span class="math inline">\(X_1,\ldots,X_{p-1}\)</span> eveneens Normaal verdeeld zijn <span class="math display">\[Y_i\sim N(\beta_0+\beta_1 X_{i1}+\ldots+\beta_{p-1} X_{ip-1},\sigma^2),\]</span> met een gemiddelde dat varieert in functie van de waarde van de onafhankelijke variabelen <span class="math inline">\(X_{i1},\ldots,X_{ip-1}\)</span>.</p>
<p>Merk op dat de onzekerheid op de hellingen af zal nemen wanneer er meer observaties zijn en/of wanneer de observaties meer gespreid zijn. Voor het opzetten van een experiment kan dit belangrijke informatie zijn. Uiteraard wordt de precisie ook beïnvloed door de grootte van de variabiliteit van de observaties rond het regressievlak, <span class="math inline">\(\sigma^2\)</span>, maar dat heeft een onderzoeker typisch niet in de hand.</p>
<p>De conditionele variantie (<span class="math inline">\(\sigma^2\)</span>) is echter niet gekend en is noodzakelijk voor de berekening van de variantie op de parameterschatters. We kunnen <span class="math inline">\(\sigma^2\)</span> echter opnieuw schatten op basis van de <em>mean squared error</em> (MSE):</p>
<p><span class="math display">\[\hat\sigma^2=MSE=\frac{\sum\limits_{i=1}^n \left(y_i-\hat\beta_0-\hat\beta_1 X_{i1}-\ldots-\hat\beta_{p-1} X_{ip-1}\right)^2}{n-p}=\frac{\sum\limits_{i=1}^n e^2_i}{n-p}.\]</span></p>
<p>Analoog als in Hoofdstuk <a href="chap-linReg.html#chap:linReg">6</a> kunnen we opnieuw toetsen en betrouwbaarheidsintervallen construeren op basis van de teststatistieken<br />
<span class="math display">\[T_k=\frac{\hat{\beta}_k-\beta_k}{SE(\hat{\beta}_k)} \text{ met } k=0, \ldots, p-1.\]</span> Als aan alle aannames is voldaan dan volgen deze statistieken <span class="math inline">\(T_k\)</span> een t-verdeling met <span class="math inline">\(n-p\)</span> vrijheidsgraden. Wanneer niet is voldaan aan de veronderstelling van normaliteit maar wel aan lineariteit, onafhankelijkheid en homoscedasticiteit dan kunnen we voor inferentie opnieuw beroep doen op de centrale limietstelling die zegt dat de statistiek <span class="math inline">\(T_k\)</span> bij benadering een standaard Normale verdeling zal volgen wanneer het aantal observaties voldoende groot is.</p>
<p>Voor het prostaatkanker voorbeeld kunnen we de effecten in de steekproef opnieuw veralgemenen naar de populatie toe door betrouwbaarheidsintervallen te bouwen voor de hellingen: <span class="math display">\[[\hat\beta_j - t_{n-p,\alpha/2} \text{SE}_{\hat\beta_j},\hat\beta_j + t_{n-p,\alpha/2} \text{SE}_{\hat\beta_j}]\]</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(lmVWS)</code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -1.3473509 0.8112061
## lcavol       0.4033628 0.6999144
## lweight      0.2103288 0.8067430
## sviinvasion  0.2495824 1.0827342</code></pre>
<p>Gezien nul niet in de intervallen ligt weten we eveneens dat de associaties tussen lpsa <span class="math inline">\(\leftrightarrow\)</span> lcavol, lpsa <span class="math inline">\(\leftrightarrow\)</span> lweight, lpsa <span class="math inline">\(\leftrightarrow\)</span> svi, statistisch significant zijn op het 5% significantieniveau.</p>
<p>Anderzijds kunnen we ook formele hypothesetoetsen uitvoeren. Onder de nulhypothese veronderstellen we dat er geen associatie is tussen lpsa en de predictor <span class="math inline">\(X_j\)</span>: <span class="math display">\[H_0: \beta_j=0\]</span> en onder de alternatieve hypothese is er een associatie tussen response en predictor <span class="math inline">\(X_j\)</span>: <span class="math display">\[H_1: \beta_j\neq0\]</span></p>
<p>Met de test statistiek <span class="math display">\[T=\frac{\hat{\beta}_j-0}{SE(\hat{\beta}_j)}\]</span> kunnen we de nulhypothese falsifiëren. Onder <span class="math inline">\(H_0\)</span> volgt de statistiek een t-verdeling met <span class="math inline">\(n-p\)</span> vrijheidsgraden, waarbij p het aantal model parameters is van het regressiemodel inclusief het intercept.</p>
<p>Deze tweezijdige testen zijn standaard geïmplementeerd in de standaard output van R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lmVWS)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + svi, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.72966 -0.45767  0.02814  0.46404  1.57012 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.26807    0.54350  -0.493  0.62301    
## lcavol       0.55164    0.07467   7.388  6.3e-11 ***
## lweight      0.50854    0.15017   3.386  0.00104 ** 
## sviinvasion  0.66616    0.20978   3.176  0.00203 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7168 on 93 degrees of freedom
## Multiple R-squared:  0.6264, Adjusted R-squared:  0.6144 
## F-statistic: 51.99 on 3 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>De testen geven weer dat de associaties tussen lpsa<span class="math inline">\(\leftrightarrow\)</span>lcavol, lpsa<span class="math inline">\(\leftrightarrow\)</span>lweight en lpsa<span class="math inline">\(\leftrightarrow\)</span>svi, respectievelijk extreem significant (<span class="math inline">\(p &lt;&lt; 0.001\)</span>) en sterk significant (<span class="math inline">\(p=0.001\)</span> en <span class="math inline">\(p=0.002\)</span>) zijn.</p>
</div>
<div id="nagaan-van-modelveronderstellingen-1" class="section level2">
<h2><span class="header-section-number">10.4</span> Nagaan van modelveronderstellingen</h2>
<p>Voor de statistische besluitvorming hebben we volgende aannames gedaan</p>
<ol style="list-style-type: decimal">
<li>Lineariteit</li>
<li>Onafhankelijkheid<br />
</li>
<li>Homoscedasticiteit</li>
<li>Normaliteit</li>
</ol>
<p>Onafhankelijkheid is moeilijk te verifiëren op basis van de data, dat zou gegarandeerd moeten zijn door het design van de studie. Als we afwijkingen zien van lineariteit dan heeft besluitvorming geen zin gezien het de primaire veronderstelling is. In dat geval moeten we het conditioneel gemiddelde eerst beter modelleren. In geval van lineariteit maar schendingen van homoscedasticiteit of normaliteit dan weten we dat de besluitvorming mogelijks incorrect is omdat de teststatistieken dan niet langer een t-verdeling volgen.</p>
<div id="lineariteit-1" class="section level3">
<h3><span class="header-section-number">10.4.1</span> Lineariteit</h3>
<p>De primaire veronderstelling in meervoudige lineaire regressie-analyse is de aanname dat de uitkomst (afhankelijke variabele) lineair varieert in functie van de verklarende variabelen.</p>
<p>Afwijkingen van lineariteit kunnen opnieuw worden opgespoord d.m.v. een <em>residuplot</em>. Deze wordt weergegeven in Figuur <a href="chap-glm.html#fig:prosLinDiag1">10.3</a> links boven. Als de veronderstelling van lineariteit opgaat, krijgt men in een residuplot geen patroon te zien. De residuen zijn immers gemiddeld nul voor elke waarde van de predictoren en zouden dus mooi rond nul moeten variëren. Dat is inderdaad het geval voor het meervoudig lineaire regressiemodel dat we hebben gefit o.b.v. de prostaat dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lmVWS)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:prosLinDiag1"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosLinDiag1-1.png" alt="Diagnostische plots voor het nagaan van de veronderstellingen van het lineair regressiemodel waarbij lpsa gemodelleerd wordt a.d.h.v. de predictoren lcavol, lweight en svi." width="100%" />
<p class="caption">
Figuur 10.3: Diagnostische plots voor het nagaan van de veronderstellingen van het lineair regressiemodel waarbij lpsa gemodelleerd wordt a.d.h.v. de predictoren lcavol, lweight en svi.
</p>
</div>
</div>
<div id="homoscedasticiteit" class="section level3">
<h3><span class="header-section-number">10.4.2</span> Homoscedasticiteit</h3>
<p>De residu-plot kan opnieuw worden gebruikt om de veronderstelling na te gaan van homoscedasticiteit of gelijkheid van variantie. De residu-plot voor het prostaatkanker voorbeeld Figuur <a href="chap-glm.html#fig:prosLinDiag1">10.3</a> links boven geeft geen afwijkingen weer van homoscedasiticiteit. Alle residuen zijn mooi gespreid binnen dezelfde grenzen voor elke gefitte waarde <span class="math inline">\(\hat y_i\)</span>. De plot van de vierkantswortel van de absolute waarde van de gestandardiseerde error <span class="math inline">\(\sqrt{|e_i|/\sqrt{MSE}}\)</span> in functie van de predicties (Figuur <a href="chap-glm.html#fig:prosLinDiag1">10.3</a> links onder) geeft ook geen afwijkingen van homoscedasticiteit weer.</p>
</div>
<div id="normaliteit" class="section level3">
<h3><span class="header-section-number">10.4.3</span> Normaliteit</h3>
<p>Opnieuw kunnen we de veronderstelling van normaliteit nagaan door gebruik te maken van QQ-plots. Figuur <a href="chap-glm.html#fig:prosLinDiag1">10.3</a> rechts boven geeft de QQ-plot weer van de residuen voor het prostaatkanker voorbeeld. We zien in de plot geen aanwijzing voor afwijkingen van normaliteit.</p>
</div>
</div>
<div id="het-niet-additieve-meervoudig-lineair-regressiemodel" class="section level2">
<h2><span class="header-section-number">10.5</span> Het niet-additieve meervoudig lineair regressiemodel</h2>
<div id="sec:intCont" class="section level3">
<h3><span class="header-section-number">10.5.1</span> Interactie tussen twee continue variabelen</h3>
<p>We breiden het meervoudig lineaire regressie model nu uit door toevoeging van interactie-termen.</p>
<p>Het model in de vorige secties werd een additief model genoemd omdat de bijdrage van het kanker volume in lpsa niet afhangt van de hoogte van het prostaat gewicht en de status van de zaadblaasjes. De helling voor lcavol hangt m.a.w. niet af van de hoogte van het log prostaat gewicht en de status van de zaadblaasjes.</p>
<p><span class="math display">\[\beta_0 + \beta_v (x_{v}+\delta_v) + \beta_w x_{w} +\beta_s x_{s} - \beta_0 - \beta_v x_{v} - \beta_w x_{w} -\beta_s x_s = \beta_v \delta_v
\]</span></p>
<p>De svi status en de hoogte van het log-prostaatgewicht (<span class="math inline">\(x_w\)</span>) heeft geen invloed op de bijdrage van het log-tumorvolume (<span class="math inline">\(x_v\)</span>) in de gemiddelde log-prostaat antigeen concentratie en vice versa.</p>
<p>Het zou nu echter kunnen zijn dat de associatie tussen lpsa en lcavol wel afhangt van het prostaatgewicht. De gemiddelde toename in lpsa tussen patiënten die één eenheid van log-tumorvolume verschillen zou bijvoorbeeld lager kunnen zijn voor patiënten met een hoog prostaatgewicht dan bij patiënten met een laag prostaatgewicht. Het effect van het tumorvolume op de prostaat antigeen concentratie hangt in dit geval af van het prostaatgewicht.</p>
<p>Om een dergelijke  of  tussen 2 variabelen <span class="math inline">\(X_v\)</span> en <span class="math inline">\(X_w\)</span> statistisch te modelleren, kan men het product van beide variabelen in kwestie aan het model toevoegen:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_v x_{iv} + \beta_w x_{iw} +\beta_s x_{is} + \beta_{vw} x_{iv}x_{iw} +\epsilon_i
\]</span></p>
<p>Deze term kwantificeert het <em>interactie-effect</em> van de predictoren <span class="math inline">\(x_v\)</span> en <span class="math inline">\(x_w\)</span> op de gemiddelde uitkomst. In dit model worden de termen <span class="math inline">\(\beta_vx_{iv}\)</span> en <span class="math inline">\(\beta_wx_{iw}\)</span> dikwijls de <em>hoofdeffecten</em> van de predictoren <span class="math inline">\(x_v\)</span> en <span class="math inline">\(x_w\)</span> genoemd.</p>
<p>Het ‘effect’ van een verschil in 1 eenheid in <span class="math inline">\(X_v\)</span> op de gemiddelde uitkomst bedraagt nu:</p>
<p><span class="math display">\[
\begin{array}{l}
E(Y|X_v=x_v+1,X_w=x_w,X_s=x_s) − E(X_v=x_v,X_w=x_w,X_s=x_s) \\
\quad = \beta_0 + \beta_v (x_{v}+1) + \beta_w x_w +\beta_s x_{s} + \beta_{vw} (x_{v}+1) x_w - \beta_0 - \beta_v x_{v} - \beta_w x_w -\beta_s x_{s} - \beta_{vw} (x_{v}) x_w \\
\quad = \beta_v +  \beta_{vw} x_w
 \end{array} 
 \]</span></p>
<p>wanneer het log-prostaatgewicht <span class="math inline">\(X_w=c\)</span> en de <span class="math inline">\(X_s=x_s\)</span> status ongewijzigd blijven. Merk op dat het ‘effect’ van een wijzing in het tumorvolume bij constant log-prostaat gewicht nu inderdaad afhankelijk is van de hoogte van het log-prostaatgewicht <span class="math inline">\(x_w\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmVWS_IntVW &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa<span class="op">~</span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi <span class="op">+</span><span class="st"> </span>lcavol<span class="op">:</span>lweight ,prostate)
<span class="kw">summary</span>(lmVWS_IntVW)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + svi + lcavol:lweight, 
##     data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.65886 -0.44673  0.02082  0.50244  1.57457 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)     -0.6430     0.7030  -0.915  0.36278   
## lcavol           1.0046     0.5427   1.851  0.06734 . 
## lweight          0.6146     0.1961   3.134  0.00232 **
## sviinvasion      0.6859     0.2114   3.244  0.00164 **
## lcavol:lweight  -0.1246     0.1478  -0.843  0.40156   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7179 on 92 degrees of freedom
## Multiple R-squared:  0.6293, Adjusted R-squared:  0.6132 
## F-statistic: 39.05 on 4 and 92 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>De output van het model geeft een schatting van -0.125 voor de interactie <span class="math inline">\(\beta_{vw}\)</span> tussen het log-tumorvolume en het log-prostaatgewicht. Dat betekent dat de gemiddelde toename in lpsa tussen patiënten met een verschil in het log-tumorvolume maar met eenzelfde prostaatgewicht afhankelijk zal zijn van het prostaatgewicht. In het bijzonder suggereert de output dat patiënten die 1% verschillen in het tumorvolume maar hetzelfde log prostaat gewicht hebben gemiddeld (<span class="math inline">\(1.004-0.125 \times x_w\)</span>)% verschillen in prostaat antigeen concentratie (interpretatie volgt uit log transformatie van de response en tumorvolume). Patiënten die 1% verschillen in tumorvolume en die een log-prostaatgewicht hebben van 3 zullen gemiddeld 0.631% in prostaat antigeen concentratie verschillen. Terwijl patiënten die 1% verschillen in tumorvolume en die een log-prostaatgewicht hebben van 4 gemiddeld een verschil van 0.506% in prostaat antigeen concentratie hebben. De associatie van het log-tumorvolume en de log prostaat antigeen concentratie neemt dus af met toenemend prostaatgewicht.</p>
<p>Grafische interpretatie wordt weergegeven in Figuur <a href="chap-glm.html#fig:prosIntFit1">10.4</a>. Hier worden het additieve model en het model met de lcavol:lweight interactie vergeleken. De fit toont duidelijk aan dat de associate tussen lpsa en lcavol gelijk is ongeacht de grootte van het prostaatgewicht voor het additieve model (parallele lijnen in het regressieoppervlak). Voor het model met interactie is dat niet het geval, de associate (helling) neemt af met toenemend prostaatgewicht. We zien een analoog effect wanneer we focussen op de associatie tussen lpsa en lweight. De lpsa <span class="math inline">\(\leftrightarrow\)</span> lweight associatie neemt af met toenemend log-tumorvolume.</p>
<div class="figure" style="text-align: center"><span id="fig:prosIntFit1"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosIntFit1-1.png" alt="Fit van het additieve model met de termen lcavol, lweight, svi (links) en het model met interactie lcavol, lweight, svi en lcavol:lweight (rechts). Merk op dat we enkel het regressieoppervlak weergeven voor patiënten zouder invasie van de zaadblaasjes. Dat voor patiënten met invasie van de zaadblaasjes is parallel met het getoonde oppervlak, maar ligt iets hoger. De rechtse figuur toont duidelijk dat de interactie ervoor zorgt dat de associatie tussen de response en het tumorvolume afhankelijk is van de hoogte van het prostaatgewicht en vice versa, dat zorgt voor een torsie in het regressievlak." width="100%" />
<p class="caption">
Figuur 10.4: Fit van het additieve model met de termen lcavol, lweight, svi (links) en het model met interactie lcavol, lweight, svi en lcavol:lweight (rechts). Merk op dat we enkel het regressieoppervlak weergeven voor patiënten zouder invasie van de zaadblaasjes. Dat voor patiënten met invasie van de zaadblaasjes is parallel met het getoonde oppervlak, maar ligt iets hoger. De rechtse figuur toont duidelijk dat de interactie ervoor zorgt dat de associatie tussen de response en het tumorvolume afhankelijk is van de hoogte van het prostaatgewicht en vice versa, dat zorgt voor een torsie in het regressievlak.
</p>
</div>
<p>Merk op, dat het interactie effect dat geobserveerd wordt in de steekproef echter statistisch niet significant is (p=0.4). Gezien de hoofdeffecten die betrokken zijn in een interactie term niet los van elkaar kunnen worden geïnterpreteerd is de conventie om een interactieterm uit het model te verwijderen wanneer die niet significant is. Na verwijdering van de niet-significante interactieterm kunnen de hoofdeffecten worden geïnterpreteerd.</p>
</div>
<div id="interactie-tussen-continue-variabele-en-factor-variabele" class="section level3">
<h3><span class="header-section-number">10.5.2</span> Interactie tussen continue variabele en factor variabele</h3>
<p>We kunnen ook de interactie bestuderen tussen lcavol <span class="math inline">\(\leftrightarrow\)</span> svi en lweight <span class="math inline">\(\leftrightarrow\)</span> svi. Merk op dat svi een factor is. Het model wordt dan</p>
<p><span class="math display">\[Y=\beta_0+\beta_vX_v+\beta_wX_w+\beta_sX_s+\beta_{vs}X_vX_s + \beta_{ws}X_wX_s +\epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmVWS_IntVS_WS &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi <span class="op">+</span><span class="st"> </span>svi<span class="op">:</span>lcavol <span class="op">+</span><span class="st"> </span>svi<span class="op">:</span>lweight,<span class="dt">data=</span>prostate) 
<span class="kw">summary</span>(lmVWS_IntVS_WS)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + svi + svi:lcavol + svi:lweight, 
##     data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.50902 -0.44807  0.06455  0.45657  1.54354 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         -0.52642    0.56793  -0.927 0.356422    
## lcavol               0.54060    0.07821   6.912 6.38e-10 ***
## lweight              0.58292    0.15699   3.713 0.000353 ***
## sviinvasion          3.43653    1.93954   1.772 0.079771 .  
## lcavol:sviinvasion   0.13467    0.25550   0.527 0.599410    
## lweight:sviinvasion -0.82740    0.52224  -1.584 0.116592    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7147 on 91 degrees of freedom
## Multiple R-squared:  0.6367, Adjusted R-squared:  0.6167 
## F-statistic: 31.89 on 5 and 91 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Het effect van lcavol op lpsa en het effect van lweight op lpsa zal nu afhangen van de waarde voor svi. <span class="math inline">\(X_s\)</span> is echter een dummy variabele die twee waarden aan kan nemen, <span class="math inline">\(X_s=0\)</span> als de zaadblaasjes niet aangetast zijn en <span class="math inline">\(X_s=1\)</span> als er invasie is van de zaadblaadjes. Gezien <span class="math inline">\(X_S\)</span> een dummy variabele is bekomen we nu twee verschillende regressievlakken:</p>
<ol style="list-style-type: decimal">
<li>Een regressievlak voor <span class="math inline">\(X_s=0\)</span>: <span class="math display">\[Y=\beta_0+\beta_vX_v+\beta_wX_w + \epsilon\]</span> waar de hellingen voor lcavol en lweight de hoofdeffecten zijn.</li>
<li>En een regressievlak voor <span class="math inline">\(X_s=1\)</span>: <span class="math display">\[Y=\beta_0+\beta_vX_v+\beta_s+\beta_wX_w+\beta_{vs}X_v + \beta_{ws}X_w +\epsilon=(\beta_0+\beta_s)+(\beta_v+\beta_{vs})X_v+(\beta_w+\beta_{ws})X_w+\epsilon\]</span> waar het intercept <span class="math inline">\(\beta_0 + \beta_s\)</span> is, de som van het intercept en het hoofdeffect voor <span class="math inline">\(X_s\)</span>, en de hellingen voor lcavol en lweight respectievelijk <span class="math inline">\(\beta_v+\beta_{vs}\)</span> en <span class="math inline">\(\beta_w+\beta_{ws}\)</span> zijn, m.a.w. de sum van het hoofdeffect en de overeenkomstige interactieterm.</li>
</ol>
<p>Grafisch wordt het model weergegeven in Figuur <a href="chap-glm.html#fig:prosIntFit2">10.5</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:prosIntFit2"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosIntFit2-1.png" alt="Fit van het additieve model met de termen lcavol, lweight, svi (links) en het model met interacties lcavol, lweight, svi . lcavol:svi, lweight:svi (rechts). De rechtse figuur toont duidelijk dat de interactie er nu voor zorgt dat de associaties tussen de response &lt;-&gt; het log-tumorvolume en de response &lt;-&gt; het log-gewicht afhankelijk is van de status van de zaadblaasjes. De interacties zorgen voor andere hellingen bij patiënten met (rood) en zonder invasie (blauw) van de zaadblaasjes. Voor het additieve model (links) zien we enkel een verschuiving van het regressievlak, maar parallelle hellingen. Het hoofdeffect voor een factor variabele zorgt m.a.w. voor een ander intercept." width="100%" />
<p class="caption">
Figuur 10.5: Fit van het additieve model met de termen lcavol, lweight, svi (links) en het model met interacties lcavol, lweight, svi . lcavol:svi, lweight:svi (rechts). De rechtse figuur toont duidelijk dat de interactie er nu voor zorgt dat de associaties tussen de response &lt;-&gt; het log-tumorvolume en de response &lt;-&gt; het log-gewicht afhankelijk is van de status van de zaadblaasjes. De interacties zorgen voor andere hellingen bij patiënten met (rood) en zonder invasie (blauw) van de zaadblaasjes. Voor het additieve model (links) zien we enkel een verschuiving van het regressievlak, maar parallelle hellingen. Het hoofdeffect voor een factor variabele zorgt m.a.w. voor een ander intercept.
</p>
</div>
<p>Merk op dat de helling voor lcavol groter is bij patiënten met invasie van de zaadblaasjes dan bij patiënten zonder invasie van de zaadblaasjes en dat de helling voor lweight van teken veranderd. Verder zijn beide interactie-termen opnieuw niet significant.</p>
</div>
</div>
<div id="anova-tabel-2" class="section level2">
<h2><span class="header-section-number">10.6</span> ANOVA Tabel</h2>
<div id="sstot-ssr-en-sse" class="section level3">
<h3><span class="header-section-number">10.6.1</span> SSTot, SSR en SSE</h3>
<p>Voor de enkelvoudige lineaire regressie hebben we in detail de decompositie van SSTot=SSR+SSE besproken. In deze sectie breiden we die resultaten uit naar meervoudige lineaire regressie.</p>
<p>De totale kwadratensom SSTot is gedefinieerd zoals voorheen, <span class="math display">\[
  \text{SSTot} = \sum_{i=1}^n (Y_i - \bar{Y})^2.
\]</span></p>
<p>Het is nog steeds een maat voor de totale variabiliteit in de geobserveerde uitkomsten. Ook de residuele kwadratensom is zoals voorheen. <span class="math display">\[
  \text{SSE} = \sum_{i=1}^n (Y_i-\hat{Y}_i)^2.
\]</span></p>
<p>Beschouw nu een meervoudig lineair regressiemodel met <span class="math inline">\(p-1\)</span> regressoren. Dan geldt de volgende decompositie van de totale kwadratensom, <span class="math display">\[
  \text{SSTot} = \text{SSR} + \text{SSE} ,
\]</span> met <span class="math display">\[
  \text{SSR} = \sum_{i=1}^n (\hat{Y}_i-\bar{Y})^2.
\]</span></p>
<p>De kwadratensom van de regressie (SSR) kan nog steeds geïnterpreteerd worden als de variabiliteit in de uitkomsten die verklaard kan worden door het regressiemodel.</p>
<p>Voor de vrijheidsgraden en de gemiddelde kwadratensommen geldt:</p>
<ul>
<li>SSTot heeft <span class="math inline">\(n-1\)</span> vrijheidsgraden en <span class="math inline">\(\text{SSTot}/(n-1)\)</span> is een schatter voor de variantie van <span class="math inline">\(Y\)</span> (van de marginale distributie van <span class="math inline">\(Y\)</span>).</li>
<li>SSE heeft <span class="math inline">\(n-p\)</span> vrijheidsgraden en <span class="math inline">\(\text{MSE}=\text{SSE}/(n-p)\)</span> is een schatter voor de residuele variantie van <span class="math inline">\(Y\)</span> gegeven de regressoren (i.e. een schatter voor de residuele variantie <span class="math inline">\(\sigma^2\)</span> van de foutterm <span class="math inline">\(\epsilon\)</span>).</li>
<li>SSR heeft <span class="math inline">\(p-1\)</span> vrijheidsgraden en <span class="math inline">\(\text{MSR}=\text{SSR}/(p-1)\)</span> is de gemiddelde kwadratensom van de regressie.</li>
</ul>
<p>Een gevolg van de decompositie van SSTot is dat de determinatiecoëfficiënt blijft zoals voorheen, i.e. <span class="math display">\[
  R^2 = 1-\frac{\text{SSE}}{\text{SSTot}} = \frac{\text{SSR}}{\text{SSTot}}
\]</span> is de fractie van de totale variabiliteit in de uitkomsten die verklaard wordt door het regressiemodel.</p>
<p>De teststatistiek <span class="math inline">\(F=\text{MSR}/\text{MSE}\)</span> is onder <span class="math inline">\(H_0:\beta_1=\ldots=\beta_{p-1}=0\)</span> verdeeld als <span class="math inline">\(F_{p-1;n-p}\)</span>. De F-test test m.a.w. het effect van alle predictoren simultaan. Onder de nulhypothese is er geen associatie tussen de respons en elk van de predictoren. De output van deze F-test wordt standaard gegeven onderaan in de summary output.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lmVWS)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + svi, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.72966 -0.45767  0.02814  0.46404  1.57012 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.26807    0.54350  -0.493  0.62301    
## lcavol       0.55164    0.07467   7.388  6.3e-11 ***
## lweight      0.50854    0.15017   3.386  0.00104 ** 
## sviinvasion  0.66616    0.20978   3.176  0.00203 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7168 on 93 degrees of freedom
## Multiple R-squared:  0.6264, Adjusted R-squared:  0.6144 
## F-statistic: 51.99 on 3 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We zien dat de algemene nulhypothese heel significant kan worden verworpen. Minstens 1 predictor is extreem significant geassocieerd met de respons. In de individuele t-testen zien we dat elk van de predictoren een sterk significante associatie vertonen.</p>
</div>
<div id="extra-kwadratensommen" class="section level3">
<h3><span class="header-section-number">10.6.2</span> Extra Kwadratensommen</h3>
<p>We kunnen een stap verder gaan en voor iedere individuele regressor een kwadratensom definiëren. Er zijn echter verschillende mogelijkheden.</p>
<p>Beschouw de volgende twee regressiemodellen voor regressoren <span class="math inline">\(x_1\)</span> en <span class="math inline">\(x_2\)</span>: <span class="math display">\[
  Y_i = \beta_0+\beta_1 x_{i1} + \epsilon_i,
\]</span> met <span class="math inline">\(\epsilon_i\text{ iid } N(0,\sigma_1^{2})\)</span>, en <span class="math display">\[
Y_i = \beta_0+\beta_1 x_{i1}+\beta_2 x_{i2} + \epsilon_i,
\]</span> met <span class="math inline">\(\epsilon_i\text{ iid } N(0,\sigma_2^{2})\)</span>.</p>
<p>Merk op dat we subscript 1 en 2 toegevoegd hebben aan de residuele varianties, maar dat we dezelfde <span class="math inline">\(\beta\)</span>-parameternotatie gebruiken voor beide modellen; dit is om de notatie niet nodeloos complex te maken, maar je moet je ervan bewust zijn dat de <span class="math inline">\(\beta\)</span>-parameters uit beide modellen niet noodzakelijk gelijk zijn.</p>
<p>Voor het eerste (gereduceerde) model geldt de decompositie <span class="math display">\[
  \text{SSTot} = \text{SSR}_1 + \text{SSE}_1
\]</span> en voor het tweede (niet-gereduceerde) model <span class="math display">\[
  \text{SSTot} = \text{SSR}_2 + \text{SSE}_2
\]</span> (SSTot is uiteraard dezelfde in beide modellen omdat dit niet afhangt van het regressiemodel).</p>
<p><strong>Definitie extra kwadratensom</strong> De <em>extra kwadratensom</em> (Engels: <em>extra sum of squares</em>) van predictor <span class="math inline">\(x_2\)</span> t.o.v. het model met enkel <span class="math inline">\(x_1\)</span> als predictor wordt gegeven door <span class="math display">\[
  \text{SSR}_{2\mid 1} = \text{SSE}_1-\text{SSE}_2=\text{SSR}_2-\text{SSR}_1.
\]</span></p>
<p><strong>Einde definitie</strong></p>
<p>Merk eerst op dat <span class="math inline">\(\text{SSE}_1-\text{SSE}_2=\text{SSR}_2-\text{SSR}_1\)</span> triviaal is gezien de decomposities van de totale kwadratensommen.</p>
<p>De extra kwadratensom <span class="math inline">\(\text{SSR}_{2\mid 1}\)</span> kan eenvoudig geïnterpreteerd worden als de extra variantie van de uitkomst die verklaard kan worden door regressor <span class="math inline">\(x_2\)</span> toe te voegen aan een model waarin regressor <span class="math inline">\(x_1\)</span> reeds aanwezig is.</p>
<p>Met dit nieuw soort kwadratensom kunnen we voor het model met twee predictoren schrijven <span class="math display">\[
  \text{SSTot} = \text{SSR}_1+ \text{SSR}_{2\mid 1} + \text{SSE}.
\]</span> Dit volgt rechtstreeks uit de definitie van de extra kwadratensom <span class="math inline">\(\text{SSR}_{2\mid 1}\)</span>.</p>
<p>De definitie voor de extra kwadratensom kan uitgebreid worden naar een situatie waar twee geneste lineaire regressiemodellen beschouwd worden.</p>
<p>Zonder in te boeten in algemeenheid starten we met de regressiemodellen (<span class="math inline">\(s&lt;p-1\)</span>) <span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_{s} x_{is} + \epsilon_i 
\]</span> met <span class="math inline">\(\epsilon_i\text{ iid }N(0,\sigma_1^{2})\)</span>, en (<span class="math inline">\(s&lt; q\leq p-1\)</span>) <span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_{s} x_{is} + \beta_{s+1} x_{is+1} + \cdots \beta_{q}x_{iq}+ \epsilon_i 
\]</span> met <span class="math inline">\(\epsilon_i\text{ iid } N(0,\sigma_2^{2})\)</span>.</p>
<p>De <strong>extra kwadratensom</strong> van predictoren <span class="math inline">\(x_{s+1}, \ldots, x_q\)</span> t.o.v. het model met enkel de predictoren <span class="math inline">\(x_1,\ldots, x_{s}\)</span> wordt gegeven door <span class="math display">\[
  \text{SSR}_{s+1, \ldots, q\mid 1,\ldots, s} = \text{SSE}_1-\text{SSE}_2=\text{SSR}_2-\text{SSR}_1.
\]</span></p>
<p>De extra kwadratensom <span class="math inline">\(\text{SSR}_{s+1, \ldots, q\mid 1,\ldots, s}\)</span> meet de extra variabiliteit in uitkomst die verklaard wordt door de predictoren <span class="math inline">\(x_{s+1}, \ldots, x_q\)</span> toe te voegen aan een model met predictoren <span class="math inline">\(x_1,\ldots, x_{s}\)</span>. Anders gezegd: het meet de variatie van de uitkomsten verklaard door predictoren <span class="math inline">\(x_{s+1}, \ldots, x_q\)</span> die niet verklaard wordt door de predictoren <span class="math inline">\(x_1,\ldots, x_{s}\)</span>.</p>
<p>We hebben hier SSR notatie gebruikt met lange indexen (bv. <span class="math inline">\(\text{SSR}_{s, \ldots, q\mid 1,\ldots, s-1}\)</span>). Soms wordt de voorkeur gegeven aan de notatie <span class="math display">\[
  \text{SSR}(s+1, \ldots, q\mid 1,\ldots, s).
\]</span></p>
</div>
<div id="type-i-kwadratensommen" class="section level3">
<h3><span class="header-section-number">10.6.3</span> Type I Kwadratensommen</h3>
<p>Stel dat <span class="math inline">\(p-1\)</span> regressoren beschouwd worden, en beschouw een sequentie van modellen (<span class="math inline">\(s=2,\ldots, p-1\)</span>) <span class="math display">\[
Y_i = \beta_0 + \sum_{j=1}^{s} \beta_j x_{ij} + \epsilon_i
\]</span> met <span class="math inline">\(\epsilon_i\text{ iid } N(0,\sigma^{2})\)</span>. De overeenkomstige kwadratensommen worden genoteerd als <span class="math inline">\(\text{SSR}_{s}\)</span> en <span class="math inline">\(\text{SSE}_{s}\)</span>. De modelsequentie geeft ook aanleiding tot extra kwadratensommen <span class="math inline">\(\text{SSR}_{s\mid 1,\ldots, s-1}\)</span>. Deze laatste kwadratensom wordt een type I kwadratensom genoemd. Merk op dat deze afhangt van de volgorde (nummering) van regressoren.</p>
<p>Er kan aangetoond worden dat voor Model met <span class="math inline">\(s=p-1\)</span> geldt <span class="math display">\[
 \text{SSTot} = \text{SSR}_1 + \text{SSR}_{2\mid 1} + \text{SSR}_{3\mid 1,2} + \cdots + \text{SSR}_{p-1\mid 1,\ldots, p-2} + \text{SSE},
\]</span> met <span class="math inline">\(\text{SSE}\)</span> de residuele kwadratensom van het model met alle <span class="math inline">\(p-1\)</span> regressoren en <span class="math display">\[
  \text{SSR}_1 + \text{SSR}_{2\mid 1} + \text{SSR}_{3\mid 1,2} + \cdots + \text{SSR}_{p-1\mid 1,\ldots, p-2} = \text{SSR}
\]</span> met <span class="math inline">\(\text{SSR}\)</span> de kwadratensom van de regressie van het model met alle <span class="math inline">\(p-1\)</span> regressoren.</p>
<p>De interpretatie van iedere individuele SSR term werd eerder gegeven, maar het is belangrijk om op te merken dat de interpretatie van iedere term afhangt van de volgorde van de regressoren in de sequentie van regressiemodellen.</p>
<p>Dus de type I kwadratensommen laten een decompositie van SSTot toe, maar de SSR-termen hangen af van de volgorde waarin de regressoren in het regressiemodel voorkomen.</p>
<p>Iedere type I SSR heeft betrekking op het effect van 1 regressor en heeft dus 1 vrijheidsgraad. Voor iedere type I SSR term kan een gemiddelde kwadratensom gedefinieerd worden als <span class="math inline">\(\text{MSR}_{j\mid 1,\ldots, j-1}=\text{SSR}_{j\mid 1,\ldots, j-1}/1\)</span>. De teststatistiek <span class="math inline">\(F=\text{MSR}_{j\mid 1,\ldots, j-1}/\text{MSE}\)</span> is onder <span class="math inline">\(H_0:\beta_j=0\)</span> met <span class="math inline">\(s=j\)</span> verdeeld als <span class="math inline">\(F_{1;n-(j+1)}\)</span>.</p>
<p>Deze kwadratensommen worden standaard weergegeven door de anova functie in R.</p>
</div>
<div id="type-iii-kwadratensommen" class="section level3">
<h3><span class="header-section-number">10.6.4</span> Type III Kwadratensommen</h3>
<p>Beschouw opnieuw het regressiemodel met <span class="math inline">\(p-1\)</span> regressoren. De type III kwadratensom van regressor <span class="math inline">\(x_j\)</span> wordt gegeven door de extra kwadratensom <span class="math display">\[
  \text{SSR}_{j \mid 1,\ldots, j-1,j+1,\ldots, p-1} = \text{SSE}_1-\text{SSE}_2
\]</span></p>
<ul>
<li><span class="math inline">\(\text{SSE}_2\)</span> de residuele kwadratensom van regressiemodel met alle <span class="math inline">\(p-1\)</span> regressoren.</li>
<li><span class="math inline">\(\text{SSE}_1\)</span> de residuele kwadratensom van regressiemodel met alle <span class="math inline">\(p-1\)</span> regressoren, uitgezonderd regressor <span class="math inline">\(x_j\)</span>.</li>
</ul>
<p>De type III kwadratensom <span class="math inline">\(\text{SSR}_{j \mid 1,\ldots, j-1,j+1,\ldots, p-1}\)</span> kwantificeert dus het aandeel van de totale variantie van de uitkomst dat door regressor <span class="math inline">\(x_j\)</span> verklaard wordt en dat niet door de andere <span class="math inline">\(p-2\)</span> regressoren verklaard wordt.</p>
<p>De type III kwadratensom heeft ook 1 vrijheidsgraad omdat het om 1 <span class="math inline">\(\beta\)</span>-parameter gaat.</p>
<p>Voor iedere type III SSR term kan een gemiddelde kwadratensom gedefinieerd worden als <span class="math inline">\(\text{MSR}_{j \mid 1,\ldots, j-1,j+1,\ldots, p-1}=\text{SSR}_{j \mid 1,\ldots, j-1,j+1,\ldots, p-1}/1\)</span>.</p>
<p>De teststatistiek <span class="math inline">\(F=\text{MSR}_{j \mid 1,\ldots, j-1,j+1,\ldots, p-1}/\text{MSE}\)</span> is onder <span class="math inline">\(H_0:\beta_j=0\)</span> verdeeld as <span class="math inline">\(F_{1;n-p}\)</span>.</p>
<p>Deze kwadratensommen kunnen worden verkregen d.m.v. de Anova functie van het car package. In de Anova functie wordt hiervoor het argument ‘type=3’ gebruikt.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)
<span class="kw">Anova</span>(lmVWS,<span class="dt">type=</span><span class="dv">3</span>)</code></pre></div>
<pre><code>## Anova Table (Type III tests)
## 
## Response: lpsa
##             Sum Sq Df F value    Pr(&gt;F)    
## (Intercept)  0.125  1  0.2433  0.623009    
## lcavol      28.045  1 54.5809 6.304e-11 ***
## lweight      5.892  1 11.4678  0.001039 ** 
## svi          5.181  1 10.0841  0.002029 ** 
## Residuals   47.785 93                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Merk op dat de p-waarden die we verkrijgen voor het testen van elk van de effecten identiek zijn als de p-waarden van de tweezijdige t-testen. De F-test o.b.v. een type III kwadratensom voor 1 parameter is equivalent met de tweezijdige t-test voor deze parameter.</p>
</div>
</div>
<div id="regressiediagnostieken" class="section level2">
<h2><span class="header-section-number">10.7</span> Regressiediagnostieken</h2>
<div id="multicollineariteit" class="section level3">
<h3><span class="header-section-number">10.7.1</span> Multicollineariteit</h3>
<p>Het is interessant om in de R output voor het model met lcavol:lweight interactie ook naar schattingen van de hoofdeffecten te kijken (Sectie <a href="chap-glm.html#sec:intCont">10.5.1</a>). De waarden van de schattingen zijn niet alleen verschillend van wat we in het additieve model vonden, maar de standaardfouten zijn nu veel groter! De oorzaak moet gezocht worden in het probleem van multicollineariteit. Wanneer 2 predictoren sterk gecorreleerd zijn, dan delen ze voor een groot stuk dezelfde informatie en is het moeilijk om de afzonderlijke effecten van beiden op de uitkomst te schatten. Dit uit zich in het feit dat de computationele berekening van de kleinste kwadratenschatters onstabiel wordt, in die zin dat kleine wijzigingen aan de gegevens of het toevoegen of weglaten van een predictorvariabele een belangrijke impact kunnen hebben op de grootte, en zelfs het teken, van de geschatte regressieparameters. Een tweede effect van multicollineariteit is dat standaard errors bij de geschatte regressieparameters fel kunnen worden opgeblazen en de bijhorende betrouwbaarheidsintervallen bijgevolg zeer breed kunnen worden. Zolang men enkel predicties tracht te bekomen op basis van het regressiemodel zonder daarbij te extrapoleren buiten het bereik van de predictoren is multicollineariteit geen probleem.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(<span class="kw">cbind</span>(prostate<span class="op">$</span>lcavol,prostate<span class="op">$</span>lweight,prostate<span class="op">$</span>lcavol<span class="op">*</span>prostate<span class="op">$</span>lweight))</code></pre></div>
<pre><code>##           [,1]      [,2]      [,3]
## [1,] 1.0000000 0.1941283 0.9893127
## [2,] 0.1941283 1.0000000 0.2835608
## [3,] 0.9893127 0.2835608 1.0000000</code></pre>
<p>We zien dat de correlatie inderdaad erg hoog is tussen het log-tumorvolume en de interactieterm. Het is gekend dat hogere orde termen (interacties en kwadratische termen) vaak een sterke correlatie vertonen.</p>
<p>Problemen als gevolg van multicollineariteit kunnen herkend worden aan het feit dat de resultaten onstabiel worden. Zo kunnen grote wijzigingen optreden in de parameters na toevoeging van een predictor, kunnen zeer brede betrouwbaarheidsintervallen bekomen worden voor sommige parameters of kunnen gewoonweg onverwachte resultaten worden gevonden. Meer formeel kan men zich een idee vormen van de mate waarin er van multicollineariteit sprake is door de correlaties te inspecteren tussen elk paar predictoren in het regressiemodel of via een scatterplot matrix die elk paar predictoren uitzet op een scatterplot. Dergelijke diagnostieken voor multicollineariteit zijn echter niet ideaal. Vooreerst geven ze geen idee in welke mate de geobserveerde multicollineariteit de resultaten onstabiel maakt. Ten tweede kan het in modellen met 3 of meerdere predictoren, zeg X1, X2, X3, voorkomen dat er zware multicollineariteit is ondanks het feit dat alle paarsgewijze correlaties tussen de predictoren laag zijn. Dit kan bijvoorbeeld optreden wanneer de correlatie hoog is tussen X1 en een lineaire combinatie van X2 en X3.</p>
<p>Bovenstaande nadelen kunnen vermeden worden door de  te onderzoeken, die voor de <span class="math inline">\(j\)</span>-de parameter in het regressiemodel gedefinieerd wordt als <span class="math display">\[\textrm{VIF}_j=\left(1-R_j^2\right)^{-1}\]</span> In deze uitdrukking stelt <span class="math inline">\(R_j^2\)</span> de meervoudige determinatiecoëfficiënt voor van een lineaire regressie van de <span class="math inline">\(j\)</span>-de predictor op alle andere predictoren in het model. De VIF heeft de eigenschap dat ze gelijk is aan 1 indien de <span class="math inline">\(j\)</span>-de predictor niet lineair geassocieerd is met de andere predictoren in het model, en bijgevolg wanneer de <span class="math inline">\(j\)</span>-de parameter in het model niet onderhevig is aan het probleem van multicollineariteit. De VIF is groter dan 1 in alle andere gevallen. In het bijzonder drukt ze uit met welke factor de geobserveerde variantie op de schatting voor de <span class="math inline">\(j\)</span>-de parameter groter is dan wanneer alle predictoren onafhankelijk zouden zijn. Hoe groter de VIF, hoe minder stabiel de schattingen bijgevolg zijn. Hoe kleiner de VIF, hoe dichter de schattingen dus bij de gezochte populatiewaarden verwacht worden. In de praktijk spreekt men van ernstige multicollineariteit voor een regressieparameter wanneer haar VIF de waarde 10 overschrijdt.</p>
<p>We illustreren dat a.d.h.v. onderstaande voorbeeld.</p>
<p><strong>Voorbeeld vetpercentage</strong></p>
<p>Het percentage lichaamsvet van een persoon bepalen is een moeilijke en dure meting. Om die reden werden in het verleden verschillende studies opgezet met als doel het patroon te ontrafelen tussen werkelijk percentage lichaamsvet en verschillende, makkelijker te meten surrogaten. In een studie heeft men voor 20 gezonde vrouwen tussen 25 en 34 jaar het percentage lichaamsvet <span class="math inline">\(Y\)</span>, de dikte van de huidplooi rond de triceps <span class="math inline">\(X_1\)</span>, de dij-omtrek <span class="math inline">\(X_2\)</span> en de middenarmomtrek <span class="math inline">\(X_3\)</span> gemeten. Indien we een nauwkeurig regressiemodel kunnen opstellen op basis van de gegevens, dan zal ons dat toelaten om in de toekomst met behulp van dat model voorspellingen te maken voor het percentage lichaamsvet in gezonde vrouwen tussen 25 en 34 jaar, op basis van de huidplooi rond de triceps, de dij-omtrek en de middenarmomtrek.</p>
<div class="figure" style="text-align: center"><span id="fig:vetScatter"></span>
<img src="Statistiek_2019_2020_files/figure-html/vetScatter-1.png" alt="Scatterplot matrix van de dataset bodyfat." width="100%" />
<p class="caption">
Figuur 10.6: Scatterplot matrix van de dataset bodyfat.
</p>
</div>
<p>Wanneer we de 3 predictoren simultaan aan een regressiemodel toevoegen, bekomen we de volgende output.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmFat &lt;-<span class="st"> </span><span class="kw">lm</span>(Body_fat<span class="op">~</span>Triceps<span class="op">+</span>Thigh<span class="op">+</span>Midarm ,<span class="dt">data=</span>bodyfat)
<span class="kw">summary</span>(lmFat)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Body_fat ~ Triceps + Thigh + Midarm, data = bodyfat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7263 -1.6111  0.3923  1.4656  4.1277 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  117.085     99.782   1.173    0.258
## Triceps        4.334      3.016   1.437    0.170
## Thigh         -2.857      2.582  -1.106    0.285
## Midarm        -2.186      1.595  -1.370    0.190
## 
## Residual standard error: 2.48 on 16 degrees of freedom
## Multiple R-squared:  0.8014, Adjusted R-squared:  0.7641 
## F-statistic: 21.52 on 3 and 16 DF,  p-value: 7.343e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vif</span>(lmFat)</code></pre></div>
<pre><code>##  Triceps    Thigh   Midarm 
## 708.8429 564.3434 104.6060</code></pre>
<p>Hoewel het model meer dan 80% van de variabiliteit in het vetpercentage kan verklaren en dat de F-test die test voor alle predictoren simultaan extreem significant is, is de associatie echter voor geen enkele predictor significant volgens de individuele t-testen. De scatterplot matrix in Figuur <a href="chap-glm.html#fig:vetScatter">10.6</a> geeft aan dat er multicollineariteit aanwezig is wat betreft de predictoren <span class="math inline">\(X_1\)</span> en <span class="math inline">\(X_2\)</span>, maar niet meteen wat betreft de middenarmomtrek <span class="math inline">\(X_3\)</span>. Niettemin bekomen we erg hoge VIFs voor alle model parameters. Dit suggereert dat ook de middenarmomtrek gevoelig is aan ernstige multicollineariteit en bijgevolg dat scatterplot matrices inderdaad slechts een beperkt licht werpen op het probleem van multicollineariteit. De VIF varieert van 105-709, hetgeen aantoont dat de (kwadratische) afstand tussen de schattingen voor de regressieparameters en hun werkelijke waarden 105 tot 709 keer hoger kan worden verwacht dan wanneer er geen multicollineariteit zou zijn. Hoewel de paarsgewijze correlatie tussen Midarm en Triceps en Midarm en Thigh laag is, toont de regressie van Midarm op Triceps en Thigh echter aan dat beide variabelen samen 99% van de variabiliteit in de variabiliteit van Midarm kunnen verklaren, wat er voor zorgt dat er ook voor Midarm een extreem hoge multicollineariteit is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmMidarm &lt;-<span class="st"> </span><span class="kw">lm</span>(Midarm <span class="op">~</span><span class="st"> </span>Triceps<span class="op">+</span>Thigh,<span class="dt">data=</span>bodyfat)
<span class="kw">summary</span>(lmMidarm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Midarm ~ Triceps + Thigh, data = bodyfat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.58200 -0.30625  0.02592  0.29526  0.56102 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 62.33083    1.23934   50.29   &lt;2e-16 ***
## Triceps      1.88089    0.04498   41.82   &lt;2e-16 ***
## Thigh       -1.60850    0.04316  -37.26   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.377 on 17 degrees of freedom
## Multiple R-squared:  0.9904, Adjusted R-squared:  0.9893 
## F-statistic: 880.7 on 2 and 17 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Einde voorbeeld</strong></p>
<p>We evalueren nu de VIF in het prostaatkanker voorbeeld voor het additieve model en het model met interactie.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vif</span>(lmVWS)</code></pre></div>
<pre><code>##   lcavol  lweight      svi 
## 1.447048 1.039188 1.409189</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vif</span>(lmVWS_IntVW)</code></pre></div>
<pre><code>##         lcavol        lweight            svi lcavol:lweight 
##      76.193815       1.767121       1.426646      80.611657</code></pre>
<p>We zien dat de variance inflation factors voor het additieve model laag zijn, ze liggen allen dicht bij 1. Deze voor het model met interactie zijn echter hoog, voor lcavol en de interactie liggen ze respectievelijk op 76.2 en 80.6. Wat wijst op zeer ernstige multicollineariteit.</p>
<p>Merk op dat dit voor interactietermen vaak wordt veroorzaakt door het feit dat het hoofdeffect een andere interpretatie krijgt. Voor lcavol wordt dit b.v. het effect van het log-tumorvolume bij een log-prostaatgewicht van 0. Dit kan uiteraard niet voorkomen, alle log-prostaatgewichten liggen tussen 2.37 en 6.108 en berust dus op sterke extrapolatie. In de literatuur wordt daarom vaak voorgesteld om de variabelen te centreren rond het gemiddelde wanneer men hogere orde termen in het model opneemt. Dat is echter niet nodig, we weten immers dat het effect van het log-tumorvolume in het model met de lcavol:lweight interactie niet kan worden bestudeerd zonder het log-prostaatgewicht in rekening te brengen. We zullen in de practica zien dat we i.p.v. de data te centreren evengoed een test kunnen uitvoeren voor het effect van lcavol bij het gemiddelde log-prostaatgewicht, wat de interpretatie is voor het effect van lcavol bij het gecentreerde model.</p>
</div>
<div id="invloedrijke-observaties" class="section level3">
<h3><span class="header-section-number">10.7.2</span> Invloedrijke observaties</h3>
<p>In onderstaande code wordt data gesimuleerd om de impact van outliers te illustreren.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">112358</span>)
nobs&lt;-<span class="dv">20</span>
sdy&lt;-<span class="dv">1</span>
x&lt;-<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">length=</span>nobs)
y&lt;-<span class="dv">10</span><span class="op">+</span><span class="dv">5</span><span class="op">*</span>x<span class="op">+</span><span class="kw">rnorm</span>(nobs,<span class="dt">sd=</span>sdy)
x1&lt;-<span class="kw">c</span>(x,<span class="fl">0.5</span>)
y1 &lt;-<span class="st"> </span><span class="kw">c</span>(y,<span class="dv">10</span><span class="op">+</span><span class="dv">5</span><span class="op">*</span><span class="fl">1.5</span><span class="op">+</span><span class="kw">rnorm</span>(<span class="dv">1</span>,<span class="dt">sd=</span>sdy))
x2 &lt;-<span class="st"> </span><span class="kw">c</span>(x,<span class="fl">1.5</span>)
y2 &lt;-<span class="st"> </span><span class="kw">c</span>(y,y1[<span class="dv">21</span>])
x3 &lt;-<span class="st"> </span><span class="kw">c</span>(x,<span class="fl">1.5</span>)
y3 &lt;-<span class="st"> </span><span class="kw">c</span>(y,<span class="dv">11</span>)
<span class="kw">plot</span>(x,y,<span class="dt">xlim=</span><span class="kw">range</span>(<span class="kw">c</span>(x1,x2,x3)),<span class="dt">ylim=</span><span class="kw">range</span>(<span class="kw">c</span>(y1,y2,y3)))
<span class="kw">points</span>(<span class="kw">c</span>(x1[<span class="dv">21</span>],x2[<span class="dv">21</span>],x3[<span class="dv">21</span>]),<span class="kw">c</span>(y1[<span class="dv">21</span>],y2[<span class="dv">21</span>],y3[<span class="dv">21</span>]),<span class="dt">pch=</span><span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>),<span class="dt">col=</span><span class="dv">2</span><span class="op">:</span><span class="dv">4</span>) 
<span class="kw">abline</span>(<span class="kw">lm</span>(y<span class="op">~</span>x),<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="kw">lm</span>(y1<span class="op">~</span>x1),<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="kw">lm</span>(y2<span class="op">~</span>x2),<span class="dt">col=</span><span class="dv">3</span>,<span class="dt">lty=</span><span class="dv">3</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="kw">lm</span>(y3<span class="op">~</span>x3),<span class="dt">col=</span><span class="dv">4</span>,<span class="dt">lty=</span><span class="dv">4</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">4</span>,<span class="dt">lty=</span><span class="dv">1</span><span class="op">:</span><span class="dv">4</span>,<span class="dt">legend=</span><span class="kw">paste</span>(<span class="st">&quot;lm&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;&quot;</span>,<span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>))),<span class="dt">text.col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">4</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:influential"></span>
<img src="Statistiek_2019_2020_files/figure-html/influential-1.png" alt="Impact van outliers op de regressie. Regressie zonder outliers (zwart), regressie met outlier 1 (groen), regressie met outlier 2 (rood), regressie met outlier 3 (blauw)." width="100%" />
<p class="caption">
Figuur 10.7: Impact van outliers op de regressie. Regressie zonder outliers (zwart), regressie met outlier 1 (groen), regressie met outlier 2 (rood), regressie met outlier 3 (blauw).
</p>
</div>
<p>Een dataset bevat vaak extreme observaties voor zowel de uitkomst <span class="math inline">\(Y\)</span> als de predictoren <span class="math inline">\(X\)</span>. Deze kunnen de geschatte regressieparameters en regressielijn sterk beïnvloeden. Dat is niet verwonderlijk vermits de regressielijn de gemiddelde uitkomst voorstelt in functie van <span class="math inline">\(X\)</span> en gemiddelden zeer gevoelig zijn aan outliers. Figuur <a href="chap-glm.html#fig:influential">10.7</a> toont een puntenwolk met 3 afwijkende observaties samen met 4 lineaire regressielijnen één zonder en één met elk van deze observaties. Merk op dat de regressielijn in bijzondere mate afwijkt wanneer observatie 3 wordt opgenomen in de dataset. Dit kan als volgt worden verklaard. De aanwezigheid van observatie 1 impliceert dat de regressielijn (en bijgevolg het intercept) naar boven wordt getrokken, maar heeft verder geen invloed op het patroon van de regressielijn. Observatie 2 is extreem, maar heeft geen impact op de regressielijn omdat ze het patroon van de rechte volgt. Hoewel observatie 3 niet met een zeer extreme uitkomst <span class="math inline">\(y\)</span> overeenstemt, zal deze observatie toch het meest invloedrijk zijn omdat de predictorwaarde <span class="math inline">\(x\)</span> en, in het bijzonder, de <span class="math inline">\((x,y)\)</span>-combinatie zeer afwijkend is.</p>
<p>Het spreekt voor zich dat het niet wenselijk is dat een enkele observatie het resultaat van een lineaire regressie-analyse grotendeels bepaalt. We wensen daarom over diagnostieken te beschikken die ons toelaten om extreme observaties op te sporen. <em>Residu’s</em> geven weer hoe ver de uitkomst afwijkt van de regressielijn en kunnen bijgevolg gebruikt worden om extreme uitkomsten te identificeren. In het bijzonder hebben we eerder vermeld dat residu’s bij benadering Normaal verdeeld zijn wanneer het model correct is en de uitkomst Normaal verdeeld (bij vaste predictorwaarden) met homogene variantie. Of een residu extreem is, kan in dat opzicht geverifieerd worden door haar te vergelijken met de Normale verdeling. Stel bijvoorbeeld dat men over 100 observaties beschikt, dan verwacht men dat ongeveer 5% van de residu’s in absolute waarde extremer zijn dan 1.96<span class="math inline">\(\hat{\sigma}\)</span>. Indien men veel meer extreme residu’s observeert, dan is er een indicatie op outliers.</p>
<p>In de literatuur heeft men een aantal modificaties van residu’s ingevoerd met als doel deze nuttiger te maken voor de detectie van outliers. <em>Studentized residu’s</em> zijn een transformatie van de eerder gedefinieerde residu’s die <span class="math inline">\(t\)</span>-verdeeld zijn met <span class="math inline">\(n-1\)</span> vrijheidsgraden onder de onderstellingen van het model. Outliers kunnen aldus nauwkeuriger worden opgespoord door na te gaan of veel meer dan 5% van de studentized residu’s in absolute waarde het 97.5% percentiel van de <span class="math inline">\(t_{n-1}\)</span>-verdeling overschrijden.</p>
<p>Extreme predictorwaarden kunnen in principe opgespoord worden via een scatterplot matrix voor de uitkomst en verschillende predictoren. Wanneer er meerdere predictoren zijn, hebben deze echter ernstige tekortkomingen omdat het een combinatie van meerdere predictoren kan zijn die ongewoon is en dit niet kan opgespoord worden via dergelijke grafieken. Om die reden is het veel zinvoller om de zogenaamde <em>leverage (invloed, hefboom)</em> van elke observatie te onderzoeken. Dit is een diagnostische maat voor de mogelijkse invloed van predictor-observaties (in tegenstelling tot de residu’s die een diagnostische maat vormen voor de invloed van de uitkomsten). In het bijzonder is de leverage van de <span class="math inline">\(i\)</span>-de observatie een maat voor de afstand van predictorwaarde voor de <span class="math inline">\(i\)</span>-de observatie tot de gemiddelde predictorwaarde in de steekproef. Hieruit volgt bijgevolg dat indien de leverage voor de <span class="math inline">\(i\)</span>-de observatie groot is, ze predictorwaarden heeft die sterk afwijken van het gemiddelde. In dat geval heeft die observatie mogelijks ook grote invloed op de regressieparameters en predicties. Leverage waarden variëren normaal tussen <span class="math inline">\(1/n\)</span> en 1 en zijn gemiddeld <span class="math inline">\((p+1)/n\)</span> met <span class="math inline">\(p+1\)</span> het aantal ongekende parameters (intercept + <span class="math inline">\(p\)</span> hellingen). Een extreme leverage wordt typisch aanschouwd als een waarde groter dan <span class="math inline">\(2p/n\)</span>.</p>
</div>
<div id="cooks-distance" class="section level3">
<h3><span class="header-section-number">10.7.3</span> Cook’s distance</h3>
<p>Een meer rechtstreekse maat om de invloed van elke observatie op de regressie-analyse uit te drukken is de <em>Cook’s distance</em>. De Cook’s distance voor de <span class="math inline">\(i\)</span>-de observatie is een diagnostische maat voor de invloed van die observatie op alle predicties of, equivalent, voor haar invloed op <em>alle</em> geschatte parameters. Men bekomt deze door elke predictie <span class="math inline">\(\hat{Y}_j\)</span> die men op basis van het regressiemodel heeft bekomen voor de <span class="math inline">\(j\)</span>-de uitkomst, <span class="math inline">\(j=1,...,n\)</span>, te vergelijken met de overeenkomstige predictie <span class="math inline">\(\hat{Y}_{j(i)}\)</span> die men zou bekomen indien de <span class="math inline">\(i\)</span>-de observatie niet gebruikt werd om het regressiemodel te fitten <span class="math display">\[D_i=\frac{\sum_{j=1}^n(\hat{Y}_j-\hat{Y}_{j(i)})^2}{p\textrm{MSE}}\]</span> Indien de Cook’s distance <span class="math inline">\(D_i\)</span> groot is, dan heeft de <span class="math inline">\(i\)</span>-de observatie een grote invloed op de predicties en geschatte parameters. In het bijzonder stelt men dat een extreme Cook’s distance het 50% percentiel van de <span class="math inline">\(F_{p+1,n-(p+1)}\)</span>-verdeling overschrijdt.</p>
<p>Deze plots komen standaard bij diagnose van het lineair model. We evalueren dit voor het additieve model en het model met de lcavol:lweight interactie voor de prostaatkanker studie.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lmVWS,<span class="dt">which=</span><span class="dv">5</span>)
<span class="kw">plot</span>(lmVWS_IntVW,<span class="dt">which=</span><span class="dv">5</span>)
<span class="kw">plot</span>(<span class="kw">cooks.distance</span>(lmVWS),<span class="dt">type=</span><span class="st">&quot;h&quot;</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="dt">main=</span><span class="st">&quot;Additive model&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">qf</span>(<span class="fl">0.5</span>,<span class="kw">length</span>(lmVWS<span class="op">$</span>coef),<span class="kw">nrow</span>(prostate)<span class="op">-</span><span class="kw">length</span>(lmVWS<span class="op">$</span>coef)),<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">plot</span>(<span class="kw">cooks.distance</span>(lmVWS_IntVW),<span class="dt">type=</span><span class="st">&quot;h&quot;</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">main=</span><span class="st">&quot;Model with lcavol:lweight interaction&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">qf</span>(<span class="fl">0.5</span>,<span class="kw">length</span>(lmVWS_IntVW<span class="op">$</span>coef),<span class="kw">nrow</span>(prostate)<span class="op">-</span><span class="kw">length</span>(lmVWS_IntVW<span class="op">$</span>coef)),<span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:prosCooksAdditiveInt"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosCooksAdditiveInt-1.png" alt="Evaluatie van de invloed van individuele observaties op het additieve model (links) en het model met de lcavol:lweight interactie (rechts)." width="100%" />
<p class="caption">
Figuur 10.8: Evaluatie van de invloed van individuele observaties op het additieve model (links) en het model met de lcavol:lweight interactie (rechts).
</p>
</div>
<p>Het is duidelijk dat observatie 32 een grote leverage heeft. Het heeft in het model met interactie ook de grootste invloed van alle datapunten op de fit van het model.</p>
<p>Eenmaal men vastgesteld heeft dat een observatie invloedrijk is, kan men zogenaamde <em>DFBETAS</em> gebruiken om te bepalen op welke parameter(s) ze een grote invloed uitoefent. De DFBETAS van de <span class="math inline">\(i\)</span>-de observatie vormen een diagnostische maat voor de invloed van die observatie <em>op elke regressieparameter afzonderlijk</em>, in tegenstelling tot de Cook’s distance die de invloed op alle parameters tegelijk evalueert. In het bijzonder bekomt men de DFBETAS voor de <span class="math inline">\(i\)</span>-de observatie en de <span class="math inline">\(j\)</span>-de parameter door de <span class="math inline">\(j\)</span>-de parameter <span class="math inline">\(\hat{\beta}_j\)</span> te vergelijken met de parameter <span class="math inline">\(\hat{\beta}_{j(i)}\)</span> die men zou bekomen indien het regressiemodel gefit werd zonder de <span class="math inline">\(i\)</span>-de observatie in de analyse te betrekken: <span class="math display">\[\textrm{DFBETAS}_{j(i)}=\frac{\hat{\beta}_{j}-\hat{\beta}_{j(i)}}{\textrm{SD}(\hat{\beta}_{j})}\]</span> Uit bovenstaande uitdrukking volgt dat het teken van de DFBETAS voor de <span class="math inline">\(i\)</span>-de observatie aangeeft of het weglaten van die observatie uit de analyse een stijging (DFBETAS<span class="math inline">\(&lt;0\)</span>) of daling (DFBETAS<span class="math inline">\(&gt;0\)</span>) in de overeenkomstige parameter veroorzaakt. In het bijzonder stelt men dat een DFBETAS extreem is wanneer ze 1 overschrijdt in kleine tot middelgrote datasets en <span class="math inline">\(2/\sqrt{n}\)</span> overschrijdt in grote datasets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">dfbetasPlots</span>(lmVWS)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:prosDfBetasAdditive"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosDfBetasAdditive-1.png" alt="DFBETAS voor additieve model in prostaatkanker." width="100%" />
<p class="caption">
Figuur 10.9: DFBETAS voor additieve model in prostaatkanker.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">dfbetasPlots</span>(lmVWS_IntVW)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:prosDfBetasInt"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosDfBetasInt-1.png" alt="DFBETAS voor model met lcavol:lweight interactie." width="100%" />
<p class="caption">
Figuur 10.10: DFBETAS voor model met lcavol:lweight interactie.
</p>
</div>
<p>De Cooks distances en de DFBETAS plots geven aan dat observatie 32 het grootste effect heeft op de regressieparameters. Daarnaast heeft deze observatie ook een extreme “influence”.</p>
<p>We gaan observatie 32 nu wat beter bestuderen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(prostate[<span class="dv">32</span>,<span class="st">&quot;lweight&quot;</span>])</code></pre></div>
<pre><code>## [1] 449.25</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxplot</span>(<span class="kw">exp</span>(prostate<span class="op">$</span>lweight),<span class="dt">ylab=</span><span class="st">&quot;Prostaatgewicht (g)&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:prosInfl"></span>
<img src="Statistiek_2019_2020_files/figure-html/prosInfl-1.png" alt="Boxplot met outlier voor prostaatgewicht." width="100%" />
<p class="caption">
Figuur 10.11: Boxplot met outlier voor prostaatgewicht.
</p>
</div>
<p>Wanneer we het gewicht terugtransformeren naar de originele schaal zien we dat het prostaatgewicht voor deze patiënt449.25g bedraagt. De prostaat van een man heeft gewoonlijk een gewicht van 20-30 gram en het kan vergroten tot 50-100 gram. Een prostaatgewicht van meer dan 400 gram komt dus niet voor. De auteurs die de dataset uit de originele publicatie hebben opgenomen in een handboek, hebben gerapporteerd dat ze een tikfout hebben gemaakt en ze hebben het extreme prostaat gewicht later gecorrigeerd naar 49.25 gram, het gewicht dat in de originele publicatie werd gerapporteerd.</p>
<p>Ga zelf na welke invloed het corrigeren van het prostaatgewicht heeft op het geschatte regressiemodel.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-categorisch.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-modsel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-GeneralLinearModel.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Statistiek_2019_2020.pdf", "Statistiek_2019_2020.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
