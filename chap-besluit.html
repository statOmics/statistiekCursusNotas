<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Hoofdstuk 5 Statistische besluitvorming | Cursus Statistiek 2019-2020</title>
  <meta name="description" content="Basiscursus Statistiek voor de 2de Bachelor of Science in de Biologie, - in de Biochemie &amp; de Biotechnologie, - in de Biomedische Wetenschappen, en - in de Chemie" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Hoofdstuk 5 Statistische besluitvorming | Cursus Statistiek 2019-2020" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Basiscursus Statistiek voor de 2de Bachelor of Science in de Biologie, - in de Biochemie &amp; de Biotechnologie, - in de Biomedische Wetenschappen, en - in de Chemie" />
  <meta name="github-repo" content="statOmics/statistiek2deBach" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Hoofdstuk 5 Statistische besluitvorming | Cursus Statistiek 2019-2020" />
  
  <meta name="twitter:description" content="Basiscursus Statistiek voor de 2de Bachelor of Science in de Biologie, - in de Biochemie &amp; de Biotechnologie, - in de Biomedische Wetenschappen, en - in de Chemie" />
  

<meta name="author" content="Lieven Clement" />


<meta name="date" content="2019-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-describe.html">
<link rel="next" href="chap-linReg.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cursus Statistiek 2019-2020</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Woord vooraf</a></li>
<li class="chapter" data-level="" data-path="links.html"><a href="links.html"><i class="fa fa-check"></i>Links</a></li>
<li class="chapter" data-level="1" data-path="inleiding.html"><a href="inleiding.html"><i class="fa fa-check"></i><b>1</b> Inleiding</a><ul>
<li class="chapter" data-level="1.1" data-path="inleiding.html"><a href="inleiding.html#sec:wetMeth"><i class="fa fa-check"></i><b>1.1</b> De Wetenschappelijke Methode</a></li>
<li class="chapter" data-level="1.2" data-path="inleiding.html"><a href="inleiding.html#voorbeeld-horizon---homeopathy-the-test"><i class="fa fa-check"></i><b>1.2</b> Voorbeeld: Horizon - Homeopathy the test</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inleiding.html"><a href="inleiding.html#wetenschappelijke-hypothese-fragmenten-1-2-000-600-740-1130"><i class="fa fa-check"></i><b>1.2.1</b> Wetenschappelijke hypothese (fragmenten 1-2: 0’00’‘-6’00’‘&amp; 7’40’‘-11’30’’)</a></li>
<li class="chapter" data-level="1.2.2" data-path="inleiding.html"><a href="inleiding.html#onderzoek-dient-reproduceerbaar-te-zijn.-wat-ging-er-fout-fragment-1450-1856"><i class="fa fa-check"></i><b>1.2.2</b> Onderzoek dient reproduceerbaar te zijn. Wat ging er fout? (Fragment: 14’50”-18’56”)</a></li>
<li class="chapter" data-level="1.2.3" data-path="inleiding.html"><a href="inleiding.html#the-ultimate-test---proefopzet-fragment-3100-3930"><i class="fa fa-check"></i><b>1.2.3</b> The ultimate test - proefopzet (Fragment 31’00-39’30’’)</a></li>
<li class="chapter" data-level="1.2.4" data-path="inleiding.html"><a href="inleiding.html#the-ultimate-test---data-analyse-fragment-3930-4300"><i class="fa fa-check"></i><b>1.2.4</b> The ultimate test - data analyse (Fragment 39’30-43’00’’)</a></li>
<li class="chapter" data-level="1.2.5" data-path="inleiding.html"><a href="inleiding.html#mogelijke-fouten"><i class="fa fa-check"></i><b>1.2.5</b> Mogelijke fouten</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html"><i class="fa fa-check"></i><b>2</b> Belangrijke concepten &amp; conventies</a><ul>
<li class="chapter" data-level="2.1" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#variabelen"><i class="fa fa-check"></i><b>2.1</b> Variabelen</a></li>
<li class="chapter" data-level="2.2" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#subsec:pop"><i class="fa fa-check"></i><b>2.2</b> Populatie</a></li>
<li class="chapter" data-level="2.3" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#toevalsveranderlijken-of-toevallige-veranderlijken"><i class="fa fa-check"></i><b>2.3</b> Toevalsveranderlijken (of toevallige veranderlijken)</a></li>
<li class="chapter" data-level="2.4" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#beschrijven-van-de-populatie"><i class="fa fa-check"></i><b>2.4</b> Beschrijven van de populatie</a></li>
<li class="chapter" data-level="2.5" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#steekproef"><i class="fa fa-check"></i><b>2.5</b> Steekproef</a></li>
<li class="chapter" data-level="2.6" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#schatten-van-de-verdeling-in-de-populatie"><i class="fa fa-check"></i><b>2.6</b> Schatten van de verdeling in de populatie</a></li>
<li class="chapter" data-level="2.7" data-path="belangrijke-concepten-conventies.html"><a href="belangrijke-concepten-conventies.html#statistieken"><i class="fa fa-check"></i><b>2.7</b> Statistieken</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap-design.html"><a href="chap-design.html"><i class="fa fa-check"></i><b>3</b> Studiedesign</a><ul>
<li class="chapter" data-level="3.1" data-path="chap-design.html"><a href="chap-design.html#inleiding-1"><i class="fa fa-check"></i><b>3.1</b> Inleiding</a></li>
<li class="chapter" data-level="3.2" data-path="chap-design.html"><a href="chap-design.html#sec:steekproefdesigns"><i class="fa fa-check"></i><b>3.2</b> Steekproefdesigns</a><ul>
<li class="chapter" data-level="3.2.1" data-path="chap-design.html"><a href="chap-design.html#replicatie"><i class="fa fa-check"></i><b>3.2.1</b> Replicatie</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="chap-design.html"><a href="chap-design.html#experimentele-studies"><i class="fa fa-check"></i><b>3.3</b> Experimentele studies</a><ul>
<li class="chapter" data-level="3.3.1" data-path="chap-design.html"><a href="chap-design.html#de-salk-vaccin-veldstudie"><i class="fa fa-check"></i><b>3.3.1</b> De Salk Vaccin Veldstudie</a></li>
<li class="chapter" data-level="3.3.2" data-path="chap-design.html"><a href="chap-design.html#gerandomiseerd-gecontroleerde-studies"><i class="fa fa-check"></i><b>3.3.2</b> Gerandomiseerd gecontroleerde studies</a></li>
<li class="chapter" data-level="3.3.3" data-path="chap-design.html"><a href="chap-design.html#parallelle-designs"><i class="fa fa-check"></i><b>3.3.3</b> Parallelle designs</a></li>
<li class="chapter" data-level="3.3.4" data-path="chap-design.html"><a href="chap-design.html#cross-over-designs"><i class="fa fa-check"></i><b>3.3.4</b> Cross-over designs</a></li>
<li class="chapter" data-level="3.3.5" data-path="chap-design.html"><a href="chap-design.html#factoriele-designs"><i class="fa fa-check"></i><b>3.3.5</b> Factoriële designs</a></li>
<li class="chapter" data-level="3.3.6" data-path="chap-design.html"><a href="chap-design.html#quasi-experimentele-designs"><i class="fa fa-check"></i><b>3.3.6</b> Quasi-experimentele designs</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chap-design.html"><a href="chap-design.html#sec:observational"><i class="fa fa-check"></i><b>3.4</b> Observationele studies</a></li>
<li class="chapter" data-level="3.5" data-path="chap-design.html"><a href="chap-design.html#subsec:design:prosp"><i class="fa fa-check"></i><b>3.5</b> Prospectieve studies</a></li>
<li class="chapter" data-level="3.6" data-path="chap-design.html"><a href="chap-design.html#subsec:design:retro"><i class="fa fa-check"></i><b>3.6</b> Retrospectieve studies</a></li>
<li class="chapter" data-level="3.7" data-path="chap-design.html"><a href="chap-design.html#niet-gecontroleerde-studies"><i class="fa fa-check"></i><b>3.7</b> Niet-gecontroleerde studies</a><ul>
<li class="chapter" data-level="3.7.1" data-path="chap-design.html"><a href="chap-design.html#subsec:prepost"><i class="fa fa-check"></i><b>3.7.1</b> Pre-test/Post-test studies</a></li>
<li class="chapter" data-level="3.7.2" data-path="chap-design.html"><a href="chap-design.html#cross-sectionele-surveys"><i class="fa fa-check"></i><b>3.7.2</b> Cross-sectionele surveys</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap-describe.html"><a href="chap-describe.html"><i class="fa fa-check"></i><b>4</b> Data exploratie en beschrijvende statistiek</a><ul>
<li class="chapter" data-level="4.1" data-path="chap-describe.html"><a href="chap-describe.html#inleiding-2"><i class="fa fa-check"></i><b>4.1</b> Inleiding</a></li>
<li class="chapter" data-level="4.2" data-path="chap-describe.html"><a href="chap-describe.html#sec:univar"><i class="fa fa-check"></i><b>4.2</b> Univariate beschrijving van de variabelen</a></li>
<li class="chapter" data-level="4.3" data-path="chap-describe.html"><a href="chap-describe.html#sec:summarize"><i class="fa fa-check"></i><b>4.3</b> Samenvattingsmaten voor continue variabelen</a><ul>
<li class="chapter" data-level="4.3.1" data-path="chap-describe.html"><a href="chap-describe.html#maten-voor-de-centrale-ligging"><i class="fa fa-check"></i><b>4.3.1</b> Maten voor de centrale ligging</a></li>
<li class="chapter" data-level="4.3.2" data-path="chap-describe.html"><a href="chap-describe.html#subsec:spreiding"><i class="fa fa-check"></i><b>4.3.2</b> Spreidingsmaten</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chap-describe.html"><a href="chap-describe.html#sec:normal"><i class="fa fa-check"></i><b>4.4</b> De Normale benadering van gegevens</a><ul>
<li class="chapter" data-level="4.4.1" data-path="chap-describe.html"><a href="chap-describe.html#subsec:normalcalc"><i class="fa fa-check"></i><b>4.4.1</b> Bepalen van oppervlaktes onder de Normale curve</a></li>
<li class="chapter" data-level="4.4.2" data-path="chap-describe.html"><a href="chap-describe.html#sec:qq"><i class="fa fa-check"></i><b>4.4.2</b> QQ-plots</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chap-describe.html"><a href="chap-describe.html#sec:explCatVar"><i class="fa fa-check"></i><b>4.5</b> Samenvattingsmaten voor categorische variabelen</a><ul>
<li class="chapter" data-level="4.5.1" data-path="chap-describe.html"><a href="chap-describe.html#prospectieve-studies-en-lukrake-steekproeven"><i class="fa fa-check"></i><b>4.5.1</b> Prospectieve studies en lukrake steekproeven</a></li>
<li class="chapter" data-level="4.5.2" data-path="chap-describe.html"><a href="chap-describe.html#subsec:retrospect"><i class="fa fa-check"></i><b>4.5.2</b> Retrospectieve studies</a></li>
<li class="chapter" data-level="4.5.3" data-path="chap-describe.html"><a href="chap-describe.html#rates-versus-risicos"><i class="fa fa-check"></i><b>4.5.3</b> Rates versus risico’s</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="chap-describe.html"><a href="chap-describe.html#associaties-tussen-twee-variabelen"><i class="fa fa-check"></i><b>4.6</b> Associaties tussen twee variabelen</a><ul>
<li class="chapter" data-level="4.6.1" data-path="chap-describe.html"><a href="chap-describe.html#subsec:kruistabel"><i class="fa fa-check"></i><b>4.6.1</b> Associatie tussen twee kwalitatieve variabelen</a></li>
<li class="chapter" data-level="4.6.2" data-path="chap-describe.html"><a href="chap-describe.html#subsec:asskwalcont"><i class="fa fa-check"></i><b>4.6.2</b> Associatie tussen één kwalitatieve en één continue variabele</a></li>
<li class="chapter" data-level="4.6.3" data-path="chap-describe.html"><a href="chap-describe.html#sec:correlatie"><i class="fa fa-check"></i><b>4.6.3</b> Associatie tussen twee continue variabelen</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="chap-describe.html"><a href="chap-describe.html#sec:missing"><i class="fa fa-check"></i><b>4.7</b> Onvolledige gegevens</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap-besluit.html"><a href="chap-besluit.html"><i class="fa fa-check"></i><b>5</b> Statistische besluitvorming</a><ul>
<li class="chapter" data-level="5.1" data-path="chap-besluit.html"><a href="chap-besluit.html#inleiding-3"><i class="fa fa-check"></i><b>5.1</b> Inleiding</a></li>
<li class="chapter" data-level="5.2" data-path="chap-besluit.html"><a href="chap-besluit.html#captopril-voorbeeld"><i class="fa fa-check"></i><b>5.2</b> Captopril voorbeeld</a><ul>
<li class="chapter" data-level="5.2.1" data-path="chap-besluit.html"><a href="chap-besluit.html#proefopzet"><i class="fa fa-check"></i><b>5.2.1</b> Proefopzet</a></li>
<li class="chapter" data-level="5.2.2" data-path="chap-besluit.html"><a href="chap-besluit.html#data-exploratie-beschrijvende-statistiek"><i class="fa fa-check"></i><b>5.2.2</b> Data Exploratie &amp; Beschrijvende Statistiek</a></li>
<li class="chapter" data-level="5.2.3" data-path="chap-besluit.html"><a href="chap-besluit.html#schatten"><i class="fa fa-check"></i><b>5.2.3</b> Schatten</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chap-besluit.html"><a href="chap-besluit.html#puntschatters-het-steekproefgemiddelde"><i class="fa fa-check"></i><b>5.3</b> Puntschatters: het steekproefgemiddelde</a><ul>
<li class="chapter" data-level="5.3.1" data-path="chap-besluit.html"><a href="chap-besluit.html#het-steekproefgemiddelde-is-onvertekend"><i class="fa fa-check"></i><b>5.3.1</b> Het steekproefgemiddelde is onvertekend</a></li>
<li class="chapter" data-level="5.3.2" data-path="chap-besluit.html"><a href="chap-besluit.html#imprecisiestandard-error"><i class="fa fa-check"></i><b>5.3.2</b> Imprecisie/standard error</a></li>
<li class="chapter" data-level="5.3.3" data-path="chap-besluit.html"><a href="chap-besluit.html#subsec:verdelingXbar"><i class="fa fa-check"></i><b>5.3.3</b> Verdeling van het steekproefgemiddelde</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="chap-besluit.html"><a href="chap-besluit.html#intervalschatters"><i class="fa fa-check"></i><b>5.4</b> Intervalschatters</a><ul>
<li class="chapter" data-level="5.4.1" data-path="chap-besluit.html"><a href="chap-besluit.html#subsec:bigek"><i class="fa fa-check"></i><b>5.4.1</b> Gekende variantie op de metingen</a></li>
<li class="chapter" data-level="5.4.2" data-path="chap-besluit.html"><a href="chap-besluit.html#sec:tBI"><i class="fa fa-check"></i><b>5.4.2</b> Ongekende variantie op de metingen</a></li>
<li class="chapter" data-level="5.4.3" data-path="chap-besluit.html"><a href="chap-besluit.html#subsec:interpretBI"><i class="fa fa-check"></i><b>5.4.3</b> Interpretatie van betrouwbaarheidsintervallen</a></li>
<li class="chapter" data-level="5.4.4" data-path="chap-besluit.html"><a href="chap-besluit.html#wat-rapporteren"><i class="fa fa-check"></i><b>5.4.4</b> Wat rapporteren?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chap-besluit.html"><a href="chap-besluit.html#principe-van-hypothesetoetsen-via-one-sample-t-test"><i class="fa fa-check"></i><b>5.5</b> Principe van Hypothesetoetsen (via one sample t-test)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="chap-besluit.html"><a href="chap-besluit.html#hypotheses"><i class="fa fa-check"></i><b>5.5.1</b> Hypotheses</a></li>
<li class="chapter" data-level="5.5.2" data-path="chap-besluit.html"><a href="chap-besluit.html#test-statistiek"><i class="fa fa-check"></i><b>5.5.2</b> Test-statistiek</a></li>
<li class="chapter" data-level="5.5.3" data-path="chap-besluit.html"><a href="chap-besluit.html#de-p-waarde"><i class="fa fa-check"></i><b>5.5.3</b> De p-waarde</a></li>
<li class="chapter" data-level="5.5.4" data-path="chap-besluit.html"><a href="chap-besluit.html#kritieke-waarde"><i class="fa fa-check"></i><b>5.5.4</b> Kritieke waarde</a></li>
<li class="chapter" data-level="5.5.5" data-path="chap-besluit.html"><a href="chap-besluit.html#beslissingsfouten"><i class="fa fa-check"></i><b>5.5.5</b> Beslissingsfouten</a></li>
<li class="chapter" data-level="5.5.6" data-path="chap-besluit.html"><a href="chap-besluit.html#conclusies-captopril-voorbeeld."><i class="fa fa-check"></i><b>5.5.6</b> Conclusies Captopril voorbeeld.</a></li>
<li class="chapter" data-level="5.5.7" data-path="chap-besluit.html"><a href="chap-besluit.html#eenzijdig-of-tweezijdig-toetsen"><i class="fa fa-check"></i><b>5.5.7</b> Eenzijdig of tweezijdig toetsen?</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="chap-besluit.html"><a href="chap-besluit.html#two-sample-t-test"><i class="fa fa-check"></i><b>5.6</b> Two-sample t-test</a><ul>
<li class="chapter" data-level="5.6.1" data-path="chap-besluit.html"><a href="chap-besluit.html#oksel-voorbeeld"><i class="fa fa-check"></i><b>5.6.1</b> Oksel-voorbeeld</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="chap-besluit.html"><a href="chap-besluit.html#aannames"><i class="fa fa-check"></i><b>5.7</b> Aannames</a><ul>
<li class="chapter" data-level="5.7.1" data-path="chap-besluit.html"><a href="chap-besluit.html#nagaan-van-de-veronderstelling-van-normaliteit"><i class="fa fa-check"></i><b>5.7.1</b> Nagaan van de veronderstelling van Normaliteit</a></li>
<li class="chapter" data-level="5.7.2" data-path="chap-besluit.html"><a href="chap-besluit.html#nagaan-van-homoscedasticiteit"><i class="fa fa-check"></i><b>5.7.2</b> Nagaan van homoscedasticiteit</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="chap-besluit.html"><a href="chap-besluit.html#wat-rapporteren-1"><i class="fa fa-check"></i><b>5.8</b> Wat rapporteren?</a><ul>
<li class="chapter" data-level="5.8.1" data-path="chap-besluit.html"><a href="chap-besluit.html#reden-1-relatie-toetsen-en-betrouwbaarheidsintervallen"><i class="fa fa-check"></i><b>5.8.1</b> Reden 1: Relatie toetsen en betrouwbaarheidsintervallen</a></li>
<li class="chapter" data-level="5.8.2" data-path="chap-besluit.html"><a href="chap-besluit.html#reden-2-statistische-significantie-versus-wetenschappelijke-relevantie"><i class="fa fa-check"></i><b>5.8.2</b> Reden 2: Statistische significantie versus wetenschappelijke relevantie</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="chap-besluit.html"><a href="chap-besluit.html#equivalentie-intervallen"><i class="fa fa-check"></i><b>5.9</b> Equivalentie-intervallen</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap-linReg.html"><a href="chap-linReg.html"><i class="fa fa-check"></i><b>6</b> Enkelvoudige lineaire regressie</a><ul>
<li class="chapter" data-level="6.1" data-path="chap-linReg.html"><a href="chap-linReg.html#inleiding-4"><i class="fa fa-check"></i><b>6.1</b> Inleiding</a><ul>
<li class="chapter" data-level="6.1.1" data-path="chap-linReg.html"><a href="chap-linReg.html#borstkanker-dataset"><i class="fa fa-check"></i><b>6.1.1</b> Borstkanker dataset</a></li>
<li class="chapter" data-level="6.1.2" data-path="chap-linReg.html"><a href="chap-linReg.html#data-exploratie"><i class="fa fa-check"></i><b>6.1.2</b> Data exploratie</a></li>
<li class="chapter" data-level="6.1.3" data-path="chap-linReg.html"><a href="chap-linReg.html#model"><i class="fa fa-check"></i><b>6.1.3</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="chap-linReg.html"><a href="chap-linReg.html#lineaire-regressie"><i class="fa fa-check"></i><b>6.2</b> Lineaire regressie</a></li>
<li class="chapter" data-level="6.3" data-path="chap-linReg.html"><a href="chap-linReg.html#parameterschatting"><i class="fa fa-check"></i><b>6.3</b> Parameterschatting</a></li>
<li class="chapter" data-level="6.4" data-path="chap-linReg.html"><a href="chap-linReg.html#sec:linBesluit"><i class="fa fa-check"></i><b>6.4</b> Statistische besluitvorming</a></li>
<li class="chapter" data-level="6.5" data-path="chap-linReg.html"><a href="chap-linReg.html#nagaan-van-modelveronderstellingen"><i class="fa fa-check"></i><b>6.5</b> Nagaan van modelveronderstellingen</a><ul>
<li class="chapter" data-level="6.5.1" data-path="chap-linReg.html"><a href="chap-linReg.html#lineariteit"><i class="fa fa-check"></i><b>6.5.1</b> Lineariteit</a></li>
<li class="chapter" data-level="6.5.2" data-path="chap-linReg.html"><a href="chap-linReg.html#veronderstelling-van-homoscedasticiteit-gelijkheid-van-variantie"><i class="fa fa-check"></i><b>6.5.2</b> Veronderstelling van homoscedasticiteit (gelijkheid van variantie)</a></li>
<li class="chapter" data-level="6.5.3" data-path="chap-linReg.html"><a href="chap-linReg.html#veronderstelling-van-normaliteit"><i class="fa fa-check"></i><b>6.5.3</b> Veronderstelling van normaliteit</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="chap-linReg.html"><a href="chap-linReg.html#afwijkingen-van-modelveronderstellingen"><i class="fa fa-check"></i><b>6.6</b> Afwijkingen van Modelveronderstellingen</a></li>
<li class="chapter" data-level="6.7" data-path="chap-linReg.html"><a href="chap-linReg.html#besluitvorming-over-gemiddelde-uitkomst"><i class="fa fa-check"></i><b>6.7</b> Besluitvorming over gemiddelde uitkomst</a></li>
<li class="chapter" data-level="6.8" data-path="chap-linReg.html"><a href="chap-linReg.html#predictie-intervallen"><i class="fa fa-check"></i><b>6.8</b> Predictie-intervallen</a></li>
<li class="chapter" data-level="6.9" data-path="chap-linReg.html"><a href="chap-linReg.html#sec:linAnova"><i class="fa fa-check"></i><b>6.9</b> Kwadratensommen en Anova-tabel</a><ul>
<li class="chapter" data-level="6.9.1" data-path="chap-linReg.html"><a href="chap-linReg.html#determinatie-coefficient"><i class="fa fa-check"></i><b>6.9.1</b> Determinatie-coëfficiënt</a></li>
<li class="chapter" data-level="6.9.2" data-path="chap-linReg.html"><a href="chap-linReg.html#f-testen-in-het-enkelvoudig-lineair-regressiemodel"><i class="fa fa-check"></i><b>6.9.2</b> F-Testen in het enkelvoudig lineair regressiemodel</a></li>
<li class="chapter" data-level="6.9.3" data-path="chap-linReg.html"><a href="chap-linReg.html#anova-tabel"><i class="fa fa-check"></i><b>6.9.3</b> Anova Tabel</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="chap-linReg.html"><a href="chap-linReg.html#sec:linDummy"><i class="fa fa-check"></i><b>6.10</b> Dummy variabelen</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-anova.html"><a href="chap-anova.html"><i class="fa fa-check"></i><b>7</b> Variantie analyse</a><ul>
<li class="chapter" data-level="7.1" data-path="chap-anova.html"><a href="chap-anova.html#inleiding-5"><i class="fa fa-check"></i><b>7.1</b> Inleiding</a><ul>
<li class="chapter" data-level="7.1.1" data-path="chap-anova.html"><a href="chap-anova.html#prostacycline-voorbeeld"><i class="fa fa-check"></i><b>7.1.1</b> Prostacycline voorbeeld</a></li>
<li class="chapter" data-level="7.1.2" data-path="chap-anova.html"><a href="chap-anova.html#model-1"><i class="fa fa-check"></i><b>7.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chap-anova.html"><a href="chap-anova.html#variantie-analyse"><i class="fa fa-check"></i><b>7.2</b> Variantie-analyse</a><ul>
<li class="chapter" data-level="7.2.1" data-path="chap-anova.html"><a href="chap-anova.html#model-2"><i class="fa fa-check"></i><b>7.2.1</b> Model</a></li>
<li class="chapter" data-level="7.2.2" data-path="chap-anova.html"><a href="chap-anova.html#kwadratensommen-en-anova"><i class="fa fa-check"></i><b>7.2.2</b> Kwadratensommen en Anova</a></li>
<li class="chapter" data-level="7.2.3" data-path="chap-anova.html"><a href="chap-anova.html#anova-test"><i class="fa fa-check"></i><b>7.2.3</b> Anova-test</a></li>
<li class="chapter" data-level="7.2.4" data-path="chap-anova.html"><a href="chap-anova.html#anova-tabel-1"><i class="fa fa-check"></i><b>7.2.4</b> Anova Tabel</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="chap-anova.html"><a href="chap-anova.html#post-hoc-analyse-meervoudig-vergelijken-van-gemiddelden"><i class="fa fa-check"></i><b>7.3</b> Post hoc analyse: Meervoudig Vergelijken van Gemiddelden</a><ul>
<li class="chapter" data-level="7.3.1" data-path="chap-anova.html"><a href="chap-anova.html#naieve-methode"><i class="fa fa-check"></i><b>7.3.1</b> Naïeve methode</a></li>
<li class="chapter" data-level="7.3.2" data-path="chap-anova.html"><a href="chap-anova.html#family-wise-error-rate"><i class="fa fa-check"></i><b>7.3.2</b> Family-wise error rate</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="chap-anova.html"><a href="chap-anova.html#conclusies-prostacycline-voorbeeld"><i class="fa fa-check"></i><b>7.4</b> Conclusies: Prostacycline Voorbeeld</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html"><i class="fa fa-check"></i><b>8</b> Niet-parametrische statistiek</a><ul>
<li class="chapter" data-level="8.1" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#inleiding-6"><i class="fa fa-check"></i><b>8.1</b> Inleiding</a></li>
<li class="chapter" data-level="8.2" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#vergelijken-van-twee-groepen"><i class="fa fa-check"></i><b>8.2</b> Vergelijken van twee groepen</a><ul>
<li class="chapter" data-level="8.2.1" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#cholestorol-voorbeeld"><i class="fa fa-check"></i><b>8.2.1</b> Cholestorol voorbeeld</a></li>
<li class="chapter" data-level="8.2.2" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#permutatietesten"><i class="fa fa-check"></i><b>8.2.2</b> Permutatietesten</a></li>
<li class="chapter" data-level="8.2.3" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#rank-testen"><i class="fa fa-check"></i><b>8.2.3</b> Rank Testen</a></li>
<li class="chapter" data-level="8.2.4" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#wilcoxon-mann-whitney-test"><i class="fa fa-check"></i><b>8.2.4</b> Wilcoxon-Mann-Whitney Test</a></li>
<li class="chapter" data-level="8.2.5" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#conclusie-cholestorol-voorbeeld"><i class="fa fa-check"></i><b>8.2.5</b> Conclusie Cholestorol Voorbeeld</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#vergelijken-van-g-behandelingen"><i class="fa fa-check"></i><b>8.3</b> Vergelijken van <span class="math inline">\(g\)</span> Behandelingen</a><ul>
<li class="chapter" data-level="8.3.1" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#dmh-voorbeeld"><i class="fa fa-check"></i><b>8.3.1</b> DMH Voorbeeld</a></li>
<li class="chapter" data-level="8.3.2" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#permutatietest"><i class="fa fa-check"></i><b>8.3.2</b> Permutatietest</a></li>
<li class="chapter" data-level="8.3.3" data-path="niet-parametrische-statistiek.html"><a href="niet-parametrische-statistiek.html#kruskal-wallis-rank-test"><i class="fa fa-check"></i><b>8.3.3</b> Kruskal-Wallis Rank Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chap-categorisch.html"><a href="chap-categorisch.html"><i class="fa fa-check"></i><b>9</b> Categorische data analyse</a><ul>
<li class="chapter" data-level="9.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#inleiding-7"><i class="fa fa-check"></i><b>9.1</b> Inleiding</a></li>
<li class="chapter" data-level="9.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#toetsen-voor-een-proportie"><i class="fa fa-check"></i><b>9.2</b> Toetsen voor een proportie</a><ul>
<li class="chapter" data-level="9.2.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#subsec:binom"><i class="fa fa-check"></i><b>9.2.1</b> Binomiale test</a></li>
<li class="chapter" data-level="9.2.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#betrouwbaarheidsinterval-op-een-proportie"><i class="fa fa-check"></i><b>9.2.2</b> Betrouwbaarheidsinterval op een proportie</a></li>
<li class="chapter" data-level="9.2.3" data-path="chap-categorisch.html"><a href="chap-categorisch.html#conclusie"><i class="fa fa-check"></i><b>9.2.3</b> Conclusie</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="chap-categorisch.html"><a href="chap-categorisch.html#toets-voor-associatie-tussen-2-kwalitatieve-variabelen"><i class="fa fa-check"></i><b>9.3</b> Toets voor associatie tussen 2 kwalitatieve variabelen</a><ul>
<li class="chapter" data-level="9.3.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#gepaarde-gegevens"><i class="fa fa-check"></i><b>9.3.1</b> Gepaarde gegevens</a></li>
<li class="chapter" data-level="9.3.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#subsec:catOnPaired"><i class="fa fa-check"></i><b>9.3.2</b> Ongepaarde gegevens</a></li>
<li class="chapter" data-level="9.3.3" data-path="chap-categorisch.html"><a href="chap-categorisch.html#de-pearson-chi-kwadraat-test-voor-ongepaarde-gegevens"><i class="fa fa-check"></i><b>9.3.3</b> De Pearson Chi-kwadraat test voor ongepaarde gegevens</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chap-categorisch.html"><a href="chap-categorisch.html#logistische-regressie"><i class="fa fa-check"></i><b>9.4</b> Logistische regressie</a><ul>
<li class="chapter" data-level="9.4.1" data-path="chap-categorisch.html"><a href="chap-categorisch.html#categorische-predictor"><i class="fa fa-check"></i><b>9.4.1</b> Categorische predictor</a></li>
<li class="chapter" data-level="9.4.2" data-path="chap-categorisch.html"><a href="chap-categorisch.html#continue-predictor"><i class="fa fa-check"></i><b>9.4.2</b> Continue predictor</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap-glm.html"><a href="chap-glm.html"><i class="fa fa-check"></i><b>10</b> Algemeen lineair model</a><ul>
<li class="chapter" data-level="10.1" data-path="chap-glm.html"><a href="chap-glm.html#inleiding-8"><i class="fa fa-check"></i><b>10.1</b> Inleiding</a><ul>
<li class="chapter" data-level="10.1.1" data-path="chap-glm.html"><a href="chap-glm.html#sec:prostate"><i class="fa fa-check"></i><b>10.1.1</b> Prostaatkanker dataset</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="chap-glm.html"><a href="chap-glm.html#het-additieve-meervoudig-lineaire-regressie-model"><i class="fa fa-check"></i><b>10.2</b> Het additieve meervoudig lineaire regressie model</a><ul>
<li class="chapter" data-level="10.2.1" data-path="chap-glm.html"><a href="chap-glm.html#statistisch-model"><i class="fa fa-check"></i><b>10.2.1</b> Statistisch model</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chap-glm.html"><a href="chap-glm.html#besluitvorming-in-regressiemodellen"><i class="fa fa-check"></i><b>10.3</b> Besluitvorming in regressiemodellen</a></li>
<li class="chapter" data-level="10.4" data-path="chap-glm.html"><a href="chap-glm.html#nagaan-van-modelveronderstellingen-1"><i class="fa fa-check"></i><b>10.4</b> Nagaan van modelveronderstellingen</a><ul>
<li class="chapter" data-level="10.4.1" data-path="chap-glm.html"><a href="chap-glm.html#lineariteit-1"><i class="fa fa-check"></i><b>10.4.1</b> Lineariteit</a></li>
<li class="chapter" data-level="10.4.2" data-path="chap-glm.html"><a href="chap-glm.html#homoscedasticiteit"><i class="fa fa-check"></i><b>10.4.2</b> Homoscedasticiteit</a></li>
<li class="chapter" data-level="10.4.3" data-path="chap-glm.html"><a href="chap-glm.html#normaliteit"><i class="fa fa-check"></i><b>10.4.3</b> Normaliteit</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="chap-glm.html"><a href="chap-glm.html#het-niet-additieve-meervoudig-lineair-regressiemodel"><i class="fa fa-check"></i><b>10.5</b> Het niet-additieve meervoudig lineair regressiemodel</a><ul>
<li class="chapter" data-level="10.5.1" data-path="chap-glm.html"><a href="chap-glm.html#sec:intCont"><i class="fa fa-check"></i><b>10.5.1</b> Interactie tussen twee continue variabelen</a></li>
<li class="chapter" data-level="10.5.2" data-path="chap-glm.html"><a href="chap-glm.html#interactie-tussen-continue-variabele-en-factor-variabele"><i class="fa fa-check"></i><b>10.5.2</b> Interactie tussen continue variabele en factor variabele</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="chap-glm.html"><a href="chap-glm.html#anova-tabel-2"><i class="fa fa-check"></i><b>10.6</b> ANOVA Tabel</a><ul>
<li class="chapter" data-level="10.6.1" data-path="chap-glm.html"><a href="chap-glm.html#sstot-ssr-en-sse"><i class="fa fa-check"></i><b>10.6.1</b> SSTot, SSR en SSE</a></li>
<li class="chapter" data-level="10.6.2" data-path="chap-glm.html"><a href="chap-glm.html#extra-kwadratensommen"><i class="fa fa-check"></i><b>10.6.2</b> Extra Kwadratensommen</a></li>
<li class="chapter" data-level="10.6.3" data-path="chap-glm.html"><a href="chap-glm.html#type-i-kwadratensommen"><i class="fa fa-check"></i><b>10.6.3</b> Type I Kwadratensommen</a></li>
<li class="chapter" data-level="10.6.4" data-path="chap-glm.html"><a href="chap-glm.html#type-iii-kwadratensommen"><i class="fa fa-check"></i><b>10.6.4</b> Type III Kwadratensommen</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="chap-glm.html"><a href="chap-glm.html#regressiediagnostieken"><i class="fa fa-check"></i><b>10.7</b> Regressiediagnostieken</a><ul>
<li class="chapter" data-level="10.7.1" data-path="chap-glm.html"><a href="chap-glm.html#multicollineariteit"><i class="fa fa-check"></i><b>10.7.1</b> Multicollineariteit</a></li>
<li class="chapter" data-level="10.7.2" data-path="chap-glm.html"><a href="chap-glm.html#invloedrijke-observaties"><i class="fa fa-check"></i><b>10.7.2</b> Invloedrijke observaties</a></li>
<li class="chapter" data-level="10.7.3" data-path="chap-glm.html"><a href="chap-glm.html#cooks-distance"><i class="fa fa-check"></i><b>10.7.3</b> Cook’s distance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-modsel.html"><a href="chap-modsel.html"><i class="fa fa-check"></i><b>11</b> Modelselectie</a><ul>
<li class="chapter" data-level="11.1" data-path="chap-modsel.html"><a href="chap-modsel.html#inleiding-9"><i class="fa fa-check"></i><b>11.1</b> Inleiding</a></li>
<li class="chapter" data-level="11.2" data-path="chap-modsel.html"><a href="chap-modsel.html#modelselectie-op-basis-van-hypothesetesten"><i class="fa fa-check"></i><b>11.2</b> Modelselectie op basis van hypothesetesten</a><ul>
<li class="chapter" data-level="11.2.1" data-path="chap-modsel.html"><a href="chap-modsel.html#voorwaartse-modelselectie"><i class="fa fa-check"></i><b>11.2.1</b> Voorwaartse modelselectie</a></li>
<li class="chapter" data-level="11.2.2" data-path="chap-modsel.html"><a href="chap-modsel.html#achterwaartse-modelselectie"><i class="fa fa-check"></i><b>11.2.2</b> Achterwaartse modelselectie</a></li>
<li class="chapter" data-level="11.2.3" data-path="chap-modsel.html"><a href="chap-modsel.html#stapsgewijze-modelselectie"><i class="fa fa-check"></i><b>11.2.3</b> Stapsgewijze modelselectie</a></li>
<li class="chapter" data-level="11.2.4" data-path="chap-modsel.html"><a href="chap-modsel.html#opmerkingen"><i class="fa fa-check"></i><b>11.2.4</b> Opmerkingen</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chap-modsel.html"><a href="chap-modsel.html#modelselectie-voor-predictie"><i class="fa fa-check"></i><b>11.3</b> Modelselectie voor predictie</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chap-modsel.html"><a href="chap-modsel.html#inleiding-10"><i class="fa fa-check"></i><b>11.3.1</b> Inleiding</a></li>
<li class="chapter" data-level="11.3.2" data-path="chap-modsel.html"><a href="chap-modsel.html#selectie-criterium"><i class="fa fa-check"></i><b>11.3.2</b> Selectie-criterium</a></li>
<li class="chapter" data-level="11.3.3" data-path="chap-modsel.html"><a href="chap-modsel.html#alternatieve-criteria"><i class="fa fa-check"></i><b>11.3.3</b> Alternatieve criteria</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cursus Statistiek 2019-2020</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap:besluit" class="section level1">
<h1><span class="header-section-number">Hoofdstuk 5</span> Statistische besluitvorming</h1>
<div id="inleiding-3" class="section level2">
<h2><span class="header-section-number">5.1</span> Inleiding</h2>
<p>In dit hoofdstuk zullen we werken rond de <em>Captopril dataset</em>. Captopril is een medicijn dat wordt voorgeschreven bij hypertensie en chronisch hartfalen. Het behoort tot de klasse van ACE remmers die activiteit van het renine-angiotensine-aldosteronsysteem onderdrukken. Dat systeem zet het hormoon angiotensineI om in angiotensine II, die een krachtige vaatvernauwende werking heeft. ACE remmers verminderen de omzetting van angiotensine I naar angiotensine II waardoor de vaatvernauwing wordt onderdrukt. Tijdens de ontwikkeling van het medicijn werd een eerste kleine studie opgezet om na te gaan of captopril een bloeddrukverlagend effect heeft bij patiënten met hypertensie.</p>
<p>Observaties bij een klein aantal subjecten mogen een onderzoeker er dan al van overtuigen iets nieuws te hebben ontdekt, maar om anderen te overtuigen zijn objectieve, wetenschappelijke argumenten nodig. Vooreerst moeten de resultaten voldoende <em>representatief</em> zijn, d.w.z. veralgemeenbaar naar een ruime biologische populatie (bvb. naar de volledige populatie van patiënten met hypertensie). Ten tweede moet er rekening mee gehouden worden dat de resultaten <em>variabel</em> zijn, d.w.z. dat men door toeval doorgaans andere resultaten zou vinden indien men een andere, vergelijkbare groep subjecten zou analyseren. Om die reden is het belangrijk om uit te drukken in welke mate de resultaten (bvb. de geschatte bloeddrukdaling) zouden variëren van steekproef tot steekproef en of men op basis van de steekproef kan aantonen dat er een effect is van een behandeling (b.v. dat het middel captopril bloeddrukverlagend werkt in de populatie). Dit vormt het doel van dit hoofdstuk.</p>
<p>Om een representatieve groep subjecten te waarborgen, vertrekt een goede onderzoeksopzet vanuit een belangrijke, precies geformuleerde vraagstelling omtrent een duidelijk omschreven populatie.</p>
<p>Zoals eerder in de cursus aangegeven, zal men in de praktijk om financiële en logistieke redenen bijna nooit een volledige populatie kunnen bestuderen. Populatieparameters kunnen daarom meestal niet exact bepaald worden. Enkel een deel van de populatie kan onderzocht worden, wat men een <em>steekproef</em> noemt. Volgens een gestructureerd design worden daartoe lukraak subjecten uit de doelpopulatie getrokken en geobserveerd. De onbekende parameters worden vervolgens geschat o.b.v. die steekproef en noemt men schattingen. In de praktijk hoopt men uiteraard dat de schattingen die men bekomt op basis van de steekproef vergelijkbaar zijn met de overeenkomstige populatieparameters die men voor de volledige populatie zou bekomen.<br />
Typisch kan de onderzoeksvraag worden vertaald naar een populatieparameter. Ze kan bijvoorbeeld worden uitgedrukt in termen van een populatiegemiddelde, bijvoorbeeld de gemiddelde bloeddrukverandering na de inname van captopril bij patiënten met hypertensie.</p>
</div>
<div id="captopril-voorbeeld" class="section level2">
<h2><span class="header-section-number">5.2</span> Captopril voorbeeld</h2>
<p>Onderzoekers wensen na te gaan of het medicijn Captopril een bloeddruk verlagend effect heeft. De onderzoekers wensen uitspraken te kunnen doen over het effect van captopril op de systolische bloeddruk van huidige en toekomstige patiënten met hypertensie, m.a.w. ze wensen uitspraken te doen over het effect van captopril op het niveau van de <em>Populatie</em>. Ze zullen hiervoor een experiment opzetten om het effect van captopril bestuderen (<em>Proefopzet</em>) waarbij een <em>steekproef</em> (sample) van de patiënten met hypertensie is getrokken uit de populatie. Vervolgens zullen ze de data exploreren en het effect van captopril besturen in de steekproef (<em>Data Exploratie &amp; Beschrijvende Statistiek</em>). Op basis van de steekproef zullen ze dan het effect van captopril <em>Schatten</em> in de populatie en zullen ze a.d.h.v. methoden uit <em>Statistische besluitvorming</em><a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a> nagaan in hoeverre de geobserveerde effecten in de steekproef veralgemeend kunnen worden naar de algemene populatie toe.</p>
<p>Deze verschillende stappen worden geïllustreerd in Figuur <a href="chap-besluit.html#fig:captoPop2Samp2Pop">5.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:captoPop2Samp2Pop"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoPop2Samp2Pop-1.png" alt="Verschillende stappen in de captopril studie." width="100%" />
<p class="caption">
Figuur 5.1: Verschillende stappen in de captopril studie.
</p>
</div>
<div id="proefopzet" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Proefopzet</h3>
<p>Bij proefopzet zullen we een gestructureerd design voorstellen om lukraak subjecten uit de doelpopulatie te selecteren, toe te wijzen aan een behandeling en te observeren. We zullen hierbij een response variabele meten, een karakteristiek van interesse. In het captopril voorbeeld is dit de systolische bloeddruk.</p>
<p>In de captopril studie hebben de onderzoekers gebruik gemaakt van een een pre-test/post-test design. De patiënten werden at random gekozen uit de populatie. Van elke patiënt in de studie werd de systolische en diasystolische bloeddruk gemeten voor en na het toedienen van captopril. Het pre-test/post-test design heeft als voordeel dat we het effect van het toedienen van captopril op de bloeddruk kunnen meten voor elke patiënt. Een nadeel daarentegen is dat er geen controle behandeling is waardoor we een mogelijkse bloeddrukverlaging niet noodzakelijkerwijs kunnen toeschrijven aan de werking van captopril. Er zou immers ook een placebo-effect kunnen optreden waardoor de bloeddruk van de patiënt daalt omdat men weet dat men een medicijn kreeg tegen een hoge bloeddruk.</p>
</div>
<div id="data-exploratie-beschrijvende-statistiek" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Data Exploratie &amp; Beschrijvende Statistiek</h3>
<p>Eens de data zijn geobserveerd, is het belangrijk om deze te exploreren om inzicht te krijgen in hun verdeling en karakteristieken. Vervolgens zullen we de gegevens samenvatten zodat we het effect van interesse kunnen kwantificeren in de steekproef. In deze studie is de systolische bloeddruk en de diasystolische bloeddruk gemeten voor elke patiënt voor en na het toedienen van captopril. De data is opgeslagen in een tekstbestand met naam <code>captopril.txt</code> in de folder dataset. We zullen eerst exploreren welke figuren nuttig zijn in onze context. In wetenschappelijke artikels worden vaak figuren gemaakt van het gemiddelde en de standaardafwijking (zie Figuur <a href="chap-besluit.html#fig:captoBar">5.2</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Eerst lezen we de data in. </span>
<span class="co">#Deze bevindt zich in de subdirectory dataset</span>
<span class="co">#Het is een tekstbestand waarbij de kolommen van elkaar gescheiden zijn d.m.v kommas.</span>
<span class="co">#sep=&quot;,&quot;</span>
<span class="co">#De eerste rij bevat de namen van de variabelen</span>
captopril &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;dataset/captopril.txt&quot;</span>,<span class="dt">header=</span><span class="ot">TRUE</span>,<span class="dt">sep=</span><span class="st">&quot;,&quot;</span>) 
<span class="kw">head</span>(captopril)</code></pre></div>
<pre><code>##   id SBPb DBPb SBPa DBPa
## 1  1  210  130  201  125
## 2  2  169  122  165  121
## 3  3  187  124  166  121
## 4  4  160  104  157  106
## 5  5  167  112  147  101
## 6  6  176  101  145   85</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#We gebruiken de apply functie om het gemiddelde en de standaard deviatie</span>
<span class="co">#te berekenen voor de kolommen die bloeddruk data bevatten (kolom 2:4)</span>
<span class="co">#We gebruiken argument MARGIN=2 om de functie toe te passen op de kolommen</span>
<span class="co">#MARGIN=1 kan gebruikt worden om de functie op de rijen toe te passen</span>
mm&lt;-<span class="kw">apply</span>(captopril[,<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>],<span class="dt">MARGIN=</span><span class="dv">2</span>,<span class="dt">FUN=</span>mean)
hh&lt;-<span class="kw">apply</span>(captopril[,<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>],<span class="dt">MARGIN=</span><span class="dv">2</span>,<span class="dt">FUN=</span>sd)

mp &lt;-<span class="st"> </span><span class="kw">barplot</span>(mm,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">250</span>),<span class="dt">ylab=</span><span class="st">&quot;Gemiddelde bloeddruk (mmHg)&quot;</span>,<span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="co">#fouten vlaggen</span>
<span class="kw">segments</span>(mp,mm,mp,mm<span class="op">+</span><span class="dv">2</span><span class="op">*</span>hh)
<span class="kw">segments</span>(mp<span class="op">-</span>.<span class="dv">2</span>,mm<span class="op">+</span><span class="dv">2</span><span class="op">*</span>hh,mp<span class="op">+</span>.<span class="dv">2</span>,mm<span class="op">+</span><span class="dv">2</span><span class="op">*</span>hh)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:captoBar"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoBar-1.png" alt="Barplot van de gemiddelde bloeddruk in de captopril studie. De foutenvlag is 2x de standaard deviatie op de metingen (SBPb: systolic BloodPressure before, DBPb: Diasystolic BloodPressure before, SBPa: systolic BloodPressure after, DBPa: Diasystolic BloodPressure after)." width="100%" />
<p class="caption">
Figuur 5.2: Barplot van de gemiddelde bloeddruk in de captopril studie. De foutenvlag is 2x de standaard deviatie op de metingen (SBPb: systolic BloodPressure before, DBPb: Diasystolic BloodPressure before, SBPa: systolic BloodPressure after, DBPa: Diasystolic BloodPressure after).
</p>
</div>
<p>De figuur is echter niet informatief. De hoogte van de balken zegt enkel iets over het gemiddelde. We kunnen onmogelijk weten wat het bereik van de ruwe gegevens is bijvoorbeeld. Daarom is het beter om de gegevens zo ruw mogelijk weer te geven in een plot. We kunnen hiervoor bijvoorbeeld gebruik maken van boxplots (Figuur <a href="chap-besluit.html#fig:captoBox">5.3</a>). Aangezien we maar over 15 patiënten beschikken kunnen we ook de ruwe datapunten toevoegen. In de figuur zien we dat de systolische bloeddruk in de steekproef gemiddeld lager ligt na de behandeling met captopril. We krijgen ook een duidelijk beeld op het bereik van de data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxplot</span>(captopril[,<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>],<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">250</span>),<span class="dt">ylab=</span><span class="st">&quot;Bloeddruk (mmHg)&quot;</span>,<span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="co">#toevoegen van originele datapunten op de plot</span>
<span class="co">#jitter zal de punten random verspreiden</span>
<span class="co">#set seed om gekleurde volle bol pch=19 te zetten</span>
<span class="co">#en daarna een zwarte rand te kunnen zetten op zelfde plaats.</span>
<span class="kw">set.seed</span>(<span class="dv">19</span>)
<span class="kw">stripchart</span>(captopril[,<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>], 
            <span class="dt">vertical =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;jitter&quot;</span>, 
            <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span><span class="kw">c</span>(<span class="st">&quot;bisque&quot;</span>,<span class="st">&quot;coral&quot;</span>,<span class="st">&quot;darkcyan&quot;</span>,<span class="st">&quot;purple&quot;</span>), 
            <span class="dt">add =</span> <span class="ot">TRUE</span>)
<span class="kw">set.seed</span>(<span class="dv">19</span>)
<span class="kw">stripchart</span>(captopril[,<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>], 
            <span class="dt">vertical =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;jitter&quot;</span>, 
            <span class="dt">pch =</span> <span class="dv">1</span>, <span class="dt">col =</span><span class="dv">1</span>, 
            <span class="dt">add =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:captoBox"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoBox-1.png" alt="Boxplot en ruwe data van de bloeddruk in de captopril studie (SBPb: systolic BloodPressure before, DBPb: Diasystolic BloodPressure before, SBPa: systolic BloodPressure after, DBPa: Diasystolic BloodPressure after)." width="100%" />
<p class="caption">
Figuur 5.3: Boxplot en ruwe data van de bloeddruk in de captopril studie (SBPb: systolic BloodPressure before, DBPb: Diasystolic BloodPressure before, SBPa: systolic BloodPressure after, DBPa: Diasystolic BloodPressure after).
</p>
</div>
<p>Als alle bloeddrukmetingen onafhankelijk zouden zijn dan is Figuur <a href="chap-besluit.html#fig:captoBox">5.3</a> een goede figuur om de data te exploreren. We weten echter dat de metingen voor en na het toedienen van captopril afkomstig zijn van dezelfde patiënt. We kunnen die informatie toevoegen in een dotplot zoals we illustreren voor de systolische bloeddruk in Figuur <a href="chap-besluit.html#fig:captoDotBsl">5.4</a>. In deze figuur zijn de twee bloeddrukmetingen voor dezelfde persoon verbonden met een lijn. Deze figuur geeft duidelijk weer dat de bloeddruk daalt voor elke patiënt wat een sterke aanwijzing is dat er een effect is van het toedienen van captopril op de systolische bloeddruk.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#D.m.v de matplot functie kunnen we eenvoudig </span>
<span class="co">#de data van dezelfde patient (per kolom)</span>
<span class="co">#vandaar dat we de dataset transponeren (t(.)) functie</span>
<span class="co">#en verbinden a.d.h.v. een lijn. (lty=1)</span>
<span class="co">#we gebruiken ook een dezelfde kleur.</span>
<span class="co">#en gebruiken zowel een punt als een lijn</span>
<span class="co">#om de data voor te stellen type=&quot;b&quot;</span>
<span class="kw">matplot</span>(<span class="kw">t</span>(captopril[,<span class="kw">c</span>(<span class="st">&quot;SBPb&quot;</span>,<span class="st">&quot;SBPa&quot;</span>)]),<span class="dt">pch=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">1</span>,<span class="dt">col=</span><span class="st">&quot;black&quot;</span>,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>,<span class="dt">xaxt=</span><span class="st">&quot;none&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">2.5</span>),<span class="dt">ylab=</span><span class="st">&quot;Systolische bloeddruk (mmHg)&quot;</span>,<span class="dt">cex=</span>.<span class="dv">5</span>)
<span class="kw">axis</span>(<span class="dv">1</span>,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;voor&quot;</span>,<span class="st">&quot;na&quot;</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:captoDotBsl"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoDotBsl-1.png" alt="Dotplot van de systolische bloeddruk in de captopril studie voor en na het toedienen van captopril." width="100%" />
<p class="caption">
Figuur 5.4: Dotplot van de systolische bloeddruk in de captopril studie voor en na het toedienen van captopril.
</p>
</div>
<p>Aangezien we slechts twee bloeddrukmetingen hebben per patiënt kunnen we het effect van captopril ook berekenen per patiënt door het verschil in de systolische bloeddruk na en voor de toediening van captopril te berekenen. Dat is één van de voordelen van een pre-test/post-test design.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#we selecteren de bloeddruk na en voor toedienen </span>
<span class="co">#uit de dataset via naam van variabele d.m.v. $-teken</span>
<span class="co">#en berekenen het verschil</span>
delta &lt;-<span class="st"> </span>captopril<span class="op">$</span>SBPa<span class="op">-</span>captopril<span class="op">$</span>SBPb
<span class="kw">boxplot</span>(delta,<span class="dt">ylab=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Verschil in bloeddruk (&quot;</span>,Delta[Na <span class="op">-</span><span class="st"> </span>Voor],<span class="st">&quot;)&quot;</span>)))
<span class="kw">set.seed</span>(<span class="dv">19</span>)
<span class="kw">stripchart</span>(delta, 
            <span class="dt">vertical =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;jitter&quot;</span>, 
            <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span><span class="kw">c</span>(<span class="st">&quot;bisque&quot;</span>), 
            <span class="dt">add =</span> <span class="ot">TRUE</span>)
<span class="kw">set.seed</span>(<span class="dv">19</span>)
<span class="kw">stripchart</span>(delta, 
            <span class="dt">vertical =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;jitter&quot;</span>, 
            <span class="dt">pch =</span> <span class="dv">1</span>, <span class="dt">col =</span><span class="dv">1</span>, 
            <span class="dt">add =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:captoBoxDelta"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoBoxDelta-1.png" alt="Boxplot van het verschil in systolische bloeddruk voor en na het toedienen van captopril." width="100%" />
<p class="caption">
Figuur 5.5: Boxplot van het verschil in systolische bloeddruk voor en na het toedienen van captopril.
</p>
</div>
<p>We observeren in Figuur <a href="chap-besluit.html#fig:captoBoxDelta">5.5</a> een bloeddrukdaling voor elke patiënt in de steekproef wat opnieuw een heel sterke indicatie is voor een gunstig effect van het toedienen van captopril op de bloeddruk. De verschillen in systolische bloeddruk zijn een goede maat om het effect van captopril te bepalen. We kunnen de data als volgt samenvatten.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(delta)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -33.00  -24.50  -20.00  -18.93  -13.50   -3.00</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(delta)</code></pre></div>
<pre><code>## [1] 9.027471</code></pre>
<p>We observeren gemiddeld een systolische bloeddrukdaling van 18.93 mmHg en een standaard deviatie van 9.03 mmHg.</p>
</div>
<div id="schatten" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Schatten</h3>
<p>Pre-test/post-test design: Het effect van captopril in de steekproef kan worden bestudeerd door het verschil te bepalen in systolische bloeddruk na en voor de behandeling (<span class="math inline">\(X=\Delta_\text{na-voor}\)</span>)! Hoe kunnen we de bloeddrukverschillen modelleren en het effect van het toedienen van captopril schatten?</p>
<div class="figure" style="text-align: center"><span id="fig:captoBoxDiffQQ"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoBoxDiffQQ-1.png" alt="QQ-plot voor het verschil in systolische bloeddruk voor en na het toedienen van captopril." width="100%" />
<p class="caption">
Figuur 5.6: QQ-plot voor het verschil in systolische bloeddruk voor en na het toedienen van captopril.
</p>
</div>
<pre><code>## [1] 4 2</code></pre>
<p>We zien geen grote afwijkingen van Normaliteit in Figuur <a href="chap-besluit.html#fig:captoBoxDiffQQ">5.6</a>. We kunnen de bloeddrukverschillen dus modelleren aan de hand van een Normale verdeling en kunnen het effect van captopril in de populatie beschrijven a.d.h.v. de gemiddelde bloeddrukverschil <span class="math inline">\(\mu\)</span>. Het bloeddrukverschil <span class="math inline">\(\mu\)</span> in de populatie kan worden geschat a.d.h.v. het steekproefgemiddelde <span class="math inline">\(\bar x\)</span>=-18.93 en de standaard afwijking <span class="math inline">\(\sigma\)</span> a.d.h.v. de steekproefstandaarddeviatie <span class="math inline">\(\text{SD}\)</span>=9.03.</p>
<p>We vragen ons nu af of het effect dat we observeren in de steekproef groot genoeg is om te kunnen spreken van een effect van captopril in de populatie. We weten immers dat onze statistiek voor de schatting van het effect van captopril in de populatie berekend wordt op basis van de gegevens uit de steekproef en daarom zal variëren van steekproef tot steekproef. Het is daarom belangrijk om een inzicht te krijgen in hoe het steekproefgemiddelde zal variëren van steekproef tot steekproef.</p>
</div>
</div>
<div id="puntschatters-het-steekproefgemiddelde" class="section level2">
<h2><span class="header-section-number">5.3</span> Puntschatters: het steekproefgemiddelde</h2>
Zij <span class="math inline">\(X\)</span> een lukrake trekking uit de populatie van de bestudeerde karakteristiek en onderstel dat haar theoretische verdeling[bvb. de Normale verdeling] een gemiddelde <span class="math inline">\(\mu\)</span> en variatie <span class="math inline">\(\sigma^2\)</span> heeft. Onderstel bovendien dat we geïnteresseerd zijn in het gemiddelde <span class="math inline">\(\mu\)</span> van die karakteristiek in de studiepopulatie. Dan kunnen we <span class="math inline">\(\mu\)</span> schatten op basis van een eenvoudige lukrake steekproef, <span class="math inline">\(X_1,...,X_n\)</span>, als het (rekenkundig) gemiddelde
<span class="math display">\[\begin{equation*}
\bar X = \frac{X_1+ X_2+ ... + X_n}{n} = \frac{\sum_{i=1}^{n} X_i}{n}
\end{equation*}\]</span>
<p>van de toevalsveranderlijken <span class="math inline">\(X_1,X_2, ..., X_n\)</span>. Dit wordt het <em>steekproefgemiddelde</em> genoemd. Het is belangrijk om te begrijpen dat het steekproefgemiddelde opnieuw een toevalsveranderlijke<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> is, d.w.z. dat haar waarde zal variëren van steekproef tot steekproef. Hoewel er slechts 1 populatie is, zijn er heel wat verschillende steekproeven die men daaruit kan trekken. Dat heeft tot gevolg dat verschillende onderzoekers (die verschillende steekproeven uit dezelfde populatie analyseren) verschillende waarden zullen vinden voor het steekproefgemiddelde. Om die reden heeft het steekproefgemiddelde zelf een verdeling. Men zou die theoretisch kunnen bekomen door een oneindig aantal keer een steekproef van <span class="math inline">\(n\)</span> experimentele eenheden uit de populatie te trekken, telkens het steekproefgemiddelde te berekenen en al deze steekproefgemiddelden vervolgens uit te zetten in een histogram.</p>
<p>We zullen in deze sectie de theoretische verdeling van het steekproefgemiddelde bestuderen. Dat is belangrijk (a) omdat ze ons inzicht geeft in welke mate het resultaat van de studie zou variëren indien men een nieuwe, gelijkaardige studie zou opzetten; en (b) omdat ze ons leert hoe ver <span class="math inline">\(\bar X\)</span> van het gezochte populatiegemiddelde <span class="math inline">\(\mu\)</span> kan afwijken. Omdat we slechts over 1 steekproef beschikken (en dus slechts over 1 observatie voor <span class="math inline">\(\bar X\)</span>), is het niet evident<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a> hoe we inzicht kunnen ontwikkelen in de verdeling van het steekproefgemiddelde. In het vervolg van deze sectie tonen we hoe dit toch mogelijk is op basis van de beschikbare steekproef wanneer we bepaalde aannames doen over de gegevens.</p>
<div id="het-steekproefgemiddelde-is-onvertekend" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Het steekproefgemiddelde is onvertekend</h3>
<p>In de praktijk hoopt men uiteraard dat de schattingen die men bekomt op basis van de steekproef vergelijkbaar zijn met de overeenkomstige populatieparameters die men voor de volledige populatie zou bekomen.<br />
Of dat zo is, hangt er in eerste instantie vanaf of de steekproef representatief is voor de studiepopulatie en bijgevolg of men al dan niet lukraak individuen uit de populatie gekozen heeft ter observatie (m.a.w. het hangt af van het design van de studie). Het volgende voorbeeld illustreert dit.</p>

<div class="example">
<span id="exm:unnamed-chunk-64" class="example"><strong>Voorbeeld 5.1  (Ecstasy)  </strong></span>
</div>
<p> Aan Stanford University werd een survey uitgevoerd om de prevalentie van ecstasy-gebruik onder de studenten van deze universiteit te bepalen. Twee assistenten werden op het hoofdplein van de campus geplaatst en kregen de opdracht om alle studenten te interviewen die op bepaalde tijdstippen voorbij kwamen. Van de 369 studenten die geïnterviewd werden, rapporteerde 39% ooit ecstasy gebruikt te hebben. Dit resultaat wordt uiteraard deels bepaald door het algemene ecstasy-gebruik onder Stanford-studenten (d.i. door de verdeling van het ecstasy-gebruik over de populatie van Stanford-studenten). Maar ook door het feit dat de studenten die geïnterviewd werden, vermoedelijk een selectieve groep vormen van studenten die bijvoorbeeld niet in de les aanwezig waren of die in de buurt van het hoofdplein les kregen en bijgevolg voornamelijk uit 1 bepaalde studierichting afkomstig waren.</p>
<p><code>**Einde voorbeeld**</code></p>
<p>Omwille hiervan is het design van een studie van primair belang om lukrake en representatieve steekproeven te garanderen (zie Sectie <a href="chap-design.html#sec:steekproefdesigns">3.2</a>). Zoals u doorheen deze cursus zult vaststellen, zullen de meeste wetenschappelijke rapporten daarom een gedetailleerde beschrijving geven van de manier waarop de data bekomen werden. Dit moet de lezer toelaten om de validiteit van de studie te beoordelen.</p>
<p>Algemeen zullen we met <span class="math inline">\(E(X)\)</span>, <span class="math inline">\(\text{Var}(X)\)</span> en <span class="math inline">\(\text{Cor}(X,Y)\)</span> respectievelijk het gemiddelde, de variantie en de correlatie noteren van 2 toevalsveranderlijken <span class="math inline">\(X\)</span> en <span class="math inline">\(Y\)</span> in de populatie. Deze worden respectievelijk de <em>theoretische verwachtingswaarde</em> van <span class="math inline">\(X\)</span>, <em>theoretische variantie</em> van <span class="math inline">\(X\)</span> en <em>theoretische correlatie</em> van <span class="math inline">\(X\)</span> en <span class="math inline">\(Y\)</span> genoemd. Men zou ze bekomen door voor alle individuen in de populatie de karakteristieken <span class="math inline">\(X\)</span> en <span class="math inline">\(Y\)</span> op te meten en vervolgens respectievelijk het rekenkundig gemiddelde, de variantie en de Pearson correlatie te berekenen. Om die reden blijven de rekenregels voor gemiddelden en varianties geldig<a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a> voor populatiegemiddelden en -varianties.</p>
In de onderstelling dat we over een eenvoudige lukrake steekproef beschikken van metingen <span class="math inline">\(X_1,...,X_n\)</span> voor een karakteristiek <span class="math inline">\(X\)</span>, volgen <span class="math inline">\(X_1,...,X_n\)</span> allen dezelfde verdeling. In het bijzonder hebben ze allen gemiddelde <span class="math inline">\(\mu\)</span> en variantie <span class="math inline">\(\sigma^2\)</span>; d.i. <span class="math inline">\(E(X_1)=...=E(X_n)=\mu\)</span> en <span class="math inline">\(\text{Var}(X_1)=...=\text{Var}(X_n)=\sigma^2\)</span>. Het feit dat we subjecten 1 tot <span class="math inline">\(n\)</span> lukraak uit de populatie getrokken hebben, staat er m.a.w. garant voor dat verdeling van de karakteristiek in deze steekproef representatief is voor de theoretische verdeling in de doelpopulatie. Gebruik makend van de rekenregels voor gemiddelden, vinden we bijgevolg dat:
<span class="math display">\[\begin{eqnarray*}
E(\bar X) &amp;=&amp; E \left(\frac{X_1+ X_2+ ... + X_n}{n}\right) \\
&amp;= &amp; \frac{E(X_1)+ E(X_2)+ ... + E(X_n)}{n} \\
&amp;=&amp; \frac{\mu + \mu + ... +\mu}{n} \\
&amp;= &amp; \mu
\end{eqnarray*}\]</span>
<p>Dit geeft aan dat het verwachte steekproefgemiddelde in een eenvoudige lukrake steekproef gelijk is aan het beoogde populatiegemiddelde <span class="math inline">\(\mu\)</span>. Men zegt dan dat <span class="math inline">\(\bar X\)</span> een <em>onvertekende schatter</em> is voor <span class="math inline">\(\mu\)</span>. We kunnen in dat geval verwachten dat de waarde <span class="math inline">\(\bar x\)</span> die we schatten voor <span class="math inline">\(\mu\)</span> op basis van de steekproef, niet systematisch hoger of lager dan de gezochte waarde <span class="math inline">\(\mu\)</span> zal zijn. Het spreekt voor zich dat dit een zeer wenselijke eigenschap is.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-65" class="definition"><strong>Definitie 5.1  (Onvertekende schatter)  </strong></span>Een statistiek of schatter <span class="math inline">\(S\)</span> voor een parameter <span class="math inline">\(\theta\)</span> wordt <strong>onvertekend</strong> genoemd als haar theoretische verwachtingswaarde gelijk is aan die parameter, d.w.z. <span class="math inline">\(E(S)= \theta\)</span>.</p>
<strong>Einde definitie</strong>
</div>

</div>
<div id="imprecisiestandard-error" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Imprecisie/standard error</h3>
<p>Het feit dat het steekproefgemiddelde (over een groot aantal vergelijkbare studies) <em>gemiddeld</em> gezien niet afwijkt van de gezochte waarde <span class="math inline">\(\mu\)</span>, impliceert niet dat ze niet rond die waarde varieert. Om inzicht te krijgen hoe dicht we het steekproefgemiddelde bij <span class="math inline">\(\mu\)</span> mogen verwachten, wensen we bijgevolg ook haar variabiliteit te kennen. Om dit te bepalen, zullen we ervan uitgaan dat de metingen <span class="math inline">\(X_1, X_2, ..., X_n\)</span> werden gemaakt bij <span class="math inline">\(n\)</span> <em>onafhankelijke</em> observationele eenheden. In woorden betekent onafhankelijkheid dat elk subject een volledig nieuw stukje informatie bijdraagt tot het geheel. Een voorbeeld van afhankelijkheid tussen studie-objecten komt klassiek uit de studie van kankerverwekkende stoffen. Bij testen op zwangere ratten, worden metingen gedaan op hun levende foetussen of boorlingen. Foetussen van eenzelfde moeder delen dezelfde genetische achtergrond en zijn daarom waarschijnlijk meer aan elkaar gelijk dan foetussen van verschillende moeders. Zelfs al zijn de moeders die opgenomen worden in zo’n studie onafhankelijk van elkaar gekozen, de verschillende kleine ratjes leveren niet langer onafhankelijke stukjes informatie: via de gedeelde moeders is een afhankelijkheid ingebouwd. Afhankelijke gegevens worden ondermeer ook verzameld in pre-test/post-test designs en cross-over studies. De volgende eigenschap illustreert de noodzaak om over onafhankelijke gegevens te beschikken, wil men gemakkelijk de variabiliteit van het steekproefgemiddelde kunnen bepalen.</p>
<p><strong>Eigenschap</strong></p>
Als <span class="math inline">\(X\)</span> en <span class="math inline">\(Y\)</span> onafhankelijke toevalsveranderlijken zijn, dan geldt<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a>:
<span class="math display">\[\begin{equation*}
\text{Var}(X+Y) = \text{Var}(X) + \text{Var}(Y)
\end{equation*}\]</span>
Algemeen (d.i. voor mogelijks afhankelijke toevalsveranderlijken <span class="math inline">\(X\)</span> en <span class="math inline">\(Y\)</span>) geldt voor constanten <span class="math inline">\(a\)</span> en <span class="math inline">\(b\)</span>:
<span class="math display">\[\begin{eqnarray*}
\text{Var}(aX+bY) &amp;=&amp; a^2 \text{Var}(X) + b^2 \text{Var}(Y) + 2 ab {%
\text{Cor}}(X,Y)\sqrt{\text{Var}(X)}\sqrt{\text{Var}(Y)}
\end{eqnarray*}\]</span>
<p><strong>Einde Eigenschap</strong></p>
Een veelgemaakte fout is dat men beweert dat <span class="math inline">\(\text{Var}(X-Y)=\text{Var}(X)-\text{Var}(Y)\)</span>. Niets is minder waar! Stel bijvoorbeeld dat de lengte <span class="math inline">\(X\)</span> van moeders en de lengte <span class="math inline">\(Y\)</span> van vaders evenveel variëren zodat <span class="math inline">\(\text{Var}(X)=\text{Var}(Y)\)</span>. Dan impliceert dat nog niet dat als je het verschil <span class="math inline">\(X-Y\)</span> neemt tussen de lengte van een moeder en haar partner, dat dit verschil variantie nul heeft; d.w.z. dat het niet varieert en bijgevolg voor alle moeder-vader paren exact dezelfde waarde aanneemt! Bovenstaande formules geven inderdaad integendeel aan dat:
<span class="math display">\[\begin{equation*}
\text{Var}(X-Y) = \text{Var}(X) + \text{Var}(Y) -2{\text{Cor}}(X,Y)\sqrt{\text{Var}(X)}\sqrt{\text{Var}(Y)}.
\end{equation*}\]</span>
Gebruik makend van deze rekenregels en steunend op de onafhankelijkheid van de observaties (waarvan we gebruik maken in de derde overgang, *) kunnen we nu verder berekenen dat:
<span class="math display">\[\begin{eqnarray*}
\text{Var}(\bar X)&amp;=&amp;\text{Var} \left(\frac{X_1+ X_2+ ... + X_n}{n}\right) \\
&amp;= &amp; \frac{\text{Var} (X_1+ X_2+ ... + X_n)}{n^2} \\
&amp;\overset{*}{=} &amp; \frac{\text{Var}(X_1)+ \text{Var}(X_2)+ ... + \text{Var}(X_n)}{n^2} \\
&amp;=&amp; \frac{\sigma^2 + \sigma^2 + ... \sigma^2}{n^2} \\
&amp;= &amp; \frac{\sigma^2}{n}.
\end{eqnarray*}\]</span>
<p>Het steekproefgemiddelde heeft dus een spreiding (standaarddeviatie) rond haar gemiddelde <span class="math inline">\(\mu\)</span> die <span class="math inline">\(\sqrt{n}\)</span> keer kleiner is dan de deviatie op de oorspronkelijke observaties. Vandaar dat we meer over <span class="math inline">\(\mu\)</span> kunnen leren door het steekproefgemiddelde <span class="math inline">\(\bar X\)</span> te observeren dan door een individuele waarde <span class="math inline">\(X\)</span> te observeren.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-66" class="definition"><strong>Definitie 5.2  (Standaard error)  </strong></span>De standaarddeviatie van <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(\sigma/\sqrt{n}\)</span> en krijgt in de literatuur de speciale naam {standard error} van het gemiddelde. Algemeen noemt men de standaarddeviatie van een schatter voor een bepaalde parameter <span class="math inline">\(\theta\)</span>, de <strong>standard error</strong> van die schatter. Men noteert dit als <span class="math inline">\(SE\)</span>.</p>
<p><strong>Einde definitie</strong></p>
</div>


<div class="example">
<span id="exm:unnamed-chunk-67" class="example"><strong>Voorbeeld 5.2  (Gemiddelde bloeddrukverandering)  </strong></span>
</div>
<p> Stel dat we <span class="math inline">\(n = 15\)</span> systolische bloeddrukobservaties zullen meten en dat de standaarddeviatie van de bloeddrukverschillen in de populatie <span class="math inline">\(\sigma = 9.0\)</span> mmHg bedraagt, dan is standard error (SE) van de systolische bloeddrukveranderingen <span class="math inline">\(\bar X\)</span>: <span class="math display">\[
SE= \frac{9.0}{\sqrt{15}}=2.32\text{mmHg.}
\]</span></p>
<p>Meestal is <span class="math inline">\(\sigma\)</span>, en bijgevolg de standard error van het steekproefgemiddelde, ongekend. Men moet dan de standard error schatten. Een voor de hand liggende schatter met goede eigenschappen is <span class="math inline">\(S/\sqrt{n},\)</span> waarbij <span class="math inline">\(S^2\)</span> de <em>steekproefvariantie</em> van de reeks observaties <span class="math inline">\(X_1,...,X_n\)</span> is en <span class="math inline">\(S\)</span> de <em>steekproef standaarddeviatie</em> wordt genoemd.</p>
<p>Voor het captopril voorbeeld kunnen we de standard error op het steekproefgemiddelde van de bloeddrukveranderingen schatten in R als</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n=<span class="kw">length</span>(delta)
se=<span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(n)
se</code></pre></div>
<pre><code>## [1] 2.330883</code></pre>
<div id="standaarddeviatie-vs-standard-error" class="section level4">
<h4><span class="header-section-number">5.3.2.1</span> Standaarddeviatie vs standard error</h4>
<p>Er is vaak nogal wat verwarring over het onderscheid tussen standard error en standaarddeviatie. De standard error verwijst steeds naar de spreiding op een geschatte parameter zoals het steekproefgemiddelde. Omdat een schatting steeds precieser wordt naarmate de steekproef groter wordt, daalt de standard error met stijgende steekproefgrootte <span class="math inline">\(n\)</span>. Als de term standaarddeviatie verwijst naar het steekproefgemiddelde (m.a.w. als men spreekt over de standaarddeviatie van het steekproefgemiddelde), dan is deze standaarddeviatie identiek gelijk aan de standard error. Als ze verwijst naar de individuele observaties, dan niet. Dit kun je ondermeer zien aan het feit dat de individuele observaties niet minder variabel zijn in grote steekproeven dan in kleine steekproeven; m.a.w. de standaarddeviatie van de individuele observaties neemt niet af naarmate de steekproef groter wordt, het is immers een karakteristiek van de populatie.</p>
<p>De standaarddeviatie op de observaties is een maat voor de variabiliteit tussen individuen met betrekking tot een bepaalde meetwaarde. De standaard error van een schatter meet de onzekerheid in die schatter voor een bepaalde parameter.</p>
<p>Beide statistieken worden ook anders beïnvloed door de steekproefgrootte. De variabiliteit in de populatie verandert niet. Buiten het feit dat we de standaarddeviatie meer nauwkeurig kunnen schatten in een grotere steekproef zal ze dus steeds in dezelfde grootteorde liggen. Ze heeft als verwachte waarde immers de theoretische standaarddeviatie <span class="math inline">\(\sigma\)</span> in de populatie. De standard error van een schatter wordt echter sterk beïnvloed door de steekproefgrootte: hoe groter de steekproef hoe nauwkeuriger de schatter voor een bepaalde parameter en hoe kleiner zijn standard error!</p>
</div>
<div id="geclusterde-metingen" class="section level4">
<h4><span class="header-section-number">5.3.2.2</span> Geclusterde metingen</h4>
De data in studies zijn niet altijd onafhankelijk. Dat heeft zijn consequenties voor het schatten van de standaard errors. Beschouw een studiedesign waarbij voor <span class="math inline">\(n\)</span> planten, tijdens een bepaalde fase in de groei, de expressie van een bepaald gen 2 maal wordt gemeten om meetfouten te drukken. Men is geïnteresseerd in de gemiddelde genexpressie. Als we met <span class="math inline">\(Y_{i1}\)</span> en <span class="math inline">\(Y_{i2}\)</span> de eerste en tweede meting, respectievelijk, voorstellen voor plant <span class="math inline">\(i=1,...,n\)</span>, dan kunnen we dit schatten als
<span class="math display">\[\begin{equation*}
\bar Y = \sum_{i=1}^n \frac{Y_{i1}+Y_{i2}}{2n}
\end{equation*}\]</span>
In de onderstelling dat de <span class="math inline">\(n\)</span> planten onafhankelijk van elkaar gekozen werden en de eerste en tweede metingen even variabel zijn (d.w.z. <span class="math inline">\(\text{Var}(Y_{i1})=\text{Var}(Y_{i2})=\sigma^2\)</span>), bedraagt de variantie op dit steekproefgemiddelde
<span class="math display">\[\begin{eqnarray*}
\text{Var}(\bar Y)&amp;=&amp;\sum_{i=1}^n \frac{\text{Var}(Y_{i1}+Y_{i2})}{4n^2} \\
&amp;=&amp;\sum_{i=1}^n \frac{\sigma^2+\sigma^2+2\text{Cor}(Y_{i1},Y_{i2})\sigma^2}{%
4n^2} \\
&amp;=&amp;\frac{\sigma^2}{2n}\{1+\text{Cor}(Y_{1},Y_{2})\}
\end{eqnarray*}\]</span>
<p>Vermits verschillende metingen afkomstig van eenzelfde plant doorgaans positief met elkaar gecorreleerd zijn, is de standard error op <span class="math inline">\(\bar Y\)</span> dus groter dan wanneer de <span class="math inline">\(2n\)</span> metingen van <span class="math inline">\(2n\)</span> verschillende, onafhankelijke planten afkomstig zouden zijn. Dat is omdat, gegeven de eerste meting <span class="math inline">\(Y_{i1}\)</span>, de tweede meting <span class="math inline">\(Y_{i2}\)</span> geen volledig nieuwe informatie toevoegt en er bijgevolg minder informatie beschikbaar is om het gemiddelde te schatten dan wanneer alle gegevens van verschillende planten afkomstig waren. In het bijzonder, wanneer <span class="math inline">\(\text{Cor}(Y_{1},Y_{2})=1\)</span>, dan levert de tweede meting geen nieuwe informatie en bekomt men eenzelfde nauwkeurigheid als wanneer men slechts 1 meting per plant had bekomen. Wanneer <span class="math inline">\(\text{Cor}(Y_{1},Y_{2})=0\)</span>, dan levert de tweede meting volledig nieuwe informatie en bekomt men eenzelfde nauwkeurigheid als wanneer men 1 meting had bekomen voor <span class="math inline">\(2n\)</span> i.p.v. <span class="math inline">\(n\)</span> verschillende planten. Vermits <span class="math display">\[\frac{\sigma^2}{2n}\{1+\text{Cor}(Y_{1},Y_{2})\}\geq \frac{\sigma^2}{2n}\]</span></p>
<p><em>Wanneer de correlatie tussen herhaalde genexpressie metingen positief is (hetgeen we verwachten), zal men in de praktijk meer preciese resultaten bekomen door 1 meting te bepalen voor <span class="math inline">\(2n\)</span> verschillende planten dan door 2 metingen te bepalen voor <span class="math inline">\(n\)</span> verschillende planten.</em></p>
<p>De metingen in de captopril voorbeeld zijn eveneens geclusterd. We hebben immers twee systolische bloeddrukmetingen per patiënt. 1 meting voor en 1 meting na het toedienen van captopril. We beogen om de gemiddelde bloeddrukverandering <span class="math inline">\(\mu\)</span> te schatten a.d.h.v. de gegevens <span class="math display">\[(Y_{i1} , Y_{i2}),\]</span> voor subjecten <span class="math inline">\(i = 1, ..., n\)</span>. En we bekomen de volgende schatting: <span class="math display">\[\bar X = \sum_{i=1}^n \frac{Y_{i2}-Y_{i1}}{n}\]</span></p>
Uit de rekenregels voor de variantie weten we dat
<span class="math display">\[\begin{eqnarray*}
\text{Var}\left[\bar X\right]&amp;=&amp;\sum_{i=1}^n \frac{\text{Var}\left[Y_{i1}-Y_{i2}\right]}{n^2}\\
&amp;=&amp;\sum_{i=1}^n \frac{\sigma^2_1+\sigma^2_2-2\text{Cor}\left[Y_{i1},Y_{i2}\right]\sigma_1\sigma_2}{n^2}\\
&amp;=&amp;\frac{\sigma^2_1+\sigma^2_2-2\text{Cor}\left[Y_{i1},Y_{i2}\right]\sigma_1\sigma_2}{n},\\
\end{eqnarray*}\]</span>
<p>In R kunnen we dit als volgt berekenen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#functie var op een matrix berekent varianties sigma_1^2, sigma_2^2</span>
<span class="co">#covariantie sigma_{12}</span>
vars=<span class="kw">var</span>(captopril[,<span class="kw">c</span>(<span class="st">&quot;SBPb&quot;</span>,<span class="st">&quot;SBPa&quot;</span>)])
vars</code></pre></div>
<pre><code>##          SBPb     SBPa
## SBPb 422.9238 370.7857
## SBPa 370.7857 400.1429</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(captopril<span class="op">$</span>SBPa,captopril<span class="op">$</span>SBPb)</code></pre></div>
<pre><code>## [1] 0.9013312</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varXbarDelta=(vars[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>vars[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">-</span><span class="dv">2</span><span class="op">*</span>vars[<span class="dv">1</span>,<span class="dv">2</span>])<span class="op">/</span><span class="dv">15</span>
<span class="kw">sqrt</span>(varXbarDelta)</code></pre></div>
<pre><code>## [1] 2.330883</code></pre>
<p>We zien dat de metingen heel sterk gecorreleerd zijn, waardoor de variantie op het verschil veel lager zal liggen dan op de originele metingen.</p>
<p>Gezien we voor elke patiënt twee metingen hebben bestaat een alternatieve methode om de standard error te bepalen erin om alle gecorreleerde metingen tot 1 meting te reduceren. Merk op dat we dit enkel kunnen doen voor gepaarde metingen. Alle resulterende metingen zijn dan onafhankelijk. Concreet kunnen we voor elke patiënt <span class="math inline">\(i\)</span> in de steekproef het bloeddrukverschil berekenen: <span class="math display">\[X_{i}=Y_{ai}-Y_{bi}\]</span> en vervolgens standard error op <span class="math inline">\(\bar X\)</span>. In het captopril voorbeeld wordt de schatting</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">15</span>)</code></pre></div>
<pre><code>## [1] 2.330883</code></pre>
<p>We zien dat we exact dezelfde schatting voor de standard error bekomen. Verder zien we ook dat het design een groot voordeel heeft: Aangezien de bloeddrukmetingen voor en na het toedienen van captopril sterk positief gecorreleerd zijn is de variantie van het verschil veel lager dan deze op de originele bloeddrukmetingen. Iedere patiënt in de studie dient immers als zijn eigen controle en op die manier kunnen we de variabiliteit in de bloeddrukmetingen tussen patiënten uit de analyse verwijderen!</p>
</div>
<div id="normaal-verdeelde-gegevens" class="section level4">
<h4><span class="header-section-number">5.3.2.3</span> Normaal verdeelde gegevens</h4>
<p>Als de gegevens Normaal verdeeld zijn, dan zijn er meerdere onvertekende schatters voor het populatiegemiddelde <span class="math inline">\(\mu\)</span>, bvb. het steekproefgemiddelde en de mediaan. Men kan echter aantonen dat in dat geval het steekproefgemiddelde <span class="math inline">\(\bar{X}\)</span> de onvertekende schatter is voor <span class="math inline">\(\mu\)</span> met de kleinste standard error. Dat betekent dat ze gemiddeld minder afwijkt van de echte parameterwaarde dan de mediaan, die veel meer varieert van steekproef tot steekproef. Het steekproefgemiddelde is bijgevolg een schatter die accuraat is (want onvertekend) en meest precies (kleinste standaarddeviatie).</p>
</div>
</div>
<div id="subsec:verdelingXbar" class="section level3">
<h3><span class="header-section-number">5.3.3</span> Verdeling van het steekproefgemiddelde</h3>
<p>Om ondermeer goed de betekenis van de standard error te kunnen vatten, moeten we van <span class="math inline">\(\bar X\)</span> niet alleen het gemiddelde en de standaarddeviatie, maar ook de exacte verdeling kennen. De standard error is immers een standaardeviatie (bvb. van het steekproefgemiddelde), waarvan de betekenis het meest duidelijk is wanneer de metingen (in dit geval, het steekproefgemiddelde) Normaal verdeeld zijn. In het bijzonder geval dat de individuele observaties <span class="math inline">\(X_i\)</span> een Normale verdeling hebben met gemiddelde <span class="math inline">\(\mu\)</span> en variantie <span class="math inline">\(\sigma^2\)</span>, kan men aantonen dat ook <span class="math inline">\(\bar X\)</span> Normaal verdeeld is met gemiddelde <span class="math inline">\(\mu\)</span> en variantie <span class="math inline">\(\sigma^2/n.\)</span> Dit fenomeen wordt geïllustreerd in Figuur <a href="chap-besluit.html#fig:meansim">5.7</a>. De linkse figuur illustreert een lukrake trekking of steekproef van observaties uit een Normale verdeling. Als men dit blijft herhalen en voor alle bekomen steekproeven het steekproefgemiddelde berekent en en vervolgens deze gemiddeldes uitzet in een histogram, dan krijgt men het histogram uit rechtse figuur. De steekproefgemiddeldes in deze figuur lijken inderdaad een Normale verdeling te volgen.</p>
<div class="figure" style="text-align: center"><span id="fig:meansim"></span>
<img src="Statistiek_2019_2020_files/figure-html/meansim-1.png" alt="Simulaties van steekproeven met n=15 observaties uit een normale verdeling met gemiddelde systolische bloeddrukdaling 19 mmHg en standaard deviate van 9 mmHg. (links één steekproef, rechts een histogram van steekproefgemiddelden voor 1000 steekproeven. Het gemiddelde in de populatie is weergegeven d.m.v. rode lijn)." width="100%" />
<p class="caption">
Figuur 5.7: Simulaties van steekproeven met n=15 observaties uit een normale verdeling met gemiddelde systolische bloeddrukdaling 19 mmHg en standaard deviate van 9 mmHg. (links één steekproef, rechts een histogram van steekproefgemiddelden voor 1000 steekproeven. Het gemiddelde in de populatie is weergegeven d.m.v. rode lijn).
</p>
</div>
<p>In het captopril voorbeeld zagen we dat de systolische bloeddrukverandering approximatief normaal verdeeld is. De standard error op de bloeddrukverandering bedroeg 2.32 mm Hg. Dus op 100 studies met n = 15 subjecten, verwachten we dat de geschatte gemiddelde systolische bloeddrukafwijking (<span class="math inline">\(\bar X\)</span>) op minder dan 2 × 2.32 = 4.64mm Hg van het werkelijke populatiegemiddelde (<span class="math inline">\(\mu\)</span>) ligt in 95 studies.</p>
<p>In het algemeen, wanneer de individuele observaties <span class="math inline">\(X_i\)</span> geen Normale verdeling hebben, is <span class="math inline">\(\bar X\)</span>  toch nog Normaal verdeeld zodra het aantal observaties groot genoeg is. Hoe groot de steekproef hiervoor moet zijn, hangt hierbij af van hoe scheef de verdeling van de oorspronkelijke observaties is. Dat is het gevolg van de volgende fundamentele en veel toegepaste wiskundestelling.</p>
<p><strong>De Centrale Limietstelling (CLT)</strong></p>
<p>Stel dat <span class="math inline">\(X_1, X_2, \dots, X_n, \; n\)</span> onafhankelijke lukrake trekkingen van de toevalsveranderlijke <span class="math inline">\(X\)</span> voorstellen, met allen dezelfde theoretische verdeling. Laat <span class="math inline">\(X\)</span> gemiddelde <span class="math inline">\(\mu\)</span> en variantie <span class="math inline">\(\sigma^2\)</span> hebben maar verder een ongespecifieerde verdeling, dan wordt de verdeling van het steekproefgemiddelde <span class="math inline">\(\bar{X}_n = {\sum_{i=1}^{n} X_i}/{n}\)</span> naarmate <span class="math inline">\(n\)</span> groter wordt steeds beter benaderd door de Normale verdeling met gemiddelde <span class="math inline">\(\mu\)</span> en variantie <span class="math inline">\(\sigma^2/n.\)</span></p>
<p><strong>Einde Stelling</strong></p>
<p>Deze belangrijke eigenschap zal ons toelaten om de meeste technieken die in deze cursus aan bod komen toe te passen op een zeer uitgebreid spectrum van experimenten.</p>
<p>We illustreren deze stelling in Figuur <a href="chap-besluit.html#fig:CLT">5.8</a>. We simuleren data uit een experiment waarbij we een munt opwerpen. De data zijn dan Bernouilli verdeeld en kunnen de waarde <span class="math inline">\(X=0\)</span> (munt) of <span class="math inline">\(X=1\)</span> (kop) aannemen met een kans van 50% en zijn duidelijk niet-Normaal verdeeld. We simuleren steekproeven met een steekproefgrootte van 10 observaties en 100 observaties en onderzoeken de verdeling van het steekproefgemiddelde voor elke steekproefgrootte. We zien duidelijk dat CLT niet van toepassing is bij een steekproefgrootte van 10. Voor steekproeven met 100 observaties zien we dat de verdeling van het steekproefgemiddelde al beter benaderd kan worden door een Normale verdeling.</p>
<div class="figure" style="text-align: center"><span id="fig:CLT"></span>
<img src="Statistiek_2019_2020_files/figure-html/CLT-1.png" alt="Illustratie van de Centrale Limietstelling d.m.v. Bernouilli verdeelde gegevens (opwerpen van een muntstuk) Steekproefgroottes (n=10, links, en n=100, rechts). Densiteit van de normale verdeling worden weergegeven in rood. We zien duidelijk dat CLT niet van toepassing is bij een steekproefgrootte van 10. Voor steekproeven met 100 observaties zien we dat de verdeling van het steekproefgemiddelde al beter benaderd kan worden door een Normale verdeling." width="100%" />
<p class="caption">
Figuur 5.8: Illustratie van de Centrale Limietstelling d.m.v. Bernouilli verdeelde gegevens (opwerpen van een muntstuk) Steekproefgroottes (n=10, links, en n=100, rechts). Densiteit van de normale verdeling worden weergegeven in rood. We zien duidelijk dat CLT niet van toepassing is bij een steekproefgrootte van 10. Voor steekproeven met 100 observaties zien we dat de verdeling van het steekproefgemiddelde al beter benaderd kan worden door een Normale verdeling.
</p>
</div>
</div>
</div>
<div id="intervalschatters" class="section level2">
<h2><span class="header-section-number">5.4</span> Intervalschatters</h2>
<p>In de vorige sectie hebben we vastgesteld dat het steekproefgemiddelde van steekproef tot steekproef varieert rond het populatiegemiddelde dat we willen schatten. Om die reden wensen we in deze sectie een interval rond het steekproefgemiddelde te bepalen waarbinnen we het populatiegemiddelde met gegeven kans (bvb. 95% kans) kunnen verwachten. In Sectie <a href="chap-besluit.html#subsec:bigek">5.4.1</a> zullen we dit uitwerken voor het geval waar de populatievariantie <span class="math inline">\(\sigma^2\)</span> op de metingen gekend is. Deze onderstelling is meestal onredelijk<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a>, maar wordt hier gemaakt om redenen van eenvoud. In Sectie <a href="chap-besluit.html#sec:tBI">5.4.2</a> zullen we van deze onderstelling afstappen.</p>
<div id="subsec:bigek" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Gekende variantie op de metingen</h3>
<p>Wanneer de individuele observaties <span class="math inline">\(X\)</span> Normaal verdeeld zijn met gemiddelde <span class="math inline">\(\mu\)</span> en gekende variantie <span class="math inline">\(\sigma^2\)</span>, noteren we dat als volgt: <span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>. Uit vorige sectie volgt dan dat het steekproefgemiddelde <span class="math inline">\(\bar{X}\)</span> eveneens Normaal verdeeld is volgens <span class="math inline">\(N(\mu,\sigma^2/n)\)</span>. Een 95% referentie-interval voor het steekproefgemiddelde ziet er bijgevolg uit als</p>
<span class="math display">\[\begin{equation*}
\left[\mu - 1.96 \frac{\sigma}{\sqrt{n}},\mu + 1.96 \frac{\sigma}{\sqrt{n}}%
\right]
\end{equation*}\]</span>
Het bevat met 95% kans het steekproefgemiddelde van een lukrake steekproef. Dit interval kunnen we niet expliciet berekenen op basis van de geobserveerde gegevens, omdat <span class="math inline">\(\mu\)</span> ongekend is (we gaan er hier voorlopig van uit dat <span class="math inline">\(\sigma\)</span> wel gekend is). Het kan wel geschat worden als
<span class="math display">\[\begin{equation*}
\left[\bar X - 1.96 \frac{\sigma}{\sqrt{n}},\bar X + 1.96 \frac{\sigma}{\sqrt{n}}\right]
\end{equation*}\]</span>
Hoewel dit laatste interval nog steeds kan geïnterpreteerd worden als een referentie-interval voor het steekproefgemiddelde, kunnen we er een veel nuttigere interpretatie aan geven. Immers, de ongelijkheid <span class="math inline">\(\mu - 1.96 \
\sigma/\sqrt{n} &lt; \bar{X}\)</span> kan equivalent worden herschreven als <span class="math inline">\(\mu &lt; \bar{X} + 1.96 \ \sigma/\sqrt{n}\)</span>. Hieruit volgt:
<span class="math display">\[\begin{eqnarray*}
95\% &amp;=&amp; P( \mu - 1.96 \ \sigma/\sqrt{n} &lt; \bar{X} &lt; \mu + 1.96 \ \sigma/\sqrt{n} ) \\
&amp;=&amp;P( \bar{X} - 1.96 \ \sigma/\sqrt{n} &lt; \mu &lt; \bar{X} + 1.96 \ \sigma/\sqrt{n} )
\end{eqnarray*}\]</span>
<p>Dit leidt tot volgende definitie.</p>

<div class="definition">
<span id="def:unnamed-chunk-71" class="definition"><strong>Definitie 5.3  (95<span class="math inline">\(\%\)</span> betrouwbaarheidsinterval voor populatiegemiddelde)  </strong></span>Het interval
<span class="math display" id="eq:bi">\[\begin{equation}  
[\bar{X} - 1.96 \ \sigma/\sqrt{n} , \bar{X} + 1.96 \ \sigma/\sqrt{n} ], \tag{5.1}
\end{equation}\]</span>
<p>bevat met 95% kans het populatiegemiddelde <span class="math inline">\(\mu\)</span>. Het wordt een <strong>95% betrouwbaarheidsinterval</strong> (in het Engels: <em>95% confidence interval</em>) voor het populatiegemiddelde <span class="math inline">\(\mu\)</span> genoemd. De kans dat het de populatieparameter <span class="math inline">\(\mu\)</span> bevat, d.i. 95%, wordt het <em>betrouwbaarheidsniveau</em> genoemd.</p>
<p><strong>Einde definitie</strong></p>
</div>

<p>Een 95% betrouwbaarheidsinterval bepaalt met andere woorden een reeks waarden waarbinnen de gezochte populatieparameter <em>waarschijnlijk</em> (namelijk met 95% kans) valt.</p>
<p>Stel dat we in een steekproef een bloeddrukdaling van -18.93mmHg observeren en dat we weten dat de standaarddeviatie van de bloeddrukmetingen 9mmHg bedraagt. Dan vinden we een betrouwbaarheidsinterval voor de gemiddelde bloeddrukdaling van <span class="math inline">\(\left[-18.93-1.96\times 9/\sqrt{15},-18.9+1.95\times 9/\sqrt{15}\right]=\)</span>[-23.48,-14.38]mmHg.</p>
<p>De reden waarom over “95% kans” gesproken wordt, is omdat de eindpunten van het 95% betrouwbaarheidsinterval toevalsveranderlijken zijn die variëren van steekproef tot steekproef. Met andere woorden, verschillende steekproeven leveren telkens andere betrouwbaarheidsintervallen op, vermits die intervallen berekend zijn op basis van de gegevens in de steekproef. Men noemt het om die reden <em>stochastische intervallen</em>. Voor 95% van alle steekproeven zal het berekende 95% betrouwbaarheidsinterval de gezochte waarde van de populatieparameter bevatten, en voor de overige 5% niet. Dat wordt geïllustreerd a.d.h.v. een simulatiestudie in Sectie <a href="chap-besluit.html#subsec:interpretBI">5.4.3</a> (nadat we de intervallen hebben uitgebreid voor de meer realistische setting waarbij de variantie in de populatie ongekend is).</p>
<p>Uiteraard kunnen de onderzoekers o.b.v. een gegeven betrouwbaarheidsinterval niet besluiten of het de gezochte parameterwaarde bevat of niet, vermits ze precies op zoek zijn naar die onbekende waarde. Maar ze gebruiken een procedure die in 95% van de gevallen werkt; m.a.w. die in 95% van de gevallen de gezochte waarde bevat. Of nog, als men dagelijks gegevens zou verzamelen en telkens een 95% betrouwbaarheidsinterval zou berekenen voor een nieuwe parameter <span class="math inline">\(\theta\)</span> (bvb. een odds ratio), dan zou men op lange termijn in 95% van de gevallen de gezochte waarde omvat hebben.</p>
<p>Tot nog toe zijn we ervan uitgegaan dat de individuele observaties Normaal verdeeld zijn en dat hun variantie gekend is (want als de variantie <span class="math inline">\(\sigma^2\)</span> niet gekend is, kan men de grenzen van het interval niet berekenen). Wegens de Centrale Limietstelling bevat Vergelijking <a href="chap-besluit.html#eq:bi">(5.1)</a> het gemiddelde <span class="math inline">\(\mu\)</span> bij benadering met 95% kans wanneer de steekproef groot is en de variantie van de individuele observaties gekend, maar hun verdeling ongekend is.</p>
<p>Wanneer bovendien de variantie ongekend is, kan me ze schatten door gebruik te maken van de steekproefvariantie <span class="math inline">\(S^2\)</span> van de reeks observaties <span class="math inline">\(X_1,...,X_n\)</span>. Men kan aantonen dat het interval <span class="math inline">\([\bar{X} - 1.96 \ s/\sqrt{n} , \bar{X} + 1.96 \ s/\sqrt{n} ]\)</span> dan het populatiegemiddelde met bij benadering 95% kans bevat, op voorwaarde dat de steekproef groot is. In de volgende sectie gaan we na hoe een betrouwbaarheidsinterval voor het populatiegemiddelde geconstrueerd kan worden wanneer de variantie ongekend is en de steekproef relatief klein.</p>
<p>Om een betrouwbaarheidsinterval met een ander betrouwbaarheidsniveau, <span class="math inline">\((1- \alpha)100\%\)</span> te construeren, vervangt men 1.96 door het relevante kwantiel <span class="math inline">\(z_{\alpha/2}.\)</span></p>
<p>De breedte van een <span class="math inline">\(100\%(1-\alpha)\)</span> betrouwbaarheidsinterval voor een populatiegemiddelde <span class="math inline">\(\mu\)</span> is <span class="math inline">\(2 z_{\alpha/2} \ \sigma/\sqrt{n}\)</span>. Ze wordt dus bepaald door 3 factoren: de standaarddeviatie op de individuele observaties, <span class="math inline">\(\sigma\)</span>, de grootte van de steekproef, <span class="math inline">\(n\)</span>, en het betrouwbaarheidsniveau, <span class="math inline">\(1-\alpha\)</span>:</p>
<ul>
<li><p><span class="math inline">\(n\)</span>: naarmate de steekproefgrootte toeneemt, krimpt het betrouwbaarheidsinterval. In grote steekproeven beschikken we immers over veel informatie en kunnen we de gezochte populatieparameter bijgevolg relatief nauwkeurig afschatten.</p></li>
<li><p><span class="math inline">\(\sigma\)</span>: naarmate de standaarddeviatie van de oorspronkelijke observaties toeneemt, neemt de lengte van het betrouwbaarheidsinterval toe. Indien er immers veel ruis op de gegevens zit, dan is het moeilijker om populatieparameters of -kenmerken te identificeren.</p></li>
<li><p><span class="math inline">\(1-\alpha\)</span>: naarmate het betrouwbaarheidsniveau toeneemt, wordt het betrouwbaarheidsinterval breder. Indien we immers eisen dat het interval met 99.9% kans de populatiewaarde bevat i.p.v. met 80% kans, dan zullen we duidelijk een breder interval nodig hebben.</p></li>
</ul>
<p>Betrouwbaarheidsintervallen worden niet enkel gebruikt voor het populatiegemiddelde, maar kunnen in principe voor om het even welke populatieparameter worden gedefinieerd. Zo kunnen ze bijvoorbeeld gedefinieerd worden voor een verschil tussen 2 gemiddelden, voor een odds ratio, voor een variantie, … De manier om die intervallen te berekenen is vaak complex en sterk afhankelijk van de gebruikte schatter voor de populatieparameter. Er wordt daarom niet van u verwacht dat u voor alle populatieparameters die we in deze cursus ontmoeten, een betrouwbaarheidsinterval kunt berekenen, maar wel dat u het kunt interpreteren.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-72" class="definition"><strong>Definitie 5.4  (Betrouwbaarheidsinterval)  </strong></span>Een <strong><span class="math inline">\((1-\alpha)100\)</span>% betrouwbaarheidsinterval</strong> voor een populatieparameter <span class="math inline">\(\theta\)</span> is een geschat (en bijgevolg stochastisch) interval dat met <span class="math inline">\((1-\alpha)100\)</span>% kans de echte waarde van die populatieparameter <span class="math inline">\(\theta\)</span> bevat.</p>
<p><strong>Einde Definitie</strong></p>
</div>

</div>
<div id="sec:tBI" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Ongekende variantie op de metingen</h3>
Tot nog toe werd verondersteld dat de populatievariantie <span class="math inline">\(\sigma^2\)</span> gekend is bij het berekenen van een betrouwbaarheidsinterval voor <span class="math inline">\(\mu\)</span>. Betrouwbaarheidsintervallen voor <span class="math inline">\(\mu\)</span> werden dan opgebouwd door op te merken dat de gestandaardiseerde waarde <span class="math inline">\((\bar{X} - \mu)/(\sigma/\sqrt{n})\)</span> standaardnormaal verdeeld is en bijgevolg
<span class="math display">\[\begin{equation*}
\left[\mu - 1.96 \frac{\sigma}{\sqrt{n}},\mu + 1.96 \frac{\sigma}{\sqrt{n}}%
\right]
\end{equation*}\]</span>
<p>een 95% referentie-interval voor het steekproefgemiddelde voorstelt.</p>
In de praktijk komt het quasi nooit voor dat men de populatievariantie <span class="math inline">\(\sigma^2\)</span> exact kent. In de praktijk wordt deze geschat als <span class="math inline">\(S^2\)</span> op basis van de voorhanden zijnde steekproef. Als gevolg hiervan zullen de betrouwbaarheidsintervallen uit voorgaande sectie doorgaans iets te smal zijn (omdat ze er geen rekening mee houden dat ook de variantie werd geschat) en is het noodzakelijk om bij de berekening <span class="math inline">\((\bar{X} - \mu)/(S/\sqrt{n})\)</span> te gebruiken als gestandaardiseerde waarde i.p.v. <span class="math inline">\((\bar{X} - \mu)/(\sigma/\sqrt{n})\)</span>. Wanneer de steekproef voldoende groot is, ligt de vierkantswortel van variantie <span class="math inline">\(S^2\)</span> voldoende dicht bij <span class="math inline">\(\sigma\)</span> zodat <span class="math inline">\({(\bar{X} - \mu)}/{(S/\sqrt{n}) }\)</span> bij benadering een standaardnormale verdeling volgt en, bijgevolg,
<span class="math display">\[\begin{equation*}
\left[\bar{X} - z_{\alpha/2} \ \frac{S}{\sqrt{n}} , \bar{X} + z_{\alpha/2} \ 
\frac{S}{\sqrt{n}}\right]
\end{equation*}\]</span>
<p>een benaderd <span class="math inline">\((1- \alpha)100\%\)</span> betrouwbaarheidsinterval is voor <span class="math inline">\(\mu\)</span>. Voor kleine steekproeven is dit niet langer het geval. Daardoor introduceert men een extra onnauwkeurigheid in de gestandaardiseerde waarde <span class="math inline">\({(\bar{X} - \mu)}/{(S/\sqrt{n})}\)</span>. Deze is nog wel gecentreerd rond nul en symmetrisch, maar niet langer Normaal verdeeld. De echte verdeling voor eindige steekproefgrootte <span class="math inline">\(n\)</span> heeft zwaardere staarten dan de Normale. Hoeveel zwaarder de staarten zijn, hangt van de steekproefgrootte <span class="math inline">\(n\)</span> af. Als <span class="math inline">\(n\)</span> oneindig groot wordt, komt <span class="math inline">\(S\)</span> zodanig dicht bij <span class="math inline">\(\sigma\)</span> te liggen dat de extra onnauwkeurigheid in de gestandaardiseerde waarde verwaarloosbaar is en bijgevolg ook het verschil met de Normale verdeling. Maar voor relatief kleine steekproeven hangt de verdeling van <span class="math inline">\({(\bar{X} - \mu)}/({S/\sqrt{n}})\)</span> af van de grootte <span class="math inline">\(n\)</span> van de steekproef. Ze krijgt de naam (Student) <span class="math inline">\(t\)</span>-verdeling met <span class="math inline">\(n-1\)</span> vrijheidsgraden (in het Engels: <em>degrees of freedom</em>). Deze verdeling wordt voor een aantal verschillende vrijheidsgraden geïllustreerd in Figuur <a href="chap-besluit.html#fig:tdist">5.9</a>. De t-verdelingen in de figuur hebben duidelijk bredere staarten dan de normaalverdeling, waardoor ze ook een grotere percentielwaarden hebben voor een vooropgesteld betrouwbaarheidsniveau. Dat zal leiden tot bredere intervallen, wat logisch is aangezien we de extra onzekerheid inbouwen die gerelateerd is aan het schatten van de standaarddeviatie.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-73" class="definition"><strong>Definitie 5.5  (t-verdeling)  </strong></span>Als <span class="math inline">\(X_1, X_2, ..., X_n\)</span> een steekproef vormen uit de Normale verdeling <span class="math inline">\(N(\mu, \sigma^2)\)</span>, dan is <span class="math inline">\((\bar{X} - \mu)/(S/\sqrt{n})\)</span> verdeeld als een <span class="math inline">\(t\)</span>-verdeling met <span class="math inline">\(n-1\)</span> vrijheidsgraden.</p>
<p>**Einde Definitie</p>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid=<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,.<span class="dv">1</span>)
<span class="kw">plot</span>(grid,<span class="kw">dnorm</span>(grid),<span class="dt">ylab=</span><span class="st">&quot;densiteit&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;X&quot;</span>,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
dfs=<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">14</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(dfs))
     <span class="kw">lines</span>(grid,<span class="kw">dt</span>(grid,dfs[i]),<span class="dt">col=</span>i<span class="op">+</span><span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>,<span class="dt">lty=</span><span class="dv">1</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">4</span>,<span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;N(X,mean=0,sd=1)&quot;</span>,<span class="kw">paste0</span>(<span class="st">&quot;t(X,df=&quot;</span>,dfs,<span class="st">&quot;)&quot;</span>)))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tdist"></span>
<img src="Statistiek_2019_2020_files/figure-html/tdist-1.png" alt="Normale verdeling en t-verdeling met verschillende vrijheidsgraden." width="100%" />
<p class="caption">
Figuur 5.9: Normale verdeling en t-verdeling met verschillende vrijheidsgraden.
</p>
</div>
<p>Percentielen van de <span class="math inline">\(t\)</span>-verdeling kunnen niet met de hand berekend worden, maar kan men voor de verschillende waarden van <span class="math inline">\(n\)</span> aflezen in Tabellen of berekenen in R. In de onderstaande code wordt het 95%, 97.5%, 99.5% percentiel berekend voor een t-verdeling met 14 vrijheidsgraden, die gebruik kunnen worden voor de berekening van 90%, 95% en 99% betrouwbaarheidsintervallen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dt">df=</span><span class="dv">14</span>)</code></pre></div>
<pre><code>## [1] 2.144787</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="kw">c</span>(.<span class="dv">95</span>,.<span class="dv">975</span>,.<span class="dv">995</span>),<span class="dt">df=</span><span class="dv">14</span>)</code></pre></div>
<pre><code>## [1] 1.761310 2.144787 2.976843</code></pre>
<p>We zien dat het 97.5% percentiel 2.14 voor een t-verdeling met <span class="math inline">\(n-1=14\)</span> vrijheidsgraden inderdaad groter is dan het kwantiel uit de normaal verdeling 1.96.</p>
Een gelijkaardige logica als voor de Normale verdeling met gekende variantie, geeft dan aan dat een <span class="math inline">\(100\% (1-\alpha)\)</span> betrouwbaarheidsinterval voor het gemiddelde <span class="math inline">\(\mu\)</span> van een Normaal verdeelde veranderlijke <span class="math inline">\(X\)</span> met onbekende variantie kan berekend worden als
<span class="math display">\[\begin{equation*}
\left[\bar{X} - t_{n-1, \alpha/2} \frac{s}{\sqrt{n}} , \bar{X} + t_{n-1,
\alpha/2} \frac{s}{\sqrt{n}}\right]
\end{equation*}\]</span>
<p>Deze uitdrukking verschilt van deze in de vorige sectie doordat het <span class="math inline">\((1-\alpha/2)100\%\)</span> percentiel van de Normale verdeling wordt vervangen door het <span class="math inline">\((1-\alpha/2)100\%\)</span> percentiel van de t-verdeling met <span class="math inline">\(n-1\)</span> vrijheidsgraden.</p>
<p>Voor het captopril voorbeeld kunnen we dus een 95% betrouwbaarheidsinterval bekomen door</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(delta) <span class="op">-</span><span class="st">  </span><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dt">df=</span><span class="dv">14</span>)<span class="op">*</span><span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(n)</code></pre></div>
<pre><code>## [1] -23.93258</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(delta) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dt">df=</span><span class="dv">14</span>)<span class="op">*</span><span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(n)</code></pre></div>
<pre><code>## [1] -13.93409</code></pre>
<p>Een 99% betrouwbaarheidsinterval voor gemiddelde bloeddrukverandering wordt als volgt bekomen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(delta) <span class="op">-</span><span class="st">  </span><span class="kw">qt</span>(.<span class="dv">995</span>,<span class="dt">df=</span><span class="dv">14</span>)<span class="op">*</span><span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(n)</code></pre></div>
<pre><code>## [1] -25.87201</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(delta) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(.<span class="dv">995</span>,<span class="dt">df=</span><span class="dv">14</span>)<span class="op">*</span><span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(n)</code></pre></div>
<pre><code>## [1] -11.99466</code></pre>
</div>
<div id="subsec:interpretBI" class="section level3">
<h3><span class="header-section-number">5.4.3</span> Interpretatie van betrouwbaarheidsintervallen</h3>
<p>We zullen de interpretatie van betrouwbaarheidsintervallen weergegeven a.d.h.v. een simulatie studie waarbij we 1000 herhaalde steekproeven simuleren met 15 observaties uit een normaal verdeling. De gemiddelde bloeddrukdaling in de populatie bedraagt -18.9 mmHg en de standaarddeviate 9.0 mmHg. We houden voor elke steekproef volgende gegevens bij: het gemiddelde, de ondergrens en bovengrens van het BI en of het BI het werkelijke gemiddelde.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">115</span>)
mu &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">18.9</span>
sigma &lt;-<span class="st"> </span><span class="fl">9.0</span>
nSim &lt;-<span class="st"> </span><span class="dv">1000</span>
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>
n &lt;-<span class="st"> </span><span class="dv">15</span>
muHat &lt;-<span class="st"> </span>sigmaHat &lt;-<span class="st"> </span>BI.ondergrens &lt;-<span class="st"> </span>BI.bovengrens &lt;-<span class="st"> </span>omvat &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dt">dim=</span>nSim)
cnt&lt;-<span class="dv">0</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nSim) {
  y&lt;-<span class="kw">rnorm</span>(n,<span class="dt">mean=</span>mu,<span class="dt">sd=</span>sigma)
  muHat[i]&lt;-<span class="kw">mean</span>(y)
  sigmaHat[i]&lt;-<span class="kw">sd</span>(y)<span class="op">/</span><span class="kw">sqrt</span>(n)
  BI.ondergrens[i]&lt;-muHat[i]<span class="op">-</span><span class="kw">qt</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,<span class="dt">df=</span>n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>sigmaHat[i]
   BI.bovengrens[i]&lt;-muHat[i]<span class="op">+</span><span class="kw">qt</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,<span class="dt">df=</span>n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>sigmaHat[i]  
  omvat[i]&lt;-(mu<span class="op">&lt;</span>BI.bovengrens[i])<span class="op">&amp;</span>(BI.ondergrens[i]<span class="op">&lt;</span>mu)
  cnt&lt;-cnt<span class="op">+</span><span class="kw">as.numeric</span>(omvat[i])
 }
 cnt<span class="op">/</span>nSim</code></pre></div>
<pre><code>## [1] 0.951</code></pre>
<p>Op basis van de 1000 herhaalde steekproeven van de simulatiestudie zien we dat voor 95.1% van de steekproeven de intervallen het werkelijke populatiegemiddelde bevat<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a>. De simulatiestudie toont dus op een empirische wijze aan dat de constructie correct is. Het demonstreert bovendien de interpretatie van probabiliteit via herhaalde steekproefname. In Figuur <a href="chap-besluit.html#fig:biInterpret">5.10</a> wordt de interpretatie ook grafisch weergegeven voor de eerste 100 gesimuleerde steekproeven. De figuur toont duidelijk aan dat het werkelijke populatiegemiddelde vast is maar ongekend. Het wordt geschat aan de hand van het steekproefgemiddelde dat at random varieert van steekproef tot steekproef rond het werkelijk gemiddelde. We zien ook dat de grenzen van de betrouwbaarheidsintervallen variëren van steekproef tot steekproef. Daarnaast varieert de breedte van de betrouwbaarheidsintervallen eveneens omdat de steekproefstandaarddeviatie eveneens varieert van steekproef tot steekproef<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a>.</p>
<p>In de praktijk zullen we op basis van 1 steekproef besluiten dat het betrouwbaarheidsinterval het populatiegemiddelde bevat en we weten dat dergelijke uitspraken met een kans van <span class="math inline">\(1-\alpha\)</span> (hier 95%) correct zijn.</p>
<div class="figure" style="text-align: center"><span id="fig:biInterpret"></span>
<img src="Statistiek_2019_2020_files/figure-html/biInterpret-1.png" alt="Interpretatie van 95$\%$ betrouwbaarheidintervallen. Resultaten op basis van 100 gesimuleerde steekproeven. We zien in de figuur duidelijk dat het populatiegemiddelde vast is maar ongekend (blauwe lijn) en dat de bovengrens en ondergrens van betrouwbaarheidsintervallen voor het populatiegemiddelde varieert van steekproef tot steekproef. Van de 100 betrouwbaarheidsintervallen die worden geplot bevatten 95 intervallen het werkelijke steekproef gemiddelde (zwarte BIs). Voor 5 intervallen is dat niet het geval (rode BIs)." width="100%" />
<p class="caption">
Figuur 5.10: Interpretatie van 95<span class="math inline">\(\%\)</span> betrouwbaarheidintervallen. Resultaten op basis van 100 gesimuleerde steekproeven. We zien in de figuur duidelijk dat het populatiegemiddelde vast is maar ongekend (blauwe lijn) en dat de bovengrens en ondergrens van betrouwbaarheidsintervallen voor het populatiegemiddelde varieert van steekproef tot steekproef. Van de 100 betrouwbaarheidsintervallen die worden geplot bevatten 95 intervallen het werkelijke steekproef gemiddelde (zwarte BIs). Voor 5 intervallen is dat niet het geval (rode BIs).
</p>
</div>
<p>We zullen nu de simulatie herhalen, maar zullen het aantal observaties in de steekproef verdubbelen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">18.9</span>
sigma &lt;-<span class="st"> </span><span class="fl">9.0</span>
nSim &lt;-<span class="st"> </span><span class="dv">1000</span>
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>
n &lt;-<span class="st"> </span><span class="dv">30</span>
muHat &lt;-<span class="st"> </span>sigmaHat &lt;-<span class="st"> </span>BI.ondergrens &lt;-<span class="st"> </span>BI.bovengrens &lt;-<span class="st"> </span>omvat &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dt">dim=</span>nSim)
cnt&lt;-<span class="dv">0</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nSim) {
  y&lt;-<span class="kw">rnorm</span>(n,<span class="dt">mean=</span>mu,<span class="dt">sd=</span>sigma)
  muHat[i]&lt;-<span class="kw">mean</span>(y)
  sigmaHat[i]&lt;-<span class="kw">sd</span>(y)<span class="op">/</span><span class="kw">sqrt</span>(n)
  BI.ondergrens[i]&lt;-muHat[i]<span class="op">-</span><span class="kw">qt</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,<span class="dt">df=</span>n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>sigmaHat[i]
   BI.bovengrens[i]&lt;-muHat[i]<span class="op">+</span><span class="kw">qt</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,<span class="dt">df=</span>n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>sigmaHat[i]  
  omvat[i]&lt;-(mu<span class="op">&lt;</span>BI.bovengrens[i])<span class="op">&amp;</span>(BI.ondergrens[i]<span class="op">&lt;</span>mu)
  cnt&lt;-cnt<span class="op">+</span><span class="kw">as.numeric</span>(omvat[i])
 }
 cnt<span class="op">/</span>nSim</code></pre></div>
<pre><code>## [1] 0.949</code></pre>
<p>We zien een coverage van 94.9% wat opnieuw dicht ligt bij de nominale coverage van 95%.</p>
<p>Wanneer we opnieuw de eerste 100 betrouwbaarheidsintervallen plotten (Figuur <a href="chap-besluit.html#fig:biInterpretLargeSample">5.11</a>) merken we op dat de intervallen smaller zijn dan in Figuur <a href="chap-besluit.html#fig:biInterpret">5.10</a> (waarom is dat het geval, ga zelf na met welke factor de intervallen ongeveer versmallen?)</p>
<div class="figure" style="text-align: center"><span id="fig:biInterpretLargeSample"></span>
<img src="Statistiek_2019_2020_files/figure-html/biInterpretLargeSample-1.png" alt="Interpretatie van 95$\%$ betrouwbaarheidintervallen. Resultaten op basis van 100 gesimuleerde steekproeven. We zien in de figuur duidelijk dat het populatiegemiddelde vast is maar ongekend (blauwe lijn) en dat de bovengrens en ondergrens van betrouwbaarheidsintervallen voor het populatiegemiddelde varieert van steekproef tot steekproef. Van de 100 betrouwbaarheidsintervallen die worden geplot bevatten 95 intervallen het werkelijke steekproef gemiddelde (zwarte BIs). Voor 5 intervallen is dat niet het geval (rode BIs)." width="100%" />
<p class="caption">
Figuur 5.11: Interpretatie van 95<span class="math inline">\(\%\)</span> betrouwbaarheidintervallen. Resultaten op basis van 100 gesimuleerde steekproeven. We zien in de figuur duidelijk dat het populatiegemiddelde vast is maar ongekend (blauwe lijn) en dat de bovengrens en ondergrens van betrouwbaarheidsintervallen voor het populatiegemiddelde varieert van steekproef tot steekproef. Van de 100 betrouwbaarheidsintervallen die worden geplot bevatten 95 intervallen het werkelijke steekproef gemiddelde (zwarte BIs). Voor 5 intervallen is dat niet het geval (rode BIs).
</p>
</div>
</div>
<div id="wat-rapporteren" class="section level3">
<h3><span class="header-section-number">5.4.4</span> Wat rapporteren?</h3>
<p>Rapporteer dus zeker steeds de onzekerheid op de resultaten! Conclusies trekken op basis van 1 schatting kan zeer misleidend zijn! In statistische analyses rapporteert men daarom systematisch betrouwbaarheidsintervallen. Betrouwbaarheidsintervallen vormen een goed compromis: ze zijn smal genoeg om informatief te zijn, maar haast nooit zeer misleidend. We besluiten dat de parameter die ons interesseert in het 95% betrouwbaarheidsinterval zit, en weten dat die uitspraak met 95% kans correct is. In de statistiek trekt men dus nooit absolute conclusies.</p>
<p>Op basis van de data-analyse voor het captopril voorbeeld kunnen we dus besluiten dat de gemiddelde bloeddrukdaling 18.9mmHg bedraagt na het toedienen van captopril. Met een 95% betrouwbaarheidsinterval op het gemiddelde van [-22.3,-15.6]mmHg. Op basis van het betrouwbaarheidsinterval is het duidelijk dat het toedienen van captopril resulteert in een sterke bloeddrukdaling bij patiënten met hypertensie.</p>
</div>
</div>
<div id="principe-van-hypothesetoetsen-via-one-sample-t-test" class="section level2">
<h2><span class="header-section-number">5.5</span> Principe van Hypothesetoetsen (via one sample t-test)</h2>
<p>We wensen een uitspraak te kunnen doen of er al dan niet een effect is van het toedienen van Captopril op de systolische bloeddruk? Beslissen op basis van gegevens is niet evident. Er is immers onzekerheid of de bevindingen uit de steekproef generaliseerbaar zijn naar de populatie. We stellen ons dus de vraag of het schijnbaar gunstig effect systematisch of toevallig is? Een natuurlijke beslissingsbasis is het gemiddeld verschil <span class="math inline">\(X\)</span> in de systolische bloeddruk:</p>
<p><span class="math inline">\(\bar x=\)</span> -18.93mmHg (<span class="math inline">\(s =\)</span> 9.03, <span class="math inline">\(SE =\)</span> 2.33).</p>
<p>Dat <span class="math inline">\(\bar{x}&lt; 0\)</span> volstaat niet om te beslissen dat de gemiddelde systolische bloeddruk lager is na het toedienen van captopril <em>op het niveau van de volledige populatie</em>. Om het effect die we in de steekproef observeren te kunnen <em>veralgemenen</em> naar de populatie moet de bloeddrukverlaging voldoende groot zijn. Maar hoe groot moet dit effect nu zijn?</p>
<p>Hiervoor hebben statistici zogenaamde <em>toetsen</em> ontwikkeld om met dit soort vragen om te gaan. Deze leveren een ja/nee antwoord op de vraag of een geobserveerde associatie systematisch is (d.w.z. opgaat voor de studiepopulatie) of als er integendeel onvoldoende informatie in de steekproef voorhanden is om te besluiten dat de geobserveerde associatie ook aanwezig is in de volledige studiepopulatie. Tegenwoordig is het haast onmogelijk om een wetenschappelijk onderzoeksartikel te lezen zonder de resultaten van dergelijke toetsen te ontmoeten. Om die reden wensen we in dit hoofdstuk in te gaan op de betekenis van statistische toetsen en hun nomenclatuur.</p>
<p>We weten dat we volgens het <em>falcificatieprincipe</em> van Popper nooit een hypothese kunnen bewijzen op basis van data (zie Sectie <a href="inleiding.html#sec:wetMeth">1.1</a>). Daarom zullen we twee hypotheses introduceren: een nulhypothese en een alternatieve hypothese. We zullen dan later a.d.h.v. de toets de nulhypothese trachten te ontkrachten.</p>
<div id="hypotheses" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Hypotheses</h3>
<p>Algemeen starten we met het vertalen van de wetenschappelijke vraagstelling naar een nulhypothese (<span class="math inline">\(H_0\)</span>) en een alternatieve hypothese (<span class="math inline">\(H_1\)</span>). Dit kan pas nadat de probleemstelling vertaald is naar een geparametriseerd statistisch model. Uit de beschrijving van de proefopzet volgt dat <span class="math inline">\(X_1,...,X_n\)</span> i.i.d.<a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a> <span class="math inline">\(f(X)\)</span> met <span class="math inline">\(f(X)\)</span> de dichtheidsfunctie van de bloeddrukverschillen.</p>
<p><strong>Vereenvoudiging</strong>: veronderstel dat <span class="math inline">\(f(X)\)</span> gekend is op een eindig-dimensionale set van parameters <span class="math inline">\(\mathbf{\theta}\)</span> na (parametrisch statistisch model). Voor het captopril voorbeeld veronderstellen we dat <span class="math inline">\(f(X)\)</span> een normale distributie <span class="math inline">\(N(\mu,\sigma^2)\)</span> volgt met parameters <span class="math inline">\(\mathbf{\theta}=(\mu,\sigma^2)\)</span>, het gemiddelde <span class="math inline">\(\mu\)</span> en variantie <span class="math inline">\(\sigma^2\)</span>.</p>
<p>De vraagstelling is geformuleerd in termen van de gemiddelde bloeddrukdaling: <span class="math inline">\(\mu=E_f[X]\)</span>.</p>
<p>De <strong>alternatieve hypothese</strong> wordt geformuleerd in termen van een parameter van <span class="math inline">\(f(X)\)</span> en dient uit te drukken wat de onderzoekers wensen te bewijzen aan de hand van de studie. Hier: <span class="math display">\[H_1: \mu&lt;0.\]</span> Gemiddeld gezien daalt de bloeddruk bij patiënten met hypertensie na toediening van captopril.</p>
<p>De <strong>nulhypothese</strong> is meestal een uitdrukking van de nultoestand, i.e. de omstandigheden waarin niets bijzonders aan de hand is. De onderzoekers wensen meestal te bewijzen via empirisch onderzoek dat de nulhypothese niet waar is: <strong>Falsificatie principe</strong>. De <strong>nulhypothese wordt veelal uitgedrukt door gebruik te maken van dezelfde parameter als deze die in <span class="math inline">\(H_1\)</span></strong> gebruikt is. Hier: <span class="math display">\[H_0 : \mu=0\]</span> m.a.w. gemiddeld gezien blijft de systolische bloeddruk na toediening van captopril onveranderd.</p>
</div>
<div id="test-statistiek" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Test-statistiek</h3>
<p>Eens de populatie, de parameters en de nulhypothese en alternatieve hypothese bepaald zijn, kan de basisgedachte van een hypothesetest als volgt bondig beschreven worden.</p>
<p>Construeer een teststatistiek zodanig dat deze</p>
<ol style="list-style-type: decimal">
<li>de evidentie meet die aanwezig is in de steekproef,</li>
<li>tegen de gestelde nulhypothese,</li>
<li>ten voordele van de alternatieve hypothese.</li>
</ol>
<p>Een teststatistiek is dus noodzakelijk een functie van de steekproefobservaties.</p>
<p>Voor het captopril voorbeeld drukt de statistiek <span class="math display">\[T=\bar X - \mu_0\]</span> uit hoever het steekproefgemiddelde van de bloeddrukdaling ligt van het gemiddelde <span class="math inline">\(\mu_0=0\)</span> in de populatie onder de nulhypothese<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a>.</p>
<ul>
<li>Als <span class="math inline">\(H_0\)</span> waar is en er dus geen effect is van captopril in de populatie, dan verwachten we dat de teststatistiek T dicht ligt bij <span class="math inline">\(T=0\)</span></li>
<li>Als <span class="math inline">\(H_1\)</span> waar is, dan verwachten we dat <span class="math inline">\(T&lt;0\)</span>.</li>
</ul>
<p>In de praktijk gebruiken we echter meestal teststatistieken die niet alleen de grootte van het effect in rekening brengen maar ook de onzekerheid op het effect. We doen dit door de effectgrootte te balanceren t.o.v. de standard error.</p>
<p><span class="math display">\[T=\frac{\bar{X}-0}{\text{SE}_{\bar X}}\]</span> Waarbij <span class="math inline">\(\mu_0=0\)</span> voor het captopril voorbeeld.</p>
<p>Opnieuw geldt dat</p>
<ul>
<li>Als <span class="math inline">\(H_0\)</span> waar is en er dus geen effect is van captopril in de populatie, dan verwachten we dat de teststatistiek T dicht ligt bij <span class="math inline">\(T=0\)</span></li>
<li>Als <span class="math inline">\(H_1\)</span> waar is, dan verwachten we dat <span class="math inline">\(T&lt;0\)</span>.</li>
<li>Voor het captopril voorbeeld vinden we <span class="math inline">\(t=(-18.93-0)/2.33=-8.12\)</span>.</li>
<li>Is <span class="math inline">\(t = -8.12\)</span> groot genoeg in absolute waarde om te kunnen besluiten dat <span class="math inline">\(\mu &lt; 0\)</span> en met welke zekerheid kunnen we dit besluiten?</li>
</ul>
<p>Om daar een uitspraak over te doen zullen we de teststatistiek T verder bestuderen. T is een toevalsveranderlijke en de verdeling van T hangt af van de verdeling van de steekproefobservaties, maar die verdeling is ongekend! We hebben normaliteit verondersteld, maar dit laat nog steeds het gemiddelde en de variantie onbepaald. Bovendien wordt de hypothesetest net geconstrueerd om een uitspraak te kunnen doen over het gemiddelde <span class="math inline">\(\mu\)</span>! De oplossing zit in de nulhypothese die we kunnen veronderstellen als er geen effect is van captopril. De <span class="math inline">\(H_0\)</span> stelt dat <span class="math inline">\(\mu=0\)</span>. Als we aannemen dat <span class="math inline">\(H_0\)</span> waar is, dan is het gemiddelde van de normale distributie gekend! Als de bloeddrukverschillen <span class="math inline">\(X_1, \ldots X_{15}\)</span> onafhankelijk en identiek normaal verdeeld (i.i.d.) zijn, dan weten we dat <span class="math display">\[\bar X  \stackrel{H_0}{\sim} N(0, \sigma^2/n)\]</span></p>
<p>Gezien we <span class="math inline">\(\sigma^2\)</span> niet kennen kunnen we deze vervangen door de steekproef variantie. Dan weten we dat <span class="math display">\[T=\frac{\bar{X}-0}{\text{SE}_{\bar X}}\stackrel{H_0}{\sim} t(n-1) \]</span> een t-verdeling volgt met n-1 vrijheidsgraden onder de <strong>nulhypothese</strong>. We weten dat indien de alternatieve hypothese waar zou zijn, we mogen verwachten dat er meer kans is op het observeren van een kleine waarde voor de teststatistiek dan wat verwacht wordt onder de nulhypothese. We zullen de verdeling van de teststatistiek onder de nulhypothese gebruiken om na te gaan of de geobserveerde test-statistiek <span class="math inline">\(t = -8.12\)</span> klein genoeg is om te kunnen besluiten dat <span class="math inline">\(\mu &lt; 0\)</span>.</p>
<ul>
<li><strong>Is de geobserveerde teststatistiekwaarde (<span class="math inline">\(t=-8.12\)</span>) een waarde die we verwachten als <span class="math inline">\(H_0\)</span> waar is</strong>, of is het een waarde die onwaarschijnlijk klein is als <span class="math inline">\(H_0\)</span> waar is?</li>
<li>In het laatste geval deduceren we dat we niet langer kunnen aannemen dat <span class="math inline">\(H_0\)</span> waar is, en dienen we dus <span class="math inline">\(H_1\)</span> te concluderen.</li>
<li>De vraag blijft: (a) hoe groot moet de geobserveerde teststatistiek <span class="math inline">\(t\)</span> zijn opdat we <span class="math inline">\(H_0\)</span> verwerpen zodat (b) we bereid zijn om <span class="math inline">\(H_1\)</span> te besluiten en (c) hoe zeker zijn we van deze beslissing?</li>
<li>Het antwoord hangt samen met de interpretatie van de kansen die berekend kunnen worden op basis van de nuldistributie<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a> en de geobserveerde teststatistiek <span class="math inline">\(t\)</span>.</li>
</ul>
</div>
<div id="de-p-waarde" class="section level3">
<h3><span class="header-section-number">5.5.3</span> De p-waarde</h3>
<p>De kans waarop de keuze tussen <span class="math inline">\(H_0\)</span> en <span class="math inline">\(H_1\)</span> gebaseerd wordt, wordt de <strong><span class="math inline">\(p\)</span>-waarde</strong> genoemd. De berekeningswijze is context-afhankelijk, maar voor het huidige voorbeeld wordt de <span class="math inline">\(p\)</span>-waarde gegeven door <span class="math display">\[
    p = P\left[T \leq t \mid H_0\right] = \text{P}_0\left[T\leq t\right],
  \]</span> waar de index “0” in <span class="math inline">\(\text{P}_0\left[.\right]\)</span> aangeeft dat de kans onder de nulhypothese berekend wordt. Het is met andere woorden de kans om in een willekeurige steekproef onder de nulhypothese een waarde voor de teststatistiek T te bekomen die lager of gelijk is aan<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a> de waarde die in de huidige steekproef werd geobserveerd.</p>
<p>De <span class="math inline">\(p\)</span>-waarde voor het captopril voorbeeld wordt berekend als <span class="math display">\[p= \text{P}_0\left[T\leq -8.12\right]=F_t(-8.12;14) = 0.6\ 10^{-6}.\]</span></p>
<p>waarbij <span class="math inline">\(F_t(;14)\)</span> de cumulatieve distributie functie is van een t-verdeling met 14 vrijheidsgraden, <span class="math display">\[F_t(x;14)=\int\limits_{-\infty}^{x} f_t(x;14).\]</span> Waarbij <span class="math inline">\(f_t(.;14)\)</span> de densiteitsfunctie is van de t-verdeling. De oppervlakte onder de densiteitsfunctie is opnieuw een kans. Deze kans kan berekend worden in R m.b.v. de functie <code>pt(x,df)</code> die twee argumenten heeft, de waarde van de test-statistiek <code>x</code> en het aantal vrijheidsgraden van de t-verdeling <code>df</code>. <code>pt(x,df)</code> berekent de kans om een waarde te observeren die kleiner of gelijk is aan x wanneer men een willekeurige observatie trekt uit een t-verdeling met df vrijheidsgraden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(delta)
stat&lt;-(<span class="kw">mean</span>(delta)<span class="op">-</span><span class="dv">0</span>)<span class="op">/</span>(<span class="kw">sd</span>(delta)<span class="op">/</span><span class="kw">sqrt</span>(n))
stat</code></pre></div>
<pre><code>## [1] -8.122816</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pt</span>(stat,n<span class="op">-</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] 5.731936e-07</code></pre>

<div class="definition">
<p><span id="def:unnamed-chunk-80" class="definition"><strong>Definitie 5.6  (<span class="math inline">\(p\)</span>-waarde)  </strong></span>De <strong>p-waarde</strong> (ook wel <strong>geobserveerd significantieniveau</strong> genoemd) is de kans om onder de nulhypothese een even of meer “extreme” toetsinggrootheid waar te nemen (in de richting van het alternatief) dan de waarde <span class="math inline">\(t\)</span> die geobserveerd werd o.b.v. de steekproef. Hoe kleiner die kans is, hoe sterker het bewijs tegen de nulhypothese.</p>
<p>Merk op dat de p-waarde de kans <strong>niet</strong> uitdrukt dat de nulhypothese waar is!<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a>.</p>
<p><strong>Einde Definitie</strong></p>
</div>

<p>Het woord “extreem” duidt op de richting waarvoor de teststatistiek onder de alternatieve hypothese meer waarschijnlijk is. In het voorbeeld is <span class="math inline">\(H_1: \mu &lt; 0\)</span> en verwachten we dus kleinere waarden van <span class="math inline">\(t\)</span> onder <span class="math inline">\(H_1\)</span>. Vandaar de kans op <span class="math inline">\(T\leq t\)</span>. Uit de definitie van de <span class="math inline">\(p\)</span>-waarde volgt dat een kleine <span class="math inline">\(p\)</span>-waarde betekent dat de geobserveerde teststatistiek eerder onwaarschijnlijk is als aangenomen wordt dat <span class="math inline">\(H_0\)</span> correct is. Dus een voldoende kleine <span class="math inline">\(p\)</span>-waarde noopt ons tot het <strong>verwerpen van <span class="math inline">\(H_0\)</span></strong> ten voordele van <span class="math inline">\(H_1\)</span>. De drempelwaarde waarmee de <span class="math inline">\(p\)</span>-waarde vergeleken wordt, wordt het <strong>significanctieniveau</strong> genoemd en wordt voorgesteld door <span class="math inline">\(\alpha\)</span>.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-81" class="definition"><strong>Definitie 5.7  (significantieniveau)  </strong></span>De drempelwaarde <span class="math inline">\(\alpha\)</span> staat gekend als het <strong>significantieniveau</strong> van de statistische test. Een statistische test uitgevoerd op het <span class="math inline">\(\alpha\)</span> significantieniveau wordt een <strong>niveau-<span class="math inline">\(\alpha\)</span> test</strong> genoemd (Engels: <em>level-<span class="math inline">\(\alpha\)</span> test</em>).</p>
<strong>Einde definitie</strong>
</div>

<p>Een toetsingsresultaat wordt <em>statistisch significant</em> genoemd wanneer de bijhorende p-waarde kleiner is dan <span class="math inline">\(\alpha\)</span>, waarbij <span class="math inline">\(\alpha\)</span> meestal gelijk aan 5% wordt genomen. Hoe kleiner de p-waarde hoe meer `significant’ het testresultaat afwijkt van de verwachting onder de nulhypothese. Het aangeven van een p-waarde voor een toets geeft bijgevolg meer informatie over het resultaat dan een eenvoudig ja/nee antwoord of de nulhypothese wordt verworpen op een vast gekozen <span class="math inline">\(\alpha\)</span>-niveau. Het geeft immers niet alleen aan of de nulhypothese verworpen wordt op een gegeven significantieniveau, maar ook op welke significantieniveaus de nulhypothese verworpen wordt.</p>
<p>Ze vat dus de bewijskracht tegen de nulhypothese samen <span class="math display">\[\begin{array}{cl}&gt;0.10 &amp; \text{ niet significant (zwak bewijs)}\\0.05-0.10 &amp; \text{ marginaal significant, suggestief}\\0.01-0.05 &amp; \text{ significant}\\0.001-0.01 &amp; \text{ sterk significant}\\&lt;0.001 &amp; \text{ extreem significant}\end{array}\]</span></p>
</div>
<div id="kritieke-waarde" class="section level3">
<h3><span class="header-section-number">5.5.4</span> Kritieke waarde</h3>
<p>Een <strong>alternatieve wijze voor de formulering van de beslissingsregel</strong> kan worden bekomen door gebruik te maken van een kritieke waarde. In plaats van <span class="math inline">\(p\)</span>-waarden, kan de beslissingsregel geschreven worden in termen van de teststatistiek. Bij gebruik van <span class="math inline">\(p\)</span>-waarden bepaalt <span class="math inline">\(p=\alpha\)</span> de grens. Een <span class="math inline">\(p\)</span>-waarde van <span class="math inline">\(\alpha\)</span> schrijven we als <span class="math display">\[p=\text{P}_0 \left[ T \leq t \right]=\alpha.\]</span></p>
<p>Dat is exact de definitie van het het <span class="math inline">\(\alpha\)</span>-percentiel van de distributie van <span class="math inline">\(T\)</span>. In het voorbeeld is de nuldistributie <span class="math inline">\(t_{n-1}\)</span>. Dus,<span class="math display">\[\text{P}_0\left[T\leq -t_{n-1;\alpha}\right]=\alpha.\]</span></p>
De beslissingsregel mag dus ook geschreven worden als
<span class="math display">\[\begin{eqnarray*} 
\text{als } &amp; t&lt; -t_{n-1;\alpha} &amp; \text{ dan verwerp }H_0\text{ en besluit }H_1 \\
  \text{als } &amp; t\geq -t_{n-1;\alpha} &amp; \text{ dan aanvaard }H_0.
\end{eqnarray*}\]</span>
<p>Het percentiel <span class="math inline">\(t_{n-1;\alpha}\)</span> dat de drempelwaarde vormt in de beslissingsregel wordt in deze context de <strong>kritieke waarde</strong> op het <span class="math inline">\(5\%\)</span> significantieniveau genoemd. De beslissingsregel waarbij de geobserveerde <span class="math inline">\(t\)</span> vergeleken wordt met een kritieke waarde is minder algemeen geformuleerd dan deze gebruik makend van de <span class="math inline">\(p\)</span>-waarde omdat het expliciet gebruik maakt van de nuldistributie die van teststatistiek tot teststatistiek, of zelfs van dataset tot dataset kan variëren.</p>
<p>De begrippen p-waarde, kritieke waarde, significantie-niveau, verwerpings- en aanvaardingsregio worden weergegeven in Figuur <a href="chap-besluit.html#fig:captoTest">5.12</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:captoTest"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoTest-1.png" alt="Interpretatie van p-waarde, kritieke waarde, verwerpingsgebied, aanvaardingsgebied voor het captopril voorbeeld." width="100%" />
<p class="caption">
Figuur 5.12: Interpretatie van p-waarde, kritieke waarde, verwerpingsgebied, aanvaardingsgebied voor het captopril voorbeeld.
</p>
</div>
</div>
<div id="beslissingsfouten" class="section level3">
<h3><span class="header-section-number">5.5.5</span> Beslissingsfouten</h3>
<p>Aangezien de beslissing over het al dan niet verwerpen van de nulhypothese bepaald wordt door slechts een steekproef te observeren, kunnen volgende beslissing genomen worden:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Werkelijkheid
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Besluit
</th>
<th style="text-align:center;">
H0
</th>
<th style="text-align:center;">
H1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Aanvaard H0
</td>
<td style="text-align:center;">
OK
</td>
<td style="text-align:center;">
Type II (β)
</td>
</tr>
<tr>
<td style="text-align:center;">
Verwerp H0
</td>
<td style="text-align:center;">
Type I (α)
</td>
<td style="text-align:center;">
OK
</td>
</tr>
</tbody>
</table>
<p>Het schema geeft de vier mogelijke situaties:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span> is in werkelijkheid waar, en dit wordt ook besloten aan de hand van de statistische test (dus geen beslissingsfout)</p></li>
<li><p><span class="math inline">\(H_1\)</span> is in werkelijkheid waar, en dit wordt ook besloten aan de hand van de statistische test (dus geen beslissingsfout)</p></li>
<li><p><span class="math inline">\(H_0\)</span> is in werkelijkheid waar, maar aan de hand van de statistische test wordt besloten om <span class="math inline">\(H_0\)</span> te verwerpen en <span class="math inline">\(H_1\)</span> te concluderen. Dus <span class="math inline">\(H_1\)</span> wordt foutief besloten. Dit is een zogenaamde <strong>type I</strong> fout.</p></li>
<li><p><span class="math inline">\(H_1\)</span> is in werkelijkheid waar, maar aan de hand van de statistische test wordt besloten om <span class="math inline">\(H_0\)</span> te aanvaarden. Dit is een zogenaamde <strong>type II</strong> fout. Dus <span class="math inline">\(H_0\)</span> wordt foutief aanvaard.</p></li>
</ul>
<p>De beslissing is gebaseerd op een teststatistiek <span class="math inline">\(T\)</span> die een toevalsveranderlijke is. De beslissing is dus ook stochastisch en aan de vier mogelijke situaties uit bovenstaand schema kunnen dus probabiliteiten toegekend worden. Net zoals voor het afleiden van de steekproefdistributie van de teststatistiek, moeten we de distributie van de steekproefobservaties kennen alvorens het stochastisch gedrag van de beslissingen te kunnen beschrijven. Indien we aannemen dat <span class="math inline">\(H_0\)</span> waar is, dan is de distributie van <span class="math inline">\(T\)</span> gekend en kunnen ook de kansen op de beslissingen bepaald worden voor de eerste kolom van de tabel.</p>
<p>We starten met de kans op een type I fout (hier uitgewerkt voor het captopril voor beeld): <span class="math display">\[\text{P}\left[\text{type I fout}\right]=\text{P}\left[\text{verwerp }H_0 \mid H_0\right] = \text{P}_0\left[T&lt;t_{n-1;1-\alpha}\right]=\alpha.\]</span> Dit geeft ons meteen een interpretatie van het significantieniveau <span class="math inline">\(\alpha\)</span>: het is de kans op het maken van een type I fout. De constructie van de statistische test garandeert dus dat de kans op het maken van een type I fout gecontroleerd wordt op het significantieniveau <span class="math inline">\(\alpha\)</span>. De kans op het correct aanvaarden van <span class="math inline">\(H_0\)</span> is dus <span class="math inline">\(1-\alpha\)</span>. Verder kan aangetoond worden dat de p-waarde onder <span class="math inline">\(H_0\)</span> uniform verdeeld is. Het leidt dus tot een uniforme beslissingsstrategie.</p>
<p>Het bepalen van de kans op een type II fout is minder evident omdat de alternatieve hypothese minder éénduidig is als de nulhypothese. In het captopril voorbeeld is <span class="math inline">\(H_1: \mu&lt;0\)</span>; met deze informatie wordt de distributie van de steekproefobservaties niet volledig gespecifieerd en dus ook niet de distributie van de teststatistiek. Dit impliceert dat we eigenlijk de kans op een type II fout niet kunnen berekenen. De klassieke <em>work-around</em> bestaat erin om één specifieke distributie te kiezen die voldoet aan <span class="math inline">\(H_1\)</span>.</p>
<p><span class="math display">\[H_1(\delta): \mu=0-\delta \text{ voor een }\delta&gt;0.\]</span></p>
<p>De parameter <span class="math inline">\(\delta\)</span> kwantificeert de afwijking van de nulhypothese.</p>
<p>De <strong>kracht</strong> van een test (Engels: <em>power</em>) is een kans die meer frequent gebruikt wordt dan de kans op een type II fout <span class="math inline">\(\beta\)</span>. De kracht wordt gedefinieerd als</p>
<p><span class="math display">\[\pi(\delta) = 1-\beta(\delta) = \text{P}_\delta\left[T&gt;t_{n-1;1-\alpha}\right]=\text{P}_\delta\left[P&lt;\alpha\right].\]</span></p>
<p>De kracht van een niveau-<span class="math inline">\(\alpha\)</span> test voor het detecteren van een afwijking <span class="math inline">\(\delta\)</span> van het gemiddelde onder de nulhypothese <span class="math inline">\(\mu_0=0\)</span> is dus de kans dat de niveau-<span class="math inline">\(\alpha\)</span> test dit detecteert wanneer de afwijking in werkelijkheid <span class="math inline">\(\delta\)</span> is.</p>
<p>Merk op dat <span class="math inline">\(\pi(0)=\alpha\)</span> en de kracht van een test toeneemt als de afwijking van de nulhypothese toeneemt.</p>
<p>De <strong>kracht</strong> van de test (d.i. de kans om Type II fouten te vermijden) wordt typisch niet gecontroleerd, tenzij d.m.v. studiedesign en steekproefgrootte.</p>
<p><strong>Interpretatie</strong></p>
<p>Stel dat we voor een gegeven dataset bekomen dat <span class="math inline">\(p&lt;\alpha\)</span>, m.a.w. <span class="math inline">\(H_0\)</span> wordt verworpen. Volgens het schema van de beslissingsfouten zijn er dan slechts twee mogelijkheden (zie onderste rij van schema): ofwel is de beslissing correct, ofwel hebben we een type I fout gemaakt. Over de type I fout weten we echter dat ze slechts voorkomt met een kleine kans. Anderzijds, indien <span class="math inline">\(p\geq \alpha\)</span> en we <span class="math inline">\(H_0\)</span> niet verwerpen, dan zijn er ook twee mogelijkheden: ofwel is de beslissing correct, ofwel hebben we een type II fout gemaakt. De kans op een type II fout (<span class="math inline">\(\beta\)</span>) is echter niet gecontroleerd op een gespecifieerde waarde. De statistische test is zodanig geconstrueerd dat ze enkel de kans op een type I fout controleert (op <span class="math inline">\(\alpha\)</span>). Om wetenschappelijk eerlijk te zijn, moeten we een pessimistische houding aannemen en er rekening mee houden dat <span class="math inline">\(\beta\)</span> groot zou kunnen zijn (i.e. een kleine kracht).</p>
<p>Bij <span class="math inline">\(p &lt; \alpha\)</span> wordt de nulhypothese verworpen en we mogen hieruit concluderen dat <span class="math inline">\(H_1\)</span> waarschijnlijk juist is. Dit noemen we een sterke conclusie. Bij <span class="math inline">\(p\geq \alpha\)</span> wordt de nulhypothese aanvaard, maar dat impliceert niet dat we concluderen dat <span class="math inline">\(H_0\)</span> juist is. We kunnen enkel besluiten dat de data onvoldoende bewijskracht tegen <span class="math inline">\(H_0\)</span> ten gunste van <span class="math inline">\(H_1\)</span> bevatten. Dit noemen we een daarom zwakke conclusie.</p>
</div>
<div id="conclusies-captopril-voorbeeld." class="section level3">
<h3><span class="header-section-number">5.5.6</span> Conclusies Captopril voorbeeld.</h3>
<p>De test die we hebben uitgevoerd is in de literatuur ook bekend als de <strong>one sample t-test</strong> op het verschil of als een <strong>gepaarde t-test</strong>, we beschikken immers over gepaarde gegevens per patiënt. De test is eenzijdig uitgevoerd. We testen tegen het alternatief dat er een bloeddrukdaling is.</p>
<p>Beide testen (one sample t-test op het verschil en de gepaarde t-test) geven ons inderdaad dezelfde resultaten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(delta,<span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  delta
## t = -8.1228, df = 14, p-value = 5.732e-07
## alternative hypothesis: true mean is less than 0
## 95 percent confidence interval:
##       -Inf -14.82793
## sample estimates:
## mean of x 
## -18.93333</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">with</span>(captopril, <span class="kw">t.test</span>(SBPa,SBPb,<span class="dt">paired=</span><span class="ot">TRUE</span>,<span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>))</code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  SBPa and SBPb
## t = -8.1228, df = 14, p-value = 5.732e-07
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf -14.82793
## sample estimates:
## mean of the differences 
##               -18.93333</code></pre>
<p>We kunnen op basis van de test het volgende concluderen: Na toediening van captopril is er een extreem significante verlaging van de systolische bloeddruk bij patiënten met hypertensie (<span class="math inline">\(p &lt;&lt; 0.001\)</span>). De systolische bloeddruk neemt gemiddeld met 18.9 mm kwik af na de behandeling met captopril (95% BI [<span class="math inline">\(-\infty,-14.82\)</span>] mm Hg).</p>
<p>Merk op dat we</p>
<ol style="list-style-type: decimal">
<li>Een eenzijdig interval rapporteren gezien we enkel geïnteresseerd zijn om aan te tonen dat er een bloeddrukdaling is.</li>
<li>Door het pre-test/post-test design geen uitsluitsel kunnen geven of dit te wijten is aan de werking van het middel of aan een placebo effect. Er was geen goeie controle! Het gebrek van een goeie controle is veelal een probleem bij pre-test/post-test designs.</li>
</ol>
</div>
<div id="eenzijdig-of-tweezijdig-toetsen" class="section level3">
<h3><span class="header-section-number">5.5.7</span> Eenzijdig of tweezijdig toetsen?</h3>
<p>De test in het captopril voorbeeld was een eenzijdige test. We wensen immers enkel te detecteren of de captopril behandeling de bloeddruk gemiddeld gezien doet dalen.</p>
<p>In andere gevallen of een andere context wenst men enkel een stijging te detecteren.<br />
Stel dat men het bloeddrukverschil had gedefineerd als <span class="math inline">\(X_{i}^\prime=Y_{i}^\text{voor}-Y_{i}^\text{na}\)</span> dan zouden positieve waarden aangeven dat er een bloeddrukdaling was na de behandeling van captopril: de bloeddruk bij aanvang is dan immers groter dan na de behandeling. De gemiddelde bloeddrukverandering in de populatie noteren we nu als <span class="math inline">\(\mu^\prime=\text{E}[X^*]\)</span>. In dat geval hadden we een eenzijdige test uit moeten voeren om <span class="math inline">\(H_0: \mu^\prime=0\)</span> te testen tegen <span class="math inline">\(H_1: \mu^\prime&gt;0\)</span>. Voor deze test kunnen we de p-waarde als volgt berekenen: <span class="math display">\[p=\text{P}_0\left[T\geq t\right].\]</span></p>
<p>We voeren nu de analyse uit in R op basis van de toevallige veranderlijke <span class="math inline">\(X^\prime\)</span>. We zullen nu het argument <code>alternative=&quot;greater&quot;</code> gebruiken in de <code>t.test</code> functie zodat we de nulhypothese toetsen tegen het alternatief <span class="math inline">\(H_1: \mu^\prime&gt;0\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">delta2 &lt;-<span class="st"> </span>captopril<span class="op">$</span>SBPb<span class="op">-</span>captopril<span class="op">$</span>SBPa
<span class="kw">t.test</span>(delta2,<span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  delta2
## t = 8.1228, df = 14, p-value = 5.732e-07
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  14.82793      Inf
## sample estimates:
## mean of x 
##  18.93333</code></pre>
<p>Uiteraard bekomen we met deze analyse exact dezelfde p-waarde en hetzelfde betrouwbaarheidsinterval. Enkel het teken is omgewisseld.</p>
<p>Naast eenzijdige testen kunnen eveneens tweezijdige testen worden uitgevoerd. Het had gekund dat de onderzoekers de werking van het nieuwe medicijn captopril wensten te testen, maar het werkingsmechanisme nog niet kenden in de ontwerpfase. In dat geval zou het eveneens interessant geweest zijn om zowel een stijging als een daling van de bloeddruk te kunnen detecteren. Hiervoor zou men een tweezijdige toetsstrategie moeten gebruiken waarbij men de nulhypothese <span class="math display">\[H_0: \mu=0\]</span> gaat testen versus het alternatieve hypothese <span class="math display">\[H_1: \mu\neq0,\]</span> zodat het gemiddelde onder de alternatieve hypothese verschillend is van 0. Het kan zowel een positieve of negatieve afwijking zijn en men weet niet bij aanvang van de studie in welke richting het werkelijk gemiddelde zal afwijken onder de alternatieve hypothese.</p>
<p>We kunnen tweezijdig testen op het <span class="math inline">\(\alpha=5\%\)</span> significantieniveau door</p>
<ol style="list-style-type: decimal">
<li>een kritieke waarde af te leiden:
<ul>
<li>Bij een tweezijdige test kan het effect onder de alternatieve hypothese zowel positief of negatief zijn. Hierdoor zullen we onder de nulhypothese de kans berekenen om onder de nulhypothese een effect te observeren dat meer extreem is dan het resultaat dat werd geobserveerd in de steekproef. In deze context betekent “meer extreem” dat de statistiek groter is in absolute waarde dan het geobserveerde resultaat, want zowel grote (sterk positieve) als kleine (sterk negatieve) waarden zijn een indicatie van een afwijking van de nulhypothese.</li>
<li>Om een kritieke waarde af te leiden,zullen we het significatie-niveau <span class="math inline">\(\alpha\)</span> daarom verdelen over de linker en rechter staart van de verdeling onder <span class="math inline">\(H_0\)</span>. Gezien de t-verdeling symmetrisch is, volgt dat we een kritieke waarde <span class="math inline">\(c\)</span> kiezen zodat er een kans is van <span class="math inline">\(\alpha/2=2.5\%\)</span> dat <span class="math inline">\(T\geq c\)</span> en er <span class="math inline">\(\alpha/2=2.5\%\)</span> kans is dat <span class="math inline">\(T\leq -c\)</span>. We kunnen dit ook nog als volgt formuleren: Er is onder <span class="math inline">\(H_0\)</span> <span class="math inline">\(\alpha=5\%\)</span> kans dat <span class="math inline">\(\vert T\vert\geq c\)</span> (zie Figuur <a href="chap-besluit.html#fig:captoTest2">5.13</a>).</li>
</ul></li>
<li>We kunnen ook gebruik maken van een tweezijdige p-waarde:
<span class="math display">\[\begin{eqnarray*}
  p&amp;=&amp;\text{P}_0\left[T\leq -|t|\right] + \text{P}_0\left[T\geq |t|\right]\\
  &amp;=&amp;\text{P}_0\left[\vert T\vert \geq \vert t \vert\right]\\
  &amp;=&amp;\text{P}_0\left[T \geq \vert t \vert\right]\times 2.
  \end{eqnarray*}\]</span></li>
</ol>
<p>We berekenen dus de kans dat de t-statistiek onder <span class="math inline">\(H_0\)</span> meer extreem is dan de geobserveerde teststatistiek <span class="math inline">\(t\)</span> in de steekproef. Waarbij meer extreem tweezijdig moet geïnterpreteerd worden. De teststatistiek onder <span class="math inline">\(H_0\)</span> is meer extreem als hij groter is in absolute waarde dan <span class="math inline">\(\vert t \vert\)</span>, de geobserveerde test statistiek. Gezien de verdeling symmetrisch is, kunnen we ook eerst de kans in de rechter staart van de verdeling berekenen en deze kans vervolgens vermenigvuldigen met 2 zodoende een tweezijdige p-waarde te bekomen.</p>
<p>Als de onderzoekers niet vooraf gedefineerd hadden dat ze enkel een bloeddrukdaling wensten te detecteren, dan hadden ze dus een twee-zijdige test uitgevoerd. Merk op dat het argument <code>alternative</code> van de <code>t.test</code> functie een default waarde heeft <code>alternative=&quot;two.sided&quot;</code> zodat er standaard tweezijdig wordt getoetst.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(delta)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  delta
## t = -8.1228, df = 14, p-value = 1.146e-06
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -23.93258 -13.93409
## sample estimates:
## mean of x 
## -18.93333</code></pre>
<p>We bekomen nog steeds een exteem significant resultaat. De p-waarde is echter dubbel zo groot omdat we tweezijdig testen. We verkrijgen eveneens een tweezijdig betrouwbaarheidsinterval. De tweezijdige toetsstrategie wordt weergegeven in Figuur <a href="chap-besluit.html#fig:captoTest2">5.13</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:captoTest2"></span>
<img src="Statistiek_2019_2020_files/figure-html/captoTest2-1.png" alt="Interpretatie van p-waarde, kritieke waarde, verwerpingsgebied, aanvaardingsgebied voor het captopril voorbeeld wanneer we een tweezijdige toets uitvoeren." width="100%" />
<p class="caption">
Figuur 5.13: Interpretatie van p-waarde, kritieke waarde, verwerpingsgebied, aanvaardingsgebied voor het captopril voorbeeld wanneer we een tweezijdige toets uitvoeren.
</p>
</div>
<p>We kunnen ons nu de vraag stellen wanneer we eenzijdig of tweezijdig toetsen. Met een eenzijdige toets kan men gemakkelijker een alternatieve hypothese aantonen (op voorwaarde dat ze waar is) dan met een tweezijdige toets. Dit komt essentieel omdat bij zo’n toets alle informatie kan worden aangewend om in 1 enkele richting te zoeken. Precies daarom vergt de eenzijdige toets een extra beschouwing vóór de aanvang van de studie. Ook al hebben we sterke a priori vermoedens, vaak kunnen we niet zeker zijn dat dat zo is. Anders was er immers geen reden om dit te willen toetsen.</p>
<p>Als men een eenzijdige test voorstelt, maar men vindt een resultaat in de andere richting dat formeel statistisch significant is, dan is het niet geschikt om dit te zien als bewijs voor een werkelijk effect in die richting. Dat is omdat de onderzoekers die mogelijkheid uitgesloten hebben bij de planning van de studie en het resultaat daarom zó onverwacht is dat het als een vals positief resultaat kan gezien worden. Een eenzijdige test is om die reden niet aanbevolen. Een tweezijdige toets is altijd verdedigbaar omdat ze in principe toelaat om elke afwijking van de nulhypothese te detecteren. Ze worden daarom het meest gebruikt en ten zeerste aangeraden. Het is <strong>nooit toegelaten</strong> om een tweezijdige toets in een eenzijdige toets om te zetten <strong>op basis van wat men observeert in de gegevens</strong>! Anders wordt de type I fout van de toetsingsstrategie niet correct gecontroleerd.</p>
<p>Dat wordt geïllustreerd in de onderstaande simulatie. We evalueren twee strategieën, de correcte tweezijdige test en een test waar we eenzijdig toetsen op basis van het teken van het geobserveerde effect.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">115</span>)
mu &lt;-<span class="st"> </span><span class="dv">0</span>
sigma &lt;-<span class="st"> </span><span class="fl">9.0</span>
nSim &lt;-<span class="st"> </span><span class="dv">1000</span>
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>
n &lt;-<span class="st"> </span><span class="dv">15</span>
pvalsCor &lt;-<span class="st"> </span>pvalsInCor&lt;-<span class="kw">array</span>(<span class="dv">0</span>,nSim)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nSim)
{
    x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dt">mean=</span>mu,<span class="dt">sd=</span>sigma)
    pvalsCor[i] &lt;-<span class="st"> </span><span class="kw">t.test</span>(x)<span class="op">$</span>p.value
    <span class="cf">if</span> (<span class="kw">mean</span>(x)<span class="op">&lt;</span><span class="dv">0</span>) pvalsInCor[i] &lt;-<span class="st"> </span><span class="kw">t.test</span>(x,<span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)<span class="op">$</span>p.value <span class="cf">else</span>
        pvalsInCor[i] &lt;-<span class="st"> </span><span class="kw">t.test</span>(x,<span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)<span class="op">$</span>p.value
}
<span class="kw">mean</span>(pvalsCor<span class="op">&lt;</span><span class="fl">0.05</span>)</code></pre></div>
<pre><code>## [1] 0.049</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(pvalsInCor<span class="op">&lt;</span><span class="fl">0.05</span>)</code></pre></div>
<pre><code>## [1] 0.106</code></pre>
<p>We zien inderdaad dat de type I fout correct gecontroleerd wordt op het nominaal significantie-niveau <span class="math inline">\(\alpha\)</span> wanneer we tweezijdig testen en dat dit helemaal niet het geval is wanneer we eenzijdige toetsen op basis van het teken van het geobserveerde effect.</p>
</div>
</div>
<div id="two-sample-t-test" class="section level2">
<h2><span class="header-section-number">5.6</span> Two-sample t-test</h2>
<p>Een two-sample t-test is een statistische toets die werd ontwikkeld om verschillen in gemiddelde te detecteren tussen twee onafhankelijke groepen. We introduceren eerst een motiverende dataset. Men vermoedt dat hinderlijke geur onder de oksels (bromhidrosis) wordt veroorzaakt door specifieke microorganismen die behoren tot de groep van de <em>Corynebacterium spp.</em>. Het is immers niet het zweet dat de geur veroorzaakt, maar de geur is het resultaat van specifieke bacteriën die het zweet metaboliseren. Een andere sterk abundante groep wordt gevormd door de <em>Staphylococcus spp.</em>. In de CMET onderzoeksgroep van de Universiteit Gent wordt onderzoek verricht naar de mogelijkheid van microbiële transplanties in de oksels om mensen van de hinderlijke okselgeur te verlossen. Deze therapie bestaat erin om eerst het oksel-microbioom te verwijderen door een lokale antibiotica behandeling, en vervolgens via een microbiële transplantie de populatie te beïnvloeden. (zie: <a href="https://youtu.be/9RIFyqLXdVw" class="uri">https://youtu.be/9RIFyqLXdVw</a> )</p>
<p>De primaire onderzoeksvraag: leidt de microbiële transplantatie na zes weken tot een verandering in de relatieve abundantie van <em>Staphylococcus spp.</em> in het oksel microbioom in vergelijking met een placebo behandeling die enkel bestaat uit een antibiotica behandeling? Twintig personen met een hinderlijke okselgeur worden willekeurig toegekend aan twee behandelingsgroepen: placebo (enkel antibiotica) en transplantie (antibiotica, gevolgd door microbiële transplantatie). Zes weken na de start van de behandeling wordt een staal van de huid uit de okselholte genomen en worden de relatieve abundanties van <em>Staphylococcus spp.</em> en <em>Corynebacterium spp.</em> in het microbioom gemeten via DGGE (<em>Denaturing Gradient Gel Electrophoresis</em>).</p>
<p>De dataset bevat de variabelen Staph en Cor die de relatieve abundanties (%) weergeven van <em>Staphylococcus spp.</em> en <em>Corynebacterium spp.</em> De variabele Rel werd berekend als <span class="math display">\[
    \text{Rel}=\frac{\text{Staph}}{\text{Staph}+\text{Cor}}.
  \]</span> Deze variabele is het relatief aandeel van <em>Staphylococcus spp.</em> op het totaal aantal <em>Staphylococcus spp.</em> en <em>Corynebacterium spp.</em>.</p>
<p>In de folder dataset staat de file <code>oksel.rda</code>, een dump van het R object <code>oksel</code>, een data frame voor het oksel voorbeeld. R objecten die zijn opgeslagen kunnen via de <code>load(.)</code> functie worden ingelezen. De resultaten worden weergegeven in Figuur <a href="chap-besluit.html#fig:okselBox">5.14</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;dataset/oksel.rda&quot;</span>)
<span class="kw">head</span>(oksel)</code></pre></div>
<pre><code>##              trt Staph  Cor      Rel
## 1 trt 2: placebo  34.7 28.4 54.99208
## 2 trt 2: placebo  16.4 35.1 31.84466
## 3 trt 2: placebo  31.4 45.0 41.09948
## 4 trt 2: placebo  44.7 30.4 59.52064
## 5 trt 2: placebo  45.9 26.3 63.57341
## 6 trt 2: placebo  30.7 43.3 41.48649</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#outline = FALSE, geen outliers </span>
<span class="co">#alle datapunten worden toegevoegd via stripchart</span>
<span class="co">#dus ook outliers zijn zichtbaar</span>
<span class="kw">boxplot</span>(Rel<span class="op">~</span>trt,<span class="dt">data=</span>oksel,<span class="dt">xlab=</span><span class="st">&quot;behandeling&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Relatieve abundantie&quot;</span>,<span class="dt">outline=</span><span class="ot">FALSE</span>)
<span class="kw">set.seed</span>(<span class="dv">394</span>)
<span class="kw">stripchart</span>(Rel<span class="op">~</span>trt, <span class="dt">data=</span>oksel,<span class="dt">vertical =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;jitter&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span><span class="kw">c</span>(<span class="st">&quot;bisque&quot;</span>,<span class="st">&quot;coral&quot;</span>), <span class="dt">add =</span> <span class="ot">TRUE</span>)
<span class="kw">set.seed</span>(<span class="dv">394</span>)
<span class="kw">stripchart</span>(Rel<span class="op">~</span>trt, <span class="dt">data=</span>oksel,<span class="dt">vertical =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;jitter&quot;</span>, <span class="dt">pch =</span> <span class="dv">1</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:okselBox"></span>
<img src="Statistiek_2019_2020_files/figure-html/okselBox-1.png" alt="Boxplot van de relatieve Staphylococcus spp. abundantie t.o.v. het totaal van Staphylococcus spp. en Corynebacterium spp., voor beide behandelingsgroepen." width="100%" />
<p class="caption">
Figuur 5.14: Boxplot van de relatieve Staphylococcus spp. abundantie t.o.v. het totaal van Staphylococcus spp. en Corynebacterium spp., voor beide behandelingsgroepen.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
oksel<span class="op">$</span>trt=<span class="kw">as.factor</span>(oksel<span class="op">$</span>trt)<span class="co">#zet charactervector om in factor</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">levels</span>(oksel<span class="op">$</span>trt))
    <span class="kw">with</span>(<span class="kw">subset</span>(oksel,trt<span class="op">==</span>i), {
         <span class="kw">qqPlot</span>(Rel,<span class="dt">main=</span>i)
})</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:okselQQ"></span>
<img src="Statistiek_2019_2020_files/figure-html/okselQQ-1.png" alt="QQ-plots van relatieve Staphylococcus spp. abundantie t.o.v. het totaal van Staphylococcus spp. en Corynebacterium spp." width="100%" />
<p class="caption">
Figuur 5.15: QQ-plots van relatieve Staphylococcus spp. abundantie t.o.v. het totaal van Staphylococcus spp. en Corynebacterium spp.
</p>
</div>
<p>Normaliteit van de data in beide groepen wordt ook nagegaan d.m.v. QQ-plots (zie Figuur <a href="chap-besluit.html#fig:okselQQ">5.15</a>). De QQ-plots geven geen te grote afwijkingen weer van normaliteit.</p>
<p>We introduceren eerst de notatie. Stel <span class="math inline">\(Y_{ij}\)</span> de uitkomst van observatie <span class="math inline">\(i=1,\ldots, n_j\)</span> uit populatie <span class="math inline">\(j=1,2\)</span>. We zullen dikwijls de term <strong>behandeling</strong> of <strong>groep</strong> gebruiken in plaats van populatie, zelfs wanneer de twee populaties niet geïnterpreteerd kunnen worden als behandelingen. Beschouw het als een (misgroeide) conventie. In de context van het voorbeeld is behandeling <span class="math inline">\(j=1\)</span> de microbiële transplantatie en behandeling <span class="math inline">\(j=2\)</span> de placebo behandeling.</p>
<p>We veronderstellen</p>
<p><span class="math display">\[Y_{ij}\text{ i.i.d. } N(\mu_j,\sigma^2)\;\;\;i=1,\ldots,n_i\;j=1,2.\]</span></p>
<p>Merk op dat dit inhoudt dat gelijke varianties verondersteld worden. De eigenschap van gelijke varianties wordt ook aangeduid met de term <strong>homoskedasticiteit</strong>, en ongelijke varianties met <strong>heteroskedasticiteit</strong>.</p>
<p>We zijn geïnteresseerd in het testen van de nulhypothese <span class="math display">\[ H_0: \mu_1 = \mu_2 \]</span> tegenover de alternatieve hypothese <span class="math display">\[  H_1: \mu_1 \neq \mu_2 .\]</span> De alternatieve hypothese drukt dus de onderzoeksvraag uit: een verschil in relatieve abundantie van <em>Staphylococcus spp.</em> na microbiële transplantatie t.o.v. de placebo behandeling.<br />
De nul en alternatieve hypothese kunnen ook worden uitgedrukt in termen van de effectgrootte tussen behandeling en placebo groep <span class="math inline">\(\mu_1-\mu_2\)</span>: <span class="math display">\[H_0: \mu_1-\mu_2 = 0,\]</span> <span class="math display">\[H_1: \mu_1-\mu_2 \neq 0.\]</span></p>
<p>We kunnen de effectgrootte in het experiment schatten a.d.h.v. de steekproefgemiddeldes: <span class="math display">\[\hat \mu_1-\hat \mu_2=\bar Y_1 -\bar Y_2.\]</span> Gezien de experimentele eenheden onafhankelijk zijn, zijn de steekproefgemiddeldes dat ook en is de variantie op het verschil: <span class="math display">\[\text{Var}_{\bar Y_1 -\bar Y_2}=\frac{\sigma^2}{n_1}+\frac{\sigma^2}{n_2}=\sigma^2 \left(\frac{1}{n_1}+\frac{1}{n_2}\right).\]</span> De standard error is bijgevolg: <span class="math display">\[\sigma_{\bar Y_1 -\bar Y_2}=\sigma\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}.\]</span></p>
<p>We zouden de variantie apart kunnen schatten in elke groep aan de hand van de steekproefvariatie, maar als we gelijkheid van variantie kunnen veronderstellen kan de variantie meer precies worden geschat door gebruik te maken van alle gegevens in beide groepen. Deze variatieschatter wordt ook de gepoolde variantieschatter genoemd: <span class="math inline">\(S^2_p\)</span>.</p>
<p>Op basis van de observaties uit de eerste groep kan <span class="math inline">\(\sigma^2_1\)</span> geschat worden als <span class="math display">\[S_1^2 = \frac{1}{n_1-1}\sum_{i=1}^{n_1} (Y_{i1}-\bar{Y}_1)^2.\]</span></p>
<p>Analoog: op basis van de observaties uit de tweede groep kan <span class="math inline">\(\sigma^2_2\)</span> geschat worden als <span class="math display">\[S_2^2 = \frac{1}{n_2-1}\sum_{i=1}^{n_2} (Y_{i2}-\bar{Y}_2)^2.\]</span></p>
<p>Merk op dat we homoscedasticiteit veronderstellen, <span class="math inline">\(\sigma_1^2=\sigma_2^2=\sigma^2\)</span>. Dus <span class="math inline">\(S_1^2\)</span> en <span class="math inline">\(S_2^2\)</span> zijn schatters zijn voor dezelfde parameter <span class="math inline">\(\sigma^2\)</span>. Daarom kunnen ze gezamenlijk gebruikt worden om tot één schatter te komen die alle <span class="math inline">\(n_1+n_2\)</span> observaties gebruikt: <span class="math display">\[  S_p^2 = \frac{n_1-1}{n_1+n_2-2} S_1^2 + \frac{n_2-1}{n_1+n_2-2} S_2^2 = \frac{1}{n_1+n_2-2}\sum_{j=1}^2\sum_{i=1}^{n_j} (Y_{ij} - \bar{Y}_j)^2.\]</span></p>
<p>De gepoolde variantieschatter wordt dus geschat door gebruik te maken van de kwadratische afwijkingen tussen de observaties en hun groepsgemiddelde en dat te delen door het aantal vrijheidsgraden <span class="math inline">\(n_1+n_2-2\)</span><a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a>.</p>
<p>Nu we de effectgrootte en de standard error op de effectgrootte hebben kunnen schatten, kunnen we opnieuw een t-statistiek definiëren (two-sample <span class="math inline">\(t\)</span>-teststatistiek):</p>
<p><span class="math display">\[T = \frac{\bar{Y}_1-\bar{Y}_2}{\sqrt{\frac{S_p^2}{n_1}+\frac{S_p^2}{n_2}}} = 
  \frac{\bar{Y}_1 - \bar{Y}_2}{S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}.\]</span></p>
<p>Als de data onafhankelijk zijn, de steekproefgemiddelden normaal verdeeld zijn en de variantie in beide groepen gelijk zijn, dan kan men aantonen de teststatistiek T opnieuw een t-verdeling volgt met <span class="math inline">\(n_1+n_2-2\)</span> vrijheidsgraden onder de nulhypothese.</p>
Aangezien de alternatieve hypothese <span class="math inline">\(H_1: \mu_1 \neq \mu_2\)</span> impliceert dat de probabiliteitsmassa van de distributie van <span class="math inline">\(T\)</span> onder <span class="math inline">\(H_1\)</span> verschuift naar hogere of lagere waarden, zullen we <span class="math inline">\(H_0\)</span> wensen te verwerpen ten gunste van <span class="math inline">\(H_1\)</span> voor grote absolute waarde van de teststatistiek. De <span class="math inline">\(p\)</span>-waarde wordt dus
<span class="math display">\[\begin{eqnarray*}
  p&amp;=&amp;\text{P}_0\left[T\leq -|t|\right] + \text{P}_0\left[T\geq |t|\right]\\
  &amp;=&amp;\text{P}_0\left[\vert T\vert \geq \vert t \vert\right]\\
  &amp;=&amp;\text{P}_0\left[T \geq \vert t \vert\right]\times 2\\
  &amp;=&amp; 2\times(1-F_T(\vert t\vert;n_1+n_2-2)),
  \end{eqnarray*}\]</span>
<p>met <span class="math inline">\(F_T(\cdot;n_1+n_2-2)\)</span> de cumulatieve distributiefunctie van <span class="math inline">\(t_{n_1+n_2-2}\)</span>.</p>
<div id="oksel-voorbeeld" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Oksel-voorbeeld</h3>
<p>De onderzoeksvraag van het oksels-voorbeeld kan vertaald worden in een nulhypothese en een alternatieve hypothese.</p>
<p>De nulhypothese verwoordt de stelling dat de behandeling geen effect heeft op de gemiddelde relatieve abundantie van <em>Staphylococcus spp.</em>.</p>
<p>Indien <span class="math inline">\(\mu_1\)</span> en <span class="math inline">\(\mu_2\)</span> de gemiddelde abundanties voorstellen in respectievelijk de transplantatie groep en de placebo groep, dan schrijven we <span class="math display">\[   H_0: \mu_1=\mu_2.\]</span> De alternatieve hypothese correspondeert met wat we wensen te bewijzen aan de hand van de experimentele data: een verschil in gemiddelde abundantie van <em>Staphylococcus spp.</em> in de transplantatie groep i.v.m. de placebo groep. Dus <span class="math display">\[H_1: \mu_1\neq \mu_2.\]</span></p>
<p>De berekeningen kunnen als volgt in R worden uitgevoerd:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ybar1&lt;-<span class="kw">mean</span>(oksel<span class="op">$</span>Staph[oksel<span class="op">$</span>trt<span class="op">==</span><span class="st">&quot;trt 1: transplant&quot;</span>])
ybar1</code></pre></div>
<pre><code>## [1] 49.79</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ybar2&lt;-<span class="kw">mean</span>(oksel<span class="op">$</span>Staph[oksel<span class="op">$</span>trt<span class="op">==</span><span class="st">&quot;trt 2: placebo&quot;</span>])
ybar2</code></pre></div>
<pre><code>## [1] 31.9</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var1&lt;-<span class="kw">var</span>(oksel<span class="op">$</span>Staph[oksel<span class="op">$</span>trt<span class="op">==</span><span class="st">&quot;trt 1: transplant&quot;</span>])
var1</code></pre></div>
<pre><code>## [1] 64.95656</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var2&lt;-<span class="kw">var</span>(oksel<span class="op">$</span>Staph[oksel<span class="op">$</span>trt<span class="op">==</span><span class="st">&quot;trt 2: placebo&quot;</span>])
var2</code></pre></div>
<pre><code>## [1] 76.78222</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n1&lt;-<span class="kw">sum</span>(oksel<span class="op">$</span>trt<span class="op">==</span><span class="st">&quot;trt 1: transplant&quot;</span>)
n1</code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n2&lt;-<span class="kw">sum</span>(oksel<span class="op">$</span>trt<span class="op">==</span><span class="st">&quot;trt 2: placebo&quot;</span>)
n2</code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#gepoolde variantieschatting</span>
sp2&lt;-((n1<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>var1<span class="op">+</span>(n2<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>var2)<span class="op">/</span>(n1<span class="op">+</span>n2<span class="op">-</span><span class="dv">2</span>)
sp2</code></pre></div>
<pre><code>## [1] 70.86939</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#geobserveerde t-statistiek</span>
t.obs&lt;-(ybar1<span class="op">-</span>ybar2)<span class="op">/</span><span class="kw">sqrt</span>(sp2<span class="op">/</span>n1<span class="op">+</span>sp2<span class="op">/</span>n2)
t.obs</code></pre></div>
<pre><code>## [1] 4.751886</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#p-waarde</span>
p&lt;-(<span class="dv">1</span><span class="op">-</span><span class="kw">pt</span>(<span class="kw">abs</span>(t.obs),<span class="dt">df=</span>n1<span class="op">+</span>n2<span class="op">-</span><span class="dv">2</span>))<span class="op">*</span><span class="dv">2</span>
p</code></pre></div>
<pre><code>## [1] 0.0001592919</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#De p-waarde kon ook worden berekend door</span>
<span class="co">#gebruik te maken van de probabiliteit in de linker staart</span>
<span class="co">#dat is vaak stabieler in R</span>
p&lt;-<span class="kw">pt</span>(<span class="op">-</span><span class="kw">abs</span>(t.obs),<span class="dt">df=</span>n1<span class="op">+</span>n2<span class="op">-</span><span class="dv">2</span>)<span class="op">*</span><span class="dv">2</span>
p</code></pre></div>
<pre><code>## [1] 0.0001592919</code></pre>
<p>De R software heeft ook een specifieke functie voor het uitvoeren van deze <span class="math inline">\(t\)</span>-test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(Staph<span class="op">~</span>trt,<span class="dt">data=</span>oksel,<span class="dt">var.equal=</span><span class="ot">TRUE</span>) </code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Staph by trt
## t = 4.7519, df = 18, p-value = 0.0001593
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   9.980404 25.799596
## sample estimates:
## mean in group trt 1: transplant    mean in group trt 2: placebo 
##                           49.79                           31.90</code></pre>
<p>Uit deze analyse lezen we <span class="math inline">\(p\approx 0.16 \times 10^{-3}&lt;&lt;0.05\)</span>.</p>
<p>Dus op het <span class="math inline">\(5\%\)</span> significantieniveau verwerpen we de nulhypothese ten voordele van de alternatieve en besluiten we dat de gemiddelde abundantie van <em>Staphylococcus spp.</em> extreem significant hoger is in de transplantatie groep dan in de placebo groep<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a>.</p>
<p>Indien de transplantatie geen effect heeft op de gemiddelde abundantie van <em>Staphylococcus spp.</em>, dan is er slechts een kans van 16 in de <span class="math inline">\(100000\)</span> om een teststatistiek te bekomen in een willekeurige steekproef die minstens zo extreem is als deze die wij geobserveerd hebben.</p>
<p>Dit is uiterst zeldzaam onder de hypothese dat <span class="math inline">\(H_0\)</span> waar is, en het is kleiner dan <span class="math inline">\(5\%\)</span> (het significantieniveau). Indien <span class="math inline">\(H_1\)</span> waar zou zijn, dan verwachten we grotere absolute waarden van de teststatistiek en verwachten we dus ook kleine <span class="math inline">\(p\)</span>-waarden. Om deze reden wensen we niet verder te geloven dat <span class="math inline">\(H_0\)</span> waar is, en besluiten we dat er veel evidentie in de steekproefdata zit om te besluiten dat <span class="math inline">\(H_1\)</span> waar is op het <span class="math inline">\(5\%\)</span> significantieniveau.</p>
<p><strong>Good statistical practice</strong> houdt ook in dat niet enkel de <span class="math inline">\(p\)</span>-waarde van de hypothesetest wordt gerapporteerd, maar dat ook de gemiddelden en een maat voor de betrouwbaarheid van de schattingen (bv. BI) worden gerapporteerd.</p>
<p><strong>Conclusie</strong> Gemiddeld is de relatieve abundantie van <em>Staphylococcus spp.</em> in het microbioom van de oksel in de transplantatie groep extreem significant verschillend van dat in de controle groep (<span class="math inline">\(p&lt;&lt;0.001\)</span>). De relatieve abundantie van <em>Staphylococcus spp.</em> is gemiddeld 17.9% hoger in de transplantie groep dan in de controle groep (95% BI [10.0,25.8]%).</p>
</div>
</div>
<div id="aannames" class="section level2">
<h2><span class="header-section-number">5.7</span> Aannames</h2>
<p>In de voorgaande secties hebben we t-testen geïntroduceerd en de geldigheid ervan hangt af van enkele distributionele veronderstellingen:</p>
<ul>
<li>Onafhankelijke gegevens (design)</li>
<li>One-sample t-test: normaliteit van de steekproefobservaties</li>
<li>Paired t-test: normaliteit van de verschillen tussen de gepaarde observaties</li>
<li>Two-sample t-test: normaliteit van de steekproefobservaties in beide groepen, en gelijkheid van varianties.</li>
</ul>
<p>Indien niet voldaan is aan de veronderstellingen, is de t-distributie niet noodzakelijk de correcte nuldistributie, en bijgevolg is er geen garantie dat de p-waarde en kritieke waarden correct zijn.</p>
<p>Ook voor de constructie van het betrouwbaarheidsinterval van het gemiddelde hebben we beroep gedaan op de veronderstelling van normaliteit. De normaliteitsveronderstelling was nodig om kwantielen uit de t-verdeling te kunnen gebruiken bij het opstellen van de boven- en ondergrens, en de correcte probabiliteitsinterpretatie van het betrouwbaarheidsinterval hangt hiervan af.</p>
<div id="nagaan-van-de-veronderstelling-van-normaliteit" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Nagaan van de veronderstelling van Normaliteit</h3>
<p>Normaliteit kan via de volgende methoden nagegaan worden.</p>
<p><strong>Boxplots en histogrammen</strong></p>
<p>Beide figuren laten toe om een idee te vormen over de vorm van de distributie: symmetrie, outliers. </p>
<p><strong>QQ-plots</strong></p>
<p>Deze plots laten toe om op een grafische wijze na te gaan in welke mate steekproefobservaties zich gedragen als een vooropgestelde distributie.</p>
<p><strong>Hypothesetesten (goodness-of-fit test)</strong></p>
<p>Goodness-of-fit testen zijn statistische hypothesetesten die ontwikkeld zijn voor het testen van de nulhypothese dat de steekproefobservaties uit een vooropgestelde distributie getrokken zijn (hier: normale distributie). De alternatieve hypothese is meestal de negatie van de nulhypothese (hier: geen normaliteit). Bekende testen zijn: Kolmogorov-Smirnov, Shapiro-Wilk en Anderson-Darling.</p>
<p>Op het eerste zicht lijkt een goodness-of-fit test een gemakkelijke en zinvolle oplossing. De methode geeft een <span class="math inline">\(p\)</span>-waarde en deze laat onmiddellijk toe om te besluiten of de data normaal verdeeld zijn.</p>
<p>Er is echter kritiek te leveren op deze aanpak:</p>
<ul>
<li>indien <span class="math inline">\(p\geq \alpha\)</span>, dan is normaliteit niet bewezen! Het zegt enkel dat er onvoldoende evidentie is tegen de veronderstelling van normaliteit. In een kleine steekproef is de kracht van een test meestal klein.</li>
<li>indien <span class="math inline">\(p&lt;\alpha\)</span>, dan mag wel besloten worden om de nulhypothese te verwerpen en mag dus besloten worden dat de data niet normaal verdeeld zijn, maar soms is een afwijking van normaliteit niet zo erg.</li>
</ul>
<p><strong>Algemeen advies</strong>: Start met een grafische exploratie van de data (boxplots, histogrammen en QQ-plots) en houdt hierbij steeds de steekproefgrootte in het achterhoofd om te vermijden dat je de figuren zou overinterpreteren. Als je twijfelt kan je gebruik maken van simulaties waarbij je nieuwe steekproeven simuleert met eenzelfde steekproefgrootte en data die uit de Normaal verdeling komt met eenzelfde gemiddelde en variantie als wat in de steekproef werd geobserveerd.</p>
<p>Indien een afwijking van normaliteit wordt vastgesteld, tracht dan na te gaan (bv. via literatuur) of de statistische methode die je wenst toe te passen, gevoelig is voor dergelijke afwijkingen (een t-test is bijvoorbeeld vrij ongevoelig voor afwijkingen van Normaliteit als de afwijkingen symetrisch zijn). Eventueel kan je ook beroep doen op de centrale limietstelling.</p>
</div>
<div id="nagaan-van-homoscedasticiteit" class="section level3">
<h3><span class="header-section-number">5.7.2</span> Nagaan van homoscedasticiteit</h3>
<p>Dat kan opnieuw via boxplots. De grootte van de box is de interkwartiel range (IQR), een robuuste schatter voor de variantie (zie Sectie <a href="chap-describe.html#subsec:spreiding">4.3.2</a>). Als de verschillen tussen de IQR range van beide groepen niet te groot is, kan men besluiten dat de data homoscedastisch zijn. Opnieuw kan inzicht gekregen worden in dergelijke plots door gebruik te maken van simulaties (zie Oefeningen). Men kan eveneens een formele F-test gebruiken om de varianties te vergelijken (zie oefeningen), maar hiervoor geldt dezelfde kritiek als voor het testen van normaliteit (zie vorige sectie).</p>
<p>Als er bij het vergelijken van gemiddelden tussen twee groepen niet aan homoscedasticiteit is voldaan, kan je gebruik maken van de Welch two-sample T-test. Hierbij wordt de gepoolde variantieschatter niet langer gebruikt. <span class="math display">\[T =  \frac{\bar{Y}_1 - \bar{Y}_2}{\sqrt{\frac{S^2_1}{n_1}+\frac{S^2_2}{n_2}}}\]</span> waarbij <span class="math inline">\(S^2_1\)</span> en <span class="math inline">\(S^2_2\)</span> de steekproefvarianties zijn in beide groepen.</p>
<p>Deze statistiek volgt bij benadering een t-verdeling met een aantal vrijheidsgraden dat ligt tussen het kleinste aantal observaties <span class="math inline">\(\text{min}(n_1-1,n_2-1)\)</span> en <span class="math inline">\(n_1+n_2-2\)</span>. De vrijheidsgraden worden in R berekend via de Welch–Satterthwaite benadering. Dat kan door in de <code>t.test</code> functie het argument <code>var.equal=FALSE</code> te zetten.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(Staph<span class="op">~</span>trt,<span class="dt">data=</span>oksel,<span class="dt">var.equal=</span><span class="ot">FALSE</span>) </code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Staph by trt
## t = 4.7519, df = 17.876, p-value = 0.0001622
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   9.976456 25.803544
## sample estimates:
## mean in group trt 1: transplant    mean in group trt 2: placebo 
##                           49.79                           31.90</code></pre>
<p>Merk op dat we in de output zien dat een Welch T-test is uitgevoerd aan de titel boven de analyse. Verder zien we dat voor dit voorbeeld de aangepaste vrijheidsgraden <span class="math inline">\(df = 17.876\)</span> bijna gelijk zijn aan de vrijheidsgraden van de klassieke T-test, omdat de varianties ongeveer gelijk zijn.</p>
</div>
</div>
<div id="wat-rapporteren-1" class="section level2">
<h2><span class="header-section-number">5.8</span> Wat rapporteren?</h2>
<ul>
<li>In de wetenschappelijke literatuur is er een overdreven aandacht voor p-waarden.</li>
<li>Nochtans is het interessanter om een schatting te rapporteren samen met een betrouwbaarheidsinterval (dan met een p-waarde).</li>
</ul>
<p><strong>Vuistregel</strong>: Rapporteer een schatting steeds samen met een betrouwbaarheidsinterval (en een p-waarde), want</p>
<ol style="list-style-type: decimal">
<li>Het resultaat van een toets kan veelal uit een betrouwbaarheidsinterval worden afgeleid;</li>
<li>Dit laat toe om te oordelen of het resultaat ook <strong>wetenschappelijk van belang</strong> is.</li>
</ol>
<div id="reden-1-relatie-toetsen-en-betrouwbaarheidsintervallen" class="section level3">
<h3><span class="header-section-number">5.8.1</span> Reden 1: Relatie toetsen en betrouwbaarheidsintervallen</h3>
<p>Stel dat we voor een zekere parameter <span class="math inline">\(\theta\)</span> (bvb. een populatiegemiddelde, verschil in populatiegemiddelden, odds ratio, regressieparameter) de nulhypothese wensen te toetsen dat <span class="math inline">\(H_0 : \theta= \theta_0\)</span> versus het alternatief <span class="math inline">\(H_A : \theta \neq \theta_0\)</span> voor een zeker getal <span class="math inline">\(\theta_0\)</span>. Dan kan men aantonen dat men deze tweezijdige toetsingsprocedure kan uitvoeren op het <span class="math inline">\(\alpha 100\%\)</span> significantieniveau door de nulhypothese te verwerpen als en slechts als het <span class="math inline">\((1-\alpha)100\%\)</span> betrouwbaarheidsinterval voor <span class="math inline">\(\theta\)</span> het getal <span class="math inline">\(\theta_0\)</span> niet omvat. Met andere woorden, het <span class="math inline">\((1-\alpha)100\%\)</span> betrouwbaarheidsinterval voor <span class="math inline">\(\theta\)</span> bevat alle getallen <span class="math inline">\(\theta_0\)</span> zodat de tweezijdige toets van <span class="math inline">\(H_0 : \theta= \theta_0\)</span> versus <span class="math inline">\(H_1 : \theta \neq \theta_0\)</span> de nulhypothese niet verwerpt.</p>
</div>
<div id="reden-2-statistische-significantie-versus-wetenschappelijke-relevantie" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Reden 2: Statistische significantie versus wetenschappelijke relevantie</h3>
<p>Een betrouwbaarheidsinterval laat toe om zowel statistische significantie als wetenschappelijk belang van een resultaat te interpreteren.</p>
<p>Stel dat experimentele behandeling <em>significant betere</em> respons oplevert dan standaard/placebo. Een associatie is <em>statistisch significant</em> als P <span class="math inline">\(&lt; \alpha\)</span>, de data dragen m.a.w. voldoende bewijskracht om te besluiten dat er een associatie is. Dan blijft het mogelijk dat het effect <em>wetenschappelijk irrelevant</em> is. Met betrouwbaarheidsintervallen kunnen we dit wel evalueren.</p>
<p>Maar, dat laat echter nog veel subjectiviteit en manipulatie toe. Onderzoekers hopen in de praktijk immers wetenschappelijk belangrijke vondsten te maken en kunnen daarom geneigd zijn om hun oordeel over wat wetenschappelijk belangrijk is, wijzigen in functie van het bekomen betrouwbaarheidsinterval. Om dit te vermijden is het wenselijk dat wetenschappers a priori, d.i. vooraleer de gegevens verzameld werden, hun oordeel over wetenschappelijke relevantie uitdrukken.</p>
</div>
</div>
<div id="equivalentie-intervallen" class="section level2">
<h2><span class="header-section-number">5.9</span> Equivalentie-intervallen</h2>
Betrouwbaarheidsintervallen kunnen ook worden gebruikt om na te gaan of twee interventies <strong>wetenschappelijk equivalent</strong> zijn. Twee interventies worden <strong>wetenschappelijk equivalent</strong> genoemd als het verschil tussen de populatiegemiddelden <span class="math inline">\(\mu_1\)</span> en <span class="math inline">\(\mu_2\)</span> van hun uitkomsten <span class="math inline">\(X_1\)</span> en <span class="math inline">\(X_2\)</span> in een equivalentie-interval ligt (dat 0 zal omvatten), bijvoorbeeld:
<span class="math display">\[\begin{equation*}
(\mu_1 - \mu_2) \in [E_1, E_2]
\end{equation*}\]</span>
In de meeste gevallen worden <span class="math inline">\(E_1\)</span> en <span class="math inline">\(E_2\)</span> symmetrisch rond nul gekozen, in welk geval <span class="math inline">\(E_1=-\Delta\)</span> en <span class="math inline">\(E_2=\Delta\)</span> voor gegeven <span class="math inline">\(\Delta\)</span>. Het (wetenschappelijk) equivalentie-interval wordt dan gegeven door alle koppels <span class="math inline">\((\mu_1,\mu_2)\)</span> waarvoor
<span class="math display">\[\begin{equation*}
|\mu_1 - \mu_2| &lt; \Delta
\end{equation*}\]</span>
<p>Twee interventies zijn met andere woorden klinisch equivalent wanneer hun verschil in effect verwaarloosbaar klein is vanuit wetenschappelijk oogpunt.</p>
<p>In het vervolg van deze sectie zullen we nagaan of de gemiddelden van 2 onafhankelijke populaties wetenschappelijk equivalent zijn (of wetenschappelijk niet significant van elkaar verschillen). Een eerste stap in dit proces is om op basis van louter wetenschappelijk overwegingen een interval op te stellen waarbinnen het verschil <span class="math inline">\(\mu_1-\mu_2\)</span> verwaarloosbaar klein kan worden genoemd. Dit gebeurt met hulp van een deskundige die kan oordelen over het belang van een gegeven effectgrootte. Vervolgens wordt het gemiddeld verschil in uitkomst onder beide interventies geschat op basis van de gegevens. Nagaan of dit verschil in het equivalentie-interval gelegen is, volstaat op zich niet om wetenschappelijke equivalentie te kunnen besluiten vermits een klein/groot verschil louter het gevolg kan zijn van biologische variatie. Een logische stap is daarom een bijhorend 95% betrouwbaarheidsinterval voor <span class="math inline">\(\mu_1 - \mu_2\)</span> te berekenen op basis van de beschikbare gegevens (gepaard, ongepaard, …). De wetenschappelijke equivalentie zal nu bepaald worden door de ligging van het betrouwbaarheidsinterval te vergelijken met het interval van wetenschappelijke equivalentie.</p>
<p>Het zou verkeerd zijn om wetenschappelijke equivalentie te besluiten zodra het equivalentie-interval volledig omsloten is door het 95% betrouwbaarheidsinterval. Inderdaad, kleine steekproeven produceren brede betrouwbaarheidsintervallen zodat men op die manier in kleine steekproeven gemakkelijk equivalentie zou besluiten louter wegens gebrek aan informatie. We volgen daarom de volgende strategie. Noem <span class="math inline">\(O\)</span> de ondergrens en <span class="math inline">\(B\)</span> de bovengrens van het 95% betrouwbaarheidsinterval voor <span class="math inline">\(\mu_1-\mu_2\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Als <span class="math inline">\(E_1 &lt; O &lt; B &lt; E_2\)</span>, dan is het verschil tussen de populatiegemiddelden met minstens 95% kans binnen de grenzen van wetenschappelijke equivalentie gelegen. Men kan dan met minstens 95% zekerheid besluiten dat de 2 interventies inderdaad wetenschappelijk equivalent zijn.</p></li>
<li><p>Als <span class="math inline">\(E_2 &lt; O\)</span> dan kan men met minstens 95% zekerheid besluiten dat <span class="math inline">\(\mu_1\)</span> wetenschappelijk significant groter is dan <span class="math inline">\(\mu_2\)</span>. (In dit geval is <span class="math inline">\(\mu_1\)</span> automatisch ook statistisch significant groter dan <span class="math inline">\(\mu_2\)</span> op het 2-zijdig significantieniveau 5%).</p></li>
<li><p>Als <span class="math inline">\(B &lt; E_1\)</span> dan kan men met minstens 95% zekerheid besluiten dat <span class="math inline">\(\mu_1\)</span> wetenschappelijk significant kleiner is dan <span class="math inline">\(\mu_2.\)</span></p></li>
</ol>
<p>Het resultaat kan ook minder duidelijk zijn.</p>
<ol style="list-style-type: decimal">
<li>Als <span class="math inline">\(O &lt; E_1 &lt; E_2 &lt; B\)</span> dan is er te weinig informatie om ook maar iets betekenisvol te kunnen besluiten: meer gegevens zijn nodig.</li>
<li>Als $O &lt; E_1 &lt; B &lt; E_2 $ dan kan men op het 5% significantieniveau besluiten dat <span class="math inline">\(\mu_1\)</span> <em>niet</em> wetenschappelijk groter is dan <span class="math inline">\(\mu_2\)</span>. In dat geval zijn zowel de opties wetenschappelijk equivalent met <span class="math inline">\(\mu_2\)</span> als wetenschappelijk significant kleiner dan <span class="math inline">\(\mu_2\)</span> niet uit te sluiten met 95% zekerheid.</li>
<li>Analoog voor de symmetrische situatie waarbij <span class="math inline">\(E_1 &lt; O &lt; E_2 &lt; B.\)</span></li>
</ol>
<p>In asthmastudies legt men bijvoorbeeld <strong>op voorhand vast</strong> dat een verschil in Peak Expiratory Flow (PEF) van 15 l/min klinisch onbelangrijk is. Men bepaald m.a.w. een equivalentie-interval: [-15,15] l/min. Een 95% BI van [-10,-5] l/min voor gemiddeld verschil in PEF tussen twee geneesmiddelen Formoterol en Salbutamol wijst op een onbelangrijk effect, equivalentie. Het betrouwbaarheidsinterval geeft weer hoe groot het verschil kan zijn. Als men een BI van [-25,-16] l/min had bekomen dan kon men besluiten dat het geneesmiddel Formoterol minder efficient is gezien het gemiddeld gezien PEF waarden oplevert die wetenschappelijk significant lager zijn dan wanneer Salbutamol wordt toegediend. Als het [-20,-5] l/min zou zijn, dan is er ambiguïteit.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="23">
<li id="fn23"><p>Ook wel Statistische Inferentie genoemd<a href="chap-besluit.html#fnref23">↩</a></p></li>
<li id="fn24"><p>Om die reden duiden we ze aan met een hoofdletter.<a href="chap-besluit.html#fnref24">↩</a></p></li>
<li id="fn25"><p>Zo is het met 1 observatie voor <span class="math inline">\(\bar X\)</span> niet mogelijk om een histogram voor <span class="math inline">\(\bar X\)</span> uit te zetten.<a href="chap-besluit.html#fnref25">↩</a></p></li>
<li id="fn26"><p>In principe is een meer theoretische, mathematische ontwikkeling nodig omdit aan te tonen, maar voor het bestek van deze cursus volstaat het om het meer intuïtieve argument aan te nemen.<a href="chap-besluit.html#fnref26">↩</a></p></li>
<li id="fn27"><p>Merk op dat de vierkantswortel van een som niet gelijk is aan de som van de vierkantswortels. Bijgevolg is de standaarddeviatie van de som van <span class="math inline">\(X\)</span> en <span class="math inline">\(Y\)</span> niet de som van de corresponderende standaarddeviaties!<a href="chap-besluit.html#fnref27">↩</a></p></li>
<li id="fn28"><p>Denk zelf maar eens na of je gevallen kunt bedenken waar je al op voorhand, zonder ook maar observaties te zien, de variantie op een bepaalde karakteristiek kent…<a href="chap-besluit.html#fnref28">↩</a></p></li>
<li id="fn29"><p>95.1% is niet exact gelijk aan het nominale 95% omdat er ‘slechts’ 1000 simulaties gelopen zijn<a href="chap-besluit.html#fnref29">↩</a></p></li>
<li id="fn30"><p>De steekproefstandaarddeviatie is eveneens een toevallig veranderlijke die van steekproef tot steekproef varieert rond werkelijke standaarddeviatie. Hierdoor zal de breedte van de intervallen eveneens variëren<a href="chap-besluit.html#fnref30">↩</a></p></li>
<li id="fn31"><p>independent and identically distributed, onafhankelijk en gelijk verdeeld<a href="chap-besluit.html#fnref31">↩</a></p></li>
<li id="fn32"><p>vandaar de index 0 bij <span class="math inline">\(\mu_0\)</span><a href="chap-besluit.html#fnref32">↩</a></p></li>
<li id="fn33"><p>distributie van de teststatistiek onder de nulhypothese<a href="chap-besluit.html#fnref33">↩</a></p></li>
<li id="fn34"><p>meer extreem in de richting van <span class="math inline">\(H_1\)</span><a href="chap-besluit.html#fnref34">↩</a></p></li>
<li id="fn35"><p>In de frequentistische theorie die we hier volgen, is de nulhypothese immers ofwel altijd waar, ofwel altijd vals, en is het dus zelfs niet mogelijk om de kans te definiëren dat de nulhypothese waar is. Teminste, die kans is ofwel 1 ofwel 0.!<a href="chap-besluit.html#fnref35">↩</a></p></li>
<li id="fn36"><p>We hebben <span class="math inline">\(n_1+n_2\)</span> observaties (vrijheidsgraden) in het experiment, om de gepoolde variantie te schatten hebben we echter 2 vrijheidsgraden verloren aangezien we eerst het gemiddelde in elke groep dienden te bepalen om de variantie te kunnen schatten.<a href="chap-besluit.html#fnref36">↩</a></p></li>
<li id="fn37"><p>Merk op dat we de richting “significant hoger is in de transplantatie groep” afleiden uit de groepsgemiddelden in de output en/of het BI<a href="chap-besluit.html#fnref37">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-describe.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-linReg.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-StatistischeBesluitvorming.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Statistiek_2019_2020.pdf", "Statistiek_2019_2020.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
