[
["index.html", "Cursus Statistiek 2018-2019 Woord vooraf", " Cursus Statistiek 2018-2019 Lieven Clement 2018-09-20 Woord vooraf Zoals steeds heeft het herwerken van de cursus heel wat voeten in de aarde. Gelukkig kon ik me hierbij baseren op cursusmateriaal van collega’s. In het bijzonder wens ik prof. Stijn Vansteelandt1, prof. Olivier Thas2 en prof. Geert Verbeke3 te bedanken voor het delen van hun cursusmateriaal en de stimulerende discussies rond statistiekonderwijs. Daarnaast was het ook een nieuwe ervaring om een volledige cursus te ontwikkelen binnen het statistische opensource software pakket R via het fantastische bookdown package van Yihui Xie. die vroeger dit opleidingsonderdeel verzorgde↩ Opleidingsonderdeel “Statistische Dataverwerking”, Bachelor in de Bio-ingenieurswetenschappen, UGent↩ Opleidingsonderdeel “Beginselen van biostatistiek”, Bachelor Biomedical Sciences, KU Leuven↩ "],
["links.html", "Links", " Links Een html versie van de cursus is beschikbaar op https://users.ugent.be/~lclement/statistiek/ waardoor alle voorbeelden en code in deze cursus makkelijk in R kunnen worden gereproduceerd, wat handig kan zijn wanneer je zelf r-markdown scripts ontwikkeld. Een pdf versie van de cursus is beschikbaar op https://users.ugent.be/~lclement/statistiek/Statistiek_2018_2019.pdf Alle datasets zijn beschikbaar op https://users.ugent.be/~lclement/statistiek/data.zip "],
["inleiding.html", "Hoofdstuk 1 Inleiding 1.1 De Wetenschappelijke Methode 1.2 Voorbeeld: Horizon - Homeopathy the test", " Hoofdstuk 1 Inleiding De meeste vragen in de levenswetenschappen kunnen slechts beantwoord worden door gegevens te verzamelen en te analyseren, bijvoorbeeld: Voor welke genen verschilt het expressieniveau in kanker en normaal weefsel? Hoe snel lopen kangoeroes? Wat is de invloed van regelmatig joggen op bloeddruk? Is er een relatie tussen zweetgeur en de samenstelling van de microbiële gemeenschap onder de oksel? Bij onderzoek naar biologische processen moet men zich realiseren dat uitkomsten aan variatie onderhevig zijn. Aspirine is bijvoorbeeld niet bij iedereen even effectief om hoofdpijn te verzachten zodat de uitkomst voor een persoon met en zonder inname van aspirine meestal niet exact te voorspellen valt. Dit wordt mede veroorzaakt door het feit dat mensen verschillen in gewicht, ziektegraad, gevoeligheid voor een stof, … Bovendien reageert een persoon vaak anders op een stof naargelang hij moe of uitgerust is, het middel ’s morgens of ‘s avonds inneemt, voor of na het eten, op geregelde tijdstippen of met onregelmatige intervallen, … En zelfs al mocht een bepaalde stof voor iedereen even effectief zijn, dan nog is het zo dat verschillende metingen voor een zelfde persoon zelden gelijk. De aanwezigheid van die biologische variabiliteit is bijzonder opvallend in de context van roken: de schadelijke gevolgen van roken op longkanker en hartaandoeningen zijn intussen goed gekend, maar nagenoeg iedereen kent wel iemand die gans zijn leven gerookt heeft en desondanks meer dan 80 jaar oud geworden is. Precies omwille van die biologische variabiliteit is het moeilijk om wetenschappelijke vragen goed te beantwoorden en zal men zelden onmiddellijk het antwoord zien na het bekijken van ruwe gegevens. Onderzoekers in de fysiologie, bijvoorbeeld, gaan vaak na wat het effect is van een bepaalde substantie (bijvoorbeeld, een geneesmiddel, hormoon of toxine) op experimentele dieren (bijvoorbeeld, ratten of ook in vitro weefselpreparaten). Dit effect wordt bestudeerd door verschillen in respons te meten tussen dieren geïnjecteerd met de substantie en controledieren die werden geïnjecteerd met een inactieve zoutoplossing. Omwille van biologische variatie zullen een aantal dieren die geïnjecteerd werden met lage dosissen van de toxische stof, het er vaak beter van af brengen dan sommige controledieren. Hierdoor kunnen geobserveerde effecten zowel toevallig zijn als wijzen op een systematisch effect. Bovendien moeten we ons afvragen of de controlegroep en de met substantie-geïnjecteerde groep een vergelijkbare gezondheid hebben. Zo niet, dan zou een mogelijk verschil in respons ook mede hierdoor verklaard kunnen worden. Het doel van statistiek is precies om orde te scheppen in de chaos door duidelijk te maken hoeveel variatie op de gegevens toe te schrijven valt aan systematische verschillen (bijvoorbeeld, door het al dan niet inspuiten van een bepaalde substantie) en hoeveel aan toeval of biologische variatie. Statistiek is immers de wetenschap rond verzamelen, exploreren en analyseren van data. Ze laat toe om tot een goede proefopzet te komen, om te leren uit data en om hierbij variabiliteit en onzekerheid te kwantificeren controleren rapporteren d.m.v. statistische besluitvorming modellen op een formele wijze te toetsen aan de data. Ze vervult daarom een belangrijke rol in zowat alle wetenschappen. Zie ondermeer de populaire column ‘’points of significance’’ in Nature Methods. (http://blogs.nature.com/methagora/2013/08/giving_statistics_the_attention_it_deserves.html) In deze inleiding situeren we Statistiek in de Wetenschappelijke Methode. 1.1 De Wetenschappelijke Methode Het doel van wetenschap is het begrijpen van de natuur (van het allerkleinste tot het allergrootste, van vroeger en nu tot in de toekomst). De Wetenschappelijke Methode is de methodiek die vandaag de dag algemeen aanvaard wordt om onze wetenschappelijke kennis van de natuur op te bouwen. Twee belangrijke pijlers van de Wetenschappelijke Methode zijn theorie en observatie. Een wetenschappelijke theorie voorspelt hoe een natuurlijk proces zich gedraagt. Observaties kunnen gebruikt worden om deze theorie te bevestigen of te ontkrachten. Een wetenschappelijke theorie kan dus nooit bewezen worden door observatie, maar kan wel ontkracht worden door observatie. Dit is het falcificatieprincipe van de wetenschapsfilosoof Karl Popper (1902-1994). De levenswetenschappen berusten op empirisch onderzoek omdat observaties nodig zijn om de kennis uit te breiden. Theorieën kunnen gepostuleerd worden zonder observatie (hoewel dit zelden gebeurt), maar de wetenschapsgemeenschap neemt ze typisch maar voor waar aan nadat de nieuwe theorieën aan observatie getoetst worden. Figuur 1.1 is een schematische weergave van de Wetenschappelijke Methode. De natuur staat bovenaan de driehoek. Dit stelt het universum, de wereld, de werkelijkheid of de waarheid voor, waarover de mens kennis wil verzamelen. Een model (of een theorie) stelt een denkbeeld van een aspect van de natuur voor. Een model laat toe om voorspellingen, verder predicties genoemd te maken over het gedrag van een aspect van de natuur. Hierbij wordt niet noodzakelijk een mathematisch model bedoeld, maar kan het ook een kwalitatieve beschrijving zijn van een aspect van de natuur (bv. insecticide behandeling van planten leidt tot een vermindering van het aantal schadelijke insecten op de planten en tot een verhoogde opbrengst van de oogst). Via een wetenschappelijk experiment worden data uit de natuur gehaald. Data vormen een manifestatie van het werkelijke gedrag van de natuur. Het experiment moet representatief en reproduceerbaar zijn Statistische Besluitvorming (Engels: statistical inference) vormt de brug tussen het model van de natuur en de data uit de natuur. Statistische Besluitvorming laat toe op een formele wijze het model te toetsen aan de data en te besluiten in welke mate de wetenschappelijke gemeenschap de theorie en het model voor waar mag aannemen. Statistiek wordt ingeroepen omdat de Wetenschappelijke Methode niet zonder doel gebruikt wordt. Wetenschappers hebben gedeeltelijke kennis van de natuur via een aantal modellen/theorieën, maar deze kennis doet nieuwe vragen ontstaan. Dit leidt tot een nieuwe onderzoeksvraag (bijvoorbeeld: zorgt het gebruik van insecticiden voor minder schade van insecten aan de plant?), welke vervolgens verfijnd wordt in een nauwkeurig geformuleerde hypothese (bijvoorbeeld: Het aantal aangetaste bladeren is gelijk voor onbehandelde en pesticide-behandelde planten). Een hypothese is zodanig geformuleerd dat ze door data kan verworpen worden indien de hypothese niet waar zou zijn. De formulering van de hypothese bepaalt mede hoe het experiment moet opgezet worden om de meest informatieve data (evidentie) te kunnen bekomen om vervolgens via de statistische besluitvoering tot een conclusie (i.e. antwoord op de onderzoeksvraag) te komen. Statistiek als wetenschapdiscipline treedt dus op in drie domeinen: Proefopzet (“Experimental Design”): het ontwerpen van het exeriment, Data-exploratie en beschrijvende statistiek (“Data-exploration and Descriptive Statistics”): het exploreren, samenvatten en visualiseren van de data en Statistische besluitvorming (“Statistical Inference”): het veralgemenen van de resultaten in de steekproef naar de populatie toe. We komen nog even terug of het falcificatieprincipe. Doorheen deze cursus zal het duidelijk worden dat statistiek methoden aanlevert die toelaten om na te gaan in welke mate data consistent zijn met een vooropgestelde model. Indien de data consistent zijn met het model zullen we niet noodzakelijk onmiddellijk besluiten dat de theorie en het model correct zijn. De wijze waarop de data tot stand gekomen zijn via de opzet van experiment speelt hierbij ook een belangrijke rol. Het experiment moet eigenlijk zo opgezet worden dat het model uitgedaagd wordt. Pas als alle moeite gedaan is om te pogen data te bekomen die inconsistent zijn met het model, kunnen de theorie en het model als waar beschouwd worden met een grote waarschijnlijkheid. Wanneer de data inconsistent zijn met het gepostuleerde model, dan kan direct besloten worden dat het model niet juist is. De Wetenschappelijke Methode heeft een cyclisch karakter: bij het vaststellen van een foutief model zal de wetenschapper het model aanpassen en doorloopt hij opnieuw alle stappen van de Wetenschappelijke Methode. Figuur 1.1: De Wetenschappelijke Methode en de rol van Statistiek. Een andere belangrijke rol van de Statistiek die verder in deze cursus wordt behandeld, is om de reproduceerbaarheid van wetenschappelijk onderzoek te waarborgen, binnen zelf gekozen probabiliteitsgrenzen (onzekerheid / zekerheid). 1.2 Voorbeeld: Horizon - Homeopathy the test BBC reportage over homeopathie https://www.dailymotion.com/video/x19idby 1.2.1 Wetenschappelijke hypothese (fragmenten 1-2: 0’00’‘-6’00’‘&amp; 7’40’‘-11’30’’) Dr. J. Benveniste was een bekende Franse immunoloog die basofiele granulocyten, een soort van witte bloedcellen, bestudeerde. Basofiele granulocyten, ook wel basofielen genoemd, hebben verscheidene Immunoglobuline E (IgE)-receptoren op het membraan die antigenen kunnen binden. Als dit type van granulocyten in contact komen met allergenen dan worden ze geactiveerd en laten hun granules vrij, wat uiteindelijk kan leiden tot een allergische reactie. Benveniste ontwikkelde een test waarbij hij de actieve en inactieve basofielen kon onderscheiden aan de hand van een kleurreactie. Hierdoor kon hij allergische reacties opsporen door het aantal gekleurde basofielen (diegene die de granules vrijgelaten hebben) in een staal te tellen en te vergelijken met een controle staal. Een onderzoeker in zijn labo deed echter eigenaardige bevindingen. Heel hoge verdunningen van anti-IgE antilichamen activeert de degranulatie van humane basofielen, een bevinding die het werkingsmechanisme van homeopathie lijkt te ondersteunen. Om deze laatste bevinding te testen, pakten Dr. Benveniste en zijn team het onderzoek aan volgens de principes van de wetenschappelijke methode. Een nieuwe hypothese werd geponeerd: The Memory of Water. Deductie: Als een substantie van anti-IgE antilichamen sterk wordt verdund en heftig wordt geschud, dan wordt de informatie overgedragen naar het water zodat een reactie kan worden gedetecteerd door de allergietest met gemodificeerde basofielen bij extreem grote verdunningen. Zet een nieuw experiment op om ``Memory of Water’’-hypothese te evalueren Verken, analyseer en interpreteer de resultaten uit het experiment Verspreiden van resultaten Hun werk verscheen in Nature, Davenas et al. (1988), met een “Editorial Reservation: Readers of this article may share the incredulity of the many referees who have commented on several versions of it during the past several months. The essence of the result is that an aqueous solution of an antibody retains its ability to evoke a biological response even when diluted to such an extent that there is a negligible chance of there being a single molecule in any sample. There is no physical basis for such an activity. With the kind collaboration of Professor Benveniste, Nature has therefore arranged for independent investigators to observe repetitions of the experiments. A report of this investigation will appear shortly.” 1.2.2 Onderzoek dient reproduceerbaar te zijn. Wat ging er fout? (Fragment: 14’50”-18’56”) Een week na publicatie bezocht een team bestaande uit Nature editor Sir John Maddox, een wetenschappelijke fraudebuster Walter W. Stewart en goochelaar en scepticus James Randi, het labo van Benveniste zodat hij zijn resultaten kon reproduceren onder gecontroleerde contities. Tijdens een eerste drie pogingen kon het team van Benveniste de resultaten reproduceren en werd hoge activiteit van de basofielen bevestigd wanneer ze in contact werden gebracht met de extreem sterk verdunde substantie. Dr. Stewart merkte op dat de onderzoekers die de tellingen verrichten, wisten welke stalen behandeld werden met de controle en welke met de extreem verdunde substantie. En hij stelde een dubbelgeblindeerde proefopzet voor, waarbij geen van de onderzoekers wist welke stalen de controle en welke de behandelde stalen waren. De stalen werden in een aparte geblindeerde kamer voorbereid en gerandomiseerd. De codes werden aan het plafond van het lab geplakt. Onder deze meer rigoureuze procedure kon het team van Benveniste de resultaten niet langer reproduceren. Wat ging er fout? Proefopzet: Bias kan worden geïntroduceerd als de wetenschapper weet hoe de stalen worden behandeld. Oplossing? Blindering (“Blinding”) At random codes toe te wijzen aan de stalen De codes worden gebroken nadat alle data is gecollecteerd Hoe subjectiever de meting hoe belangrijker blindering is Dubbele blindering (“Double blinding”): Zowel proefpersoon als wetenschapper weten niet welke behandeling er werd gegeven Dubbelgeblindeerde proeven zijn de standaard in geneesmiddelenonderzoek. Het is immers nooit voldoende om enkel een nieuw middel aan een aantal patiënten toe te dienen om de werkzaamheid te evalueren. Er moet steeds een controlegroep zijn die geen werkzaam geneesmiddel krijgt, maar een placebo, zodat de effecten daarvan kunnen worden vergeleken met die van het “effectieve” middel. Men heeft dan ook als doel om te bewijzen dat een stof beter werkt dan het placebo-effect. Cruciaal hierbij is dat de arts die het middel voorschrijft, de arts die het effect beoordeelt noch de patiënt mogen weten wie de effectieve behandeling kreeg en wie het placebo kreeg. Dit om te vermijden dat de artsen hun eigen verwachtingen over het middel onbewust aan de patiënt over zouden dragen, of dat het oordeel van de artsen over de toestand van de patiënt na de behandeling beïnvloed zou worden (vb Fragment: 19’00’’-20’30“). Dit voorbeeld wijst dus op het belang van een goeie controle! 1.2.3 The ultimate test - proefopzet (Fragment 31’00-39’30’’) “The Memory of Water” hypothese duikt nog geregeld op in de wetenschappelijke literatuur. Telkens betreft het echter onderzoek met gebrekkige controles of kon het onderzoek niet gereproduceerd worden. James Randy speelt met zijn “one-million-dollar-challenge” in op deze onderzoeken. Als scepticus looft hij een prijs uit voor eenieder die onder gecontroleerde condities claims hard kan maken die volgens de huidige wetenschappelijk kennis onmogelijk zijn. Het team van Horizon gaat de “one-million-dollar-challenge” aan. Onder goedkeuring van James Randy zetten zij de volgende proef op om de “The Memory of Water” hypothese te onderzoeken. Een stockoplossing van actieve stof en een negatieve controle worden aangemaakt en ondergaan dezelfde stappen. Om mogelijke contaminatie effecten uit te sluiten worden ze beiden verdund. Eerst worden 2 x 5 proefbuizen met verdunning van 5C (5 opeenvolgende verdunningen van 1 op 100) gemaakt: 5 met actieve stof en 5 met puur water. Deze 10 tubes worden random gelabeld. Hier wordt dus wel op een effectieve manier gebruik gemaakt van blinding. Na het labelen volgt een verdere verdunning tot 18C. Vervolgens worden de stalen herlabeld om alle fraude te voorkomen en worden de stalen naar twee onafhankelijke labo’s gestuurd (Marion en Wayne). In het labo voegen de onderzoekers de humane basofiel granulocyten toe. Via flowcytometrie, een objectievere meting dan manuele tellingen, wordt nagegaan hoeveel cellen zijn geactiveerd. De labo’s werd meegedeeld dat er 20 actieve en 20 placebo oplossingen zijn om te voorkomen dat alle stalen als niet actief worden geklasseerd. Hierna geeft elk labo zijn ruwe flowcytometrie metingen, proportie actieve cellen per staal en klassering van de stalen door. 1.2.4 The ultimate test - data analyse (Fragment 39’30-43’00’’) Nadat alle labo analyses zijn uitgevoerd, verzamelen alle wetenschappers, journalisten en James Randy zich in “the Royal Society”. Een statisticus analyseert de gegevens. Bij het verkennen van de data, ook de data exploratie genoemd, bleken bepaalde stalen meer activiteit te vertonen dan anderen. De vraag is of dit systematisch het geval is voor “sterk-verdunde” stalen. In het Marion labo werden 9 proefbuizen van extreme verdunning (D) en 11 van de controles (C) negatief gelabeld. Omdat onderzoekers wisten dat er 20 actieve proefbuizen (D) en 20 controle proefbuizen (C) waren, weten we ook dat er 11 (D) en 9 (C) stalen als positief werden gelabeld. Tabel 1.1: Kruistabel van de resultaten in het lab van Marion. 11/20 proefbuizen van extreme verdunning (D) en 9/20 van de controles (C) worden als actief gelabeld. negatief postief totaal sterk verdund (D) 9 11 20 controle (C) 11 9 20 totaal 20 20 40 Falsificatie-principe: Het is niet mogelijk om een hypothese te bewijzen met empirische data. We kunnen dus niet aan tonen dat het effect van D anders is dan van C. We kunnen wel het omgekeerde proberen te ontkrachten: C en D hebben eenzelfde effect. Als C en D eenzelfde effect hebben verwachten we dat er evenveel extreem-verdunde stalen als controle stalen als actief worden gelabeld. Tabel 1.2: Kruistabel van verwachte resultaten als er geen effect is van de verdunning. negatief postief totaal sterk verdund (D) 10 10 20 controle (C) 10 10 20 totaal 20 20 40 Enerzijds zou men in het experiment een lichte aanwijzing kunnen zien dat er in de stalen met extreme verdunning activiteit is: 11/20 stalen werden correct geklasseerd. Anderzijds, zou het kunnen dat de 11/20 berust op toeval. Als er geen effect is van D zal men door toeval toch resultaten vinden die lichtjes afwijken van 10/20. Maar hoeveel is “lichtjes”: 11/20? 12/20? 13/20? … Hoeveel correcte positieve tests \\(x\\) zijn er nodig om voldoende bewijskracht te hebben voor werking van D? We kunnen dit onderbouwen met kans om ten minste \\(x\\) correcte positieve tests te vinden door zuiver toeval wanneer D niet verschilt van C. \\[p=P(\\text{ten minste } x \\text{ correcte positieve tests} \\vert \\text{effect D= effect C})\\] Dergelijke kansen kunnen worden berekend door gebruik te maken van probabiliteitstheorie (Tabel 1.3): knitr::kable(cbind(x=11:15, p=phyper(q=10:14,m=20,n=20,k=20,lower.tail=FALSE)), tableType, caption = &#39;Kans op tenminste $x$ correct geklasseerde &quot;sterk-verdunde&quot; stalen wanneer er in werkelijkheid geen effect is.&#39;, booktabs = TRUE,digits=4 ) Tabel 1.3: Kans op tenminste \\(x\\) correct geklasseerde “sterk-verdunde” stalen wanneer er in werkelijkheid geen effect is. x p 11 0.3762 12 0.1715 13 0.0564 14 0.0128 15 0.0019 Als er geen verschil is tussen C en D, dan zal men in 37.6% van de experimenten door toeval een \\(x\\) observeren van minstens 11 Het experiment geeft dus absoluut geen bewijs voor de werking van de verdunning D. De random variabiliteit in experimenten wordt ook geïllustreerd als we de resultaten van het Marion labo vergelijken met deze van Wayne (zie Tabel 1.4). Tabel 1.4: Kruistabel van de resultaten in het lab van Wayne. 9/20 proefbuizen van extreme verdunning (D) en 11/20 van de controles (C) worden als actief gelabeld. negatief postief totaal sterk verdund (D) 11 9 20 controle (C) 9 11 20 totaal 20 20 40 Bijgevolg zien we dat we op basis van empirische gegevens nooit met 100% zekerheid conclusies kunnen trekken. De gegevens zijn onderhevig aan random variabiliteit en bijgevolg zijn onze conclusies dat ook. 1.2.5 Mogelijke fouten Een experiment is onderhevig aan random variabiliteit bijgevolg zijn de conclusies dat ook. Zelfs als D en C equivalent zijn, kan men 15 correcte positieve resultaten observeren door toeval. Dat kunnen we in 2 op de 1000 experimenten verwachten. In dergelijke steekproef zal men ten onrechte besluiten dat er bewijs is voor de werking van D terwijl er in realiteit geen verschil is tussen D en C. Intuïtief voelen we aan dat we niet met absolute zekerheid uitspraken kunnen doen over populatiekarakteristieken op basis van een eindige steekproef. In deze cursus zullen we daarom steeds volgende facetten van de statistiek bespreken: Proefopzet: hoe zijn de gegevens tot stand gekomen Data exploratie en beschrijvende statistiek: exploreren, visualiseren, samenvatten en beschrijven van geobserveerde data zodat relevante aspecten naar voor komen. Statistische besluitvorming: aan de hand van statistische modellen bestuderen in hoeverre geobserveerde trends/effecten die geobserveerd worden in een steekproef veralgemeend kunnen worden naar de algemene populatie. References "],
["belangrijke-concepten-conventies.html", "Hoofdstuk 2 Belangrijke concepten &amp; conventies 2.1 Variabelen 2.2 Populatie 2.3 Toevalsveranderlijken (of toevallige veranderlijken) 2.4 Beschrijven van de populatie 2.5 Steekproef 2.6 Schatten van de verdeling in de populatie 2.7 Statistieken", " Hoofdstuk 2 Belangrijke concepten &amp; conventies De verschillende stappen in een studie worden geïllustreerd in Figuur 2.1. Eerst bepaalt de onderzoeker de populatie van interesse. Gezien het om financiële en logistieke beperkingen vrijwel nooit mogelijk is om de volledige populatie te onderzoeken zal men vervolgens een steekproef nemen uit de populatie. De manier waarop een steekproef zal worden genomen wordt vastgelegd in het design van de studie. Proefopzet of studie design is een aparte tak van de statisitiek en is een cruciaal onderdeel van een studie. Het studie design moet immers garanderen dat de gegevens en resultaten van de steekproef representatief zijn voor de populatie zodat de resultaten van de studie veralgemeneend kunnen worden naar de populatie toe. Vervolgens wordt de studie uitgevoerd, worden de gegevens verzameld en kan de eigenlijke data-analyse van start gaan. In een eerste fase is het belangrijk om de gegevens grondig te exploreren. Data-exploratie en beschrijvende statistiek is een tweede tak van de statistiek die toelaat om gegevens van de steekproef te visualiseren, samen te vatten en om inzicht in de data te verwerven. Dat is belangrijk om de data correct te kunnen modelleren en om aannames na te kunnen gaan die nodig zijn voor de verdere data analyse. Vervolgens zullen we hetgeen we observeren in de steekproef trachten te veralgemenen naar de algemene populatie toe, zodat we algemene conclusies kunnen trekken op populatie-niveau op basis van de steekproef van de studie. Hiervoor zijn methodes nodig van de statistische besluitvorming, ook wel statistische inferentie genoemd, een derde belangrijke tak van de statistiek. Figuur 2.1: Verschillende stappen in een studie. (1) In de design fase/ proefopzet definieert de onderzoeker de populatie, bepaalt hij/zij op welke manier een steekproef zal worden genomen uit de populatie en hoe het experiment zal worden uitgevoerd. Ook het volledige data analyse plan moet in deze fase zijn vastgelegd. Vervolgens wordt het experiment uitgevoerd en worden de gegevens verzameld. (2) De gegevens worden vervolgens verkend en samengevat. Hierbij verwerft men inzicht in de gegevens en kunnen aannames worden nagegaan die noodzakelijk zijn voor de verdere data analyse stappen. (3) Tenslotte zal men hetgeen men observeert in de steekproef trachten te veralgemenen naar de populatie toe a.d.h.v. statistische inferentie. Vooraleer we dieper ingaan op studie-design, data-exploratie en statistische besluitvorming zullen we eerst enkele concepten introduceren. We doen dat in dit hoofdstuk aan de hand van de de NHANES studie. Voorbeeld 2.1 (NHANES studie) De National Health and Nutrition Examination Survey (NHANES) wordt sinds 1960 op regelmatige basis afgenomen. In dit voorbeeld maken we gebruik van de gegevens die werden verzameld tussen 2009-2012 bij 10000 Amerikanen en die werden opgenomen in het R-pakket NHANES. Er werd een groot aantal fysieke, demografische, nutritionele, levelsstijl en gezondheidskarakteristieken gecollecteerd in deze studie (zie Tabel 2.1). **Einde voorbeeld** Tabel 2.1: Overzicht van een aantal variabelen uit de NHANES studie. ID Gender Age Race1 Weight Height BMI BPSysAve TotChol SmokeNow Smoke100 51624 male 34 White 87.4 164.7 32.22 113 3.49 No Yes 51625 male 4 Other 17.0 105.4 15.30 NA NA NA NA 51630 female 49 White 86.7 168.4 30.57 112 6.70 Yes Yes 51638 male 9 White 29.8 133.1 16.82 86 4.86 NA NA 51646 male 8 White 35.2 130.6 20.64 107 4.09 NA NA 51647 female 45 White 75.7 166.7 27.24 118 5.82 NA No 2.1 Variabelen Een variabele is een karakteristiek (bvb. Systolische bloeddruk, leeftijd, geslacht, …) die varieert van subject tot subject (bvb. van persoon tot persoon, van dier tot dier, …) in de studie. Er zijn verschillende types variabelen. Kwalitatieve variabelen hebben (meestal) beperkt aantal uitkomstcategorieën die niet numeriek van aard zijn. Deze worden onderverdeeld in nominale variabelen en ordinale variabelen . Nominale gegevens zijn er die men kan benoemen. Ze worden niet gemeten en kennen geen natuurlijke ordening; bijvoorbeeld geslacht, ras, bloedgroep, kleur van ogen, … Ordinale variabelen kennen wel een ordening; bijvoorbeeld de BMI klasse volgens het WHO, de rokersstatus (nooit gerookt, ooit gerookt maar gestopt, actueel roker), … Een ander type van variabelen zijn numerieke variabelen. Hierbij maakt men het onderscheid tussen numerieke discrete variabelen en numerieke continue variabelen. Numerieke discrete variabelen bestaan uit tellingen, b.v. het aantal partners die men had gedurende het leven (geregistreerd in de NHANES studie), het aantal salamanders van de species P. jordani in een bepaald gebied, het aantal reads dat mapt op een bepaald gen in een genexpressiestudie waarbij men gebruik maakt van next-generation sequencing technologie , … Numerieke continue variabelen kunnen (tenminste in theorie) tussen bepaalde grenzen elke mogelijke waarde aannemen. Bijvoorbeeld, leeftijd is continu want het verschil in leeftijd tussen 2 personen kan in principe willekeurig klein zijn (1 uur, 1 minuut, …). Analoog zijn het gewicht, BMI, fluorescentie-metingen in een ELISA experiment, … continue metingen. In de wetenschappen gaat men vaak continue gegevens dichotomiseren om ze nominaal te maken. Bijvoorbeeld, systolische bloeddruk wordt omgezet in hypertensie (\\(&gt;140\\) mmHg) en normotensie (\\(\\leq 140\\) mmHg). Dit vereenvoudigt de beschrijving van gegevens. Helaas is dit een slechte praktijk omdat het meestal leidt tot een aanzienlijk verlies aan informatie en omdat de aldus bekomen resultaten sterk afhankelijk kunnen zijn van de gekozen drempelwaarde. In de praktijk worden de uitkomsten van continue variabelen ook vaak afgerond zodat de vermelde waarden in feite discreet zijn. Om analoge redenen is het vaak wenselijk om ze als continue variabelen te blijven beschouwen. In de praktijk wil men vaak numerieke rangen toekennen aan de verschillende waarden die ordinale variabelen aannemen. Bijvoorbeeld kan men ervoor kiezen de codes 1, 2 en 3 toe te kennen aan de meetwaarden nooit gerookt, ooit gerookt maar gestopt en actueel roker. Het is belangrijk om te beseffen dat de keuze van die numerieke waarden vaak geen betekenis heeft. Het verschil tussen de toegekende codes (3-2=1, 2-1=1, 3-2=1) is niet bruikbaar gezien men bijvoorbeeld niet onderstellen dat de wijziging in rokerstatus identiek is van nooit gerookt naar ooit gerookt maar gestopt (2-1=1) en van ooit gerookt maar gestopt naar actueel roker (3-2=1). Voorbeeld 2.2 (oefening) Geef het type aan van de variabelen in Tabel 2.1 2.2 Populatie Het doel van een wetenschappelijke studie is nagenoeg altijd om uitspraken te doen over de algemene populatie. Stel bijvoorbeeld dat men een grenswaarde wil afleiden om patiënten met hypertensie op te sporen. Hiervoor zal men eerst de systolische bloeddruk moeten bestuderen bij een populatie van gezonde personen. Een populatie is meestal continu in verandering. Bovendien is men meestal niet alleen geïnteresseerd in effecten bij huidige subjecten, maar ook in het effect bij toekomstige subjecten. De populatie kan dus als oneindig groot worden beschouwd en is op een bepaald ogenblik zelfs niet volledig observeerbaar4. De populatie kan binnen de statistiek dus worden opgevat als een theoretisch concept die alle huidige en toekomstige subjecten omvat waarover men uitspraken wenst te doen. In de praktijk zal men dus nooit de volledige populatie kunnen bemonsteren en dient men een steekproef te nemen van de populatie. Om een representatieve groep subjecten te waarborgen, vertrekt een goede onderzoeksopzet vanuit een belangrijke, precies geformuleerde vraagstelling omtrent een duidelijk omschreven populatie. Vaak worden hierbij inclusie- en exclusiecriteria geformuleerd. Inclusiecriteria zijn karakteristieken die een subject/experimentele eenheid moet hebben om tot de populatie te behoren, b.v. specifieke ziekte: hypertensie leeftijdscategorie geslacht … Exclusiecriteria zijn karakteristieken die een subject/experimentele eenheid niet mag hebben om tot de populatie te behoren, b.v. geneesmiddelen gebruik andere ziekten zwangerschap … Op de subjecten zal men meestal een aantal karakteristieken meten, ook wel variabelen genoemd (bvb. Systolische bloeddruk, leeftijd, geslacht, …). Typisch zullen deze variabelen variëren van subject tot subject (bvb. van persoon tot persoon, van dier tot dier, …) in de populatie. 2.3 Toevalsveranderlijken (of toevallige veranderlijken) De belangrijke vraag, waar we in in de verdere hoofdstukken dieper op in zullen gaan, is hoe nauwkeurig we uitspraken kunnen doen over de populatie o.b.v. een groep gemeten subjecten in een steekproef. De spreiding op de gegevens zal daar een cruciale rol in spelen. Als de gegevens niet variëren tussen subjecten, dan zullen alle steekproeven uit de populatie hetzelfde resultaat opleveren en zullen de bekomen schattingen niet afwijken van de gezochte populatieparameters. Als daarentegen de gegevens zeer chaotisch zijn, dan zullen verschillende steekproeven mogelijks zeer verschillende resultaten opleveren, die bijgevolg ver kunnen afwijken van de gezochte populatieparameters. Om het denkwerk te vergemakkelijken, zullen we hoofdletters gebruiken om aan te geven dat de bestudeerde karakteristiek (vb. een meetresultaat zoals systolische bloeddruk) variabel is in de populatie, zonder daarbij concreet over de gerealiseerde waarde voor een bepaald subject na te denken. Dergelijke meting of variabele \\(X\\) wordt algemeen een toevalsveranderlijke of toevallige veranderlijke genoemd, (a) omdat ze formeel het resultaat aanduidt van een toevallige trekking van een bepaalde karakteristiek uit de studiepopulatie en (b) omdat ze bovendien veranderlijk is, niet alle subjecten in de steekproef bezitten immers dezelfde waarde voor die karakteristiek. Het makkelijkst om over een toevalsveranderlijke \\(X\\) na te denken is alsof \\(X\\) het label voorstelt van een bepaalde populatiekarakteristiek voor een lukraak individu uit de bestudeerde populatie, vooraleer haar concrete waarde gemeten werd. Met andere woorden, een toevalsveranderlijke \\(X\\) kan men opvatten als onbekende veranderlijke die een meting voorstelt die we plannen te verzamelen, maar nog niet hebben verzameld. Net zoals observaties kunnen we toevallig veranderlijken klasseren als kwalitatief, kwantitatief, discreet, continu, …. 2.4 Beschrijven van de populatie Voor we een random variabele meten, kunnen we onmogelijk zeggen hoe hoog de meting precies zal zijn. De gerealiseerde waarde van \\(X\\) is dus onderhevig aan random variabiliteit. Onze geobserveerde steekproef \\(x_1, x_2, . . . , x_{275}\\) kan dus als n = 275 realisaties worden beschouwd van dezelfde random variable X, voor subject \\(i\\), met \\(i = 1,2,...,275\\). Een random veranderlijke, een karakteristiek van de populatie, wordt beschreven door gebruik te maken van een verdeling. De verdeling beschrijft de waarschijnlijkheid om een bepaalde waarde te observeren voor de toevallig veranderlijke wanneer men volledige lukraak een proefpersoon kiest uit de populatie. De densiteitsfunctie van de verdeling wordt vaak genoteerd als f(X). Heel vaak volgen biologische en chemische data een Normale verdeling. De Normale verdeling is een theoretische verdeling met een klokvorm die volledig gedefineerd wordt door twee parameters, het gemiddelde \\(\\mu\\) en de variantie \\(\\sigma^2\\). We zullen in latere hoofdstukken dieper ingaan op de normale verdeling. Veronderstel bijvoorbeeld dat de gemiddelde bloeddruk van subjecten in de populatie van gezonde 40-65 jarigen gelijk is aan \\(\\mu=120\\) mmHg en de variantie \\(\\sigma^2=196\\). De verdeling van de systolische bloeddruk wordt weergegeven in Figuur 2.2 die d.m.v. onderstaande code wordt gegenereerd in R. grid &lt;- seq(65,175,.1) plot(grid,dnorm(grid,mean=120,sd=196^.5),xlab=&quot;Systolische Bloeddruk (mm kwik)&quot;,col=2,ylab=&quot;Densiteit&quot;,type=&quot;l&quot;,lwd=2) grid2&lt;-seq(115,120,.01) polygon(x=c(grid2,120,115),y=c(dnorm(grid2,120,196^.5),0,0),col=2,border=2) text(120,dnorm(120,120,196^.5),paste0(&quot;P(115 &lt; X &lt; 120) =&quot;,round( diff(pnorm(c(115,120),120,196^.5)) * 100, 1),&quot;%&quot;),col=2,cex=1,pos=4) Figuur 2.2: Normale verdeling voor de systolische bloeddruk van gezonde personen tussen 40-65 jaar met gemiddelde 120 mm Hg en variantie 196. Op basis van de verdeling kunnen we kansen berekenen om bijvoorbeeld een lukraak subject te bemonsteren uit de populatie met een bloeddruk tussen 115 en 120 mmHg. De kansen worden weergegeven door de oppervlakte onder de densiteitsfunctie: \\[P[115\\leq X\\leq 120]= \\int\\limits_{115}^{120} f(x) dx = 0.14\\] De grafische interpretatie wordt weergegeven in Figuur 2.2. De oppervlakte onder de volledige densiteitscurve is gelijk aan 1 \\[P[-\\infty\\leq X \\leq +\\infty]=\\int\\limits_{-\\infty}^{+\\infty} f(x) dx=1\\] Kansen liggen uiteraard steeds tussen 0 en 1! Kansen worden veelal berekend door gebruik te maken van de cumulatieve distributie functie van de verdeling, F(x), m.a.w. de functie die weergeeft wat de kans is dat een Normaal verdeelde toevallige veranderlijke een waarde zal aannemen die kleiner of gelijk is aan de vooropgestelde kwantiel x: \\[F(x)=\\int\\limits_{-\\infty}^x f(x) dx = P[X\\leq x].\\] Merk op dat de de normale distributie in R wordt geparameteriseerd a.d.h.v. het gemiddelde \\(\\mu\\) en de standaard afwijking \\(\\sigma\\). Op basis van de Normaal verdeling die we veronderstelden voor de systolische bloeddruk in de populatie \\(N(\\mu=120\\),\\(\\sigma^2=196)\\) bekomen we pnorm(120,mean=120,sd=196^.5) ## [1] 0.5 pnorm(115,mean=120,sd=196^.5) ## [1] 0.3604924 pnorm(120,mean=120,sd=196^.5)-pnorm(115,mean=120,sd=196^.5) ## [1] 0.1395076 waarbij pnorm de kans berekent dat de bloeddruk bij een willekeurig subject in de populatie lager of gelijk is aan het kwantiel dat wordt opgegeven (hier 120 mm Hg en 115 mm Hg). Het verschil tussen beide kansen geeft dan de kans weer op een bloeddruk tussen 115 en 120 mm Hg. Let wel dat R de parameterisatie gebruikt van het gemiddelde \\(\\mu\\) en de standaard afwijking \\(\\sigma\\), ipv de variantie \\(\\sigma^2\\). In de praktijk kennen we de werkelijke verdeling in de populatie niet en moet deze worden geschat o.b.v. de steekproef. 2.5 Steekproef In de praktijk is het om financiële en logistieke redenen bijna nooit mogelijk om de volledige populatie te bestuderen. Populatieparameters kunnen daarom meestal niet exact bepaald worden. Enkel een deel van de populatie kan onderzocht worden, hetgeen men de steekproef noemt. Volgens een gestructureerd design worden daartoe lukraak subjecten uit de doelpopulatie getrokken en geobserveerd. De onbekende parameters worden vervolgens geschat o.b.v. die steekproef en noemt met schattingen. In de praktijk hoopt men uiteraard dat de schattingen die men bekomt op basis van de steekproef vergelijkbaar zijn met de overeenkomstige populatieparameters die men voor de volledige populatie zou bekomen. Stel bijvoorbeeld dat we op basis van de NHANES studie hypertensie wensen te definiëren. We zullen hiervoor subjecten met “normale” bloeddrukwaarden moeten selecteren. Veronderstel dat we \\(n\\) gezonde personen zullen selecteren in de studie tussen 40 en 65 jaar en we geïnteresseerd zijn in systolische bloeddruk. Telkens een lukraak individu getrokken wordt uit de populatie zal men een realisatie van de toevalsveranderlijke \\(X\\) kunnen observeren. Die realisatie of geobserveerde waarde duiden we aan met een kleine letter \\(x\\). Deze stelt dus een welbepaald getal voor en is niet langer een onbekende veranderlijke zoals \\(X\\). Samengevat zijn de nog onbekende waarden voor de bestudeerde populatiekarakteristiek bij subjecten 1 tot \\(n\\) in de steekproef, toevalsveranderlijken die we algemeen met \\(X_1,...,X_n\\) zullen noteren. Na het trekken van de steekproef, ziet men de gerealiseerde uitkomsten \\(x_1, x_2, \\dots, x_n\\), bijvoorbeeld hun gemeten systolische bloeddruk. We selecteren hieronder de subset van gezonde personen tussen de 40-65 jaar in de NHANES studie. Deze definiëren we verder als niet rokers, zonder diabetes, met een normaal BMI, zonder historiek van hard drugs, zonder lage gezondheidsstatus en zonder slaapproblemen. Op deze manier hebben we dus inclusie- en exclusiecriteria geformuleerd voor het definiëren van de populatie van interesse. library(NHANES) NHANES2=subset(NHANES,!is.na(Race1)&amp;!is.na(Smoke100n)&amp;!is.na(BMI_WHO)%in%!is.na(Age)&amp;!is.na(HardDrugs)&amp;!is.na(HealthGen)&amp;!is.na(Gender)&amp;!is.na(AlcoholYear)&amp;!is.na(BPSys1)&amp;!is.na(BPSys2)&amp;!is.na(BPSys3)&amp;!is.na(SleepTrouble)) NHANES2$bpSys=rowMeans(NHANES2[,c(27,29,31)]) nhanesSub=subset(NHANES2, Age&lt;=65&amp;Age&gt;=40 &amp;!duplicated(ID) ) nhanesSubHealthy=subset(nhanesSub,Smoke100n==&quot;Non-Smoker&quot;&amp;Diabetes==&quot;No&quot;&amp;as.double(BMI_WHO)%in%c(2,3)&amp;HardDrugs==&quot;No&quot;&amp;HealthGen!=&quot;Poor&quot;&amp;SleepTrouble==&quot;No&quot;) head(nhanesSubHealthy$bpSys) ## [1] 114.00000 140.66667 94.66667 152.66667 128.00000 124.00000 dim(nhanesSubHealthy) ## [1] 275 77 Op basis van de inclusie en exclusie-criteria werden \\(n=275\\) gezonde individuen uit de Amerikaanse populatie weerhouden. De toevallig veranderlijke systolische bloeddruk wordt dus genoteerd als \\(X\\) terwijl de n = 275 geobserveerde metingen genoteerd worden als \\(x_1,x_2,...,x_{275}\\). De variable \\(X\\) is random of stochastisch aangezien zijn waarde veranderlijk is. Voor een random subject uit de populatie kunnen we de systolische bloeddruk niet exact voorspellen, het hangt immers af van het geselecteerde subject, tijdstip van de meting, … 2.6 Schatten van de verdeling in de populatie In realiteit kennen we de verdeling van de gegevens niet. We kunnen de verdeling o.b.v. de steekproef schatten en grafisch weergegeven a.d.h.v. een histogram (functie hist() in R) histAbs&lt;-hist(nhanesSubHealthy$bpSys,xlab=&quot;Systolische Bloeddruk (mm kwik).&quot;,breaks=seq(65,175,5),ylab=&quot;Frequentie&quot;,cex.main=1.5,cex.axis=1.5,cex.lab=1.5,main=&quot;&quot;) Figuur 2.3: Weergave van de verdeling voor de systolische bloeddruk van gezonde personen tussen 40-65 jaar geschat aan de hand van een histogram o.b.v. de geobserveerde steekproef in de NHANES studie. (Absolute frequenties) Merk op dat de hoogte van de balken, aantallen op de y-as, weergeeft hoeveel subjecten vallen in een bepaald interval bloeddrukken ([80-85[, [85-90[, …). Op basis van de steekproef kunnen we via het histogram schatten wat de kans is om een random persoon te bemonsteren met een bloeddruk tussen 115 - 120 mm Hg uit de populatie . tab&lt;-cbind(histAbs$mids,histAbs$counts) tab ## [,1] [,2] ## [1,] 67.5 0 ## [2,] 72.5 0 ## [3,] 77.5 0 ## [4,] 82.5 1 ## [5,] 87.5 2 ## [6,] 92.5 6 ## [7,] 97.5 9 ## [8,] 102.5 22 ## [9,] 107.5 35 ## [10,] 112.5 33 ## [11,] 117.5 41 ## [12,] 122.5 36 ## [13,] 127.5 35 ## [14,] 132.5 17 ## [15,] 137.5 13 ## [16,] 142.5 12 ## [17,] 147.5 8 ## [18,] 152.5 3 ## [19,] 157.5 1 ## [20,] 162.5 0 ## [21,] 167.5 0 ## [22,] 172.5 1 tab[tab[,1]==117.5,2]/sum(tab[,2]) ## [1] 0.1490909 Op basis van de steekproef wordt die kans geschat op 14.9%. Een histogram kan ook weergegeven worden a.d.h.v. relatieve frequenties/densiteiten. hist(nhanesSubHealthy$bpSys,xlab=&quot;Systolische Bloeddruk (mm kwik).&quot;,breaks=seq(65,175,5),freq=FALSE,ylab=&quot;Densiteit&quot;,cex.main=1.5,cex.axis=1.5,cex.lab=1.5,main=&quot;&quot;) Figuur 2.4: Weergave van de verdeling voor de systolische bloeddruk van gezonde personen tussen 40-65 jaar geschat aan de hand van een histogram o.b.v. de geobserveerde steekproef in de NHANES studie. (Relatieve frequenties) De oppervlakte in elke balk komt dan overeen met een kans: hoogte van de balk x breedte van de balk. In de histogrammen hebben we voor de breedte van de balk 5 mm Hg gekozen. tab2&lt;-cbind(histAbs$mids,histAbs$density) tab2 ## [,1] [,2] ## [1,] 67.5 0.0000000000 ## [2,] 72.5 0.0000000000 ## [3,] 77.5 0.0000000000 ## [4,] 82.5 0.0007272727 ## [5,] 87.5 0.0014545455 ## [6,] 92.5 0.0043636364 ## [7,] 97.5 0.0065454545 ## [8,] 102.5 0.0160000000 ## [9,] 107.5 0.0254545455 ## [10,] 112.5 0.0240000000 ## [11,] 117.5 0.0298181818 ## [12,] 122.5 0.0261818182 ## [13,] 127.5 0.0254545455 ## [14,] 132.5 0.0123636364 ## [15,] 137.5 0.0094545455 ## [16,] 142.5 0.0087272727 ## [17,] 147.5 0.0058181818 ## [18,] 152.5 0.0021818182 ## [19,] 157.5 0.0007272727 ## [20,] 162.5 0.0000000000 ## [21,] 167.5 0.0000000000 ## [22,] 172.5 0.0007272727 tab2[tab2[,1]==117.5,2] ## [1] 0.02981818 tab2[tab2[,1]==117.5,2] * 5 ## [1] 0.1490909 We bekomen opnieuw een schatting van 14.9%. We geven dat weer in een figuur, waarbij we de functie rect() gebruiken om de rechthoekige balk te tekenen. A.d.h.v. de functie text() kunnen we ook tekst toevoegen aan de figuur. hist(nhanesSubHealthy$bpSys,xlab=&quot;Systolische Bloeddruk (mm kwik).&quot;,breaks=seq(65,175,5),freq=FALSE,ylab=&quot;Densiteit&quot;,cex.main=1.5,cex.axis=1.5,cex.lab=1.5,main=&quot;&quot;) rect(115,0,120, tab2[tab2[,1]==117.5,2],col=2) text(120,tab2[tab2[,1]==117.5,2],paste0(&quot;P(115 &lt; X &lt; 120) = &quot;,round(tab2[tab2[,1]==117.5,2] * 5 * 100, 1),&quot;%&quot;),col=2,cex=1,pos=4) Figuur 2.5: Weergave van de verdeling voor de systolische bloeddruk van gezonde personen tussen 40-65 jaar geschat aan de hand van een histogram o.b.v. de geobserveerde steekproef in de NHANES studie. (Het histogram wordt weergegeven a.d.h.v. relatieve frequenties en de geschatte kans op een bloeddruk tussen 115-120 wordt aangeduid in het rood) Als we de som van de oppervlakte van alle balken zouden berekenen is die uiteraard gelijk aan 1. De kans om een random persoon uit de steekproef aan te treffen tussen de laagste en hoogste waarde in de steekproef dient immers gelijk te zijn aan 1 of 100%! Het histogram geeft verder weer dat de verdeling inderdaad vrij symmetrisch blijkt te zijn en een klokvorm lijkt te hebben. Als we kunnen veronderstellen dat de gegevens normaal verdeeld zijn dan kunnen we de verdeling in de populatie ook schatten door enkel het gemiddelde \\(\\mu\\) en de variantie \\(\\sigma^2\\) te schatten en de parameterschattingen in te pluggen in de Normale verdeling. hist(nhanesSubHealthy$bpSys,xlab=&quot;Systolische Bloeddruk (mm kwik).&quot;,breaks=seq(65,175,5),freq=FALSE,ylab=&quot;Densiteit&quot;,cex.main=1.5,cex.axis=1.5,cex.lab=1.5,main=&quot;&quot;) lines(grid,dnorm(grid,mean=mean(nhanesSubHealthy$bpSys),sd=sd(nhanesSubHealthy$bpSys)),xlab=&quot;Systolische Bloeddruk (mm kwik)&quot;,ylab=&quot;Densiteit&quot;,type=&quot;l&quot;,lwd=2) Figuur 2.6: Weergave van de verdeling voor de systolische bloeddruk van gezonde personen tussen 40-65 jaar geschat aan de hand van een histogram o.b.v. de geobserveerde steekproef in de NHANES studie en a.d.h.v. een normale verdeling met geschat gemiddelde 120.4 mm Hg en geschatte variantie 129.8 (zwarte volle lijn) In plaats van kansen te berekenen door gebruik te maken van het histogram, bestaat een alternatieve methode erin om het gemiddelde en de variantie te schatten op basis van de steekproef. Vervolgens wordt dan de kans berekend a.d.h.v. een normale verdeling waarbij we als gemiddelde en variantie de overeenkomstige schattingen in de steekproef gebruiken. We illustreren dit in R. De normale verdeling in R wordt geparameteriseerd a.d.h.v. het gemiddelde \\(\\mu\\) en de standaard afwijking \\(\\sigma\\). Deze laatste kan direct worden geschat a.d.h.v. de steekproef door gebruik te maken van de steekproef standaard deviatie (functie sd()). De kans die we dan bekomen is xBar &lt;- mean(nhanesSubHealthy$bpSys) sBar &lt;- sd(nhanesSubHealthy$bpSys) pnorm(120,mean=xBar,sd=sBar)-pnorm(115,mean=xBar,sd=sBar) ## [1] 0.1397006 Merk op dat deze schatting veel dichter ligt bij de werkelijke kans in de populatie dan de schatting die we bekwamen d.m.v. het histogram. De schatting o.b.v. de normale verdeling is inderdaad nauwkeuriger: we kunnen immers gebruik maken van alle data om deze kans te schatten gezien we het steekproefgemiddelde en de steekproefstandaarddeviatie hebben geschat o.b.v. alle gegevens in de steekproef. Voor de kans berekend o.b.v. het histogram konden we daarentegen enkel de gegevens gebruiken van de personen uit de steekproef met een bloeddruk tussen 115 en 120 mmHg. Uiteraard zal het in de praktijk steeds heel belangrijk zijn om na te gaan of er voldaan is aan de aannames die we maken over de verdeling. Anders zijn onze schattingen immers incorrect en niet bruikbaar. Het nagaan van veronderstellingen over de verdeling is één van de doelstellingen van data exploratie. We kunnen nu op basis van de steekproef en de aannames van normaliteit een grenswaarde voor de bloeddruk afleiden die extreem is voor “gezonde” personen in de populatie. Dat laat ons bijvoorbeeld toe om een bloeddruk te bepalen die maar met een kans van 5% wordt overschreden in de populatie van gezonde subjecten: \\[P(X &gt; t_\\text{drempel}) = 5\\%\\] of \\[P(X \\leq t_\\text{drempel}) = 95\\%\\] Dat kan met de functie qnorm() in R. qnorm(0.95,mean=xBar,sd=sBar) ## [1] 142.6011 Deze waarde ligt dicht bij 140 mmg Hg, een grenswaarde voor hypertensie die vaak in de literatuur wordt gebruikt. 2.7 Statistieken Formules die gebruikt worden om parameters van de verdeling in de populatie te schatten op basis van de steekproef, alsook het numerieke resultaat dat men bekomt door deze formules te evalueren, worden statistieken genoemd. Bijvoorbeeld het rekenkundig gemiddelde van alle systolische bloeddrukwaarden voor de verschillende subjecten in de steekproef, is een statistiek. Statistieken zijn dus wat de onderzoekers observeren of kunnen berekenen o.b.v. de gegevens in de steekproef; parameters zijn wat ze eigenlijk willen weten. Omdat statistieken berekend worden op basis van de gegevens uit de steekproef, zullen ze variëren van steekproef tot steekproef. We zullen ze daarom noteren met een hoofdletter (bvb. \\(\\bar X\\) voor het steekproefgemiddelde), tenzij we verwijzen naar de numerieke waarde die gerealiseerd wordt in een bepaalde steekproef, in welk geval we een kleine letter gebruiken (bvb. \\(\\bar x\\) voor het steekproefgemiddelde). Belangrijke Conventie: In de cursus gebruiken we de conventie om populatieparameters die een vaste waarden aannemen maar die meestal ongekend zijn voor te stellen door Griekse symbolen. Statistieken waarmee we deze ongekende parameters schatten o.b.v. een steekproef zullen we weergeven door letters. Voor de normaal verdeling hebben we dus: Populatie Steekproef \\(\\mu\\) \\(\\bar X\\) \\(\\sigma^2\\) \\(S^2\\) Om hetgeen we in de steekproef observeren te kunnen veralgemenen naar de populatie, zullen we gebruik moeten maken van methodes uit de statistische besluitvorming wat in latere hoofdstukken aan bod komt. De cursus is als volgt georganiseerd: In hoofdstuk 3 verdiepen we ons in studiedesign. Vervolgens gaan we in op data-exploratie in hoofdstuk 4, hierbij zullen we de gegevens in een steekproef grondig exploreren zodoende inzicht te verwerven in de data en hoe we ze statistisch kunnen modelleren. In hoofdstuk 5 introduceren we de grondslagen van statistische besluitvorming die het ons mogelijk maakt om effecten die we observeren in de steekproef te kunnen veralgemenen naar de populatie toe. In hoofdstukken 6-10 zullen we meer geavanceerde statistische modellen en methoden introduceren om data te modelleren en voor statistische besluitvorming. B.v. omdat het ook toekomstige subjecten omvat↩ "],
["chap-design.html", "Hoofdstuk 3 Studiedesign 3.1 Inleiding 3.2 Steekproefdesigns 3.3 Experimentele studies 3.4 Observationele studies 3.5 Prospectieve studies 3.6 Retrospectieve studies 3.7 Niet-gecontroleerde studies", " Hoofdstuk 3 Studiedesign 3.1 Inleiding Centraal in wetenschappelijk onderzoek is de wens en noodzaak om theorie-gebaseerde kennis empirisch (d.w.z. door middel van observatie) te verifiëren en op te bouwen. Terwijl theorie-gebaseerde kennis voortvloeit uit hypothesen omtrent het bestudeerde biologische of chemische proces, ontstaat empirische kennis door lukraak subjecten (mensen, planten, dieren) uit een doelpopulatie te trekken volgens een gestructureerd schema en hen vervolgens te observeren. Dit gestructureerde schema, dat ondermeer vastlegt welke en hoeveel subjecten in de studie worden opgenomen en eventueel wie welke experimentele interventie zal ondergaan, noemt men het design van de studie of de proefopzet. Met een goed design kunnen betrouwbare conclusies worden getrokken op basis van de gegevens. Het bepaalt immers welke informatie wel en niet in de dataset vervat zal zijn. Fouten bij het design van een studie kunnen soms gecorrigeerd worden door de statistische analyse, maar zijn helaas vaak onherroepelijk. Het design is daarom van cruciaal belang voor een studie en vereist evenveel aandacht als de uiteindelijke statistische analyse van de observaties. Ook in deze cursus vormen de concepten in dit hoofdstuk rond design wellicht het meest belangrijke onderwerp, hoewel we er slechts beknopt op in kunnen gaan. De ideeën lijken eenvoudig, maar dat is vaak een bedrieglijke indruk! Figuur 3.1: Verschillende stappen in een studie. In dit hoofdstuk ligt de focus op proefopzet. 3.2 Steekproefdesigns In de praktijk vestigt men de interesse van een onderzoek op een bepaalde biologische populatie. Vervolgens zal men een geschikt type en grootte van monsters of stalen (of meer algemeen experimentele eenheden en/of subjecten genoemd doorheen deze cursus) definiëren waarvoor men metingen zal verzamelen. Bijvoorbeeld, indien men de grootte van de populatie salamanders van de species Plethodon jordani wenst te bestuderen, kan men de aandacht van het onderzoek vestigen op de bestaande populatie P. jordani in de Great Smoky Mountains (d.i. de populatie) en vervolgens het aantal salamanders tellen op oppervlakte-eenheden van 10 m\\(^2\\) (die eenheden zijn de stalen of “experimentele eenheden”; voor elke experimentele eenheid bekomt men aldus een meting). Indien men de impact van roofvissen op zeebodemhabitats wenst te evalueren, dan kan het onderzoek de aandacht vestigen op de zeebodem binnen een afstand van 500 m voor de Belgische Noordzeekust (d.i. de biologische populatie) en kunnen vervolgens metingen worden verzameld op stukjes zeebodem met een straal van 1 m (d.i. de “stalen” in de studie). Omdat het in de praktijk bijna nooit mogelijk is om de hele populatie te onderzoeken (alle salamanders in de Great Smoky Mountains, de ganse zeebodem binnen een afstand van 500 m voor de Belgische Noordzeekust), zal men zich beperken tot gegevens voor een zogenaamde steekproef, een beperkte verzameling stalen, experimentele eenheden of subjecten uit de populatie. Welke subjecten uit de populatie men precies zal bestuderen, zal uiteraard zijn weerslag hebben op de resultaten van de uiteindelijke analyse van de gegevens. Opdat de resultaten die men observeert voor de steekproef veralgemeenbaar zouden zijn naar de ganse studiepopulatie, is het noodzakelijk dat men de subjecten uit de steekproef zodanig kiest dat ze representatief zijn voor de populatie. De basismethode om dat te realiseren, heet eenvoudige lukrake steekproeftrekking (in het Engels: simple random sampling). Ze bestaat erin te garanderen dat elk subject in de populatie een zelfde kans heeft om in de steekproef terecht te komen. Zo kan men bijvoorbeeld elke muis in een kooi een nummer geven en vervolgens lukraak een aantal \\(n\\) van die nummers trekken. In de praktijk, en in het bijzonder in de veldbiologie, is die methode echter vaak moeilijk toe te passen omdat de subjecten in de populatie bijvoorbeeld geen goed onderscheiden habitats vormen, niet op voorhand genummerd kunnen worden of omdat de populatie een te groot gebied bestrijkt. Zo is het bijvoorbeeld niet makkelijk om een eenvoudige lukrake steekproef van salamanders in de Great Smoky Mountains te bekomen omdat het bestudeerde gebied zeer groot is en de salamanders uiteraard niet genummerd kunnen worden. In die gevallen gaan biologen vaak over op haphazard sampling, waarbij men op een minder formele manier stalen verzamelt, maar er toch voor probeert te zorgen dat de resultaten niet vertekend worden doordat bepaalde subjecten meer kans hebben om in de steekproef terecht te komen. Bijvoorbeeld kan men een computer lukraak plaatsen laten aanduiden in de Great Smoky Mountains en kan men vervolgens metingen proberen te verzamelen voor de eerste salamander die telkens in de buurt van de aangeduide plaatsen voorbijkomt. Sommige steekproefdesigns houden expliciet rekening met heterogeniteit in de populatie waaruit een steekproef wordt genomen. Bij gestratificeerde lukrake steekproeven (in het Engels: stratified random samples) wordt de populatie opgedeeld in verschillende strata, die goed onderscheiden subgroepen in de populatie identificeren, en worden vervolgens eenvoudige lukrake steekproeven uit elk stratum genomen. Stel bijvoorbeeld dat men karakteristieken van stenen in een rivier wenst te beschrijven en dat stenen in verschillende habitats voorkomen (rotsige, ondiepe waters, diepe waters, stille binnenwaters,…), dan kan het zinvol zijn om een gestratificeerde lukrake steekproef te nemen om ervoor te zorgen dat er binnen elk stratum (d.i. elke habitat) een voldoende aantal stenen verzameld worden. Bij geclusterde steekproeftrekking (in het Engels: cluster sampling) worden clusters van meer verwante subjecten uit de populatie getrokken. Stel bijvoorbeeld dat we de impact van verschillende vormen van beschadiging aan bladeren van een boom wensen te meten, dan kunnen we in een eerste fase een eenvoudige lukrake steekproef van bomen bepalen. Vervolgens kunnen we in een tweede fase binnen elke boom een eenvoudige lukrake steekproef van bladeren bepalen en de verschillende gekozen bladeren aan verschillende vormen van beschadiging onderwerpen. Dit noemt men (two stage) cluster sampling omdat bladeren afkomstig van een zelfde boom meer verwant en bijgevolg geclusterd zijn. We zullen later zien dat men in de analyse van gegevens uit dergelijke studie met die clustering rekening moet houden. Tenslotte steunt men in de biologische wetenschappen ook vaak op systematische steekproeven waarbij men bijvoorbeeld monsters neemt die op vaste afstand van elkaar bekomen worden of op voorafgekozen tijdstippen, en om die reden niet volledig lukraak genoemd kunnen worden. Dit wordt vaak gebruikt wanneer men een omgevings- of tijdsgradiënt wenst te beschrijven voor een bepaald proces, zoals de wijziging in rijkdom aan species naarmate men zich verwijdert van een vervuilingsbron. Dergelijke designs zijn nuttig en logistiek zeer praktisch, maar kunnen vertekende resultaten opleveren wanneer de monsters op specifieke plaatsen genomen worden die samenvallen met een ongekende omgevings- of tijdsgradiënt (d.i. indien de gekozen plaatsen selectief zijn en afwijkend van de globale omgevings- of tijdsgradiënt). 3.2.1 Replicatie Replicatie betekent dat herhaaldelijke observaties worden bekomen, op verschillende plaatsen, voor verschillende dieren of planten, op verschillende tijdstippen, … Dergelijke herhalingen zijn essentieel in empirisch onderzoek omdat biologische en ecologische systemen vaak zeer variabel zijn en de beschikbaarheid van meerdere observaties toelaat om ruis op de gegevens te drukken. Hoewel biologen, biotechnologen en biochemici zich goed bewust zijn van de nood voor replicatie wordt vaak misbegrepen op welke schaal die herhalingen moeten bekomen worden. Wellicht is er geen enkel aspect van studiedesign dat meer verwarring veroorzaakt bij wetenschappers dan dit. Stel bijvoorbeeld dat men een studie wenst op te zetten om het effect van bosbranden op de rijkdom aan ongewervelde dieren te onderzoeken. Meestal zal men dan gebruik maken van natuurlijke bosbranden. Stel dat 1 verbrand gebied gelocaliseerd wordt en vergeleken wordt met een naburig gebied waar geen bosbrand plaatsvond. Stel verder dat men binnen elk gebied verschillende stalen bodemkorst neemt om de rijkdom aan ongewervelden te bepalen. Dan beschikt men wel over herhaaldelijke metingen (namelijk verschillende stukken bodemkorst per gebied), maar niet op de juiste schaal. De metingen voor de rijkdom aan species die men uit het verbrande gebied bekomen heeft, meten immers de impact van dezelfde brand. Als gevolg daarvan kan men op basis van eventuele verschillen in species rijkdom tussen beide gebieden niet bepalen of ze het gevolg zijn van de brand dan wel van andere verschillen tussen beide gebieden die eveneens een impact op ongewervelden hebben. Uit dergelijke vergelijking kan men hoogstens besluiten dat de gebieden al dan niet verschillen, maar niet waardoor ze verschillen. De herhaalde stukken bodemkorst in bovenstaand voorbeeld stellen substeekproeven voor. Deze stellen geen herhalingen voor van de bestudeerde interventie (bosbranden) en worden daarom pseudoreplicaties genoemd. Pseudoreplicaties zijn nuttig omdat ze replicaties zijn (op een zeker niveau) en daardoor toelaten om een deel van de ruis op de gegevens weg te middelen. In sommige studies zijn echte replicaties onmogelijk en is het bijgevolg onvermijdelijk om zijn toevlucht tot pseudoreplicaties te nemen. Bijvoorbeeld, indien men een experiment uitvoert dat kamers van constante temperatuur vereist, dan kan het best zijn dat er binnen een gegeven instituut slechts een tweetal dergelijke kamers beschikbaar zijn omwille van hun hoge kost. Indien men bijvoorbeeld de impact wenst te onderzoeken van rioollozing op de biomassa van phytoplankton in een bepaalde kuststreek, dan is er vaak maar 1 riool waarin men echt geïnteresseerd is, terwijl het aantal naburige lokaties zonder riool zeer uitgebreid kan zijn. In dat geval zal men vaak stalen nemen op meerdere plaatsen zonder riool om in ieder geval de variatie tussen controlesites (d.i. sites zonder rioollozing) te minimaliseren. Before-After-Control-Impact (BACI) designs proberen verder informatie te winnen door zowel metingen te nemen vóór de interventie (bvb. het plaatsen van een riool) als na de interventie. 3.3 Experimentele studies Studiedesigns worden opgesplits in experimentele studies of experimenten waar de onderzoeker eerst het biologische systeem manipuleert en vervolgens observeert, en observationele studies waar de onderzoeker enkel observeert zonder zelf in het systeem in te grijpen. In deze sectie gaan we dieper in op het eerste type studies. Observationele studies worden besproken in Sectie 3.4. Definitie 3.1 (experiment) Een experiment is een reeks observaties die gemaakt worden onder condities die gecontroleerd worden door de onderzoeker. De onderzoeker controleert hierbij verschillende factoren (zoals de keuze van de interventie voor een locatie, plant, dier), met als doel een zuiver antwoord op de gestelde onderzoeksvraag te bepalen.5 Bijvoorbeeld, wanneer een dierenfysioloog 2 behandelingen wenst te vergelijken tussen experimentele dieren, dan kan hij - zoals we in dit hoofdstuk zullen zien - vermijden dat het behandelingseffect vertekend6 is door vergelijkbare groepen dieren te creëren; bijvoorbeeld, door lukraak (bijvoorbeeld door het opgooien van een muntstuk) te bepalen welke behandeling aan welk dier wordt toegediend. 3.3.1 De Salk Vaccin Veldstudie Om de basisprincipes van experimentele designs in te voeren, gebruiken we als rode draad de Salk Vaccin Veldstudie. Vooraleer dieper op deze studie in te gaan, schetsen we de historische context. De eerste polio-epidemie in de Verenigde Staten brak uit in 1916 en kostte aan honderdduizenden mensen, vooral kinderen, het leven. Tegen de jaren 1950 waren er verschillende vaccins ontwikkeld. Vooral het vaccin dat door John Salk werd ontwikkeld, leek veelbelovend omdat het zich veilig en effectief had getoond in laboratoriumstudies. In 1954 werd door de National Foundation for Infantile Paralysis (NFIP) een grote studie opgezet om de effectiviteit van het vaccin buiten het laboratorium na te gaan. Meer concreet wenstte men na te gaan wat de invloed was van vaccinatie op de polio-incidentie. Definitie 3.2 (incidentie en prevalentie) De incidentie van een bepaalde ziekte of aandoening (bvb. polio) wordt gedefinieerd als het verwachte aantal nieuwe gevallen van die ziekte dat optreedt gedurende een vooraf bepaald tijdsinterval, uitgedrukt per eenheid van een ziektevrije populatie. Het drukt m.a.w. de kans uit dat een individu zonder de bestudeerde aandoening tijdens het gegeven tijdsinterval deze aandoening zal opdoen. De prevalentie van een bepaalde ziekte wordt gedefinieerd als de proportie individuen met de ziekte in een bepaalde populatie op een bepaald punt in de tijd. Einde definitie Stel dat de NFIP het vaccin gewoon had toegediend aan een groot aantal kinderen en dat ze een daling observeerden in de incidentie van polio van 1953 naar 1954. Dit betekent dat de kans dat een lukraak polio-vrij kind een polio-infectie opdeed in de loop van 1954 (d.i. de incidentie van polio in 1954), lager is dan de kans dat lukraak polio-vrij kind een polio-infectie opdoet in de loop van 1953 (d.i. de incidentie van polio in 1953). In dat geval kan men niet zomaar besluiten dat het vaccin effectief is. Immers, afgezien van de introductie van een vaccin, varieert de incidentie van polio van jaar tot jaar. Zo zou men, indien het vaccin niet effectief was, toch een daling in polio-incidentie van 1953 naar 1954 kunnen vaststellen in geval 1954 geen epidemisch jaar zou zijn. De enige manier om te ontdekken of het vaccin effectief is, is om gelijktijdig de incidentie van polio in 1954 te vergelijken tussen een groep gevaccineerde kinderen (doorgaans cases genoemd) en een groep niet-gevaccineerde kinderen (doorgaans controles genoemd). Dit is wat de NFIP heeft gedaan. De deelnemers aan de studie waren kinderen uit de leeftijdsgroepen die het meest vatbaar waren voor polio. De studie verliep in verschillende schooldistricten in de Verenigde Staten waar het risico op polio hoog was. Aan ongeveer 350000 kinderen uit de tweede graad werd vaccinatie voorgeschreven. Voor 125000 van hen weigerden de ouders toestemming te geven om deze vaccinatie te laten doorgaan, zodat de groep cases uiteindelijk uit de overige 225000 kinderen bestond. Ongeveer 750000 kinderen uit de eerste en derde graad werden vrijwillig niet gevaccineerd; zij vormden de controles. Het feit dat de groep cases en de groep controles een verschillende grootte hebben is niet problematisch zolang men niet het absolute aantal, maar het percentage polio-besmettingen tussen beide groepen vergelijkt. Toch hoeft een geobserveerd verschil in incidentie tussen gevaccineerde en niet-gevaccineerde kinderen nog steeds niet noodzakelijk te impliceren dat het vaccin effectief is. Hier zijn verschillende redenen voor: Ten eerste zou het kunnen dat men door toeval een verschil in incidentie waarneemt tussen beide groepen, doordat er per toeval bijvoorbeeld relatief gezien minder kinderen in de gevaccineerde groep polio ontwikkelen. In Hoofdstuk 5 zullen we methoden aanleren om uit te maken of een geobserveerd vaccinatie-effect (d.w.z. een vaccinatie-effect dat geschat of berekend werd o.b.v. de gegevens) al dan niet toevallig is. Ten tweede zou het kunnen dat kinderen uit de tweede graad sowieso meer vatbaar zijn voor polio en er, afgezien van het werkelijke vaccin-effect, voor de cases dus een hogere incidentie wordt verwacht. Ten derde is het zo dat vooral ouders uit hoge-inkomens gezinnen geneigd waren om de toestemming te geven hun kind te laten vaccineren, zodat de groep cases hoofdzakelijk bestaat uit kinderen van hoge-inkomens gezinnen. Deze kinderen zijn meer vatbaar voor polio omdat ze, wegens de betere hygiënische omstandigheden in deze gezinnen, minder antilichamen tegen polio ontwikkeld hebben. Het geobserveerde verschil in incidentie tussen gevaccineerde en niet-gevaccineerde kinderen weerspiegelt daarom niet alleen de effectiviteit van het vaccin, maar ook het feit dat kinderen uit graad 2 mogelijks niet vergelijkbaar zijn met de resterende kinderen en het feit dat cases, omwille van betere hygiënische omstandigheden, meer vatbaar zijn voor polio dan controles. In het bijzonder is het om die reden mogelijk om, zelfs als het vaccin effectief is, een gelijke incidentie voor cases en controles vast te stellen. In dat geval verwart men het effect van het vaccin met het feit dat cases meer vatbaar zijn voor polio dan controles. De statistische les die we hier algemeen uit kunnen trekken, is dat de verschillende interventiegroepen zo vergelijkbaar mogelijk moeten zijn bij de bepaling van het effect van een interventie, opdat elk verschil in respons tussen de groepen volledig kan toegeschreven worden aan de verschillende interventie. Wanneer de groepen cases en controles niet volledig vergelijkbaar zijn in een bepaalde factor (zoals de vatbaarheid voor polio, maar niet de interventie zelf), dan is het mogelijk dat het effect van die factor verward (in het Engels: confounded) wordt met het effect van de interventie. Men noemt die factor dan een confounder voor het effect van de interventie. De belangrijkste beperking op de ondubbelzinnige interpretatie van studieresultaten is het probleem van confounding. Voorbeeld 3.1 (De nood aan controle) Hairston (1980) bestudeerde de stelling dat 2 soorten salamander (P. jordani en P. glutinosus) in de Great Smoky Mountains mekaar rivaliseren. Hij zette daartoe experimenten op waarbij P. glutinosus verwijderd werd van bepaalde territoria. De populatie van P. jordani begon toe te nemen in de 3 jaren die volgden op de verwijdering van de salamanders, maar nam al even sterk toe op controleterritoria waar P. glutinosus niet verwijderd was. Had Hairston geen controleterritoria onderzocht, dan had hij mogelijks de toename in de populatie van P. jordani verkeerdelijk toegeschreven aan het verwijderen van P. glutinosus. **Einde voorbeeld** Definitie 3.3 (confounding en confounder) Confounding is het probleem dat verschillen ten gevolge van verschillende experimentele interventies niet kunnen losgekoppeld worden van andere factoren, confounders genoemd, die verschillen tussen de interventiegroepen. Een confounder manifesteert zich als een variabele die geassocieerd is met de blootstelling of interventie (bvb. gevaccineerd of niet) en de uitkomst (bvb. polio-geïnfecteerd of niet), maar die door geen van beiden zelf beïnvloed wordt. Bijvoorbeeld, vatbaarheid voor polio is geassocieerd met de keuze van de ouders om hun kind te laten vaccineren (d.i. de blootstelling) alsook met de infectiestatus van het kind (d.i. de uitkomst), maar wordt door geen van beiden zelf veroorzaakt. Confounders verstoren de associatie tussen blootstelling en uitkomst zodat de geobserveerde associatie tussen beiden mogelijks niet het pure effect (d.i. het causale effect) van die blootstelling op die uitkomst uitdrukt. Einde definitie Voorbeeld 3.2 (Confounding in mariene veldexperimenten) Om het effect te onderzoeken van roofvissen op mariene zeebodemhabitats zou men gebieden met en zonder viskooien kunnen vergelijken. Als men vervolgens verschillen observeert tussen beide types gebieden, dan kan dat het gevolg zijn van het verwijderen van roofvissen (via de kooien), maar eveneens van de aanwezigheid van kooien (bijvoorbeeld, door schaduw die de kooi afwerpt, door de afgenomen waterstroming, …). Het effect van roofvissen verwijderen wordt dus mogelijks verward met het effect van kooien plaatsen. De aanwezigheid van kooien manifesteert zich hier dus als een confounder. Om dergelijke confounding te vermijden, kan men controlekooien met grote gaten plaatsen waar de vis vrij in en uit kan zwemmen, maar die voor de rest vergelijkbaar zijn met de experimentele kooien. In dat geval zijn beide studiegebieden van kooien voorzien en zal een vergelijking van experimentele en controlekooien duidelijk een veel meer betrouwbare evaluatie toelaten van het effect van roofvissen. Toch blijft dergelijke vergelijking niet gegarandeerd vrij van confounding. Bijvoorbeeld, als het effect van kooien plaatsen er voornamelijk in bestaat om de stroming van water (en bijgevolg sedimentatie) te beïnvloeden, dan speelt de vraag of de stroming van water ook niet beïnvloed wordt door het feit dat vissen, omwille van de grote gaten, makkelijker in controlekooien zwemmen dan in experimentele kooien. **Einde voorbeeld** Heel wat experten in volksgezondheid zagen de problemen met het NFIP design en suggereerden dat de controles uit dezelfde populatie moesten gekozen worden als de cases (d.w.z. dat ze moesten vergelijkbaar zijn). Vergelijkbaarheid van beide groepen garanderen, zou kunnen gebeuren op basis van menselijk oordeel. Ervaring heeft niettemin aangetoond dat dit vaak niet succesvol is omdat het zich makkelijk leent tot het bewust of onbewust bevoordelen van de ene groep versus de andere. Het is daarom aangewezen om randomisatieprocedures toe te passen, waarbij de toewijzing van mensen aan verschillende interventie-armen volledig lukraak gebeurt. Men zegt in dat geval dat de studie gerandomiseerd gecontroleerd(in het Engels: randomized controlled) is. Definitie 3.4 (gerandomiseerde studie) Een gerandomiseerd gecontroleerde studie is een experiment waarbij de toewijzing van subjecten aan de verschillende interventie-armen volledig lukraak gebeurt zodat de toewijzing van een gegeven subject onmogelijk op voorhand voorspeld kan worden. Als gevolg hiervan zijn de verschillende interventiegroepen (in principe7) in alle gekende en ongekende factoren (zoals leeftijd, lichaamsgewicht, vatbaarheid voor polio …) vergelijkbaar zodat geobserveerde verschillen in uitkomst tussen de verschillende groepen (in principe) kunnen toegeschreven worden aan de interventie (d.i. het vaccin). Einde definitie Naast de NFIP studie werd voor het Salk vaccin een gerandomiseerd gecontroleerde studie opgezet waarbij de beslissing om aan een gegeven kind al dan niet het vaccin toe te dienen, gemaakt werd door het opgooien van een muntstuk. De randomisatie werd uitgevoerd onder kinderen die van hun ouders de toestemming kregen om zich te laten vaccineren, indien ze aan de vaccin-groep zouden toegewezen worden. Door de randomisatie pas uit te voeren na het krijgen van de toestemming tot vaccinatie, kon men vermijden dat er differentiële uitval was van kinderen in beide groepen. Met differentiële uitval wordt bedoeld dat de reden om niet deel te nemen aan de studie verschillend is voor de test-en controlegroep. Dit kan vooral voorkomen in klinische studies (d.i. experimenten bij mensen) wanneer 1 van beide behandelingen (in de test- of controle-arm) een zware heelkundige ingreep is die vooral door ernstig zieke mensen gemeden wordt. Wanneer er na randomisatie differentiële uitval optreedt, dan kan men niet langer vergelijkbare groepen garanderen. In de gerandomiseerde Salk vaccin studie werd aan kinderen in de controle-groep een placebo toegediend. Dat is een inerte, inactieve behandeling; in dit geval een injectie van zout opgelost in water. Tijdens de studie waren de kinderen blind voor de behandelingscode (d.i. ze wisten niet aan welke interventiegroep ze toegewezen waren). Dit heeft tot gevolg dat hun respons op de vaccinatie (d.i. of ze al dan niet polio ontwikkelen) het gevolg was van het al dan niet krijgen van het vaccin, en niet van het `idee’ om al dan niet behandeld te zijn. In deze studie lijkt het misschien onwaarschijnlijk dat het idee om gevaccineerd te zijn de kinderen zou kunnen beschermen tegen polio, maar de rol van het onderbewustzijn is soms sterker dan vermoed wordt. Zo heeft men in een studie van patiënten met ernstige post-operatieve pijn vastgesteld dat de pijn bij een derde van de patiënten spontaan verdween na inname van een volledig neutrale substantie! Het blinderen van de toegediende interventie laat algemeen toe om een zo objectief mogelijk beeld van het interventie-effect te verkrijgen. Analoog gebruiken fysiologen in dierenexperimenten injectie met een zoutoplossing als controle i.p.v. geen injectie. Op die manier vermijden ze dat verschillen die men observeert tussen controledieren en dieren die een toxische substantie ingespoten krijgen, niet het gevolg zijn van de injectieprocedure (bijvoorbeeld, van wondjes ten gevolge van de inspuiting), maar van de ingespoten substantie zelf. Een verdere voorzorgsmaatregel in de Salk vaccin studie was dat ook de dokters, die moesten vaststellen of de kinderen geïnfecteerd waren, blind waren voor de behandeling. Op die manier voorkwam men dat de arts bewust of onbewust kennis omtrent de gekregen vaccinatie zou gebruiken om een beslissing te nemen over de infectiestatus. Dit zou kunnen voorvallen wanneer het resultaat van de polio-test dubieus was en de arts (bewust of onbewust) kennis omtrent de vaccinatie-status van zijn patiënt gebruikt om de infectie-status te bepalen. Om dezelfde reden zijn ook dierenfysiologen idealiter blind voor de substantie die bij elke rat ingespoten werd. Omdat noch de arts, noch de patiënt in de Salk vaccin studie wisten welke behandeling werd toegediend, wordt deze studie dubbel blind genoemd. Dubbel blinde studies vereisen dat de verschillende interventies er hetzelfde uitzien. Tabel 3.1: De NFIP studie: aantal kinderen en incidentie (uitgedrukt per 100000 kinderen per jaar). Aantal Incidentie Vaccin 225000 25 Controle 725000 54 Geen toestemming 125000 44 Tabellen 3.1 en 3.2 geven de resultaten weer die geobserveerd werden in de NFIP studie en het dubbel blinde gerandomiseerd gecontroleerde (in het Engels: double blind randomized controlled) experiment. Op basis van Tabel 3.2 stellen we vast dat de incidentie daalt van 71 tot 28 gevallen per 100000 per jaar als gevolg van toediening van het vaccin. De enige vraag die resteert is of dergelijk verschil in incidentie gewoon door toeval kan ontstaan wanneer in werkelijkheid het vaccin geen effect zou hebben. Een gevorderde statistische analyse heeft aangetoond dat het bijna onmogelijk is om dergelijk verschil in incidentie te observeren door toeval, wanneer het vaccin geen effect heeft. We mogen dus besluiten dat het Salk vaccin effectief is. Merk tenslotte op dat er inderdaad confounding optreedt in de NFIP studie. Immers de polio-incidentie lijkt er veel minder te dalen dan in de gerandomiseerde studie, namelijk van 54 naar 25 per 100000 per jaar als gevolg van het vaccin (zie Tabel 3.1). De oorzaak is dat de controlegroep in deze studie kinderen bevat die minder vatbaar zijn voor polio dan de vaccin-groep. Tabel 3.2: De gerandomiseerd gecontroleerde studie: aantal kinderen en incidentie (uitgedrukt per 100000 kinderen per jaar). Aantal Incidentie Vaccin 200000 28 Controle 200000 71 Geen toestemming 350000 46 3.3.2 Gerandomiseerd gecontroleerde studies Bij randomisatie heeft elk subject in de studie (bijvoorbeeld, elk kind in de Salk vaccin studie, elke studieplaats op de zeebodem waar men een kooi wil plaatsen) een gekende kans om elke interventie te krijgen (bvb. bij het opgooien van een muntje heeft men 50% kans om het vaccin te krijgen en 50% kans om het placebo te krijgen), maar de te ontvangen behandeling kan niet voorspeld worden. Vreemd genoeg wordt de nood aan randomisatie niet steeds ingezien en maakt men vaak verkeerdelijk geen onderscheid met systematische allocatie. Definitie 3.5 (systematische allocatie) Systematische allocatie of louter toevallige allocatie (in het Engels: haphazard allocation) is een toewijzingsmethode die mogelijks op een lukraak mechanisme lijkt, maar waarbij men de toewijzing van (sommige) subjecten op voorhand kan voorspellen. Een typisch voorbeeld van een systematische toewijzingsmethode is er één waarbij subjecten afgewisseld toegewezen worden aan de controle- of interventiegroep. Het feit dat men hier de toewijzing van elk subject op voorhand kan voorspellen, kan tot gevolg hebben dat de onderzoeker de toewijzing manipuleert. In medisch onderzoek is het in het verleden zo meermaals gebeurd dat artsen de al te zieke patiënten die in principe aan de controle arm zouden moeten toegewezen worden, later op bezoek laten komen (zodat ze de testbehandeling krijgen) of niet in de studie opnemen. Dit kan er op zijn beurt voor zorgen dat de verschillende groepen niet langer vergelijkbaar zijn. Om systematische allocatie te vermijden, is het van belang om een degelijke randomisatietechniek toe te passen. In de volgende paragrafen geven we een aantal mogelijkheden hiertoe. Bij eenvoudige randomisatie worden subjecten lukraak toegewezen aan interventie A of B door het opgooien van een muntje, dobbelsteen, … Vaak is het efficiënter om via de computer een randomisatielijst te genereren die het proces van het opgooien van een muntje nabootst. Dit vermijdt tevens de mogelijkheid dat de onderzoeker niet naar behoren zou randomiseren (door bvb. het muntje zolang op te gooien tot de gewenste interventiecode te zien is). Hoewel eenvoudige randomisatie aan iedereen evenveel kans geeft om behandeling A of B te krijgen, verzekert het niet dat beide groepen uiteindelijk even groot zullen zijn. Zelfs in relatief grote studies kan door toeval het verschil in aantal deelnemers in elke groep relatief groot zijn. Men kan aantonen dat, als gevolg hiervan, het interventie-effect doorgaans minder nauwkeurig of minder precies geschat kan worden op basis van de gegevens dan wanneer beide groepen even groot zouden zijn. Daarmee wordt bedoeld dat wanneer men de studie meermaals zou uitvoeren onder identieke omstandigheden, de resultaten doorgaans meer variabel zullen zijn van studie tot studie wanneer de relatieve grootte van beide groepen onbeperkt is, dan wanneer men telkens groepen van gelijke grootte eist. Om na randomisatie 2 behandelingsarmen van gelijke grootte te bekomen, kan gebalanceerde of beperkte randomisatie (in het Engels: balanced of restricted randomisation) worden gebruikt. Hierbij wordt de randomisatieprocedure zó georganiseerd dat gelijke aantallen subjecten worden toegewezen aan interventie A of B per blok van bijvoorbeeld 4 subjecten. Eén methode om dat te doen is om enkel sequenties te beschouwen van de vorm (1) AABB, (2) ABAB, (3) ABBA, (4) BABA, (5) BAAB, (6) BBAA. Met behulp van een dobbelsteen of randomisatielijst wordt lukraak een nummer van 1 tot 6 gekozen. Stel dat het 1 is. Dan worden de 2 eerstvolgende subjecten toegewezen aan A en de 2 daarna aan B. Vervolgens wordt een nieuw lukraak nummer tussen 1 en 6 getrokken, enzovoort… Gebalanceerde randomisatie met blokken van grootte 1 is equivalent aan eenvoudige randomisatie. Dergelijke blokgrootte is dus niet opportuun wanneer men groepen van gelijke grootte wenst te bekomen. Doorgaans is het niettemin zinvol om relatief kleine blokgroottes te beschouwen. Bovenstaande procedure garandeert immers dat, wanneer de studie halfweg een blok eindigt, het verschil in aantal subjecten tussen beide groepen hoogstens de helft van de gekozen blokgrootte bedraagt. Kleine blokken garanderen bijgevolg kleine verschillen in aantallen deelnemers per groep. Bij een echte randomisatie hoeven de blokken niet allen dezelfde grootte te hebben. Door de lengte van elk blok te variëren (bijvoorbeeld door een lukraak mechanisme) verloopt de reeks toewijzingen van subjecten aan interventie meer lukraak en voorkomt men dat de onderzoeker de blokgrootte ontdekt en als gevolg daarvan de interventiecode van sommige subjecten kan voorspellen. Immers, indien de onderzoeker de blokgrootte kent, dan kan hij net vóór het verstrijken van elk blok voorspellen wat de interventiecode is van het laatste subject. Gebalanceerde randomisatie voor blokken van verschillende grootte is niet veel moeilijker dan voor blokken van gelijke grootte. Voor het vergelijken van 2 interventies zou men bijvoorbeeld telkens eerst lukraak kunnen kiezen uit een blokgrootte van 2, 4 of 6 en vervolgens, zoals voorheen, lukraak een blok van die grootte kiezen. Voorbeeld 3.3 (Confounding in mariene veldexperimenten, vervolg) Beschouw opnieuw het experiment naar het effect van roofvissen op zeebodemhabitats. Stel dat we 12 lukrake gebieden op de zeebodem gemarkeerd hebben en vervolgens wensen te beslissen waar we de experimentele kooien (die effectief vis vasthouden) en de controlekooien zullen plaatsen. Dan zouden we de kooien kunnen randomiseren door op elke plaats een muntje op te gooien en vervolgens een experimentele kooi te plaatsen wanneer men kop gooit en een controlekooi anders. Die procedure is erop gericht te garanderen dat experimentele kooien op vergelijkbare plaatsen opgesteld worden als controlekooien. Om te vermijden dat er, per toeval, meer controlekooien dan experimentele kooien geplaatst worden, kunnen we een gebalanceerde randomisatie uitvoeren met blokken van grootte 2. Hoe men dit kan uitvoeren, ligt echter minder voor de hand. Eén mogelijkheid kan erin bestaan om de verschillende gebieden willekeurig te nummeren en die nummers lukraak dooreen te gooien teneinde een nieuwe nummering te bekomen die gegarandeerd lukraak is. Vervolgens kan men in volgorde van de bekomen nummering blokken van grootte 2 randomiseren om zelfde aantallen experimentele kooien en controlekooien te bekomen. Zelfs na deze gebalanceerde randomisatie kan het optreden dat, door toeval, alle controlekooien dichter bij de kust belanden dan de experimentele kooien. Dat is niet wenselijk omdat we willen vermijden dat het effect van het verwijderen van roofvis verward wordt met het effect van de afstand tot de kust. Een eenvoudige oplossing lijkt erin te bestaan om de plaatsen op de zeebodem te herrandomiseren tot men een wenselijke opdeling bekomt. Echter, ook die oplossing is niet wenselijk omdat ze steunt om menselijk oordeel en daardoor niet langer een vorm van randomisatie is (d.i. ze biedt niet langer de garantie op een lukrake opstelling). Om te vermijden dat de controlekooien door toeval relatief gezien dichter bij de kust opgesteld worden, kunnen we de gebalanceerde randomisatie afzonderlijk uitvoeren op de 6 plaatsen die het dichtst bij de kust gelegen zijn en op de 6 overige plaatsen. Op die manier garanderen we dat er zich op de 6 plaatsen die het dichtst bij de kust liggen, 3 controlekooien en 3 experimentele kooien bevinden, en analoog op de 6 plaatsen die het verst van de kust verwijderd zijn. Dergelijke vorm van randomisatie wordt gestratificeerde randomisatie genoemd en het bijhorend design een gerandomiseerd compleet blok design (in het Engels: randomized complete block design). Alternatief kan men de 12 gebieden markeren door eerst 6 plaatsen langs de kust te markeren en vertrekkend vanuit elk van die 6 plaatsen, telkens 2 gebieden af te bakenen op bijvoorbeeld 100 en 500 meter van de kust. Vervolgens kan men alternerend de controlekooi en experimentele kooi op 100 meter van de kust plaatsen. Deze laatste manier van werken is logistiek vaak makkelijker, maar is in mindere mate te verkiezen omdat de toewijzing van de kooien niet gerandomiseerd verloopt en omdat de gekozen gebieden mogelijks niet als een lukrake, representatieve verzameling gebieden op de zeebodem kan gezien worden (het is met name een systematische steekproef). Immers, het zou kunnen dat plaatsen op een afstand van 100 en 500 meter van de kust niet representatief zijn omwille van een ongekende periodiciteit in bepaalde bodemkarakteristieken. **Einde voorbeeld** Definitie 3.6 (gestratificeerde randomisatie) Gestratificeerde randomisatie (in het Engels: stratified randomisation) is een gebalanceerde randomisatie die afzonderlijk wordt uitgevoerd per groep subjecten met gelijkaardige prognostische factoren8 (bvb. afzonderlijk op plaatsen dicht versus ver van de kust). Ze wordt gebruikt om te voorkomen dat die prognostische factoren door toeval niet gelijk verdeeld zouden zijn over de verschillende interventiegroepen en als gevolg daarvan, net zoals confounders, een storende invloed zouden hebben op de associatie tussen behandeling en respons. Einde definitie Randomized complete block designs zijn experimentele designs waarbij men eerst de experimentele subjecten opdeelt in blokken en vervolgens elk niveau van de interventie binnen elk blok toepast en via randomisatie toewijst. Men kan dit realiseren d.m.v. gestratificeerde randomisatie waarbij de stratificatie volgens blokken verloopt. Dergelijke designs worden vaak gebruikt wanneer biologische processen worden bestudeerd, vooral wanneer de uitkomst zó sterk varieert tussen subjecten dat het interventie-effect moeilijk op te pikken is vantussen de vele ruis op de gegevens. Als de gegevens veel minder variabel zijn per blok, laat het randomiseren van de interventie per blok immers toe om het interventie-effect per blok te evalueren met veel minder ruis9. In de biologische wetenschappen stellen blokken vaak experimentele subjecten voor die gelijkaardig zijn in tijd of ruimte, hoewel men ook organismen van dezelfde leeftijd, grootte, … kan beschouwen. Blok designs worden in de levenswetenschappen ook vaak gebruikt om op een efficiente manier om te gaan met de ruis die wordt veroorzaakt door technische variabiliteit. Bij grotere experimenten is het vaak niet mogelijk om alle experimentele eenheden bijvoorbeeld op hetzelfde moment op te groeien in het labo, zijn meerdere celculturen nodig, zijn meerdere sequeneringsruns nodig voor het bepalen van de genexpressie in alle stalen, … Fluctuaties in de labo-condities , tussen celculturen of van sequeneringsrun tot sequeneringsrun zorgen dan voor extra technische ruis. In een randomized complete block design zal het experiment opgedeeld worden in meerdere blokken (vb. tijdstippen, runs, celculturen) en zal men de behandelingen randomizeren binnen elk blok zodat de interventie-effecten opnieuw met veel minder ruis kunnen worden geschat. Voorbeeld 3.4 (Oxidatieve stress in Arabidopsis) Jacques et al. (2015) onderzochten de impact van oxidatieve stress op het proteome in Arabidopsis thaliana. Hierbij bestudeerden ze het proteoom (alle proteïnen) in catalase knock-out en wild type A. thaliana planten. De planten werden gedurende 5 weken opgegroeid in een groeikamer. Vervolgens werd het proteoom bepaald na een controle behandeling, na 1 uur hoge lichtbehandeling of na 3 uur hoge lichtbehandeling. Het experiment werd op drie verschillende tijdstippen herhaald. Op elk tijdstip werden 6 proteomen geëxtraheerd: 1 proteoom voor elk combinatie van genotype x behandeling. Bijgevolg is dit een randomized complete block design met tijdstip als block. **Einde voorbeeld** Voorbeeld 3.5 (Effect van bladschade) Microbe-specifieke molecules (MSM) kunnen door het immuunsysteem van planten worden herkend en een defensieve response induceren die ze resistent maakt tegen bepaalde ziektes. Valdés-López et al. (2014) bestudeerde het effect van MSM op de genexpressie van Soja in een RNA-seq studie10. De planten werden opgegroeid in 12 potten. Elke pot bevatte vijf verschillende planten. Na 3 weken werden alle bladeren geoogst per pot. De bladeren afkomstig van elke pot werden in twee gesneden. De ene helft werd behandeld met een controle de andere helft met MSMs en vervolgens werd het RNA geëxtraheerd. Om voldoende RNA te bekomen werden alle bladhelften afkomstig van dezelfde behandeling en dezelfde pot gebruikt per extract. Het experiment is dus een gerandomiseerd complete block design met pot als block. **Einde voorbeeld** Wanneer een prognostische factor (bvb. afstand tot de kust) ongelijk verdeeld is tussen de verschillende interventiegroepen, dan kan men toch haar eventuele storende invloed beperken door ervoor te corrigeren als voor een confounder. Met andere woorden, het is dan aangewezen om het interventie-effect afzonderlijk te schatten voor subjecten met dezelfde waarde van de prognostische factor (bijvoorbeeld afzonderlijk voor kooien op een afstand van 100 meter van de kust en voor kooien op een afstand van 500 meter van de kust). We zullen dieper ingaan op dergelijke correcties in Sectie 3.4, alsook in het extra deel rond het algemeen lineair regressiemodel voor de studenten Biotechnologie en Biochemie, of in vervolgcursussen Statistiek voor de studenten Biologie. De volgende secties belichten een aantal verschillende types gerandomiseerd gecontroleerde experimenten. 3.3.3 Parallelle designs In een parallel design ontvangt 1 groep de testinterventie en de andere groep gelijktijdig de controle interventie. Dit is het eenvoudigste en meest gebruikte design voor gerandomiseerd gecontroleerde studies. Voorbeeld 3.6 (Kiezelwieren en zware metalen) Medley &amp; Clements (1998) bestudeerden de respons van kiezelwieren op zware metalen zoals zink in rivieren in de Rocky Mountains, Colorado, U.S.A. Ze selecteerden daartoe tussen 4 en 7 plaatsen op 6 rivieren die zwaar vervuild waren met zware metalen. Op elke plaats registreerden ze een aantal fysicochemische variabelen (pH, opgeloste zuurstof, …), de zinkconcentratie en variabelen die de kiezelwieren beschrijven (mate van voorkomen, diversiteit, …). De primaire onderzoeksvraag was of de diversiteit van kiezelwieren gelijk was in 4 groepen met verschillende concentraties zink: \\(&lt;20 \\mu\\)g/l, \\(21-50 \\mu\\)g/l, \\(51-200 \\mu\\)g/l en \\(&gt;200 \\mu\\)g/l. **Einde voorbeeld** 3.3.4 Cross-over designs In een cross-over studie ondergaan alle experimentele subjecten sequentieel alle interventies die in de studie vergeleken worden, maar in een lukrake volgorde. De 2 perioden - 2 behandelingen cross-over studie is er één waarbij subjecten lukraak toegewezen worden aan 1 van 2 groepen. Subjecten in de ene groep krijgen tijdens de eerste periode interventie A toegediend en vervolgens interventie B in de tweede periode. Subjecten in de andere groep krijgen tijdens de eerste periode interventie B toegediend en vervolgens interventie A tijdens de tweede periode. Voorbeeld 3.7 (Competitie tussen species lage begroeiing) Feinsinger et al. (1991) onderzochten competitie tussen 3 soorten lage begroeiing in Centraal Ameri- kaanse wouden. Ze voerden een experiment uit om de effecten van 4 interventies (relatieve dichtheid van 1 species, Besleria of Palicourea, en een tweede species Cephaelia was 10:10 (A)11, 90:10 (B), 10:90 (C), 50:50 (D)) na te gaan op responsvariabelen zoals het aantal keren dat een bloem door kolibries wordt bezocht of het aantal zaadjes dat rijpt per bloem. Metingen werden verzameld gedurende 4 tijdsperiodes van telkens 4 tot 6 dagen. Eén van de karakteristieken van hun design was dat elk van 4 bestudeerde planten elke interventie onderging in 1 van de 4 studieperiodes, zij het dat de volgorde waarin de interventies toegepast werden anders waren voor de 4 planten (zie onderstaande tabel). Periode Plant 1 Plant 2 Plant 3 Plant 4 1 A B C D 2 B C D A 3 C D A B 4 D A B C **Einde voorbeeld** Het voordeel van dit design is dat elke plant nu onder elke interventie wordt geëvalueerd en er bijgevolg meer informatie in de gegevens aanwezig is om het interventie-effect in te schatten dan wanneer elke plant slechts onder 1 van de interventies wordt gezien. Immers, dit design laat gedeeltelijk toe om elk subject met zichzelf te vergelijken teneinde iets te leren over het interventie-effect. Men kan aantonen dat dit tot gevolg heeft dat er (doorgaans) veel minder proefsubjecten (d.i. planten) nodig zijn dan in een parallel design om even precies12 het interventie-effect te kunnen schatten. Bovendien laat dit design toe om confounding te vermijden in situaties waar replicatie moeilijk is, zoals volgend voorbeeld illustreert. Voorbeeld 3.8 (Effect van koper op neerstrijken van larven) Stel dat men het effect van koper wenst te onderzoeken op het zich neerzetten van larven van een species ongewerveld zeedier (bvb. zeepokken). Dan zou men kunnen 2 grote aquaria opzetten, het ene voorzien van een koperoplossing en het andere van een inerte controle oplossing (bvb. zeewater). Stel dat men vervolgens 1000 larven aan elk aquarium toevoegt en na verloop van tijd het aantal larven telt dat zich vasthecht in elk aquarium, dan kan men een geobserveerd verschil tussen beide aantallen niet zomaar toeschrijven aan de koperoplossing omdat ook andere verschillen tussen beide aquaria (bvb. de opstelling ervan) een invloed kunnen hebben op het aantal larven dat zich vastzet. Om dat te vermijden, kan men het experiment in een tweede fase opnieuw uitvoeren, idealiter gebruik makend van dezelfde larven, maar ditmaal de koperoplossing toedienen voor het aquarium dat voorheen met zeewater werd gevuld en vice versa. **Einde voorbeeld** Niettemin zijn er in sommige situaties een aantal problemen met cross-over designs die het inschatten van het interventie-effect compliceren. Een eerste probleem is dat het effect van de interventie in de eerste periode een tijdje kan blijven bestaan in de tweede periode. Men noemt dit een carry-over effect. In dat geval wordt het moeilijk (of zelfs onmogelijk) om de effecten van beide interventies van elkaar te onderscheiden en los te koppelen. Om die reden zijn crossover designs het meest aangewezen voor interventies die slechts een korte termijn effect hebben. Ook wanneer het interventie-effect wijzigt over de tijd is het moeilijk met dit design om correct te beschrijven hoe goed de ene interventie werkt t.o.v. de andere. Men zegt in dat geval dat er een interactie is tussen de interventie en de periode waarin ze toegediend wordt. Omdat dergelijke interacties de analyse van de gegevens bemoeilijken en de resultaten tevens minder precies maken, zijn cross-over designs vooral nuttig voor de studie van responsmetingen die stabiel blijven over een lange tijd heen. 3.3.5 Factoriële designs Factoriële designs zijn experimentele designs met als doel het effect van meer dan 1 interventie te testen. Deze designs zijn zo opgezet dat alle interventies in combinatie met elkaar voorkomen zodat men interacties tussen interventies kan meten. Ze worden zeer frequent gebruikt in de bio-wetenschappen. Definitie 3.7 (interactie of effect-modificatie) Een interactie tussen 2 interventies drukt uit dat een combinatie van 2 interventies een effect heeft dat groter of kleiner is dan de som van de effecten van de afzonderlijke interventies (op een zekere schaal). Voorbeeld 3.9 (Grootte van salamanderlarven) Maret &amp; Collins (1996) bestudeerden de effecten van (ongewerveld) voedselniveau (d.i. veel of weinig bruine garnalen) en de aan-/afwezigheid van kikkervisjes op de grootte van salamanderlarven. Voor elk van de 4 combinaties van voedselniveau en aan/afwezigheid van kikkervisjes werden 8 aquaria opgezet en na verloop van tijd werd de grootte van de snuit van salamanders in elk aquarium opgemeten. Noteer in het bijzonder de 4 interventies als volgt: A (veel voedsel en kikkervisjes), B (weinig voedsel en kikkervisjes), C (veel voedsel en geen kikkervisjes), D (weinig voedsel en geen kikkervisjes). In de afwezigheid van interacties, drukt een vergelijking van groep A-B met C-D het effect uit van kikkervisjes. Analoog drukt een vergelijking van groep A-C met B-D het effect uit van het voedselniveau. De aanwezigheid van groep D laat toe om interacties te evalueren, d.i. om na te gaan of het effect van het voedselniveau anders is alnaargelang de aanwezigheid van kikkervisjes. Denk voor dit voorbeeld zelf even na hoe u op basis van gegevens voor groepen A, B, C en D zou nagaan of er een interactie is tussen voedselniveau en de aanwezigheid van kikkervisjes. **Einde voorbeeld** Bovenstaand voorbeeld geeft aan dat, indien men op voorhand weet dat 2 of meerdere interventies niet interageren, factoriële designs toelaten om de effecten van elk van de afzonderlijke interventies te evalueren met kleinere groepen subjecten en meer precisie dan afzonderlijke parallelle designs. Voorbeeld 3.10 (Groei van esdoorn versus beuk) Poulson &amp; Platt (1996) bestudeerden de effecten van lichtinval (nl., bevindt men zich onder het bladerdak, op een plaats waar 1 boom is omgevallen, of op een plaats waar meerdere bomen omgevallen zijn) en hoogte van de zaailingen (1-2 m, 2-4 m of 4-8 m) op het verschil in groei tussen zaailingen van de esdoorn en de beuk. De respons was het verschil in groei tussen gepaarde zaailingen van elke soort. Op elk van de 9 combinaties van lichtinval en hoogte van de zaailingen werden 5 metingen voor de respons verzameld. Hoe zou u het effect van lichtinval op het groeiverschil tussen esdoorn en beuk evalueren? En het effect van de grootte van de zaailingen? Wat betekent het dat er een interactie is tussen de lichtinval en grootte van de zaailingen? **Einde voorbeeld** Voorwaarden om factoriële designs te gebruiken, zijn (a) dat de verschillende interventies kunnen gecombineerd worden (en de combinatie van interventies dus geen hoge risico’s stelt voor de studiesubjecten, d.i. iets waar men vooral bij medische interventies moet waakzaam zijn), en (b) dat men echt geïnteresseerd is in de aanwezigheid van interacties. Factoriële designs bestaan eveneens in complexere vormen waar ze meer dan 2 interventies betrekken. In die gevallen, alsook wanneer elke interventie vele niveaus heeft, kan het aantal combinaties van factoren hoog oplopen en bijgevolg eveneens het aantal subjecten dat in de studie moet opgenomen worden. Om dit te vermijden, kan men overstappen op fractionele factoriële designs waar men niet alle combinaties van interventies probeert uit te testen. 3.3.6 Quasi-experimentele designs Algemeen noemt men een experiment met test- en controlegroep, maar zonder lukrake allocatie aan 1 van beide interventiegroepen, een quasi-experimenteel design. Het grote nadeel van dit design is dat verschillen tussen beide groepen niet gegarandeerd kunnen toegeschreven worden aan verschillen in behandelingswijze. Voorbeeld 3.11 (Gezondheidscampagne in Wales) Om het effect van een gezondheidscampagne in Wales te evalueren, werd een Engels controlegebied gekozen dat ver van Wales verwijderd was (zodat het niet blootgesteld was aan de campagne) (Tudor-Smith et al., 1998). Metingen werden verzameld in beide gebieden, zowel vóór de campagne als 6 jaar later. Hoewel er verbetering werd opgemerkt over de jaren heen, konden geen verschillende evoluties tussen beide groepen aangetoond worden. **Einde voorbeeld** 3.4 Observationele studies Terwijl in een gecontroleerd experiment de onderzoeker zelf beslist welke subjecten een bepaalde interventie ondergaan, observeert men in een observationele studie verschillende subjecten die (mogelijks om zelfgekozen redenen) verschillende interventies hebben ondergaan en probeert men hier vervolgens het interventie-effect uit af te leiden. Bijvoorbeeld, om na te gaan wat het effect is van de aanwezigheid van de salamandersoort P. glutinosus op de groei van de populatie P. jordani zou men in een observationele studie verschillende studiegebieden vergelijken waar er om natuurlijke redenen al dan niet een populatie P. glutinosus aanwezig is. Dergelijke studies zijn wel gecontroleerd (omdat men studiegebieden met en zonder P. glutinosus vergelijkt), maar niet experimenteel (omdat de onderzoeker niet zelf beslist in welke studiegebieden de salamandersoort P. glutinosus aanwezig is). Inderdaad, in een experimentele studie zou men ingrijpen door in sommige studiegebieden de populatie P. glutinosus te verwijderen en in andere niet. Het grote nadeel van observationele studies is dat verschillen in uitkomst tussen verschillende interventiegroepen niet gegarandeerd kunnen toegeschreven worden aan de blootstelling of interventie. Dit komt doordat deze groepen vaak in meer verschillen dan alleen hun blootstelling. Problemen van confounding zijn dus inherent aan observationele studies. Stel bijvoorbeeld dat men vaststelt dat de populatie P. jordani sneller groeit in gebieden met dan zonder P. glutinosus. Dan kunnen we besluiten dat er een associatie of verband is tussen de aanwezigheid van P. glutinosus en de populatiegroei van P. jordani. Maar dat op zich bewijst niet dat het toevoegen van de salamandersoort P. glutinosus in gebieden waar ze niet aanwezig is, een gunstig effect zal hebben op de populatiegrootte van P. jordani (d.i. dat het toevoegen van P. glutinosus een causaal effect op P. jordani heeft). Er kunnen immers verborgen confounders zijn: zo zou het kunnen dat men meer kans heeft om P. glutinosus aan te treffen in voedselrijke gebieden, waar de populatie P. jordani ook makkelijker zal toenemen omwille van de aanwezigheid van voedsel (maar niet omwille van de aanwezigheid van P. glutinosus). De rijkdom aan voedsel is in dit geval een confounder omdat (in overeenkomst met de eerdere definitie voor confounders) zowel de aanwezigheid van P. glutinosus als de groei van P. jordani geassocieerd zijn met de rijkdom aan voedsel, maar geen van beiden de rijkdom aan voedsel beïnvloeden. Omwille van confounders is het belangrijk in observationele studies om bij de subjecten waarvoor metingen verzameld worden, zorgvuldig prognostische factoren voor de bestudeerde uitkomst te meten die mogelijks ook met de blootstelling geassocieerd zijn. Voor die confounders die gemeten zijn, kan men immers corrigeren in de statistische analyse. Bijvoorbeeld, om de vergelijking van gebieden met en zonder P. glutonisus te corrigeren voor de confounder voedselrijkdom, kan men proberen een index te verzamelen voor de voedselrijkdom van elk gebied en vervolgens de analyse afzonderlijk uitvoeren bij gebieden met dezelfde voedselrijkdom. Men zegt dan dat de analyse of het geschatte effect van P. glutonisus op de groei van P. jordani gecontroleerd (in het Engels: adjusted of controlled) werd voor de voedselrijkdom van het studiegebied. Voorbeeld 3.12 (Simpson’s paradox) De Universiteit van Californië, Berkeley voerde verschillende jaren terug een observationele studie uit om na te gaan of er geslachtsdiscriminatie was bij de toelatingsexamens. Gedurende de studieperiode namen 8442 jongens en 4321 meisjes deel aan het examen. Ongeveer 44% van de jongens en 35% van de meisjes werd toegelaten tot de universiteit. Ervan uit gaande dat jongens en meisjes even capabel zijn om voor het examen te slagen (er is immers geen bewijs van het tegendeel), krijgen we hier de indruk dat jongens en meisjes anders behandeld worden bij de toelatingsprocedure. Omdat de toelatingsexamens verschillend waren naargelang de studierichting, werd bovenstaande analyse per studierichting opgesplitst om na te gaan welke faculteiten verantwoordelijk waren voor mogelijke discriminatie. De resultaten voor de 6 grootste richtingen staan in Tabel 3.3 getabuleerd (resultaten voor de andere richtingen waren analoog). In alle studierichtingen ligt het slaagpercentage hoger bij de meisjes dan bij de jongens, behalve in richting E waar de jongens het lichtjes beter doen. Dit lijkt paradoxaal, wetende dat het algemene slaagpercentage voor de jongens dat van de meisjes ruim overstijgt. Hoe kunnen we dit verklaren? De verklaring is dat de moeilijkheidsgraad van de studierichting (en verwant hiermee de keuze van studierichting) een confounder is voor de associatie tussen geslacht en de slaagkans. Immers, zoals blijkt uit Tabel 3.3 hebben jongens meer de neiging om studierichtingen te kiezen waar de slaagkansen hoog zijn: meer dan 50% van de jongens schreven zich in voor studierichtingen A en B, waar de slaagkansen hoger waren dan 50%; meer dan 90% van de meisjes kandideerde voor de andere studierichtingen die veel zwaardere toelatingsexamens hadden. De vergelijking van de slaagkansen per studierichting in Tabel 3.3 levert een analyse op die gecontroleerd is voor de keuze van studierichting. Na deze controle blijkt relatief weinig verschil in slaagkansen tussen jongens en meisjes. De statistische les is dat relaties tussen percentages kunnen omkeren naarmate men ze al dan niet in subgroepen bekijkt. Dit noemt men Simpson’s paradox. Tabel 3.3: Resultaten van de toelatingsexamens volgens geslacht en studierichting. Jongens(aantal) Jongens(geslaagd %) Meisjes(aantal) Meisjes (geslaagd %) A 825 62 108 82 B 560 63 25 68 C 325 37 593 34 D 417 33 375 35 E 191 28 393 24 F 373 6 341 7 **Einde voorbeeld** Voorbeeld 3.13 (Confounders in de NHANES studie) De National Health and Nutrition Examination Survey (NHANES 1) is een studie naar gezondheids- en voedingsgewoontes bij 7188 vrouwen tussen 25 en 74 jaar die opgevolgd werden van 1971 tot 1975 en van 1981 tot 1984 (Schatzkin et al., 1987). De onderzoekers vonden een positieve associatie tussen alcoholconsumptie en borstkanker (d.w.z. een hogere kans op borstkanker bij hogere consumptiegraad). Een grote vraag in deze studie was of deze associatie werkelijk het gevolg was van alcoholconsumptie of het gevolg van een mogelijks groot aantal andere factoren die met alcohol consumptie geassocieerd zijn. Het zou bijvoorbeeld kunnen dat vrouwen die meer alcohol verbruiken ook meer roken en om die reden gemakkelijker borstkanker ontwikkelen. In dat geval kan men door de storende invloed van roken mogelijks waarnemen dat het risico op borstkanker toeneemt met stijgend alcoholverbruik, zelfs wanneer in werkelijkheid het alcoholverbruik geen (causaal) effect heeft op borstkanker. Roken is in dat geval een confounder omdat het hogere risico op borstkanker voor alcoholverbruikers dan niet (alleen) het gevolg is van hun alcoholverbruik, maar (ook of vooral) van hun rookgedrag. Om de invloed van roken op de associatie tussen borstkanker en alcoholconsumptie te doen verdwijnen, heeft men de statistische analyse uitgevoerd bij vrouwen met hetzelfde rookgedrag. Immers, door de analyse te beperken tot vrouwen met hetzelfde rookgedrag, zijn de groepen vrouwen die wel versus niet alcohol consumeren, beter vergelijkbaar en is er dus niet langer een storende invloed van roken. Men zegt in dat geval dat men in de analyse gecorrigeerd (in het Engels: adjusted) heeft voor het rookgedrag, waarmee men bedoelt dat men het effect van alcohol op borstkanker heeft voorgesteld voor vrouwen met hetzelfde rookgedrag. In deze studie vond men dat er na correctie voor roken een associatie bleef bestaan tussen alcoholverbruik en borstkanker. Men besloot dat alcoholconsumptie een verhoogd risico op borstkanker impliceert. **Einde voorbeeld** Goede analyses van observationele studies controleren voor confounders. In de praktijk is het echter zeer moeilijk om alle mogelijke confounders te kennen voor de associatie tussen een blootstelling en een respons. En zelfs wanneer men ze zou kennen, is het vaak onmogelijk om ze allen te meten. Om die reden zijn de resultaten van observationele studies doorgaans minder betrouwbaar dan de resultaten van gerandomiseerd gecontroleerde experimenten. Niettemin zijn observationele studies krachtig en belangrijk omdat het in vele situaties onmogelijk is om een gerandomiseerd experiment uit te voeren. Zo is het praktisch quasi niet mogelijk om een gerandomiseerde experiment uit te voeren naar het effect van bosbranden op de rijkdom aan ongewervelde dieren in de grond omdat vuur moeilijk te manipuleren valt. Hoewel de onderzoeker in bepaalde studiegebieden brandhaarden kan aanbrengen, bestaat immers steeds het risico dat de brand uit de hand loopt. Om die reden bestudeert men vaak gebieden waar op natuurlijke wijze of door brandstichters brand is ontstaan. Hoewel dergelijke studie typisch te kampen hebben met problemen van confounding, hebben observationele studies, mits correctie voor gemeten confounders, in het verleden heel wat nuttige en correctie informatie gebracht, zoals de boodschap dat roken longkanker veroorzaakt (Doll &amp; Hill, 1964). Voorbeeld 3.14 (Observationele versus gerandomiseerde studies) Foetussen kunnen in de baarmoeder onderzocht worden via echografie. Verschillende experimenten op dieren hebben aangetoond dat dergelijk onderzoek kan leiden tot laag geboortegewicht. Om na te gaan of dat ook zo is bij mensen werd verschillende jaren terug een observationele studie opgezet in het Johns Hopkins ziekenhuis, Baltimore. Na correctie voor een aantal confounders stelden de onderzoekers vast dat baby’s die via echografie onderzocht werden in de baarmoeder gemiddeld een lager geboortegewicht hadden dan baby’s die niet blootgesteld werden aan echografie. Kunnen we hieruit besluiten dat echografie leidt tot lager geboortegewicht? Het antwoord is nee. We kunnen dit niet zomaar besluiten omdat de baby’s die blootgesteld waren aan echografie mogelijks niet vergelijkbaar waren met de andere baby’s in de studie. Om een duidelijk antwoord te vinden, werd later een gerandomiseerd gecontroleerde studie uitgevoerd. Deze toonde een matig beschermend effect van echografie aan! De reden dat de observationele studie hier een andere conclusie opleverde, is omdat echografie ten tijde van deze studie vooral werd toegepast bij probleemzwangerschappen. Om die reden waren de baby’s die in de observationele studie waren blootgesteld aan echografie doorgaans a priori minder gezond dan de andere baby’s. Of het al dan niet om een probleemzwangerschap ging, was dus een confounder voor de associatie tussen geboortegewicht en blootstelling aan echografie. **Einde voorbeeld** 3.5 Prospectieve studies In prospectieve studies wenst men een associatie tussen een blootstelling en uitkomst te bepalen door eerst een groep subjecten met de blootstelling en een groep subjecten zonder de blootstelling te identificeren en vervolgens (na zekere tijd) de gewenste uitkomst voor elk subject te observeren. Men kiest bijvoorbeeld 10 studiegebieden met en 10 studiegebieden zonder P. glutinosus en na 5 jaar evalueert men voor elk studiegebied hoe groot de populatie P. jordani is. Prospectieve studies zijn vaak longitudinaal. Dat betekent dat ze de evolutie van processen over de tijd heen onderzoeken door op verschillende tijdstippen metingen voor respons (en vaak ook blootstelling) te verzamelen. Bijvoorbeeld kan men 10 studiegebieden met en 10 studiegebieden zonder P. glutinosus identificeren en jaarlijks (gedurende 5 jaar) evalueren hoe groot de populatie P. jordani is. Dergelijke prospectieve longitudinale studies laten toe om na te gaan hoe de grootte van de populatie P. jordani evolueert over de tijd in functie van de aanwezigheid van een andere salamandersoort. Ze worden (prospectieve) cohort studies genoemd. Meer algemeen zijn dit longitudinale studies waarbij voor elke subject in de studie op verschillende tijdstippen de uitkomst (en eventueel ook de blootstelling) worden geregistreerd, zonder dat de subjecten noodgedwongen eerst opgedeeld worden in een groep cases met de blootstelling en een groep controles zonder de blootstelling. Bijvoorbeeld kan men lukraak 20 gebieden in de studie opnemen en gedurende 5 jaar, jaarlijks registreren hoe groot de populatie P. jordani en hoe groot de populatie P. glutinosus is. Op basis van al die metingen kan men vervolgens nagaan of er een associatie is tussen de grootte van beide populaties. Merk op dat experimentele studies noodgedwongen prospectief zijn. Voorbeeld 3.15 (Vruchtbaarheid van schelpdieren) Ward &amp; Quinn (1988) verzamelden 37 eicapsules van het schelpdier Lepsiella Vinosa aan de litorale zone en 42 eicapsules aan de mosselzone van een rotsige kust. De onderzoekers wensten na te gaan of er een verschil was in het gemiddeld aantal eitjes per capsule tussen beide zones. Deze studie is prospectief vermits de onderzoekers eerst 2 types studiegebieden (d.i. 2 blootstellingen) identificeren en vervolgens de uitkomst observeren. **Einde voorbeeld** 3.6 Retrospectieve studies In retrospectieve studies wenst men een associatie tussen een blootstelling en een bepaalde aandoening te bepalen door eerst een groep subjecten met de aandoening en een groep subjecten zonder de aandoening te identificeren en vervolgens op te sporen welke blootstelling ze in het verleden ondervonden hebben. Men kiest bijvoorbeeld 100 longkankerpatiënten en 100 mensen zonder longkanker en vergelijkt vervolgens het DNA-profiel tussen beiden. Dergelijke studies worden ook case-controle studies of case-referent studies genoemd omdat de groep subjecten met de aandoening doorgaans cases worden genoemd, en de groep subjecten zonder de aandoening controles. Pas echter op: het is niet omdat men subjecten met (zonder) de aandoening cases (controles) noemt in een bepaalde studie, dat het om een case-controle studie gaat! Zo is ook de Salk vaccin studie geen case-controle studie hoewel gevaccineerde (niet-gevaccineerde) kinderen cases (controles) werden genoemd. Voorbeeld 3.16 (Genetische associatiestudies) Genetische associatiestudies zijn erop gericht om na te gaan of polymorfismen (d.i. verschillen in DNA sequentie tussen individuen) in bepaalde genen geassocieerd zijn met bepaalde fenotypes, bijvoorbeeld of het polymorfisme in het BRCA1 gen geassocieerd is met borstkanker. Vaak bestudeert men relatief zeldzame aandoeningen, in welk geval case-controle studies zeer efficiënt zijn. Immers, door via het design vast te leggen dat het DNA-profiel moet gemeten worden van 100 borstkankercases en 100 controles kan men met een beperkt aantal metingen toch een voldoende aantal cases evalueren. In prospectieve studies daarentegen zou men met een borstkankerprevalentie van 1% al 10000 mensen moeten evalueren om een 100-tal cases te garanderen. In dit voorbeeld beschouwen we zo’n case-controle studie die 800 borstkankercases en 572 controles omvatte. Informatie omtrent het BRCA1-polymorfisme werd bekomen via DNA-analyse en staat getabuleerd in Tabel 3.4. We stellen vast dat 89 van de 800 cases het allel Leu/Leu bezitten, of 11.1%, en 56 van de 572 controles, of 9.8%. Dit suggereert dat de aanwezigheid van het allel Leu/Leu prevalenter is bij mensen met borstkanker. In latere hoofdstukken zullen we vaststellen dat dergelijk verschil in prevalentie van blootstelling aan het allel Leu/Leu voldoende klein is om door toeval te kunnen ontstaan wanneer er in werkelijkheid geen associatie is tussen het polymorfisme in BRCA1 en borstkanker. Er is bijgevolg onvoldoende bewijs voorhanden om te kunnen besluiten dat er een associatie is tussen het polymorfisme in BRCA1 en borstkanker. Merk op dat, hoewel onder de mensen die het allel Leu/Leu bezitten \\(89/145=61.4\\%\\) aan bortskanker lijdt, dit cijfer niet veralgemeenbaar is naar de ganse bevolking. Dit komt doordat het percentage borstkankerpatiënten in deze studie vastgekozen is door het design en dus niet het werkelijke risico op borstkanker weerspiegelt! Tabel 3.4: Kruistabel van borstkanker-status versus BRCA1-allel. Genotype Controles Cases totaal Pro/Pro 266 342 608 Pro/Leu 250 369 619 Leu/Leu 56 89 145 Totaal 572 800 1372 **Einde voorbeeld** Er zijn 2 mogelijke variaties van case-controle studies. In niet-gematchte case-controle studies is de controlegroep een goedgekozen steekproef uit de populatie subjecten zonder de aandoening. Het algemeen principe om controles te kiezen is hier (a) om subjecten te kiezen die op basis van hun karakteristieken, maar afgezien van hun uitkomst (bvb. ziektestatus), case zouden kunnen geweest zijn, en (b) om hen onafhankelijk van de blootstelling te kiezen. In gematchte case-controle studies zoekt men voor elke case 1 of meerdere controlesubjecten die vergelijkbaar zijn met de case in termen van belangrijke prognostische variabelen voor de bestudeerde aandoening, zoals leeftijd en geslacht. Bijvoorbeeld kan men voor elke case een controle kiezen van exact dezelfde leeftijd en geslacht. Omdat elke case nu beter vergelijkbaar is met zijn/haar controle verhoogt men aldus de controle voor confounders bij het onderzoeken van het effect van de risicofactor op de uitkomst. Matching kan echter leiden tot een groot verlies aan observaties, met name wanneer heel wat controles verloren gaan doordat ze niet aan de matching criteria voldoen. Beide types case-controle design vergen elk hun eigen statistische analyse. In deze cursus beperken we ons grotendeels tot niet-gematchte case-controle studies. De analyse van gematchte case-controle studies is complexer omdat deze rekening moet houden met de verwantschap tussen cases en gematchte controles. Het grote voordeel van case-controle studies is dat ze nuttig aangewend kunnen worden voor de studie van zeldzame aandoeningen. Dit is zo vermits het design toelaat om op voorhand een groep individuen met de aandoening te selecteren en het bijgevolg niet nodig is om te wachten tot een voldoende aantal subjecten de bestudeerde aandoening heeft opgelopen, teneinde over voldoende informatie te beschikken om een accurate vergelijking te maken van het risico in beide blootstellingsgroepen. Een nadeel is dat ze retrospectief zijn en dus beroep doen op historische data of het geheugen van de proefpersonen om informatie te verzamelen over de blootstelling en andere factoren. Dit kan de resultaten mogelijks vertekenen, in welk geval men van recall bias spreekt. Dergelijke vertekening is vooral problematisch wanneer ze niet in even erge mate optreedt voor cases als voor controles. Bijvoorbeeld, omdat cases aan een ziekte lijden, herinneren ze zich vaak beter aan welke risicofactoren ze in het verleden blootgesteld zijn. Als gevolg hiervan kan men bepaalde blootstellingen verkeerdelijk associëren met de bestudeerde ziekte wanneer die blootstellingen in werkelijkheid even prevalent waren voor cases als controles, maar frequenter gerapporteerd werden door cases dan controles. Dergelijke problemen stellen zich minder of niet in genetische associatiestudies waar men via DNA-analyse vroegere `blootstellingen’ opspoort. Case-controle studies zijn net als cohort studies gevoelig aan het probleem van (ongemeten) confounders. In dat opzicht is een groot nadeel de moeilijke keuze van een goede (d.w.z. vergelijkbare) controlegroep. 3.7 Niet-gecontroleerde studies In niet-gecontroleerde studies is er geen gelijktijdige controlegroep aanwezig en ondergaan alle subjecten (op elk tijdstip) bijgevolg dezelfde interventie. Vermits er in dergelijke studies geen groep subjecten is die een andere interventie ondergaan, is het moeilijker en vaak zelfs onmogelijk om op basis van deze studies het effect van interventies te evalueren. In deze sectie bespreken we een aantal van deze studies. 3.7.1 Pre-test/Post-test studies Een pre-test/post-test studie is een studie waarbij een bepaalde karakteristiek gemeten wordt bij een groep subjecten, die vervolgens onderworpen worden aan een zekere interventie en bij wie diezelfde karakteristiek tenslotte opnieuw gemeten wordt. Het behandelingseffect wordt dan vaak gemeten door de metingen na interventie te vergelijken met de metingen vóór interventie. Stel bijvoorbeeld dat men de impact wenst in te schatten van het plaatsen van een waterzuiveringsstation langs een rivier op de biomassa van phytoplankton. Dan zou men op basis van verschillende waterstalen metingen kunnen verrichten zowel vóór als na het plaatsen van het station, en vervolgens beide groepen metingen kunnen vergelijken. Hoewel dergelijk design zowel metingen met als zonder interventie levert, blijft een groot nadeel de afwezigheid van een controlegroep. Wanneer men een wijziging in uitkomst observeert tussen de tijdstippen van afname van de 2 metingen, kan men immers niet garanderen dat dit het gevolg is van de interventie, vermits ook andere factoren die de uitkomst beïnvloeden, gewijzigd kunnen zijn gedurende de studie. Bijvoorbeeld, hoewel bovenstaande studie nuttige inzichten kan verschaffen in de impact van waterzuiveringsstations, blijft steeds de vraag met dit soort designs of eventuele wijzigingen in de biomassa van phytoplankton toe te schrijven zijn aan het zuiveringsstation of eerder natuurlijke evoluties weerspiegelen ten gevolge van de gewijzigde weersomstandigheden, etc… 3.7.2 Cross-sectionele surveys Cross-sectionele surveys onderzoeken een groep subjecten op een bepaald punt in de tijd afgezien van hun blootstelling of uitkomst, in tegenstelling tot cohort en case-controle studies. Bijvoorbeeld, stel dat een ecoloog een aantal meren onderzoekt en voor elk meer de grootte opmeet alsook de mate van divergentie in morfologische karakteristieken tussen vissen van een bepaalde species. Dan kunnen de bekomen metingen worden gebruikt om na te gaan of zich meer divergentie voordoet in grote dan in kleine meren. Dit studiedesign wordt cross-sectioneel genoemd omdat men op 1 bepaald tijdstip verschillende subjecten (d.i. meren) onderzoekt, afgezien van blootstelling (d.i. grootte van het meer) of uitkomst (d.i. divergentie). De resultaten uit cross-sectionele studies kunnen moeilijk interpreteerbaar zijn wanneer ze een tijdscomponent betrekken. Stel bijvoorbeeld dat men in zo’n studie een negatieve associatie vaststelt tussen leeftijd en lichaamslengte. Dan kan dit zijn omdat oudere mensen krimpen, maar ook omdat de jongere generaties doorgaans groter worden dan in het verleden het geval was, of omdat grote mensen sneller sterven! References "],
["chap-describe.html", "Hoofdstuk 4 Data exploratie en beschrijvende statistiek 4.1 Inleiding 4.2 Univariate beschrijving van de variabelen 4.3 Samenvattingsmaten voor continue variabelen 4.4 De Normale benadering van gegevens 4.5 Samenvattingsmaten voor categorische variabelen 4.6 Associaties tussen twee variabelen 4.7 Onvolledige gegevens", " Hoofdstuk 4 Data exploratie en beschrijvende statistiek 4.1 Inleiding Om de resultaten van een experimentele of observationele studie te rapporteren, is het uiteraard niet mogelijk om per subject waarvoor gegegevens verzameld werden in de studie de bekomen gegevens neer te schrijven. Met de veelheid aanwezige informatie is het integendeel belangrijk de gegevens gericht samen te vatten en voor te stellen. Zelfs wanneer het duidelijk is welke analyse er moet uitgevoerd worden, moet er eerst een basisbeschrijving komen van de verzamelde gegevens. Dit zal mee helpen aangeven of er geen fouten zijn gemaakt tijdens het onderzoek of bij de registratie van gegevens. Eventuele anomalieën of zelfs fraude worden in deze fase opgespoord en tenslotte krijgt men een indruk of voldaan is aan de onderstellingen (bvb. de onderstelling dat de gegevens Normaal verdeeld zijn13) die aan de grond liggen van de voorgestelde statistische analyses in de latere fase. De eerste vraag die moet gesteld worden bij het benaderen van een echte data set is: Wat is de oorspronkelijke vraagstelling (geweest), waarom zijn deze gegevens verzameld? Hoe en onder welke omstandigheden zijn de subjecten gekozen en de variabelen gemeten? Hierbij stelt men meteen de vraag naar het design van de studie, alsook hoeveel subjecten werden aangezocht voor meetwaarden en hoeveel daar uiteindelijk echt van in de database zijn terecht gekomen (m.a.w. of gegevens die men gepland had te verzamelen, om een of andere reden toch niet bekomen werden). Bovendien laat dit toe om te evalueren of verschillende subjecten in de studie al dan niet meer verwant zijn dan andere subjecten en of de analyse hier rekening mee moet houden. Is er een specifieke numerieke code die een ontbrekend gegeven of ander type uitzondering voorstelt in plaats van een echte meetwaarde? Als het vertrekpunt duidelijk is en alle variabelen goed beschreven zijn, kan men starten met een betekenisvolle exploratie van de gerealiseerde observaties. Figuur 4.1: Verschillende stappen in een studie. In dit hoofdstuk ligt de focus op de data-exploratie en beschrijvende statistiek Dit hoofdstuk zullen werken rond een centrale dataset: de NHANES studie. Voorbeeld 2.1 (NHANES studie) De National Health and Nutrition Examination Survey (NHANES) wordt sinds 1960 op regelmatige basis of genomen. In dit voorbeeld maken we gebruik van de gegevens die werden verzameld tussen 2009-2012 bij 10000 Amerikanen en die werden opgenomen in het R-pakket NHANES. Er werd een groot aantal fysische, demografische, nutritionele, levelsstijl en gezondheidskarakteristieken gecollecteerd in deze studie (zie Tabel 2.1). Merk op dat ontbrekende waarnemingen hier gecodeerd worden a.d.h.b. de code NA (Not Available / Missing Value) **Einde voorbeeld** Tabel 4.1: Overzicht van een aantal variabelen uit de NHANES studie. ID Gender Age Race1 Weight Height BMI BPSysAve TotChol SmokeNow Smoke100 51624 male 34 White 87.4 164.7 32.22 113 3.49 No Yes 51625 male 4 Other 17.0 105.4 15.30 NA NA NA NA 51630 female 49 White 86.7 168.4 30.57 112 6.70 Yes Yes 51638 male 9 White 29.8 133.1 16.82 86 4.86 NA NA 51646 male 8 White 35.2 130.6 20.64 107 4.09 NA NA 51647 female 45 White 75.7 166.7 27.24 118 5.82 NA No 4.2 Univariate beschrijving van de variabelen In de regel begint men met een univariate inspectie: elke variabele wordt apart onderzocht. Het is absoluut aan te raden om hierbij eerst alle ruwe gegevens te bekijken door middel van grafieken (zie verder) alvorens naar samenvattingsmaten (zoals het gemiddelde) over te stappen. Dit laat toe om een idee te krijgen hoe de geobserveerde waarden van een veranderlijke verdeeld zijn in de studiegroep (bvb. welke verdeling de bloeddrukmetingen in de studie hebben) en of er eventuele uitschieters (d.i. extreme metingen of outliers) zijn. Met outliers worden observaties aangegeven die ten opzichte van de geobserveerde verdeling van de waarden in de data set, extreem zijn, buitenbeentjes. #De data van de NHANES studie bevindt zich #in het R package NHANES library(NHANES) #laad NHANES package #NHANES is een data frame met de gegevens #De rijen bevatten informatie over elk subject #De kolommen de variabelen die werden geregistreerd #vb variabele Gender, BMI, ... #Een variabele (kolom) kan uit de dataframe #worden gehaald door gebruik van het $ teken #en de naam van de variabele # We slaan de frequentietabel voor variable Gender # op in object &#39;tab&#39; tab &lt;- table(NHANES$Gender) tab ## ## female male ## 5020 4980 barplot(tab) #teken staaf diagram Figuur 4.2: Staafdiagram van het aantal mannen en vrouwen in de NHANES studie. Er zijn weinig methoden voorhanden om nominale variabelen te beschrijven. In Voorbeeld 2.1 is de variable Gender kwalitatief nominaal. Alles is gezegd over de verdeling van het geslacht als we weergeven hoeveel vrouwen en mannen zijn opgenomen in de studie. Meer nog, als het totale aantal personen in de data set eenmaal vast ligt, dan zijn de uitkomsten verder volledig gekarakteriseerd door, bijvoorbeeld, alleen het percentage vrouwen en mannen weergeen. In het softwarepakket R kan men een beeld van de gegevens krijgen door ze in een frequentietabel weer te geven of a.d.h.v. een grafiek zoals een staafdiagram. Beiden worden gegenereerd in de R-code voor Figuur 4.2. We stellen vast dat 5020 van de 10000 subjecten, ofwel 50.2% vrouwen in de studie zijn opgenomen. Een staafdiagram geeft op de X-as de mogelijke uitkomsten van de variabele aan (bvb. geslacht). Daarbovenop komt een staaf met hoogte evenredig aan het totaal aantal keer dat die waarde voorkomt in de dataset. In het bijzonder kan men kiezen tussen de absolute frequentie (5020 voor het aantal vrouwen, 4980 voor het aantal mannen) of de relatieve frequentie ( 50.2% vrouwen, 49.8% mannen). De staven staan los van elkaar met een breedte die constant is, maar verder willekeurig. Als de steekproef representatief is voor de populatie, dan krijgen we hier misschien een eerste impressie dat er iets meer vrouwen zijn in de populatie. De variabele met de naam BMI_WHO in de dataset is kwalitatief ordinaal en heeft 4 geordende categorieën die grensen voor ondergewicht, normaal gewicht, licht-overgewicht, obesitas. Voor dergelijke ordinale variabelen worden de mogelijke uitkomsten best in volgorde gesorteerd en in een frequentietabel of staafdiagram weergegeven. Naast de (relatieve) frequentie is het nu ook zinvol om de cumulatieve (relatieve) frequentie aan te geven. Deze laatste drukt uit welk percentage van de gegevens in de gegeven klasse of een lagere klasse valt. In Figuur 4.3 vind je het staafdiagram voor het BMI. In de R-code voor de figuur vind je tevens de bijhorende frequentietabel. # sla freq. tabel op in object &#39;tabBmi&#39; tabBmi &lt;- table(NHANES$BMI_WHO) tabBmi ## ## 12.0_18.5 18.5_to_24.9 25.0_to_29.9 30.0_plus ## 1277 2911 2664 2751 #teken staaf diagram barplot(tabBmi) Figuur 4.3: Staafdiagram van het aantal personen in de NHANES studie die behoort tot elke BMI klasse. Voor numerieke continue variabelen wordt het moeilijk om de frequentie van alle uitkomstwaarden in een tabel te klasseren omdat veel waarden hoogstens 1 keer voorkomen. Het tak-en-blad diagram (in het Engels: stem and leaf plot is een middel om toch nog alle uitkomsten weer te geven. Een voorbeeld is weergegeven in onderstaande R-output voor het BMI in de NHANES studie. stem(NHANES$BMI) ## ## The decimal point is 1 digit(s) to the right of the | ## ## 1 | 33333333333333333344444444444444444444444444444444444444444444444444+37 ## 1 | 55555555555555555555555555555555555555555555555555555555555555555555+1389 ## 2 | 00000000000000000000000000000000000000000000000000000000000000000000+2264 ## 2 | 55555555555555555555555555555555555555555555555555555555555555555555+2610 ## 3 | 00000000000000000000000000000000000000000000000000000000000000000000+1693 ## 3 | 55555555555555555555555555555555555555555555555555555555555555555555+635 ## 4 | 00000000000000000000000000000000000000000000000000000000000000000000+255 ## 4 | 55555555555555555555555556666666666666666666666666666666666777777777+46 ## 5 | 0000011111122222233333444444444444 ## 5 | 5556677777789999 ## 6 | 133444 ## 6 | 567899 ## 7 | ## 7 | ## 8 | 111 Hier wordt van alle uitkomsten het eerste cijfer of de eerste paar cijfers op een verticale lijn in volgorde uitgezet in de vorm van een boomstam. Daaraan worden horizontaal de bladeren gehecht, met name de laatste cijfers van de geobserveerde uitkomsten. De output geeft bijvoorbeeld aan dat er 3 personen zijn waarvan het afgeronde BMI 55 bedraagt, 2 personen met een afgerond BMI van 56, …. Gezien de studie zo groot is, is het tak-en-blad diagram niet erg praktisch voor dit voorbeeld. In een tak-en-blad diagram krijgt men alle individuele uitkomsten nagenoeg exact te zien, terwijl de vorm die het diagram aanneemt reeds een idee van de verdeling geeft zoals in een histogram (zie verder). Een vuistregel om de vorm van de verdeling het best te zien is het aantal takken ongeveer gelijk te maken aan \\(1 + \\sqrt{n}\\), waarbij \\(n\\) het aantal observaties voorstelt. Dit aantal kan uiteraard aangepast worden aan de omstandigheden. Een populair alternatief voor het tak en blad diagram is de eenvoudige frequentietabel. Deze kan men bekomen door de continue variabele (bvb. BMI) om te zetten in een kwalitatieve ordinale variabele, waarvoor vervolgens een frequentietabel wordt weergegeven. Merk op dat dit voor het BMI eerst is gebeurd (Figuur 4.3). Het grafisch equivalent van dergelijke frequentietabel noemt een histogram, hetgeen men in R bekomt via hist(NHANES$BMI,main=&quot;&quot;,xlab=&quot;BMI&quot;) #main is hoofdtitel Figuur 4.4: Histogram van het BMI in de NHANES studie. Wanneer alle klassen een zelfde breedte hebben, worden de absolute of relatieve frequenties per klasse weergegeven door de hoogte van de bijhorende kolom. Bij ongelijke klassebreedtes is het de oppervlakte van de kolom die met de bijhorende klassefrequentie correspondeert. Omdat een histogram met ongelijke klassebreedtes moeilijker te interpreteren is, zijn histogrammen met gelijke klassebreedtes vaak te verkiezen. Als histogrammen voor verschillende groepen bekeken worden, vergemakkelijkt het gebruik van relatieve frequenties i.p.v. absolute frequenties de visuele vergelijkbaarheid. Op het histogram in Figuur 4.4 worden absolute frequenties weergegeven en klassen met een breedte van 5 eenheden. We stellen vast dat ongeveer 1500 personen van de 10000, of 15% een BMI heeft tussen de 15 en 20. De keuze van het aantal klassen is van belang bij een histogram. Als er te weinig klassen zijn, dan gaat veel informatie verloren. Als er teveel zijn, dan wordt het algemene patroon verdoezeld door een grote hoeveelheid overbodige details. Gewoonlijk kiest men tussen 5 en 15 intervallen, maar de specifieke keuze hangt af van het beeld van het histogram dat men te zien krijgt. Indien een voldoende aantal gegevens beschikbaar is, dan kan men een gladdere indruk van de verdeling van de gegevens bekomen door een zogenaamde kernel density schatter te bepalen. Zo’n schatter is een positieve functie die genormaliseerd is in die zin dat de oppervlakte onder de functie 1 is. Ze kan zo geïnterpreteerd worden dat de oppervlakte onder de functie tussen 2 punten \\(a\\) en \\(b\\) op de X-as, de kans voorstelt dat een lukrake meting in het interval \\([a,b]\\) gevonden wordt. Figuur 4.5 toont een histogram (links) en kernel density schatter (rechts) van de het BMI. # deel grafische scherm op in 1 rij en 2 kolommen par(mfrow=c(1,2)) # teken een histogram hist(NHANES$BMI,main=&quot;&quot;,xlab=&quot;BMI&quot;) # teken een kernel density schatter plot(density(NHANES$BMI,na.rm=TRUE),main=&quot;&quot;,xlab=&quot;BMI&quot;) Figuur 4.5: Histogram en kernel density schatter van BMI in de NHANES studie. # argument na.rm=TRUE omdat er ontbrekende # waarnemingen (NA) voorkomen De verdeling kan ook geëvalueerd worden aan de hand van een box-and-whisker-plot, kortweg boxplot genoemd. Deze is meer compact dan een histogram en laat om die reden gemakkelijker vergelijkingen tussen verschillende groepen toe (zie verder). Een Boxplot voor het BMI wordt getoond in Figuur 4.6. De boxplot toont een doos lopend van het 25% tot 75% percentiel met een lijntje ter hoogte van de mediaan (het 50% percentiel) en verder 2 snorharen. Die laatste kunnen in principe lopen tot het minimum en maximum, of tot het 2.5% en 97.5 % of 5% en 95% percentiel. R kiest voor de kleinste en de grootste geobserveerde waarde die geen outlier of extreme waarde zijn. Een meting wordt hierbij een outlier genoemd wanneer ze meer dan 1.5 keer de boxlengte beneden het eerste of boven het derde kwartiel ligt. Een meting wordt een extreme waarde genoemd wanneer ze meer dan 3 keer de boxlengte beneden het eerste of boven het derde kwartiel ligt. Definitie 4.1 (percentiel) Het 25% percentiel of 25% kwantiel \\(x_{25}\\) van een reeks waarnemingen wordt gedefinieerd als een uitkomstwaarde \\(x_{25}\\) zodat minstens \\(25\\%\\) van die waarnemingen kleiner of gelijk zijn aan \\(x_{25}\\) en minstens \\(75\\%\\) van die waarnemingen groter of gelijk zijn aan \\(x_{25}\\). Het 75% percentiel of 75% kwantiel van een reeks waarnemingen definieert men als een uitkomstwaarde \\(x_{75}\\) zodat minstens 75% kleiner of gelijk zijn aan \\(x_{75}\\) en minstens \\(25\\%\\) van die waarnemingen groter of gelijk zijn aan \\(x_{75}\\). Algemeen wordt het \\(k\\%\\) percentiel van een reeks waarnemingen gedefinieerd als een waarde (van \\(x\\)) waarvoor de cumulatieve frequentie gelijk is aan \\(k/100.\\) Als er meerdere observaties aan voldoen neemt men vaak het gemiddelde van die waarden. Einde definitie In R kunnen die als volgt worden bekomen quantile(NHANES$BMI,c(0.25,.5,.75),na.rm=TRUE) ## 25% 50% 75% ## 21.58 25.98 30.89 #code om boxplot te genereren boxplot(NHANES$BMI,ylab=&quot;BMI&quot;) #Code om text toe te voegen aan plot #Dit hoef je zelf normaal gezien niet te doen BMI=na.exclude(NHANES$BMI) rangeCl&lt;-quantile(BMI,c(.25,.75))+c(-1,1)*diff(quantile(BMI,c(.25,.75)))*1.5 boxYs&lt;-c(range(BMI[BMI&lt;=rangeCl[2]&amp;BMI&gt;=rangeCl[1]]),quantile(BMI,c(.25,.5,.75)),rangeCl[2]+(max(BMI)-rangeCl[2])/2) text(1.3,boxYs,labels=c(&quot;wisker&quot;,&quot;wisker&quot;,&quot;x25&quot;,&quot;mediaan&quot;,&quot;x75&quot;,&quot;outliers&quot;),pos=4,cex=1.3) lines(c(1.1,1.3,1.3,1.1),c(rangeCl[2],rangeCl[2]+(max(BMI)-rangeCl[2])/2,rangeCl[2]+(max(BMI)-rangeCl[2])/2,max(BMI)),lty=2) Figuur 4.6: Boxplot van BMI in de NHANES studie. Bij de inspectie van een dataset speelt het detecteren van outliers in het algemeen een belangrijke rol. Ze kunnen wijzen op fouten, zoals tikfouten of andere fouten die gecheckt en gecorrigeerd moeten worden. Als het geen foutief genoteerde waarden zijn, dan kan het soms wijzen op een subject dat niet echt in de studiepopulatie thuis hoort. Als het in alle opzichten om een bona fide waarde gaat, dan nog is het belangrijk om outliers te detecteren: ze kunnen zeer invloedrijk zijn op de schatting van statistische parameters (zie Sectie 4.3). Als de conclusies van een studie anders liggen met of zonder inclusie van de outlier, dan is dit een ongewenst fenomeen. Men wil immers nooit dat 1 observatie beslissend is voor de conclusies. Dit soort onzekerheid ondermijnt de geloofwaardigheid van de onderzoeksresultaten en vraagt om verdere studie. Binnen de statistiek bestaat een grote waaier aan technieken, zogenaamde robuuste statistische technieken, die erop gericht zijn om de invloed van outliers te minimaliseren. In deze cursus gaan we hier slechts in zeer beperkte mate op in (zie Sectie 4.3, mediaan). 4.3 Samenvattingsmaten voor continue variabelen Een histogram levert reeds een sterke samenvatting van de geobserveerde, continue gegevens, maar in wetenschappelijke rapporten is er zelden plaats om per geobserveerde variabele dergelijke grafiek voor te stellen. Om die reden is vaak een veel drastischere samenvattingsmaat noodzakelijk. In deze sectie geven we aan hoe de centrale locatie van de gegevens kan beschreven worden, alsook de spreiding van die gegevens rond hun centrale locatie. 4.3.1 Maten voor de centrale ligging Definitie 4.2 (rekenkundig gemiddelde) Het (rekenkundig) gemiddelde \\(\\overline{x}\\) (spreek uit: x-streep of x-bar) van een reeks waarnemingen \\(x_i, i=1, 2, \\dots, n\\) is per definitie de som van de observaties gedeeld door hun aantal \\(n\\): \\[\\begin{equation*} \\overline{x}= \\frac{x_1 + x_2 + \\dots + x_n}{n} =\\frac{1}{n} \\sum_{i=1}^n x_i \\end{equation*}\\] Einde definitie Een groot voordeel van het gemiddelde als een maat voor de centrale locatie van de observaties is dat het alle data-waarden efficiënt gebruikt vanuit statistisch perspectief. Dit wil zeggen dat ze (onder bepaalde statistische modellen) het maximum aan informatie uit de gegevens haalt en om die reden relatief gezien zeer stabiel blijft wanneer ze herberekend wordt op basis van een nieuwe, even grote steekproef die onder identieke omstandigheden werd bekomen. Bovendien beschrijft het gemiddelde ook verschillende belangrijke modellen voor de verdeling van de gegevens, zoals de Normale verdeling (zie Sectie 4.4). Een groot nadeel van het gemiddelde is dat het zeer gevoelig is aan de aanwezigheid van outliers in de dataset. Om die reden is het vooral een interessante maat van locatie wanneer de verdeling van de observaties (zoals weergegeven door bijvoorbeeld een histogram) min of meer symmetrisch is. mean(NHANES$BMI,na.rm=TRUE) ## [1] 26.66014 #opnieuw is de na.rm statement hier nodig #omdat ontbrekende waarden voorkomen. Indien men de grootste observatie (81.25) vervangt door 8125 om als het ware ene tikfout voor te stellen, dan wijzigt het rekenkundig gemiddelde naar 27.5 en dat terwijl er bijna 10000 BMI metingen zijn. Merk op dat het gemiddelde vrij sterk beïnvloed kan worden door één outlier. Eigenschap Als alle uitkomsten \\(x_i\\) met een willekeurige constante \\(a\\) worden vermenigvuldigd, dan ook het gemiddelde van die reeks uitkomsten. Als bij alle uitkomsten een constante \\(a\\) wordt opgeteld, dan ook bij het gemiddelde van die reeks uitkomsten. Formeel betekent dit: \\[\\begin{eqnarray*} \\overline{ax} &amp;= &amp;a \\overline{x} \\\\ \\overline{a + x} &amp;= &amp;a + \\overline{x} \\end{eqnarray*}\\] Voor 2 reeksen getallen \\(x_i\\) en \\(y_i\\), \\(i=1,...,n\\), geldt dat het gemiddelde van de som van de observaties gelijk is aan de som van hun gemiddelden: \\[\\begin{equation*} \\overline{x + y} = \\overline{x} + \\overline{y}. \\end{equation*}\\] Als de gegevens \\(x_i\\) enkel de waarden 0 of 1 aannemen, dan is \\(\\overline{x}\\) de proportie subjecten voor wie de waarde 1 werd geobserveerd. Immers, zij \\(n_1\\) het aantal subjecten binnen de groep van \\(n\\) subjecten waarvoor de waarde 1 werd geobserveerd, dan is \\[\\begin{equation*} \\overline{x}= \\sum_{i=1}^n \\frac{x_i}{n} = \\frac{n_1}{n}. \\end{equation*}\\] Bijvoorbeeld, als we de variabele Gender zó coderen dat mannen een waarde 0 aannemen en vrouwen een waarde 1, dan is het gemiddelde van de variabele Gender gelijk aan 50.2%, hetgeen de proportie is van het aantal vrouwen in de studie. Een percentage kan dus steeds opgevat worden als het gemiddelde van een geschikte variabele. Einde eigenschap Een centrale maat die robuuster reageert dan het gemiddelde, d.w.z. minder of niet gevoelig is aan outliers, is de mediaan of het 50% percentiel. Definitie 4.3 (mediaan) De mediaan, het 50% percentiel of het 50% kwantiel \\(x_{50}\\) van een reeks waarnemingen \\(x_i, i=1, 2, \\dots, n\\) is per definitie een uitkomstwaarde \\(x_{50}\\) zodat minstens \\(50\\%\\) van die waarnemingen groter of gelijk zijn aan \\(x_{50}\\) en minstens \\(50\\%\\) van die waarnemingen kleiner of gelijk zijn aan \\(x_{50}\\). Einde definitie Om de mediaan te schatten, rangschikt men eerst de gegevens volgens grootte. Als het aantal observaties \\(n\\) oneven is, dan is een schatting voor de mediaan de middelste waarneming. Indien \\(n\\) even is, dan zijn er 2 middelste waarnemingen en schat men de mediaan (meestal) als hun gemiddelde. Een voordeel van de mediaan is dat ze niet gevoelig is aan outliers. In het bijzonder kan ze vaak nuttig aangewend worden wanneer sommige gegevens gecensureerd zijn. Dit wil zeggen dat men voor een aantal gegevens enkel weet dat ze boven of onder een bepaalde drempelwaarde liggen. median(NHANES$BMI,na.rm=TRUE) ## [1] 25.98 #Merk op dat we hier gebruik maken van het argument na.rm=TRUE #Dit komt omdat we niet beschikken over het BMI #voor elke persoon: ontbrekende waarnemingen #Die worden in R als een NA voorgesteld #Als we het argument na.rm=TRUE gebruiken wordt #de mediaan berekend op basis van de beschikbare observaties Indien men de grootste observatie (81.25) vervangt 8125, dan wijzigt de mediaan niet. Merk ook op dat de mediaan lager is dan het gemiddelde, hij is minder gevoelig voor de outliers in de dataset. Definitie 4.4 (modus) De modus van een reeks observaties is de waarde die het meest frequent is, of wanneer de gegevens gegroepeerd worden, de klasse met de hoogste frequentie. Einde definitie De modus wordt niet vaak gebruikt in statistische analyse omdat haar waarde sterk afhangt van de nauwkeurigheid waarmee de gegevens werden gemeten. Zo is de modus van de reeks observaties \\(1, 1, 1, 1.5, 1.75, 1.9, 2, 2.1, 2.4\\) gelijk aan 1, maar wordt ze 2 wanneer alle observaties afgerond worden tot gehele getallen. Bovendien is de modus niet eenvoudig te schatten voor continue data waar de frequentie van elke geobserveerde waarde meestal 1 is. De modus is daarom het meest zinvol voor kwalitatieve en discrete numerieke gegevens, waar ze de meest frequente klasse aanduidt. Als de observaties uit een symmetrische verdeling afkomstig zijn, vallen de mediaan en het gemiddelde nagenoeg samen (als de geobserveerde verdeling perfect symmetrisch is, vallen ze theoretisch exact samen). De beste schatter voor het centrum van de verdeling op basis van de beschikbare steekproef is dan het gemiddelde eerder dan de mediaan van die observaties. Inderdaad, als men telkens opnieuw een lukrake steekproef neemt uit de gegeven studiepopulatie en voor elke steekproef het gemiddelde en de mediaan berekent, dan zal het gemiddelde minder variëren van steekproef tot steekproef dan de mediaan. Ze is bijgevolg stabieler en wordt daarom een meer precieze schatter genoemd. Intuïtief kan men begrijpen dat het gemiddelde meer informatie uit de gegevens gebruikt: niet alleen of iets groter of kleiner is dan \\(x_{50}\\) maar ook hoeveel groter of kleiner de exacte waarde van elke observatie is, wordt in de berekening betrokken. Definitie 4.5 (scheve verdeling) Een niet-symmetrische verdeling wordt scheef genoemd. Als de waarden rechts van de mediaan verder uitlopen dan links, dan is de verdeling scheef naar rechts (in het Engels: positively skew) en is het gemiddelde (meestal) groter dan de mediaan. Als de waarden links van de mediaan verder uitlopen dan rechts, dan is de verdeling scheef naar links (in het Engels: negatively skew) en is het gemiddelde (meestal) kleiner dan de mediaan. Einde definitie Voor een niet-symmetrische verdeling is de mediaan veelal een beter interpreteerbare maat dan het gemiddelde omdat ze minder beïnvloed is door de staarten van de verdeling en daarom beter het centrum van de verdeling aanduidt. Maar in sommige gevallen, zoals bijvoorbeeld voor `de gemiddelde opbrengst per week’, blijft het gemiddelde zinvol omdat het meteen verwijst naar de totale opbrengst over alle weken (gelijk aan \\(n\\) keer het gemiddelde als \\(n\\) weken werden geobserveerd). Ook voor kwalitatieve variabelen kan een gemiddelde zinvol zijn. Voor binaire nominale variabelen die als 1 of 0 gecodeerd zijn, geeft het gemiddelde immers het percentage observaties gelijk aan 1 weer. Voor ordinale variabelen die bijvoorbeeld gecodeerd zijn als \\(1, 2, 3, ...\\) levert het gemiddelde soms nuttigere informatie dan de mediaan. Niettemin berust het dan op de impliciete onderstelling dat een wijziging van score van 1 naar 2 even belangrijk is als een wijziging van 2 naar 3. Om scheve verdelingen in een paar woorden te beschrijven is het vaak nuttig om ofwel de gegevens te beschrijven in termen van percentielen, ofwel de gegevens te transformeren naar een andere schaal (bvb. door logaritmen te nemen), zodat ze op de nieuwe schaal bij benadering symmetrisch verdeeld zijn. Wanneer het gemiddelde groter is dan de mediaan en alle metingen positief zijn (vb concentraties, BMI), dan is een logaritmische transformatie van de gegevens vaak nuttig om de scheefheid weg te nemen. In dit geval is vooral het geometrisch gemiddelde interessant. Definitie 4.6 (geometrisch gemiddelde) Het geometrische gemiddelde van een reeks waarnemingen \\(x_i, i=1, 2, \\dots, n\\) ontstaat door er de natuurlijke logaritme van te berekenen, het gemiddelde hiervan te nemen en dit vervolgens terug te transformeren naar de originele schaal door er de exponentiële functie van te nemen: \\[\\begin{equation*} \\exp\\left\\{\\frac{1}{n} \\sum_{i=1}^n \\log(x_i)\\right\\} \\end{equation*}\\] Einde definitie par(mfrow=c(1,2)) hist(NHANES$BMI, main=&quot;histogram van BMI&quot;,xlab=&quot;BMI&quot;) hist(log(NHANES$BMI), main=&quot;histogram van log(BMI)&quot;,xlab=&quot;log(BMI)&quot;) Figuur 4.7: Boxplot van BMI en log(BMI) in de NHANES studie. In situaties waar de log-transformatie inderdaad de scheefheid wegneemt, zal het geometrisch gemiddelde dichter bij de mediaan liggen dan het gemiddelde. Wanneer de verdeling scheef is, is ze soms zelfs een nuttigere maat voor centrale locatie dan de mediaan: omdat ze ook gebruik maakt van de exacte waarden van de observaties en daarom doorgaans preciezer is dan de mediaan; omdat ze, op een transformatie na, berekend wordt als een rekenkundig gemiddelde (weliswaar van de logaritmisch getransformeerde observaties) en algemene statistische technieken voor een gemiddelde (zoals betrouwbaarheidsintervallen (zie volgende hoofdstukken) en toetsen van hypothesen (zie volgende hoofdstukken) daardoor vrijwel rechtstreeks toepasbaar zijn voor geometrische gemiddelden. Voorbeeld 4.1 (BMI) Het gemiddelde en mediane BMI bedraagt 26.66 en 25.98 , respectievelijk. Het gemiddelde is hier groter dan de mediaan omdat de BMI scheef verdeeld is naar rechts (zie Figuur 4.7). De verdeling wordt meer symmetrisch na log-transformatie. Het gemiddelde en mediane log-BMI liggen ook dichter bij elkaar en bedragen respectievelijk 3.25 en 3.26. De geometrisch gemiddelde BMI-concentratie bekomen we door de exponentiële functie te evalueren in 3.25, hetgeen ons 25.69 oplevert. Merk op dat dit inderdaad beter met de mediaan overeenstemt dan het rekenkundig gemiddelde. **Einde voorbeeld** Tot slot, vooraleer een eenvoudige maat voor de centrale ligging (en spreiding) te construeren of interpreteren, is het goed om altijd eerst de volledige verdeling te bekijken! Immers, stel dat men het gemiddelde of mediaan berekent van gegevens uit een bimodale verdeling (d.i. een verdeling met 2 modi, voor bvb. zieken en niet-zieke dieren). Dan kan het gemiddelde of mediaan makkelijk een zeer zeldzame waarde aannemen die geenszins in de buurt van 1 van beide maxima ligt. 4.3.2 Spreidingsmaten Nadat de centrale ligging van de gegevens werd bepaald, is men in tweede instantie geïnteresseerd in de spreiding van de gegevens rond die centrale waarde. Er zijn verschillende redenen waarom daar interesse in bestaat: Om risico’s te berekenen (zie Sectie 4.4) volstaat het niet om de centrale locatie van de gegevens te kennen, maar moet men bovendien weten hoeveel de gegevens rond die waarde variëren. Inderdaad, stel dat men wenst te weten welk percentage van de subjecten een BMI heeft van boven de 35. Wetende dat een geometrisch gemiddelde van 25.69 wordt geobserveerd, zal dat percentage relatief hoog zijn wanneer de metingen zeer gespreid zijn en relatief laag anders. Veldbiologen zijn vaak geïnteresseerd in de mate waarin dieren of planten verspreid zijn over een zeker studiegebied. Op die manier kunnen ze immers leren over de relaties tussen individuen onderling en met hun omgeving. Daartoe zal men in de praktijk op verschillende plaatsen in het studiegebied tellingen maken van het aantal individuen op die plaats. Men kan aantonen dat, onder bepaalde veronderstellingen, individuen lukraak verspreid zijn over het studiegebied wanneer de spreiding op die tellingen, zoals gemeten door de variantie (zie verder), van dezelfde grootte-orde is als de gemiddelde telling. Indien de spreiding groter is, dan hebben individuen de neiging om zich te groeperen. Andersom, indien de spreiding op die tellingen lager is dan de gemiddelde telling, dan zijn de individuen zeer uniform verdeeld over het studiegebied. Stel dat men een zekere uitkomst (bvb. het aantal species ongewervelde dieren in een stuk bodemkorst) wenst te vergelijken tussen 2 groepen (bvb. gebieden met en zonder bosbrand), dan zal men een duidelijk beeld van het groepseffect krijgen wanneer de uitkomst weinig gespreid is, maar een veel minder duidelijk beeld wanneer de gegevens meer chaotisch (en dus meer gespreid) zijn. Om uit te maken of een interventie-effect toevallig of systematisch is, moet men daarom een idee hebben van de spreiding op de gegevens. Dat uitkomsten variëren tussen individuen en binnen individuen omwille van allerlei redenen ligt aan de basis van de statistische analyse van veel fenomenen. Het goed beschrijven van variatie naast de centrale locatie van de gegevens is daarom belangrijk! Hierbij zal men typisch een onderscheid maken tussen variatie die men kan verklaren (door middel van karakteristieken, zoals bijvoorbeeld de leeftijd, van de bestudeerde individuen) en onverklaarde variatie. We gaan dieper in op dit onderscheid in Hoofdstuk 6 rond lineaire regressie. Variatie betekent dat niet alle observaties \\(x_i\\) gelijk zijn aan het gemiddelde \\(\\overline{x}\\). De afwijking \\(x_i - \\bar{x}\\) is om die reden interessant. Het gemiddelde van die afwijkingen is echter altijd 0 (verifieer!) omdat positieve en negatieve afwijkingen mekaar opheffen. Bijgevolg levert de gemiddelde afwijking geen goede maat op voor de variatie en is het beter om bijvoorbeeld naar kwadratische afwijkingen \\((x_i - \\bar{x})^2\\) te kijken. Het gemiddelde van die kwadratische afwijkingen rond het gemiddelde, het gemiddelde dus van \\((x_i - \\bar{x})^2\\), levert daarom wel een goede maat op. Merk op dat we bij het berekenen van het gemiddelde niet delen door het aantal observaties \\(n\\), maar door \\(n-1\\) waarbij we corrigeren voor het feit dat we voor de berekening van de steekproef variantie 1 vrijheidsgraad hebben gespendeerd aan het schatten van het gemiddelde. Definitie 4.7 (variantie) De variantie een reeks waarnemingen \\(x_i, i=1, 2, \\dots, n\\) is per definitie \\[\\begin{equation*} s^2_x = \\sum_{i=1}^{n} \\frac{(x_i - \\bar{x})^2}{n-1} \\end{equation*}\\] Als duidelijk is om welke waarnemingen het gaat, wordt dit ook met \\(s^2\\) genoteerd. Einde definitie Indien alle observaties gelijk waren en er dus geen variatie was, dan zou hun variantie 0 bedragen. Hoe meer de gegevens uitgesmeerd zijn rond hun gemiddelde, hoe groter \\(s^2\\). Helaas is de waarde van de variantie zelf niet gemakkelijk te interpreteren. Dit is deels omdat door het kwadrateren de variantie niet langer de dimensie van de oorspronkelijke waarnemingen heeft. Handiger om mee te werken is daarom de standaarddeviatie of standaardafwijking: \\[\\begin{equation*} s_x= \\sqrt{s_x^2} . \\end{equation*}\\] De standaarddeviatie is gedefinieerd voor elke numerieke variabele, maar is vooral nuttig omdat voor heel wat variabelen (in het bijzonder Normaal verdeelde variabelen - zie Sectie 4.4) bij benadering 68% van de waarnemingen liggen tussen \\(\\bar{x} - s_x\\) en \\(\\bar{x} + s_x\\), en 95% van de waarnemingen liggen tussen14 \\(\\bar{x} - 2 s_x\\) en \\(\\bar{x} + 2 s_x\\). Deze intervallen noemt men respectievelijk 68% en 95% referentie-intervallen. Het is precies deze eigenschap die de standaarddeviatie zo nuttig maakt in de praktijk. De standaarddeviatie van een reeks waarnemingen wordt vaak afgekort als SD in de wetenschappelijke literatuur. Eigenschap Als alle uitkomsten \\(x_i\\) met een willekeurige constante \\(a\\) worden vermenigvuldigd, dan wordt hun variantie vermenigvuldigd met \\(a^2\\) en hun standaarddeviatie met \\(|a|\\) (de absolute waarde van \\(a\\)). Als bij alle uitkomsten \\(a\\) wordt opgeteld, wijzigen hun variantie en standaarddeviatie niet. Einde eigenschap # Het gebruik van functie sd() levert de standarddeviatie # van de variabele BMI in de NHANES dataset. # Het na.rm=TRUE argument wordt gebruikt omdat er # ontbrekende waarnemingen voorkomen. sd(NHANES$BMI,na.rm=TRUE) ## [1] 7.376579 # levert de variantie van de variabele BMI var(NHANES$BMI,na.rm=TRUE) ## [1] 54.41392 Wanneer een variabele niet Normaal verdeeld is (dit is bijvoorbeeld het geval voor het BMI gezien het niet symmetrisch verdeeld is), dan geldt niet langer dat bij benadering 95% van de waarnemingen ligt tussen \\(\\bar{x} - 2 s\\) en \\(\\bar{x} + 2 s\\). Een symmetrische maat voor de spreiding van de gegevens, zoals de standaarddeviatie, is dan niet langer interessant. In dat geval zijn de range en interkwantielafstand betere maten. Definitie 4.8 (bereik en interkwartielafstand) Het bereik of de range \\(R_x\\) van een reeks waarnemingen \\(x_i, i=1,2,...,n\\), is per definitie het verschil tussen de grootste en kleinste geobserveerde waarde. De interkwartielafstand van een reeks waarnemingen \\(x_i, i=1,2,...,n\\) is per definitie de afstand tussen het derde kwartiel \\(x_{75}\\) en het eerste kwartiel \\(x_{25}\\). Dat wordt ook grafisch weergegeven op een boxplot (breedte van de box). Hierbinnen liggen circa 50% van de observaties. Circa 95% van de observaties kan men vinden tussen het 2.5% en 97.5% percentiel. Einde definitie Het bereik is zeer gevoelig voor outliers en is systematisch afhankelijk van het aantal observaties: hoe groter \\(n,\\) hoe groter men \\(R_x\\) verwacht. Om die reden vormt een interkwartielafstand een betere maat voor de spreiding van de gegevens dan de range. Tenslotte is het vaak zo dat de gegevens meer gespreid zijn naarmate hun gemiddelde hogere waarden aanneemt. De variatiecoëfficiënt=\\(VC_x\\) standaardiseert daarom de standaarddeviatie door ze uit te drukken als een percentage van het gemiddelde \\[\\begin{equation*} VC_x = \\frac{s_x}{\\bar{x}} 100\\%. \\end{equation*}\\] Omdat ze gestandaardiseerd is, dient ze beter dan de standaarddeviatie zelf om de spreiding op de gegevens te vergelijken tussen populaties met een verschillend gemiddelde. De variatiecoëfficiënt heeft verder de aantrekkelijke eigenschap dat ze geen eenheden heeft en ongevoelig is voor herschaling van de gegevens (d.w.z. wanneer alle gegevens met een constante \\(a\\) worden vermenigvuldigd, dan is \\(VC_{ax}=VC_x\\)). 4.4 De Normale benadering van gegevens Bij biologische en chemische data is het vaak zo dat het histogram van een continue meting bij verschillende subjecten de karakteristieke vorm heeft van de Normale verdeling, die geïllustreerd wordt in Figuur 4.8 (linksboven). Dat is bijvoorbeeld zo als men een histogram maakt van het logaritme van de totale cholestorol. Rond 1870 opperde de wereldberoemde Belg Adolphe Quetelet (die tevens de eerste student was die een doctoraat behaalde aan de Universiteit Gent) de idee om deze curve als `ideaal histogram’ te gebruiken voor de voorstelling en vergelijking van gegevens. Dit zal handig blijken om meer inzicht te krijgen in de gegevens op basis van een minimum aantal samenvattingsvatten, zoals het gemiddelde en de standaarddeviatie die vaak in wetenschappelijke rapporten vermeld staan. Figuur 4.8: De Normale dichtheidsfunctie (boven, links), de Normale distributiefunctie (boven, rechts), de Uniforme dichtheidsfunctie (onder, links) en de Uniforme distributiefunctie (onder, rechts). 4.4.1 Bepalen van oppervlaktes onder de Normale curve De Normale curve of Normale dichtheidsfunctie wordt gegeven door: \\[\\begin{equation*} f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi} } \\exp \\left ( - \\frac{ (x - \\mu)^2 }{ 2 \\sigma^2} \\right ). \\end{equation*}\\] Ze wordt beschreven door 2 onbekende parameters \\(\\mu\\) en \\(\\sigma\\), waarbij \\(\\mu\\) het gemiddelde van de verdeling van de observaties aangeeft en \\(\\sigma\\) de standaarddeviatie. Deze curve geeft voor elke waarde \\(x\\) weer hoe frequent deze waarde, relatief gezien, voorkomt. De notatie \\(\\pi\\) verwijst naar het getal \\(\\pi=3.1459...\\) Wanneer het gemiddelde 0 is en de variantie 1, spreekt men van de standaardnormale curve of standaardnormale dichtheidsfunctie. Een lukrake observatie uit een reeks gegevens wiens verdeling de Normale curve volgt, wordt een Normaal verdeelde observatie genoemd. Dergelijke observaties komen frequent voor: voor heel wat reeksen gegevens die symmetrisch verdeeld zijn, vormt de Normale curve met \\(\\mu\\) gelijk aan \\(\\bar x\\) en \\(\\sigma\\) gelijk aan \\(s_x\\) immers een goede benadering voor het histogram. Voor Normaal verdeelde gegevens geeft de oppervlakte onder de Normale curve tussen 2 willekeurige getallen \\(a\\) en \\(b\\) het percentage van de observaties weer dat tussen deze 2 getallen gelegen is. Op die manier laat de Normale curve toe om, enkel op basis van kennis van het gemiddelde en de standaarddeviatie, na te gaan welk percentage van de gegevens bij benadering tussen 2 willekeurige getallen \\(a\\) en \\(b\\) gelegen is. Om deze berekening uit te voeren, gaan we als volgt te werk. Zij \\(X\\) een lukrake meting uit een reeks Normaal verdeelde gegevens met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\). Dan noteren we met \\(P(X\\leq b)\\) de oppervlakte onder de Normale curve die links van \\(b\\) gelegen is, en met \\(P(a\\leq X\\leq b)\\) de oppervlakte onder de Normale curve tussen \\(a\\) en \\(b\\). Hierbij is15 \\[\\begin{equation*} P(a\\leq X\\leq b)=P(X\\leq b)-P(X\\leq a) \\end{equation*}\\] Om \\(P(a\\leq X\\leq b)\\) te berekenen, hebben we dus enkel een strategie nodig om voor een willekeurig getal \\(x\\), het getal \\(F(x) = P(X \\leq x)\\) uit te rekenen. Dit staat uitgezet in functie van \\(x\\) in Figuur 4.8 (rechtsboven) voor \\(\\mu=80\\) en \\(\\sigma=12\\) en wordt een distributiefunctie genoemd. Definitie 4.9 (distributiefunctie) De functie die voor elk getal \\(x\\) uitdrukt wat de kans is dat een lukrake meting \\(X\\) met gekende verdeling (bvb. een Normale verdeling) kleiner of gelijk is aan \\(x\\), wordt de distributiefunctie van die verdeling genoemd. Einde definitie Omdat de Normale dichtheidsfunctie zeer complex is, blijkt dat het getal \\(F(x)\\) niet expliciet uit te rekenen is. Om die reden heeft men de getallen \\(F(x)\\) voor de standaardnormale verdelingsfunctie getabuleerd. Voor deze standaardnormale curve duidt men voor een willekeurige waarde \\(z\\), het getal \\(F(z)\\) met \\(\\Phi(z)\\) aan. Omwille van de symmetrie rond 0 van de standaardnormale curve kan de waarde van \\(\\Phi(-z)\\) dan uit de waarde van \\(\\Phi(z)\\) worden afgeleid als \\[\\begin{equation*} \\Phi(-z)= 1- \\Phi(z) \\end{equation*}\\] Deze uitdrukking geeft aan dat voor een reeks standaardnormaal verdeelde metingen, het percentage dat kleiner is dan \\(-z\\) gelijk is aan het percentage dat groter is dan \\(z\\). Om nu \\(P(a\\leq X\\leq b)\\) te berekenen op basis van de tabellen voor de standaardnormale verdeling gaan we als volgt te werk. Vooreerst kan men aantonen dat het resultaat van een lineaire transformatie \\(aX+b\\) op een Normaal verdeelde meting \\(X\\) met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\) terug een Normaal verdeelde meting toevalsveranderlijke is, maar nu met gemiddelde \\(a\\mu+b\\) en standaarddeviatie \\(|a|\\sigma\\). Op die manier kan men elke Normaal verdeelde meting met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\) omzetten naar een standaardnormale meting door ze als volgt te standaardiseren: \\[\\begin{equation*} Z = \\frac{X- \\mu}{\\sigma} \\end{equation*}\\] Verifieer dat \\(Z\\) inderdaad gemiddelde 0 en standaarddeviatie 1 heeft! Aangezien voor een willekeurig getal \\(x\\) \\[\\begin{equation*} X\\leq x \\Leftrightarrow \\frac{X-\\mu}{\\sigma} \\leq \\frac{x-\\mu}{\\sigma} \\end{equation*}\\] vinden we nu dat \\[\\begin{eqnarray*} P(a \\leq X \\leq b) &amp; = &amp; P\\left(\\frac{a-\\mu}{\\sigma} \\leq Z \\leq \\frac{b-\\mu% }{\\sigma} \\right) \\\\ &amp; = &amp; \\Phi \\left (\\frac{b-\\mu}{\\sigma} \\right ) - \\Phi \\left (\\frac{a-\\mu}{% \\sigma} \\right ) \\end{eqnarray*}\\] De getallen \\(\\Phi \\left (\\frac{b-\\mu}{\\sigma} \\right )\\) en \\(\\Phi \\left (\\frac{a-\\mu}{\\sigma} \\right )\\) kunnen hierbij rechtstreeks uit tabellen of R software worden gehaald. In het vervolg zullen we algemeen de notatie \\(Z\\) gebruiken om een standaardnormaal verdeelde meting aan te duiden. Oefening 4.1 Een labo bepaalt in een visstaal Hg via een methode op basis van AAS. In werkelijkheid bevat het staal (gemiddeld) 1.90 ppm. De meetmethode is echter niet perfect, zoals aangegeven door een standaarddeviatie van 0.10 ppm. Wat is de kans dat de laborant die het staal onderzoekt, een meetresultaat van 2.10 ppm of meer vaststelt? Om op deze vraag te antwoorden, noteren we met \\(X\\) het meetresultaat van de laborant en berekenen we \\[\\begin{eqnarray*} P(X\\geq 2)&amp;=&amp;P\\left(\\frac{X-\\mu}{\\sigma}\\geq \\frac{2.1-1.9}{0.1}\\right) \\\\ &amp;=&amp;P(Z\\geq 2) = 2.28\\% \\end{eqnarray*}\\] We besluiten dat er 2.28% kans is dat de laborant een meetresultaat van minstens 2.10 ppm zal vaststellen. In R kan dit resultaat als volgt bekomen worden: 1 - pnorm(2.1, mean = 1.9, sd = 0.1) ## [1] 0.02275013 waarbij de functie pnorm de distributiefunctie van de Normale verdeling voorstelt. **Einde oefening** Met \\(z_{\\alpha}\\) duiden16 we die waarde aan waar \\(\\alpha100\\%\\) van de oppervlakte onder de standaardnormale curve rechts van zit; m.a.w. waarvoor geldt dat \\(P(Z \\geq z_{\\alpha}) = \\alpha\\). Als \\(Z\\) een standaardnormaal verdeelde meting is, dan stelt \\(z_{\\alpha}\\) bijgevolg het \\((1-\\alpha)100\\%\\) percentiel van die verdeling voor. Voor \\(z_{\\alpha/2}\\) geldt dat \\(P(-z_{\\alpha/2}\\leq Z \\leq z_{\\alpha/2}) = 1-\\alpha\\). Bijvoorbeeld, \\(P( - z_{0.025}\\leq Z \\leq z_{0.025}) = 95\\%\\). Voor een reeks standaardnormaal verdeelde metingen bevat het interval \\([-z_{\\alpha/2},z_{\\alpha/2}]\\) dus \\((1-\\alpha)100\\%\\) van de observaties. Stel dat \\(X\\) een Normaal verdeelde meting is met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\). Dan geldt dat \\[\\begin{equation*} P\\left( - z_{\\alpha/2}\\leq \\frac{X - \\mu}{\\sigma} \\leq z_{\\alpha/2}\\right) = 1-\\alpha . \\end{equation*}\\] Hieruit volgt dat \\[\\begin{equation*} P( \\mu - z_{\\alpha/2} \\sigma \\leq X \\leq \\mu + z_{\\alpha/2} \\sigma ) = 1-\\alpha . \\end{equation*}\\] Voor een reeks Normaal verdeelde metingen met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\) bevat het interval \\([\\mu-z_{\\alpha/2}\\sigma,\\mu+z_{\\alpha/2}\\sigma]\\) dus \\((1-\\alpha)100\\%\\) van de observaties. In de praktijk worden de parameters \\(\\mu\\) en \\(\\sigma\\) hierbij vervangen door \\(\\bar x\\) en \\(s_x\\). Het resulterende interval \\([\\bar x-z_{\\alpha/2}s_x,\\bar x+z_{\\alpha/2}s_x]\\) wordt vaak gebruikt17, o.a. in de klinische chemie, om referentie-intervallen te berekenen voor een test ter opsporing van een bepaalde pathologie. Eenmaal zo’n referentie-interval, ook wel normaal interval genoemd, werd bepaald, wordt het testresultaat van een patiënt met de vermoede pathologie vergeleken met het interval. Een resultaat buiten het interval is dan indicatief voor de aanwezigheid van de pathologie. Bij het bepalen van referentie-intervallen is het noodzakelijk om de methode eerst te testen bij mensen zonder de pathologie in kwestie. Voor dit doel worden `normale en gezonde vrijwilligers’ aangezocht. Vaak worden hiertoe collega’s genomen uit het laboratorium dat de test heeft ontwikkeld, hoewel dit allesbehalve ideaal is. Immers, mensen die in een zelfde laboratorium werken, zijn blootgesteld aan dezelfde werkomgeving, die op zijn beurt een invloed kan hebben op hun bloedsamenstelling. Bijgevolg is de bloedsamenstelling van de studiepersonen mogelijks niet representatief voor een normale, gezonde populatie, hetgeen kan leiden tot vertekende referentie-intervallen. In deze cursus zullen we een referentie-interval meer algemeen als volgt definiëren. Definitie 4.10 (referentie-interval) Een \\((1-\\alpha)100\\%\\) referentie-interval voor een veranderlijke \\(X\\) (bvb. albumine-concentratie in het bloed) in een gegeven studiepopulatie (bvb. volwassen Belgen onder de 60 jaar) is een interval dat zó gekozen werd dat het met \\((1-\\alpha)100\\%\\) kans de observatie voor een lukraak individu uit die populatie bevat. Voor een Normaal verdeelde veranderlijke \\(X\\) met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\) kan dit berekend worden als \\[\\begin{equation*} [\\mu-z_{\\alpha/2}\\sigma,\\mu+z_{\\alpha/2}\\sigma] \\end{equation*}\\] en geschat worden op basis van een lukrake steekproef als \\[\\begin{equation*} [\\bar x-z_{\\alpha/2}s_x,\\bar x+z_{\\alpha/2}s_x] \\end{equation*}\\] Einde definitie Voorbeeld 4.2 (Referentie-intervallen) In het Hoofdstuk 5 statistische besluitvorming handelt de centrale dataset rond een studie naar het effect van het toedienen van een bloeddrukverlagend middel captopril. Alvorens de studie aan te vangen dient men eerst een grenswaarde voor normale bloeddrukwaarden op te stellen om subjecten met normale bloeddrukken van patiënten met hypertensie te kunnen onderscheiden. We zullen hiervoor gebruik maken van een subset van de NHANES studie. In Figuur 4.9 links wordt een histogram gegeven van alle bloeddruk waarden voor subjecten tussen de 40 en 65 jaar. Rechts wordt het histogram weergegeven voor gezonde subjecten tussen de 40 en 65 jaar, waarbij gezonde personen werden geselecteerd op basis van hun BMI klasse, rokers, status algemene gezondheidsstatus, slaapproblemen, of ze aan diabetes lijden en ze in het verleden hard drugs gebruikten. #verwijderen van alle subjecten met ontbrekende waarnemingen NHANES2=subset(NHANES,!is.na(Race1)&amp;!is.na(Smoke100n)&amp;!is.na(BMI_WHO)%in%!is.na(Age)&amp;!is.na(HardDrugs)&amp;!is.na(HealthGen)&amp;!is.na(Gender)&amp;!is.na(AlcoholYear)&amp;!is.na(BPSys1)&amp;!is.na(BPSys2)&amp;!is.na(BPSys3)&amp;!is.na(SleepTrouble)) NHANES2$bpSys=rowMeans(NHANES2[,c(27,29,31)]) #subset van de personen tussen 40 en 65 jaar nhanesSub=subset(NHANES2, Age&lt;=65&amp;Age&gt;=40 &amp;!duplicated(ID) ) #De == operator resulteert in een bolean (FALSE of TRUE) # de &amp; operater is een logische AND #subset van gezonde personen nhanesSubHealthy=subset(nhanesSub,Smoke100n==&quot;Non-Smoker&quot;&amp;Diabetes==&quot;No&quot;&amp;as.double(BMI_WHO)%in%c(2,3)&amp;HardDrugs==&quot;No&quot;&amp;HealthGen!=&quot;Poor&quot;&amp;SleepTrouble==&quot;No&quot;) par(mfrow=c(1,2)) hist(nhanesSub$bpSys,xlab=&quot;Systolische bloeddruk (mm Hg)&quot;,main=&quot;Personen tussen 40-65 jaar&quot;) hist(nhanesSubHealthy$bpSys,xlab=&quot;Systolische bloeddruk (mm Hg)&quot;,main=&quot;Gezonde personen tussen 40-65 jaar&quot;) Figuur 4.9: Systolische bloeddruk bij personen tussen de 40 en 65 jaar oud. De systolische bloeddruk voor gezonde personen is symmetrisch en we zullen later aantonen dat deze approximatief normaal verdeeld zijn. Als het gemiddelde en de standard deviatie van de bloeddruk in de populatie gekend zijn kunnen we normale bloeddrukwaarden afleiden. In de praktijk zijn deze typisch niet gekend en worden deze geschat op basis van de data. In de gezonde subset is het steekproefgemiddelde 119.5mmHg en de standaarddeviatie 14.1mmHg. Als we het populatiegemiddelde en het populatiestandaarddeviatie door deze schattingen vervangen dan bekomen we volgend referentie interval: [91.9, 147]mmHg. Merk ook op dat de bovengrens van de normale systolische bloeddruk iets boven de grens van hypertensie van 140 mmHg ligt die in de literatuur wordt gehanteerd. **Einde voorbeeld** mean(nhanesSubHealthy$bpSys)+qnorm(c(0.025,0.975))*sd(nhanesSubHealthy$bpSys) ## [1] 91.88971 147.03393 4.4.2 QQ-plots Hoewel heel wat metingen in de biologische wetenschappen en scheikunde, zoals concentraties van een bepaalde stof, scheef verdeeld zijn naar rechts, worden ze door het nemen van een logaritme vaak getransformeerd naar gegevens waarvoor het histogram de vorm heeft van een Normale dichtheidsfunctie. Dit is uiteraard niet altijd zo en stappen om te verifiëren of observaties Normaal verdeeld zijn, zijn daarom van groot belang om de technieken in Sectie 4.4.1 te kunnen gebruiken, alsook heel wat technieken uit de verdere hoofdstukken die er zullen van uit gaan dat de gegevens Normaal verdeeld zijn. Hoewel een vergelijking van het histogram van de gegevens met de vorm van de Normale curve wel inzicht geeft of de gegevens al dan niet Normaal verdeeld zijn, is dit vaak niet makkelijk te zien en wordt de uiteindelijke beslissing nogal makkelijk beïnvloed door de keuze van de klassebreedtes op het histogram. Om die reden zullen we kwantielgrafieken gebruiken die duidelijker toelaten om na te gaan of gegevens Normaal verdeeld zijn. QQ-plots of kwantielgrafieken (in het Engels: quantile-quantile plots) zijn grafieken die toelaten te verifiëren of een reeks observaties lukrake trekkingen zijn uit een Normale verdeling. Met andere woorden, ze laten toe om na te gaan of een reeks observaties al dan niet de onderstelling tegenspreken dat ze realisaties zijn van een reeks Normaal verdeelde gegevens. Het principe achter deze grafieken is vrij eenvoudig. Verschillende percentielen die men heeft berekend voor de gegeven reeks observaties worden uitgezet t.o.v. de overeenkomstige percentielen die men verwacht op basis van de Normale curve. Als de onderstelling correct is dat de gegevens Normaal verdeeld zijn, dan komen beide percentielen telkens vrij goed met elkaar overeen en verwacht men bijgevolg een reeks puntjes min of meer op een rechte te zien (zoals in Figuur 4.10, rechtsboven). Systematische afwijkingen van een rechte wijzen op systematische afwijkingen van Normaliteit. Lukrake afwijkingen van een rechte kunnen het gevolg zijn van toevallige biologische variatie en zijn daarom niet indicatief voor afwijkingen van Normaliteit. We gebruiken hiervoor de functie qqPlot uit het package car. De qqPlot functie geeft op de figuur ook banden weer waarbinnen punten uit de normaal verdeling met een kans van 95% kunnen worden verwacht. ## [1] 60 235 Figuur 4.10: Histogrammen (links) en bijhorende kwantielgrafieken (rechts) voor een aantal verdelingen. ## [1] 150 181 Het berekenen van de percentielen die men verwacht op basis van de Normale curve verloopt vrij eenvoudig. Beschouw bijvoorbeeld \\(4n-1\\) geordende observaties \\(x_1,...,x_{4n-1}\\). Dan is \\(x_{2n}\\) de bijhorende mediaan en is \\(\\mu\\) de mediaan die men verwacht voor een Normaal verdeelde meting met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\). Analoog is \\(x_n\\) het \\(25\\%\\)-percentiel van de gegeven reeks observaties en is \\(\\mu-z_{0.25}\\sigma=\\mu-0.674\\sigma\\) het \\(25\\%\\)-percentiel dat men verwacht voor een Normaal verdeelde meting met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\). Algemeen is voor \\(k=1,...,4n-1\\) en \\(p=k/4n\\), \\(x_k\\) het \\(p 100\\%\\)-percentiel van de gegeven reeks observaties en \\(\\mu-z_{p}\\sigma\\) het overeenkomstige \\(p 100\\%\\)-percentiel van een Normaal verdeelde meting met gemiddelde \\(\\mu\\) en standaarddeviatie \\(\\sigma\\). Omdat \\(\\mu\\) en \\(\\sigma\\) ongekend zijn, kiest men er meestal voor om de percentielen voor de gegeven reeks observaties uit te zetten t.o.v. de gestandaardiseerde percentielen voor de Normale verdeling. Men bekomt deze laatste door de percentielen \\(\\mu-z_{p}\\sigma\\), die berekend werden voor de Normale verdeling, te standaardiseren. Aldus bekomt men een grafiek waar men voor elke \\(k=1,...,4n-1\\) het percentiel \\(x_k\\) uitzet t.o.v. \\(-z_{p}=z_{1-p}\\) met \\(p=k/4n\\). Het resultaat wordt voor een aantal fictieve datasets weergegeven in Figuur 4.10 (rechts) en noemt men een QQ-plot. De gegevens in Figuur 4.10, rij 1, zijn met een computer gesimuleerd als lukrake trekkingen uit een grote reeks Normaal verdeelde observaties. Zoals verwacht liggen de gegevens in bijhorende QQ-plot nagenoeg op een rechte lijn. Door toevallige variatie is dit geen perfecte rechte lijn, maar kunnen geen systematische afwijkingen van een rechte worden vastgesteld. Dit geeft een suggestie dat de onderstelling van een Normale verdeling hier vermoedelijk voldaan is. In Figuur 4.10 (onder, rechts) stellen we een systematische afwijking van een rechte lijn vast. Op de X-as vinden we de gestandaardiseerde percentielen die worden verwacht voor een Normale verdeling en op de Y-as vinden we de observaties zelf. Merk op dat kleine observaties minder gespreid zijn dan Normaal verdeelde gegevens en dat hoge waarden meer gespreid zijn. Dit wijst erop dat hun verdeling scheef is naar rechts, zoals men ook kan zien op basis van het histogram Figuur 4.10 (onder, links). Het grote voordeel van een QQ-plot (in vergelijking met een histogram) om afwijkingen van Normaliteit te detecteren, is dat ze dergelijke afwijkingen duidelijker weergeeft dan een histogram. Hetzelfde principe als voor Normaal verdeelde observaties kan ook herhaald worden voor andere theoretische verdelingen, die we later in deze cursus zullen ontmoeten. Bijvoorbeeld kan men analoge kwantielgrafieken opstellen voor de Poissonverdeling (verdeling voor tellingen) om na te gaan of een reeks observaties lukrake trekkingen vormen uit zo’n Poissonverdeling. Voorbeeld 4.3 (NHANES vervolg) ## [1] 260 238 ## [1] 255 56 Figuur 4.11: Kernel density schatters (boven) een QQ-plots (onder) voor de systolische bloeddruk en directe HDL cholestorol bij de subset van gezonde personen tussen de 40 en 65 jaar. ## [1] 255 71 De QQ-plot in Figuur 4.11 (links onder) geeft aan dat de systolische bloeddruk bij gezonde personen bij benadering Normaal verdeeld is, hetgeen bevestigd wordt door het histogram met de kernel density schatter (links boven). Op basis van het gemiddelde van 119.5mmHg en de standaarddeviatie van 14.1 mmHg kunnen we aldus besluiten dat 95% van de bloeddruk waarden gelegen zijn tussen de [91.9,147] mmHg. De QQ-plot in Figuur 4.11 (midden en rechts) geeft aan dat de directe cholestorol bij gezonde personen tussen de 40 en 65 jaar duidelijk scheef verdeeld is en dat de Normale benadering beter wordt na log-transformatie. De log-cholestorol is gemiddeld 0.37 en heeft een standaarddeviatie van 0.29. We kunnen bij benadering stellen dat 95% van de log-bloeddrukken liggen tussen [-0.19,0.93]. Bijgevolg verwachten we benadering 95% van de cholestorol metingen tussen \\(\\exp(-0.27)=0.76\\) en \\(\\exp(0.85)=2.34\\) \\(\\mu\\)mol/l. Deze wijken ietwat af van de overeenkomstige 2.5% en 97.5% percentielen [0.87, 2.52] \\(\\mu\\)mol/l deels doordat steekproefpercentielen minder precies (lees: minder stabiel) zijn dan schattingen die men ervoor bekomt op basis van de Normale verdeling. **Einde voorbeeld** 4.5 Samenvattingsmaten voor categorische variabelen De samenvattingsmaten uit de vorige sectie (gemiddelde, mediaan, standaarddeviatie, …) kunnen niet zomaar toegepast worden voor de beschrijving van categorische variabelen. In deze sectie gaan we hier dieper op in, daarbij onderscheid makend tussen enerzijds gegevens die uit prospectieve studies of lukrake steekproeven afkomstig zijn, en anderzijds gegevens uit retrospectieve studies. 4.5.1 Prospectieve studies en lukrake steekproeven Voorbeeld 4.4 (Houtluizen) Een bioloog verzamelt `s nachts bladerafval op een lukrake plaats van 1 m\\(^2\\) in 2 wouden, waarvan 1 met klei- en 1 met kalkgrond. Op elke plaats telt hij het aantal houtluizen van de species Armadilidium of Oniscus, met als doel na te gaan of de ene soort vaker voorkomt op kleigrond dan op kalkgrond18. Tabel 4.2 toont de bekomen gegevens. Hier stelt \\(a\\) (\\(c\\)) het aantal houtluizen van de soort Armadilidium (Oniscus) voor op kleigrond, en \\(b\\) (\\(d\\)) het aantal houtluizen van de soort Armadilidium (Oniscus) op kalkgrond. Tabel 4.2: Kruistabel van species houtluis versus type grond. Armadil. Oniscus Totaal Klei 14 (a) 6 (c) 20 (a+c) Kalk 22 (b) 46 (d) 68 (b+d) Totaal 36 (a+b) 52 (c+d) 88 (n) **Einde voorbeeld** Er zijn verschillende manieren om de resultaten van deze studie te beschrijven. De kans dat 1 van beide species houtluizen van de soort Armadilidium is, is \\(p_{kl}=a/(a+c)=0.70\\) of 70% op kleigrond en \\(p_{ka}=b/(b+d)=0.32\\) of 32% op kalkgrond. Definitie 4.11 (absolute risico verschil) Het absolute risico verschil of absolute kansverschil op een gegeven gebeurtenis (bvb. om Armadilidium aan te treffen) voor populatie T (Test, bvb. kleigrond) versus C (Controle, bvb. kalkgrond) wordt met ARV genoteerd en gedefinieerd als het verschil \\[\\begin{equation*} ARV=p_T-p_C \\end{equation*}\\] tussen de kansen dat deze gebeurtenis zich voordoet in populaties T en C. Einde definitie Het ARV op Armadilidium tussen klei- en kalkgrond bedraagt 0.38, hetgeen suggereert dat de kans dat 1 van beide species houtluizen van de soort Armadilidium is, 38% hoger is op kleigrond dan op kalkgrond. Een absoluut kansverschil van 0 drukt uit dat de overeenkomstige kansen even groot zijn in beide populaties en dat beide populaties dus vergelijkbaar zijn in termen van de bestudeerde uitkomst. Het absolute kansverschil zegt echter niet alles omtrent het bestudeerde effect. Een kansverschil kan immers een grotere impact hebben alnaargelang beide proporties \\(p_T\\) en \\(p_C\\) dicht bij 0 of 1 liggen, dan wanneer ze in de buurt van 0.5 liggen. Bijvoorbeeld, wanneer we de proportie vrouwen jonger dan 60 jaar meten die borstkanker ontwikkelen, is een risicoverschil tussen \\(p_A=0.01\\) voor vrouwen die het allel Leu/Leu bezitten op het BRCA1 gen en \\(p_B=0.001\\) voor de overige vrouwen, wellicht belangrijker dan een verschil tussen \\(p_C=0.41\\) en \\(p_D=0.401\\) voor beide populaties. Een uitspraak dat het risico 0.9% lager is in de ene dan in de andere populatie geeft om die reden slechts een beperkt beeld van het belang van die reductie. Een goede vergelijking van risico’s, kansen of percentages moet om die reden ook rekening houden met het basisrisico (d.w.z. de kans op de bestudeerde uitkomst in een referentiepopulatie). Het ARV doet dit niet, in tegenstelling tot volgende associatiemaat. Definitie 4.12 (relatief risico) Het relatief risico op een gegeven gebeurtenis (bvb. om Armadilidium aan te treffen) voor populatie T (Test, bvb. kleigrond) versus C (Controle, bvb. kalkgrond) wordt met RR genoteerd en gedefinieerd als het quotiënt \\[\\begin{equation*} RR=\\frac{p_T}{p_C} \\end{equation*}\\] van de kansen dat deze gebeurtenis zich voordoet in populaties T en C. Einde definitie In de studie naar houtluizen bedraagt dit \\(RR=0.70/0.32=2.2\\). Dit suggereert dat er 2.2 keer zoveel kans om een houtluis van de soort Armadilidium (i.p.v. Oniscus) aan te treffen op kleigrond dan op kalkgrond. Een relatief risico van 1 drukt uit dat beide populaties dus vergelijkbaar zijn in termen van de bestudeerde uitkomst. Een nadeel van het relatief risico is dat ze, in tegenstelling tot het absolute risico verschil, niet goed duidelijk maakt hoeveel meer individuen de bestudeerde uitkomst ondervinden in de ene dan in de andere populatie. Bijvoorbeeld, zelfs wetende dat het relatief risico op Armidilidium in klei-versus kalkgrond 2.2 bedraagt, is het niet mogelijk om uit te maken hoeveel meer houtluizen van de soort Armidilidium zich manifesteren op kleigrond. Als de kans om Armidilidium aan te treffen i.p.v. Oniscus 0.1% bedraagt op kalkgrond, dan verwacht men dat er per 10000 houtluizen (van de soort Armidilidium of Oniscus) er 10 van de soort Armidilidium zullen zijn op kalkgrond en 22 op kleigrond, wat neerkomt op een verwaarloosbaar verschil van 12. Als de kans om Armidilidium aan te treffen i.p.v. Oniscus 40% bedraagt op kalkgrond, dan verwacht men dat er per 10000 houtluizen (van de soort Armidilidium of Oniscus) er 4000 van de soort Armidilidium zullen zijn op kalkgrond en 8800 op kleigrond, wat neerkomt op een aanzienlijk verschil van 4800. Soms rapporteert men in de plaats van het relatief risico, het relatieve risico verschil \\(ARV/p_C=RR-1\\). Voor de gegeven studie bedraagt dit 1.2. Het drukt uit dat de toename (van kalk- naar kleigrond) in kans om Armadilidium aan te treffen succes meer dan 1 keer zo groot is als het basisrisico in de controlegroep (kalkgrond). Merk op dat alle bovenstaande associatiematen eveneens gebruikt kunnen worden wanneer men, in tegenstelling tot wat in een prospectieve studie gebeurt, een volledig lukrake groep proefpersonen selecteert zonder vast te leggen hoeveel van hen al dan niet blootgesteld zijn. 4.5.2 Retrospectieve studies Beschouw de case-controle studie uit Voorbeeld 3.16, waarvan de gegevens samengevat zijn in Tabel 4.3. Omdat men in zo’n design op zoek gaat naar \\(a+b+c\\) lukraak gekozen controles en \\(d+e+f\\) lukraak gekozen cases, liggen de marges \\(a+b+c\\) en \\(d+e+f\\) vast en is het bijgevolg onmogelijk om het risico op case (bvb. risico op borstkanker) te schatten. Dit is noch mogelijk binnen de totale groep, noch binnen de groep van blootgestelden (d.i. vrouwen met allel Leu/Leu), noch binnen de groep niet-blootgestelden. Immers, de kans op case binnen die geobserveerde groep reflecteert hoofdzakelijk de verhouding waarin cases en controles in totaal werden gekozen door het design. Alleen analyses die de kolomtotalen in de tabel vast gegeven veronderstellen, zijn hier zinvol. Dit heeft tot gevolg dat het relatief risico op de aandoening (d.w.z. op case) in de populatie voor blootgestelden versus niet-blootgestelden niet rechtstreeks kan geschat worden op basis van gegevens uit een case-controle studie. Analoog kan ook het bijhorende absolute risicoverschil niet geschat worden. Tabel 4.3: Kruistabel van borstkanker-status versus BRCA1-allel. Genotype Controles Cases Totaal Pro/Pro 266 (a) 342 (d) 608 (a+d) Pro/Leu 250 (b) 369 (e) 619 (b+e) Leu/Leu 56 (c) 89 (f) 145 (c+f) Totaal 572 (a+b+c) 800 (d+e+f) 1372 (n) Wel heeft men informatie over de kans om het allel Leu/Leu aan te treffen bij cases, \\(\\pi_1=f/(d+e+f)=89/800=11.1\\%\\), en de kans op het allel Leu/Leu bij controles, \\(\\pi_0=c/(a+b+c)=56/572=9.8\\%\\). Het relatief risico op blootstelling voor cases versus controles is bijgevolg \\(11.1/9.8=1.14\\). Vrouwen met borstkanker hebben dus 14% meer kans om de allelcombinatie Leu/Leu te hebben op het BRCA1 gen dan vrouwen zonder borstkanker. Dit suggereert dat er een associatie19 is tussen het polymorfisme op het BRCA1 gen en borstkanker, maar drukt helaas niet uit hoeveel hoger het risico op borstkanker is voor vrouwen met de allelcombinatie Leu/Leu dan voor andere vrouwen. Om toch een antwoord te vinden op deze laatste vraag, voeren we een nieuwe risicomaat in. Definitie 4.13 (Odds) De odds op een gebeurtenis wordt gedefinieerd als \\[\\begin{equation*} \\frac{p}{1-p} \\end{equation*}\\] waarbij \\(p\\) de kans is op die gebeurtenis. Einde definitie De odds is dus een transformatie van het risico, met onder andere de volgende eigenschappen: de odds neemt waarden aan tussen nul en oneindig. de odds is gelijk aan 1 als en slechts als de kans zelf gelijk is aan 1/2. de odds neemt toe als de kans toeneemt. Het gebruik van odds is populair onder gokkers omdat het uitdrukt hoeveel waarschijnlijker het is om te winnen dan om te verliezen. Een odds op winnen gelijk aan 1 drukt bijvoorbeeld uit dat het even waarschijnlijk is om te winnen dan om te verliezen. Een odds op winnen gelijk aan 0.9 drukt uit men per 10 verliesbeurten, 9 keer verwacht te winnen. In de genetische associatiestudie uit Voorbeeld 3.16 is de odds op allel Leu/Leu bij cases gelijk aan \\(\\mbox{odds}_1=f/(d+e)=89/711=0.125\\) en bij controles gelijk aan \\(\\mbox{odds}_2=c/(a+b)=56/516=0.109\\). Vrouwen met borstkanker hebben bijgevolg ongeveer 8 (\\(\\approx 1/0.125\\)) keer meer kans om de allelcombinatie Leu/Leu niet te hebben op het BRCA1 gen dan om het wel te hebben. Om de associatie tussen blootstelling en uitkomst te beschrijven, kan men nu een verhouding van odds (odds ratio) gebruiken in plaats van een verhouding van risico’s (relatief risico). Definitie 4.14 (Odds ratio) De odds ratio op een gegeven gebeurtenis (bvb. borstkanker) voor populatie T (bvb. vrouwen met allel Leu/Leu) versus C (bvb. vrouwen zonder allel Leu/Leu) wordt met OR genoteerd en gedefinieerd als het quotiënt \\[\\begin{equation*} OR=\\frac{\\mbox{odds}_T}{\\mbox{odds}_C} \\end{equation*}\\] van de odds op deze gebeurtenis in populaties T en C. Einde definitie Op basis van de gegevens in Tabel 4.3 kan de odds ratio op blootstelling voor cases versus controles geschat worden d.m.v. het kruisproduct \\[\\begin{equation*} \\frac{ \\frac{ f/(d+e+f)}{(d+e)/(d+e+f)} }{ \\frac{c/(a+b+c)}{(a+b)/(a+b+c)}} = \\frac{f(a+b)}{c (d+e)} \\end{equation*}\\] In het bijzonder vinden we dat de odds op allelcombinatie Leu/Leu voor vrouwen met versus zonder borstkanker gelijk is aan \\(OR=(89\\times 516)/(56\\times 711)=1.15\\). Helaas drukt dit resultaat nog steeds niet uit hoeveel meer risico op borstkanker vrouwen met de allelcombinatie Leu/Leu lopen. Was de bovenstaande studie echter een volledig lukrake steekproef geweest (waarbij het aantal cases en controles niet per design werden vastgelegd), dan konden we daar ook de odds ratio op borstkanker berekenen voor mensen met versus zonder het allel Leu/leu. We zouden dan vaststellen dat dit gelijk is aan \\[\\begin{equation*} \\frac{ \\frac{ f/(c+f)}{c/(c+f)} }{ \\frac{(d+e)/(a+b+d+e)}{(a+b)/(a+b+d+e)}} = \\frac{f(a+b)}{c(d+e)}, \\end{equation*}\\] en bijgevolg dezelfde waarde aanneemt. Dat is omdat de odds ratio een symmetrische associatiemaat is zodat de odds ratio op `case’ voor blootgestelden versus niet-blootgestelden steeds gelijk is aan de odds op blootstelling voor cases versus controles. Hieruit volgt dat voor het schatten van de odds ratio het er niet toe doet of we prospectief werken zoals in een typische cohort studie, of retrospectief zoals in een typische case-controle studie. In het bijzonder kunnen we in de genetische associatiestudie uit Voorbeeld 3.16 de odds op borstkanker voor vrouwen met allel Leu/leu versus zonder berekenen als \\(OR=89\\times 516/(56\\times 711)=1.15\\). De odds op borstkanker is bijgevolg 15% hoger bij vrouwen met die specifieke allelcombinatie. Stel nu dat we met \\(p_T\\) en \\(p_C\\) respectievelijk de kans op case noteren voor blootgestelden en niet-blootgestelden. Wanneer beide kansen klein zijn (namelijk \\(p_T&lt;5\\%\\) en \\(p_C&lt;5\\%\\)), dan is de odds een goede benadering voor het risico. Dit is omdat in dat geval \\(\\mbox{odds}_T=p_T/(1-p_T)\\approx p_T\\) en \\(\\mbox{odds}_C=p_C/(1-p_C)\\approx p_C\\). Er volgt dan bovendien dat de odds ratio een goede benadering voor het relatief risico: \\[\\begin{equation*} OR=\\frac{\\mbox{ odds}_T}{\\mbox{ odds}_C}\\approx \\frac{p_T}{p_C}=RR \\end{equation*}\\] Wetende dat het risico op borstkanker laag is, mogen we op basis van de gevonden OR van 1.15 bijgevolg besluiten dat het risico (i.p.v. de odds) op borstkanker (bij benadering) 15% hoger ligt bij vrouwen met het allel Leu/Leu op het BRCA1 gen. Dit is een bijzonder nuttige eigenschap omdat (a) het relatief risico, dat niet rechtstreeks geschat kan worden in case-controle studies, gemakkelijker te interpreteren is dan de odds ratio; en (b) de odds ratio bepaalde wiskundige eigenschappen heeft die ze aantrekkelijker maakt dan een relatief risico in statistische modellen20. Algemeen is de odds ratio echter steeds verder van 1 verwijderd dan het relatief risico. Wetende dat de odds ratio op borstkanker 1.15 bedraagt voor vrouwen met versus zonder de allelcombinatie Leu/Leu, kunnen we bijgevolg meer nauwkeurig besluiten dat het overeenkomstige relatief risico tussen 1 en 1.15 gelegen is (maar niettemin dicht bij 1.15). Omdat de odds ratio moeilijker te interpreteren is dan een relatief risico en bijgevolg misleidend kan zijn, valt deze laatste steeds te verkiezen in situaties (zoals prospectieve studies) waar het mogelijk is om het relatief risico in de populatie te schatten. In sommige case-controle studies (nl. matched case-controle studies) wordt voor elke case een controle gezocht die bepaalde karakteristieken gemeenschappelijk heeft, teneinde een betere onderlinge vergelijkbaarheid te garanderen. In dat geval moet de statistische analyse (inclusief de manier om odds ratio’s te schatten) rekening houden met het feit dat de resultaten van elke case gecorreleerd of verwant zijn met de resultaten van de bijhorende controle. 4.5.3 Rates versus risico’s Vaak wordt het begrip risico verward met het begrip rate. Een rate drukt een aantal gebeurtenissen (bvb. aantal sterfte- of ziektegevallen) uit per eenheid in de populatie in een bepaalde tijdspanne. Bijvoorbeeld, een crude mortality rate (CMR) voor een bepaald jaartal is gedefinieerd als 1000 maal het aantal sterftegevallen dat optreedt in dat jaar gedeeld door de grootte van de beschouwde populatie halfweg dat jaar. De reden dat met 1000 wordt vermenigvuldigd is dat het bijvoorbeeld makkelijker na te denken is over een CMR van 12 sterftes per 1000 in Engeland en Wales, dan over 0.012 sterftes per individu. Indien een specifieke leeftijdsgroep wordt gekozen, verkrijgt men de leeftijdsspecifieke mortality rate als 1000 maal het aantal sterftegevallen dat optreedt in een bepaald jaar en bepaalde leeftijdsgroep gedeeld door de grootte van de beschouwde populatie in die leeftijdsklasse halfweg dat jaar. In tegenstelling tot de incidentie, is de prevalentie geen rate omdat ze niet een aantal gebeurtenissen uitdrukt over een zekere tijdspanne. 4.6 Associaties tussen twee variabelen Tot nog toe zijn we hoofdzakelijk ingegaan op zogenaamde univariate beschrijvingen waarbij slechts 1 variabele onderzocht wordt. In de meeste wetenschappelijke studies wenst men echter associaties tussen 2 of meerdere variabelen te onderzoeken, bijvoorbeeld tussen een interventie en de daarop volgende respons. In deze Sectie onderzoeken we hoe associaties tussen 2 variabelen kunnen beschreven worden. We maken daarbij onderscheid naargelang het type van de variabelen. 4.6.1 Associatie tussen twee kwalitatieve variabelen Als twee kwalitatieve variabelen niet veel verschillende waarden aannemen, dan is een kruistabel aangewezen om hun associatie voor te stellen. In deze tabel worden de verschillende waarden die de ene variabele aanneemt in de kolommen uitgezet en de verschillende waarden die de andere variabele aanneemt in de rijen. In elke cel van de tabel (die overeenkomt met 1 specifieke combinatie van waarden voor beide variabelen) wordt de frequentie neergeschreven. Tabel 4.4: Kruistabel van Gender vs BMI klasse. 12.0_18.5 18.5_to_24.9 25.0_to_29.9 30.0_plus female 629 1616 1179 1402 male 648 1295 1485 1349 Tabel 4.4 toont zo’n kruistabel voor het aantal mannen en vrouwen per BMI klasse. Dergelijke eenvoudige kruistabel met slechts 2 rijen en 4 kolommen, noemt men ook een \\(2\\times 4\\) tabel. 4.6.2 Associatie tussen één kwalitatieve en één continue variabele De eenvoudigste grafische weergave met het maximum aan informatie om de associatie tussen een kwalitatieve en een continue variabele te beschrijven is een dot-plot. ggplot(NHANES[1:100,], aes(x = Gender, y = log(DirectChol))) + geom_dotplot(binaxis = &quot;y&quot;, stackdir = &quot;center&quot;) Figuur 4.12: Dotplot van log-getransformeerde directe HDL cholestorol concentratie in functie van Gender voor de eerste 100 subjecten van de NHANES studie. Dit wordt geïllustreerd in Figuur 4.12 waarbij de log directe cholestorol concentratie is geplot in functie van het geslacht voor de eerste 100 personen in de studie. Deze voorstellingsmethode behoudt de individuele waarden van de observaties en laat gemakkelijke vergelijkingen toe tussen de verschillende groepen. Een bijkomend voordeel is dat outliers meteen zichtbaar zijn in een dot-plot. Een nadeel ontstaat wanneer de steekproef groot is en bijgevolg vele observaties samenvallen op de figuur. Vandaar dat we de plot hebben gemaakt voor een subset van de data. Als het aantal observaties groot is, kan een dot-plot vervangen worden door boxplots. Deze is meer compact dan een histogram en laat om die reden gemakkelijker vergelijkingen tussen verschillende groepen toe. Twee dergelijke boxplots worden getoond in Figuur 4.13. boxplot(log(DirectChol)~Gender,data=NHANES,ylab=&quot;log(Direct Cholestorol)&quot;) Figuur 4.13: Dotplot van log-getransformeerde directe HDL cholestorol concentratie in functie van Gender voor alle subjecten van de NHANES studie. Op basis van deze figuur stellen we vast dat hogere log-cholestorol concentraties geobserveerd worden bij vrouwen dan bij mannen, maar dat de variabiliteit van de log-concentraties vergelijkbaar is tussen de 2 groepen. De vraag blijft of we hier kunnen spreken van een systematisch hogere log-cholestorol concentratie tussen vrouwen en mannen. We zullen in Hoofdstuk 5 dieper op deze vraag ingaan. Figuur 4.13 kan men samenvatten door gemiddelde verschillen tussen beide groepen te rapporteren. Hier stellen we een gemiddeld verschil van 0.17 in directe HDL cholestorol concentratie vast op de log schaal tussen vrouwen en mannen. Gezien we weten dat \\(\\log(C_2)-\\log(C_1)=\\log(C_2/C_1)\\) besluiten we dat de HDL cholestorol concentratie in de NHANES studie gemiddeld 1.19 keer hoger ligt voor vrouwen dan voor mannen. Dot-plots zijn bijzonder interessant in pre-test post-test designs waar dezelfde subjecten op verschillende tijdstippen worden geobserveerd. In dat geval kunnen de uitkomsten uitgezet worden op de Y-as en de tijdstippen op de X-as, en kunnen de metingen voor eenzelfde subject worden verbonden met een lijn. Een voorbeeld hiervan is weergegeven in Figuur 4.14. De figuur vat de gegevens samen van de captopril studie die de centrale dataset vormt van Hoofdstuk 5. In de studie wenst men het effect van een bloeddrukverlagend geneesmiddel captopril evalueren. Voor elke patiënt in de studie werd de systolische bloeddruk twee keer gemeten: één keer voor en één keer na de behandeling met het bloeddruk verlagende medicijn captopril. In Figuur 4.14 worden de metingen van dezelfde patiënt met een lijntje verbonden. Hierdoor krijgen we een heel duidelijk beeld van de gegevens. Namelijk, we krijgen een sterke indruk dat de bloeddruk daalt na het toedienen van captopril gezien we bijna voor alle patiënten een daling observeren. ## id SBPb DBPb SBPa DBPa ## 1 1 210 130 201 125 ## 2 2 169 122 165 121 ## 3 3 187 124 166 121 ## 4 4 160 104 157 106 ## 5 5 167 112 147 101 ## 6 6 176 101 145 85 Figuur 4.14: Dotplot van de systolische bloeddruk in de captopril studie voor en na het toedienen van het bloeddruk verlagend middel captopril. 4.6.3 Associatie tussen twee continue variabelen De associatie tussen 2 kwantitatieve variabelen kan worden onderzocht aan de hand van een puntenwolk of spreidingsdiagram (in het Engels: scatterplot). Hier worden de geobserveerde waarden van de ene variabele uitgezet tegen de andere. In Hoofdstuk 6 wordt gewerkt rond een centrale dataset m.b.t. borstkanker. Voor 32 borstkanker patiënten werd gen-expressie gemeten van de tumor a.d.h.v. microarray technologie. Figuur 4.15 zet de log-expressie uit van het S100A8 gen ten opzichte van estrogen recepter gen (ESR1). Beide genen spelen een belangrijke rol in kanker. Expressie van het ESR1 gen is een indicator dat de tumor vatbaar is voor hormoontherapie wat gunstig is voor de prognose. Het S100A8-gen daarentegen is betrokken bij de onderdrukking van het immuunsysteem en het gen speelt een rol in het creëren van een inflamatoir milieu in de tumor. borstkanker=read.table(&quot;dataset/borstkanker.txt&quot;,header=TRUE) with(borstkanker, scatter.smooth(log2(ESR1),log2(S100A8),lpars=list(lty=2))) Figuur 4.15: Expressie van het S100A8 gen in functie van de ESR1 gen-expressie. De lijn op de figuur is een (niet-parametrische) regressielijn. Deze vat de associatie tussen beide variabelen samen door de gemiddelde log2-expressie voor S100A8 weer te geven in functie van de log2-expressie van het ESR1 gen. We observeren in Figuur 4.15 een negatieve associatie tussen de S100A8 en ESR1 expressie. De expressie van S100A8 neemt gemiddeld gezien af bij patiënten waar het ESR1 gen hoger geëxpresseerd is. In de praktijk wenst men de sterkte van de samenhang tussen 2 continue variabelen graag ook beknopt uit te kunnen drukken d.m.v. een samenvattingsmaat. Zo’n veelgebruikte maat om de lineaire samenhang tussen 2 continue metingen uit te drukken, is de (Pearson) correlatiecoëfficiënt of kortweg correlatie. Definitie 4.15 (Correlatie) Stel dat \\(x_{i}\\) (bvb. lengte) en \\(y_{i}\\) (bvb. gewicht) 2 metingen zijn die opgemeten werden bij eenzelfde individu \\(i=1,...,n\\). Dan wordt de Pearson correlatie tussen de rij getallen \\(x\\) en \\(y\\) gedefinieerd als: \\[\\begin{equation*} \\mbox{Cor}(x,y)=\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{ (n-1)s_{x}s_{y}}, \\end{equation*}\\] met \\(s_{x}\\) en \\(s_{y}\\) de standaarddeviatie van respectievelijk de rij getallen \\(x\\) en \\(y\\). De Pearson correlatie wordt typisch met \\(r\\) genoteerd. Einde definitie De teller in bovenstaande uitdrukking gaat na in welke mate positieve (negatieve) afwijkingen tussen \\(x\\) en zijn gemiddelde samengaan met positieve of negatieve afwijkingen tussen \\(y\\) en zijn gemiddelde. Het teken van de correlatie geeft bijgevolg de richting van de lineaire trend aan: het teken is positief (negatief) wanneer hogere waarden voor de ene variabele samengaan met hogere (lagere) waarden voor de andere. Men zegt in dat geval dat er een positieve (negatieve) associatie is. De noemer in de uitdrukking standaardiseert het geheel waardoor, zoals men wiskundig kan aantonen, de correlatie(coëfficiënt) een getal is gelegen tussen -1 en 1. Uitkomsten die perfect lineair afhankelijk zijn van elkaar (d.w.z. dat ze in een scatterplot gelegen zijn op een rechte lijn) hebben een correlatie van 1 of -1. Onafhankelijke variabelen (d.w.z. variabelen waarvoor kennis van de waarde voor de ene variabele geen informatie levert over de waarde voor de andere variabele) hebben een correlatie gelijk aan 0. De correlatie tussen de log2-S100A8 en log2-ESR1 expressie bedraagt -0.89. Wat opnieuw op een sterke negatieve correlatie wijst tussen de log-expressie van beide genen. par(mfrow=c(2,3)) for ( i in c(.3,.7,.99,-.3,-.5,-.9)) plot(rmvnorm(100,sigma=matrix(c(1,i,i,1),ncol=2)),xlab=&quot;x&quot;,ylab=&quot;y&quot;,main=paste(&quot;correlatie&quot;,i)) Figuur 4.16: Gesimuleerde gegevens met verschillende correlatie. Figuur 4.16 toont ter illustratie verschillende scatterplots waar fictieve gegevens met verschillende correlaties werden gesimuleerd. Merk op dat het lineaire patroon tussen de twee reeksen gegevens sterker wordt met toenemende correlatie en van richting wijzigt naarmate de correlatie negatief wordt. Eigenschap De correlatie tussen 2 reeksen metingen \\((x_i)\\) en \\((y_i)\\) blijft ongewijzigd wanneer bij alle uitkomsten \\(x_i\\) een willekeurige constante \\(a\\) wordt opgeteld; wanneer alle uitkomsten \\(x_i\\) met een willekeurige constante \\(a\\) worden vermenigvuldigd; wanneer \\((x_i,\\bar x)\\) en \\((y_i,\\bar y)\\) van plaats worden verwisseld in de uitdrukking voor de correlatie. Einde eigenschap Op basis van deze eigenschap kunnen we bijvoorbeeld besluiten dat de correlatie tussen de expressie van het S100A8 en ESR1 gen niet gewijzigd wordt wanneer we een log10 transformatie hadden gebruikt ipv een log2 tranformatie. Door de eigenschappen van logaritmes weten we immers dat \\(\\log_{2}(x)=\\log_{10}(x)/\\log_{10}(2)\\) set.seed(100) #Een seed wordt gebruikt om ervoor te zorgen #dat dezelfde resultaten opnieuw kunnen worden #bekomen wanneer men at random data genereerd par(mfrow=c(1,2)) #twee plots naast elkaar #simuleer scheef=exp(rmvnorm(100,mean=rep(1.5,2),sigma=matrix(c(1.5,.75*1.5,.75*1.5,1.5),ncol=2))) #plot plot(scheef,main=paste(&quot;Correlatie&quot;,round(cor(scheef)[1,2],2)),xlab=&quot;x&quot;,ylab=&quot;y&quot;) #simuleer normal &lt;- rmvnorm(100,mean=rep(1.5,2),sigma=matrix(c(1.5,.71*1.5,.71*1.5,1.5),ncol=2)) #plot plot(normal,main=paste(&quot;Correlatie&quot;,round(cor(normal)[1,2],2)),xlab=&quot;x&quot;,ylab=&quot;y&quot;) Figuur 4.17: Links: scheef verdeelde observaties; Rechts: Normaal verdeelde observaties. Bij het interpreteren van correlaties, alsook bij het uitvoeren van regressie-analyses in de volgende secties, zijn de volgende waarschuwingen van zeer groot belang: Correlaties zijn het makkelijkst te interpreteren tussen 2 groepen Normaal verdeelde observaties. Een kleine training laat immers toe om snel inzicht te krijgen in de grootte van de correlatiecoëfficiënt zonder zich verder over de specifieke verdeling te hoeven bekommeren. In het bijzonder kan men voor Normaal verdeelde observaties visueel inzicht krijgen in de sterkte van de correlatie door een ellips rond de puntenwolk te tekenen die (nagenoeg) alle punten bevat. Als de ellips op een cirkel lijkt, dan is er geen correlatie. Hoe dunner de ellips, hoe sterker de correlatie. De oriëntatie van de ellips geeft hierbij het teken van de correlatie weer. Voor niet-Normale gegevens hangt de betekenis van een correlatiecoëfficiënt van zekere grootte, nauw samen met de specifieke vorm van de verdeling. Figuur 4.17 toont ter illustratie 1 paar scheef verdeelde (links) en 1 paar Normaal verdeelde (rechts) observaties. Hoewel de correlatie in beide figuren 0.65 bedraagt, tonen beide figuren een verschillende associatie. Merk ook op in Figuur 4.18 (rechts) dat de grootte van de correlatie sterk beïnvloed kan worden door een paar outliers. De correlatie tussen deze variabelen bedraagt slechts 0.44, maar 0.93 na verwijdering van de 2 outliers. Wanneer de 2 variabelen die we onderzoeken niet Normaal verdeeld zijn, dan zijn er 2 mogelijkheden om een zinvolle correlatiecoëfficiënt weer te geven. Variabelen die scheef verdeeld zijn, kan men transformeren (bvb. een log-transformatie) in de hoop dat de getransformeerde gegevens bij benadering Normaal verdeeld zijn en lineair samenhangen. Bemerk dat we de genexpressie van S100A8 en ESR1 daarom log-getransformeerd hebben in Figuur 4.15, concentraties en intensiteitsmetingen zijn immers vaak log-normaal verdeeld. Indien transformatie niet helpt of wanneer er outliers zijn, kan men een meer robuuste maat voor de samenhang tussen 2 variabelen rapporteren, zoals de Spearman’s rank correlatie. Dit is per definitie de Pearson correlatiecoëfficiënt van de rangen van de 2 beschouwde variabelen. Dergelijke rangen worden bekomen door voor elke variabele afzonderlijk de metingen te vervangen door de rangorde waarin ze voorkomen. In het bijzonder krijgt de kleinste meting rangorde 1 toegekend, de tweede kleinste rangorde 2, etc. Door aldus rangordes voor de 2 variabelen afzonderlijk te nemen, blijft de samenhang ruwweg behouden, maar wordt de invloed van outliers gevoelig afgezwakt (omdat rangordes relatief gezien nooit extreem worden). par(mfrow=c(1,2)) set.seed(34) x=c(rnorm(100)) y=3*x^2+rnorm(100,sd=2) plot(x,y,main=paste(&quot;Correlation&quot;,round(cor(x,y),2))) simHlp=matrix(0,ncol=2,nrow=20) simHlp[1:18,]=rmvnorm(18,sigma=matrix(c(1,.9,.9,1),ncol=2)) simHlp[19:20,]=cbind(max(simHlp[,1])*c(1.1,1.3),c(-2,-2.8)) plot(simHlp,main=paste(&quot;Correlation&quot;,round(cor(simHlp)[1,2],2)),xlab=&quot;x&quot;,ylab=&quot;y&quot;) Figuur 4.18: Links: gesimuleerde gegevens met kwadratische associatie; Rechts: gesimuleerde gegevens met een werkelijke correlatie van 0.9 en 2 outliers. #Met outliers cor(simHlp) ## [,1] [,2] ## [1,] 1.0000000 0.4399447 ## [2,] 0.4399447 1.0000000 #Zonder outliers cor(simHlp[1:18,]) ## [,1] [,2] ## [1,] 1.0000000 0.9270999 ## [2,] 0.9270999 1.0000000 Merk op dat een correlatiecoëfficiënt van 0 tussen 2 variabelen \\(X\\) en \\(Y\\) niet noodzakelijk impliceert dat deze variabelen onafhankelijk zijn. Figuur 4.18 (links) toont ter bijvoorbeeld 2 variabelen die vrij sterk geassocieerd zijn, hoewel hun correlatie nagenoeg 0 bedraagt. De oorzaak hiervan is dat de correlatie enkel de lineaire samenhang tussen 2 variabelen meet en bijgevolg niet noodzakelijk niet-lineaire verbanden detecteert. Dit betekent meer concreet dat de correlatie, op een factor na, de helling weergeeft van de `best passende rechte’ (nl. de kleinste kwadratenrechte, zie Hoofdstuk 6) doorheen de puntenwolk. Een correlatie gelijk aan 0 geeft bijgevolg aan dat een best passende rechte doorheen de puntenwolk helling 0 heeft (d.w.z. dat ze horizontaal verloopt). In Figuur 4.18 is de correlatie heel laag omdat er bij negatieve \\(X\\)-waarden een dalende associatie is en bij positieve \\(X\\)-waarden een stijgende associatie, zodat de 2 variabelen geen lineaire samenhang meer hebben. Omwille van het voorgaande fenomeen is het van belang om de aard van samenhang tussen 2 variabelen steeds te onderzoeken via een scatterplot alvorens een correlatiecoëfficiënt te rapporteren. Wanneer het verband monotoon is, maar sterk niet-lineair is, dan is het aangewezen om niet de Pearson correlatiecoëfficiënt, maar Spearman’s correlatiecoëfficiënt te rapporteren. Figuur 4.19 geeft het verband van de microarray intensiteitsmetingen weer voor het S100A8 gen in functie van deze voor het ESR1 gen. Het verband is moeilijk interpreteerbaar op de originele schaal door de aanwezigheid van heel hoge intensiteiten (en dus concentraties). Het verband op de originele schaal is exponentieel. Pearson’s correlatiecoëfficiënt zakt hierdoor van -0.89 op log-schaal naar -0.54 op de originele schaal. Spearman’s correlatiecoëfficiënt daarentegen blijft gelijk voor en na transformatie gezien de log2 transformatie monotoon is en de ordening (rangen) van de data niet verandert. Spearman’s correlatiecoëfficiënt blijft -0.73 op de originele schaal alsook op log-schaal en wijst op een sterke negatieve associatie tussen de expressie van beiden genen. par(mfrow=c(1,3)) with(borstkanker, scatter.smooth(log2(ESR1),log2(S100A8),span=1/2, main=paste(&quot;Correlatie&quot;,c(&quot;Pearson&quot;,&quot;Spearman&quot;),round(c(cor(log2(ESR1),log2(S100A8)),cor(log2(ESR1),log2(S100A8),method = &quot;spearman&quot;)),2)))) with(borstkanker, scatter.smooth(ESR1,S100A8,span=1/2,main=paste(&quot;Correlatie&quot;,c(&quot;Pearson&quot;,&quot;Spearman&quot;),round(c(cor(ESR1,S100A8),cor(ESR1,S100A8,method = &quot;spearman&quot;)),2)))) with(borstkanker, scatter.smooth(ESR1,S100A8,span=1/2,ylim=c(0,500),main=paste(&quot;Correlatie&quot;,c(&quot;Pearson&quot;,&quot;Spearman&quot;),round(c(cor(ESR1,S100A8),cor(ESR1,S100A8,method = &quot;spearman&quot;)),2)))) Figuur 4.19: Expressie van het S100A8 gen in functie van de ESR1 gen-expressie op de log2 en originele schaal. Indien het verband niet-monotoon is, dan zijn correlatiecoëfficiënten niet geschikt en moet men overstappen op meer geavanceerde regressietechnieken. Bij jonge kinderen is de grootte van hun schoenmaat uiteraard sterk gecorreleerd met hun leescapaciteiten. Dat op zich impliceert echter niet dat het leren van nieuwe woorden hun voeten doet groeien of dat het groeien van hun voeten impliceert dat ze beter kunnen lezen. Ook algemeen21 hoeft een correlatie tussen 2 variabelen niet te impliceren dat er een causaal verband is. De relatie tussen 2 metingen kan immers sterk verstoord worden door confounders (bvb. de leeftijd in bovenstaand voorbeeld). Hoewel dit overduidelijk is in bovenstaand voorbeeld, is het in vele andere contexten veel minder duidelijk en worden er, vooral in de populaire literatuur, vaak causale beweringen gemaakt die niet (volledig) door de gegevens worden gestaafd. Volgend voorbeeld illustreert dit. Voorbeeld 4.5 (Associatie versus causatie) Wanneer men de incidentie van sterfte ten gevolge van borstkanker uitzet t.o.v. van de vetinname per capita per dag voor een grote steekproef van landen over de ganse wereld, dan stelt men vast dat er sterke positieve correlatie is. Deze correlatie wordt vaak gebruikt om aan te geven dat vetinname leidt tot borstkanker (analoog voor darmkanker). Het bewijs hiervoor is echter zeer zwak. Immers, landen met een grote vetinname hebben ook een hoge inname van suiker. Een grafiek van de incidentie van sterfte ten gevolge van borstkanker t.o.v. van de suikerinname per capita per dag toont een vrijwel even sterke correlatie, hoewel nagenoeg niemand beweert dat suiker borstkanker veroorzaakt. Bovendien zijn vet en suiker op wereldschaal relatief dure producten. Landen met hoge vetinname zijn bijgevolg voornamelijk industrielanden die in heel wat meer verschillen van de andere landen dan alleen hun vetinname… Recente studies (Holmes et al., 1999) hebben intussen sterke indicaties geleverd dat hoog vetverbruik vermoedelijk niet tot borstkanker leidt. **Einde voorbeeld** Een ecologische analyse is een statistische analyse waarbij men associaties bestudeert tussen samenvattingsmaten (zoals gemiddelden, incidenties, …) die reeds berekend werden voor groepen subjecten. Dit is het geval in voorgaand voorbeeld waar de associatie wordt onderzocht tussen de incidentie van sterfte t.g.v. borstkanker en de (gemiddelde) dagelijkse vetinname per capita in verschillende landen. Wanneer men aldus een ecologische correlatie vaststelt voor groepen subjecten of individuen (in dit geval, landen), impliceert dat niet noodzakelijk dat deze correlatie ook voor de subjecten zelf opgaat22. Volgend voorbeeld illustreert dit. Voorbeeld 4.6 (Ecological fallacy) Voor de 48 staten in de V.S. werden telkens 2 getallen berekend: het percentage van de mensen die in een ander land geboren zijn en het percentage geletterden. De correlatie ertussen bedraagt 0.53 (Robinson, 1950). Dit is een ecologische correlatie omdat de eenheid van de analyse de groep residenten uit een zelfde staat is, en niet de individuele residenten zelf. Deze ecologische correlatie suggereert dat mensen van vreemde afkomst doorgaans beter geschoold zijn (in Amerikaans Engels) dan de oorspronkelijke inwoners. Wanneer men echter de correlatie berekent op basis van de gegevens voor alle individuele residenten, bekomt men -0.11. De ecologische analyse is hier duidelijk misleidend: het teken van de correlatie is er positief omdat mensen van vreemde origine de neiging hebben om te gaan wonen in staten waar de oorspronkelijke bevolking relatief goed geschoold is. **Einde voorbeeld** 4.7 Onvolledige gegevens Het gebeurt vaak in de biowetenschappen dat, ondanks zorgvuldig veld- en laboratoriumwerk, metingen die men plande te verzamelen, niet bekomen werden. Men noemt deze dan ontbrekende gegevens of missing data (points). Minder drastisch, kunnen observaties soms slechts ten dele gekend zijn. Bijvoorbeeld bij een studie van de overlevingsduur van dieren en planten wacht men niet steeds tot alle subjecten gestorven zijn. Op het eind van de studie zal men bijvoorbeeld voor een 50-jarige olifant die in leven is, slechts weten dat de overlevingstijd minstens 50 jaar bedraagt, maar niet de exacte waarde kennen. Zo’n gegeven wordt rechts-gecensureerd genoemd: we weten dat de gewenste observatie rechts van 50 ligt, maar verder niets meer. Analoog kunnen observaties links-gecensureerd zijn. Bij het meten van bepaalde concentraties kan een detectielimiet bestaan: een ondergrens beneden dewelke het meettoestel geen aanwezigheid kan detecteren. Men weet in zo’n geval dat de concentratie kleiner dan die ondergrens is, maar niet hoeveel kleiner. Tenslotte vermelden we nog interval-gecensureerde gegevens. Bij het screenen naar HIV bijvoorbeeld, zal men weten dat een subject seropositief geworden is ergens tussen de laatste negatieve HIV test en de eerste positieve HIV test, maar het exacte tijdstip van seroconversie blijft onbekend. De aanwezigheid van gegevens die niet of slechts partieel zijn opgemeten zorgt altijd voor extra moeilijkheden bij de analyse en interpretatie van de onderzoeksresultaten. Dat is omdat de missende gegevens mogelijks afkomstig zijn van een speciale populatie. Dat is het meest duidelijk in klinische experimenten bij mensen. Patiënten zullen hier vaak de studie verlaten wanneer ze genezen zijn, in welk geval men de metingen van deze patiënten niet te zien krijgt. Dit negeren door enkel de aanwezige gegevens te analyseren, zal de resultaten er slechter doen uitzien dan ze in werkelijkheid zijn. Meestal houdt dat immers de veronderstelling in dat de aanwezige gegevens representatief blijven voor de populatie die men wenst te bestuderen. Dit kan in sommige gevallen de resultaten sterk vertekenen. In de statistische literatuur zijn de laatste jaren heel wat complexe technieken ontwikkeld om hiervoor te corrigeren. Deze technieken worden meer en meer in de statistische software ingebouwd en recent heeft ook R verschillende bibliotheken toegevoegd. Het is echter aangewezen om voor het gebruik van deze gevorderde technieken een statisticus te consulteren. Zie Sectie 4.4.2.↩ Later zullen we zien dat het nog iets correcter is om te stellen dat 95% van de waarnemingen liggen tussen \\(\\bar{x} - 1.96 s_x\\) en \\(\\bar{x} + 1.96 s_x\\).↩ Hierbij maken we gebruik van het feit dat voor een Normaal verdeelde observatie \\(X\\), \\(P(X=a)=0\\) voor elk reëel getal \\(a\\), zodat \\(P(X\\leq a)=P(X&lt;a)\\).↩ Let wel op want in verschillende boeken krijgt het symbool \\(z_{\\alpha}\\) verschillende definities!↩ Dit interval bevat niet exact \\((1-\\alpha)100\\%\\) van de observaties, maar slechts bij benadering, omdat het geen rekening houdt met het feit dat \\(\\bar x\\) en \\(\\sigma_x\\) impreciese schattingen zijn voor \\(\\mu\\) en \\(\\sigma\\) op basis van een eindige steekproef. Meer accurate referentie-intervallen die deze imprecisie in rekening brengen, ook predictie-intervallen genoemd↩ Merk op dat dit design niet optimaal is omdat replicaties op de verkeerde schaal werden bekomen. Idealiter moesten meer dan 2 stukken grond in de studie opgenomen worden omdat de 2 gekozen stukken grond in veel meer kunnen verschillen dan alleen het bodemtype. Verschillen in de verdeling van houtluizen kunnen bijgevolg niet zomaar aan het bodemtype kunnen toegeschreven worden.↩ Al is het nog de vraag of die associatie toevallig is, dan wel systematisch. We komen in het hoofdstuk 9. terug op technieken om dit te onderzoeken.↩ Dit is bijvoorbeeld het geval in logistische regressiemodellen die gebruikt worden om het risico op een bepaalde aandoening te modelleren in functie van prognostische factoren.↩ In het Engels is dit welbekend onder de zinsnede `Association is not causation!’.↩ In het Engels is dit welbekend onder de naam `ecological fallacy’.↩ "],
["chap-besluit.html", "Hoofdstuk 5 Statistische besluitvorming 5.1 Inleiding 5.2 Captopril voorbeeld 5.3 Puntschatters: het steekproefgemiddelde 5.4 Intervalschatters 5.5 Principe van Hypothesetoetsen (via one sample t-test) 5.6 Two-sample t-test 5.7 Aannames 5.8 Wat rapporteren? 5.9 Equivalentie-intervallen", " Hoofdstuk 5 Statistische besluitvorming 5.1 Inleiding In dit hoofdstuk zullen we werken rond de Captopril dataset. Captopril is een medicijn dat wordt voorgeschreven bij hypertensie en chronisch hartfalen. Het behoort tot de klasse van ACE remmers die activiteit van het renine-angiotensine-aldosteronsysteem onderdrukken. Dat systeem zet het hormoon angiotensineI om in angiotensine II, die een krachtige vaatvernauwende werking heeft. ACE remmers verminderen de omzetting van angiotensine I naar angiotensine II waardoor de vaatvernauwing wordt onderdrukt. Tijdens de ontwikkeling van het medicijn werd een eerste kleine studie opgezet om na te gaan of captopril een bloeddrukverlagend effect heeft bij patiënten met hypertensie. Observaties bij een klein aantal subjecten mogen een onderzoeker er dan al van overtuigen iets nieuws te hebben ontdekt, maar om anderen te overtuigen zijn objectieve, wetenschappelijke argumenten nodig. Vooreerst moeten de resultaten voldoende representatief zijn, d.w.z. veralgemeenbaar naar een ruime biologische populatie (bvb. naar de volledige populatie van patiënten met hypertensie). Ten tweede moet er rekening mee gehouden worden dat de resultaten variabel zijn, d.w.z. dat men door toeval doorgaans andere resultaten zou vinden indien men een andere, vergelijkbare groep subjecten zou analyseren. Om die reden is het belangrijk om uit te drukken in welke mate de resultaten (bvb. de geschatte bloeddrukdaling) zouden variëren van steekproef tot steekproef en of men op basis van de steekproef kan aantonen dat er een effect is van een behandeling (b.v. dat het middel captopril bloeddrukverlagend werkt in de populatie). Dit vormt het doel van dit hoofdstuk. Om een representatieve groep subjecten te waarborgen, vertrekt een goede onderzoeksopzet vanuit een belangrijke, precies geformuleerde vraagstelling omtrent een duidelijk omschreven populatie. Zoals eerder in de cursus aangegeven, zal men in de praktijk om financiële en logistieke redenen bijna nooit een volledige populatie kunnen bestuderen. Populatieparameters kunnen daarom meestal niet exact bepaald worden. Enkel een deel van de populatie kan onderzocht worden, wat men een steekproef noemt. Volgens een gestructureerd design worden daartoe lukraak subjecten uit de doelpopulatie getrokken en geobserveerd. De onbekende parameters worden vervolgens geschat o.b.v. die steekproef en noemt men schattingen. In de praktijk hoopt men uiteraard dat de schattingen die men bekomt op basis van de steekproef vergelijkbaar zijn met de overeenkomstige populatieparameters die men voor de volledige populatie zou bekomen. Typisch kan de onderzoeksvraag worden vertaald naar een populatieparameter. Ze kan bijvoorbeeld worden uitgedrukt in termen van een populatiegemiddelde, bijvoorbeeld de gemiddelde bloeddrukverandering na de inname van captopril bij patiënten met hypertensie. 5.2 Captopril voorbeeld Onderzoekers wensen na te gaan of het medicijn Captopril een bloeddruk verlagend effect heeft. De onderzoekers wensen uitspraken te kunnen doen over het effect van captopril op de systolische bloeddruk van huidige en toekomstige patiënten met hypertensie, m.a.w. ze wensen uitspraken te doen over het effect van captopril op het niveau van de Populatie. Ze zullen hiervoor een experiment opzetten om het effect van captopril bestuderen (Proefopzet) waarbij een steekproef (sample) van de patiënten met hypertensie is getrokken uit de populatie. Vervolgens zullen ze de data exploreren en het effect van captopril besturen in de steekproef (Data Exploratie &amp; Beschrijvende Statistiek). Op basis van de steekproef zullen ze dan het effect van captopril Schatten in de populatie en zullen ze a.d.h.v. methoden uit Statistische besluitvorming23 nagaan in hoeverre de geobserveerde effecten in de steekproef veralgemeend kunnen worden naar de algemene populatie toe. Deze verschillende stappen worden geïllustreerd in Figuur 5.1. Figuur 5.1: Verschillende stappen in de captopril studie. 5.2.1 Proefopzet Bij proefopzet zullen we een gestructureerd design voorstellen om lukraak subjecten uit de doelpopulatie te selecteren, toe te wijzen aan een behandeling en te observeren. We zullen hierbij een response variabele meten, een karakteristiek van interesse. In het captopril voorbeeld is dit de systolische bloeddruk. In de captopril studie hebben de onderzoekers gebruik gemaakt van een een pre-test/post-test design. De patiënten werden at random gekozen uit de populatie. Van elke patiënt in de studie werd de systolische en diasystolische bloeddruk gemeten voor en na het toedienen van captopril. Het pre-test/post-test design heeft als voordeel dat we het effect van het toedienen van captopril op de bloeddruk kunnen meten voor elke patiënt. Een nadeel daarentegen is dat er geen controle behandeling is waardoor we een mogelijkse bloeddrukverlaging niet noodzakelijkerwijs kunnen toeschrijven aan de werking van captopril. Er zou immers ook een placebo-effect kunnen optreden waardoor de bloeddruk van de patiënt daalt omdat men weet dat men een medicijn kreeg tegen een hoge bloeddruk. 5.2.2 Data Exploratie &amp; Beschrijvende Statistiek Eens de data zijn geobserveerd, is het belangrijk om deze te exploreren om inzicht te krijgen in hun verdeling en karakteristieken. Vervolgens zullen we de gegevens samenvatten zodat we het effect van interesse kunnen kwantificeren in de steekproef. In deze studie is de systolische bloeddruk en de diasystolische bloeddruk gemeten voor elke patiënt voor en na het toedienen van captopril. De data is opgeslagen in een tekstbestand met naam captopril.txt in de folder dataset. We zullen eerst exploreren welke figuren nuttig zijn in onze context. In wetenschappelijke artikels worden vaak figuren gemaakt van het gemiddelde en de standaardafwijking (zie Figuur 5.2). #Eerst lezen we de data in. #Deze bevindt zich in de subdirectory dataset #Het is een tekstbestand waarbij de kolommen van elkaar gescheiden zijn d.m.v kommas. #sep=&quot;,&quot; #De eerste rij bevat de namen van de variabelen captopril &lt;- read.table(&quot;dataset/captopril.txt&quot;,header=TRUE,sep=&quot;,&quot;) head(captopril) ## id SBPb DBPb SBPa DBPa ## 1 1 210 130 201 125 ## 2 2 169 122 165 121 ## 3 3 187 124 166 121 ## 4 4 160 104 157 106 ## 5 5 167 112 147 101 ## 6 6 176 101 145 85 #We gebruiken de apply functie om het gemiddelde en de standaard deviatie #te berekenen voor de kolommen die bloeddruk data bevatten (kolom 2:4) #We gebruiken argument MARGIN=2 om de functie toe te passen op de kolommen #MARGIN=1 kan gebruikt worden om de functie op de rijen toe te passen mm&lt;-apply(captopril[,2:5],MARGIN=2,FUN=mean) hh&lt;-apply(captopril[,2:5],MARGIN=2,FUN=sd) mp &lt;- barplot(mm,ylim=c(0,250),ylab=&quot;Gemiddelde bloeddruk (mmHg)&quot;,main=&quot;&quot;) #fouten vlaggen segments(mp,mm,mp,mm+2*hh) segments(mp-.2,mm+2*hh,mp+.2,mm+2*hh) Figuur 5.2: Barplot van de gemiddelde bloeddruk in de captopril studie. De foutenvlag is 2x de standaard deviatie op de metingen (SBPb: systolic BloodPressure before, DBPb: Diasystolic BloodPressure before, SBPa: systolic BloodPressure after, DBPa: Diasystolic BloodPressure after). De figuur is echter niet informatief. De hoogte van de balken zegt enkel iets over het gemiddelde. We kunnen onmogelijk weten wat het bereik van de ruwe gegevens is bijvoorbeeld. Daarom is het beter om de gegevens zo ruw mogelijk weer te geven in een plot. We kunnen hiervoor bijvoorbeeld gebruik maken van boxplots (Figuur 5.3). Aangezien we maar over 15 patiënten beschikken kunnen we ook de ruwe datapunten toevoegen. In de figuur zien we dat de systolische bloeddruk in de steekproef gemiddeld lager ligt na de behandeling met captopril. We krijgen ook een duidelijk beeld op het bereik van de data. boxplot(captopril[,2:5],ylim=c(0,250),ylab=&quot;Bloeddruk (mmHg)&quot;,main=&quot;&quot;) #toevoegen van originele datapunten op de plot #jitter zal de punten random verspreiden #set seed om gekleurde volle bol pch=19 te zetten #en daarna een zwarte rand te kunnen zetten op zelfde plaats. set.seed(19) stripchart(captopril[,2:5], vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;,&quot;purple&quot;), add = TRUE) set.seed(19) stripchart(captopril[,2:5], vertical = TRUE, method = &quot;jitter&quot;, pch = 1, col =1, add = TRUE) Figuur 5.3: Boxplot en ruwe data van de bloeddruk in de captopril studie (SBPb: systolic BloodPressure before, DBPb: Diasystolic BloodPressure before, SBPa: systolic BloodPressure after, DBPa: Diasystolic BloodPressure after). Als alle bloeddrukmetingen onafhankelijk zouden zijn dan is Figuur 5.3 een goede figuur om de data te exploreren. We weten echter dat de metingen voor en na het toedienen van captopril afkomstig zijn van dezelfde patiënt. We kunnen die informatie toevoegen in een dotplot zoals we illustreren voor de systolische bloeddruk in Figuur 5.4. In deze figuur zijn de twee bloeddrukmetingen voor dezelfde persoon verbonden met een lijn. Deze figuur geeft duidelijk weer dat de bloeddruk daalt voor elke patiënt wat een sterke aanwijzing is dat er een effect is van het toedienen van captopril op de systolische bloeddruk. #D.m.v de matplot functie kunnen we eenvoudig #de data van dezelfde patient (per kolom) #vandaar dat we de dataset transponeren (t(.)) functie #en verbinden a.d.h.v. een lijn. (lty=1) #we gebruiken ook een dezelfde kleur. #en gebruiken zowel een punt als een lijn #om de data voor te stellen type=&quot;b&quot; matplot(t(captopril[,c(&quot;SBPb&quot;,&quot;SBPa&quot;)]),pch=1,lty=1,col=&quot;black&quot;,type=&quot;b&quot;,xaxt=&quot;none&quot;,xlim=c(0.5,2.5),ylab=&quot;Systolische bloeddruk (mmHg)&quot;,cex=.5) axis(1,c(1,2),labels=c(&quot;voor&quot;,&quot;na&quot;)) Figuur 5.4: Dotplot van de systolische bloeddruk in de captopril studie voor en na het toedienen van captopril. Aangezien we slechts twee bloeddrukmetingen hebben per patiënt kunnen we het effect van captopril ook berekenen per patiënt door het verschil in de systolische bloeddruk na en voor de toediening van captopril te berekenen. Dat is één van de voordelen van een pre-test/post-test design. #we selecteren de bloeddruk na en voor toedienen #uit de dataset via naam van variabele d.m.v. $-teken #en berekenen het verschil delta &lt;- captopril$SBPa-captopril$SBPb boxplot(delta,ylab=expression(paste(&quot;Verschil in bloeddruk (&quot;,Delta[Na - Voor],&quot;)&quot;))) set.seed(19) stripchart(delta, vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;), add = TRUE) set.seed(19) stripchart(delta, vertical = TRUE, method = &quot;jitter&quot;, pch = 1, col =1, add = TRUE) Figuur 5.5: Boxplot van het verschil in systolische bloeddruk voor en na het toedienen van captopril. We observeren in Figuur 5.5 een bloeddrukdaling voor elke patiënt in de steekproef wat opnieuw een heel sterke indicatie is voor een gunstig effect van het toedienen van captopril op de bloeddruk. De verschillen in systolische bloeddruk zijn een goede maat om het effect van captopril te bepalen. We kunnen de data als volgt samenvatten. summary(delta) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -33.00 -24.50 -20.00 -18.93 -13.50 -3.00 sd(delta) ## [1] 9.027471 We observeren gemiddeld een systolische bloeddrukdaling van 18.93 mmHg en een standaard deviatie van 9.03 mmHg. 5.2.3 Schatten Pre-test/post-test design: Het effect van captopril in de steekproef kan worden bestudeerd door het verschil te bepalen in systolische bloeddruk na en voor de behandeling (\\(X=\\Delta_\\text{na-voor}\\))! Hoe kunnen we de bloeddrukverschillen modelleren en het effect van het toedienen van captopril schatten? Figuur 5.6: QQ-plot voor het verschil in systolische bloeddruk voor en na het toedienen van captopril. ## [1] 4 2 We zien geen grote afwijkingen van Normaliteit in Figuur 5.6. We kunnen de bloeddrukverschillen dus modelleren aan de hand van een Normale verdeling en kunnen het effect van captopril in de populatie beschrijven a.d.h.v. de gemiddelde bloeddrukverschil \\(\\mu\\). Het bloeddrukverschil \\(\\mu\\) in de populatie kan worden geschat a.d.h.v. het steekproefgemiddelde \\(\\bar x\\)=-18.93 en de standaard afwijking \\(\\sigma\\) a.d.h.v. de steekproefstandaarddeviatie \\(\\text{SD}\\)=9.03. We vragen ons nu af of het effect dat we observeren in de steekproef groot genoeg is om te kunnen spreken van een effect van captopril in de populatie. We weten immers dat onze statistiek voor de schatting van het effect van captopril in de populatie berekend wordt op basis van de gegevens uit de steekproef en daarom zal variëren van steekproef tot steekproef. Het is daarom belangrijk om een inzicht te krijgen in hoe het steekproefgemiddelde zal variëren van steekproef tot steekproef. 5.3 Puntschatters: het steekproefgemiddelde Zij \\(X\\) een lukrake trekking uit de populatie van de bestudeerde karakteristiek en onderstel dat haar theoretische verdeling[bvb. de Normale verdeling] een gemiddelde \\(\\mu\\) en variatie \\(\\sigma^2\\) heeft. Onderstel bovendien dat we geïnteresseerd zijn in het gemiddelde \\(\\mu\\) van die karakteristiek in de studiepopulatie. Dan kunnen we \\(\\mu\\) schatten op basis van een eenvoudige lukrake steekproef, \\(X_1,...,X_n\\), als het (rekenkundig) gemiddelde \\[\\begin{equation*} \\bar X = \\frac{X_1+ X_2+ ... + X_n}{n} = \\frac{\\sum_{i=1}^{n} X_i}{n} \\end{equation*}\\] van de toevalsveranderlijken \\(X_1,X_2, ..., X_n\\). Dit wordt het steekproefgemiddelde genoemd. Het is belangrijk om te begrijpen dat het steekproefgemiddelde opnieuw een toevalsveranderlijke24 is, d.w.z. dat haar waarde zal variëren van steekproef tot steekproef. Hoewel er slechts 1 populatie is, zijn er heel wat verschillende steekproeven die men daaruit kan trekken. Dat heeft tot gevolg dat verschillende onderzoekers (die verschillende steekproeven uit dezelfde populatie analyseren) verschillende waarden zullen vinden voor het steekproefgemiddelde. Om die reden heeft het steekproefgemiddelde zelf een verdeling. Men zou die theoretisch kunnen bekomen door een oneindig aantal keer een steekproef van \\(n\\) experimentele eenheden uit de populatie te trekken, telkens het steekproefgemiddelde te berekenen en al deze steekproefgemiddelden vervolgens uit te zetten in een histogram. We zullen in deze sectie de theoretische verdeling van het steekproefgemiddelde bestuderen. Dat is belangrijk (a) omdat ze ons inzicht geeft in welke mate het resultaat van de studie zou variëren indien men een nieuwe, gelijkaardige studie zou opzetten; en (b) omdat ze ons leert hoe ver \\(\\bar X\\) van het gezochte populatiegemiddelde \\(\\mu\\) kan afwijken. Omdat we slechts over 1 steekproef beschikken (en dus slechts over 1 observatie voor \\(\\bar X\\)), is het niet evident25 hoe we inzicht kunnen ontwikkelen in de verdeling van het steekproefgemiddelde. In het vervolg van deze sectie tonen we hoe dit toch mogelijk is op basis van de beschikbare steekproef wanneer we bepaalde aannames doen over de gegevens. 5.3.1 Het steekproefgemiddelde is onvertekend In de praktijk hoopt men uiteraard dat de schattingen die men bekomt op basis van de steekproef vergelijkbaar zijn met de overeenkomstige populatieparameters die men voor de volledige populatie zou bekomen. Of dat zo is, hangt er in eerste instantie vanaf of de steekproef representatief is voor de studiepopulatie en bijgevolg of men al dan niet lukraak individuen uit de populatie gekozen heeft ter observatie (m.a.w. het hangt af van het design van de studie). Het volgende voorbeeld illustreert dit. Voorbeeld 5.1 (Ecstasy) Aan Stanford University werd een survey uitgevoerd om de prevalentie van ecstasy-gebruik onder de studenten van deze universiteit te bepalen. Twee assistenten werden op het hoofdplein van de campus geplaatst en kregen de opdracht om alle studenten te interviewen die op bepaalde tijdstippen voorbij kwamen. Van de 369 studenten die geïnterviewd werden, rapporteerde 39% ooit ecstasy gebruikt te hebben. Dit resultaat wordt uiteraard deels bepaald door het algemene ecstasy-gebruik onder Stanford-studenten (d.i. door de verdeling van het ecstasy-gebruik over de populatie van Stanford-studenten). Maar ook door het feit dat de studenten die geïnterviewd werden, vermoedelijk een selectieve groep vormen van studenten die bijvoorbeeld niet in de les aanwezig waren of die in de buurt van het hoofdplein les kregen en bijgevolg voornamelijk uit 1 bepaalde studierichting afkomstig waren. **Einde voorbeeld** Omwille hiervan is het design van een studie van primair belang om lukrake en representatieve steekproeven te garanderen (zie Sectie 3.2). Zoals u doorheen deze cursus zult vaststellen, zullen de meeste wetenschappelijke rapporten daarom een gedetailleerde beschrijving geven van de manier waarop de data bekomen werden. Dit moet de lezer toelaten om de validiteit van de studie te beoordelen. Algemeen zullen we met \\(E(X)\\), \\(\\text{Var}(X)\\) en \\(\\text{Cor}(X,Y)\\) respectievelijk het gemiddelde, de variantie en de correlatie noteren van 2 toevalsveranderlijken \\(X\\) en \\(Y\\) in de populatie. Deze worden respectievelijk de theoretische verwachtingswaarde van \\(X\\), theoretische variantie van \\(X\\) en theoretische correlatie van \\(X\\) en \\(Y\\) genoemd. Men zou ze bekomen door voor alle individuen in de populatie de karakteristieken \\(X\\) en \\(Y\\) op te meten en vervolgens respectievelijk het rekenkundig gemiddelde, de variantie en de Pearson correlatie te berekenen. Om die reden blijven de rekenregels voor gemiddelden en varianties geldig26 voor populatiegemiddelden en -varianties. In de onderstelling dat we over een eenvoudige lukrake steekproef beschikken van metingen \\(X_1,...,X_n\\) voor een karakteristiek \\(X\\), volgen \\(X_1,...,X_n\\) allen dezelfde verdeling. In het bijzonder hebben ze allen gemiddelde \\(\\mu\\) en variantie \\(\\sigma^2\\); d.i. \\(E(X_1)=...=E(X_n)=\\mu\\) en \\(\\text{Var}(X_1)=...=\\text{Var}(X_n)=\\sigma^2\\). Het feit dat we subjecten 1 tot \\(n\\) lukraak uit de populatie getrokken hebben, staat er m.a.w. garant voor dat verdeling van de karakteristiek in deze steekproef representatief is voor de theoretische verdeling in de doelpopulatie. Gebruik makend van de rekenregels voor gemiddelden, vinden we bijgevolg dat: \\[\\begin{eqnarray*} E(\\bar X) &amp;=&amp; E \\left(\\frac{X_1+ X_2+ ... + X_n}{n}\\right) \\\\ &amp;= &amp; \\frac{E(X_1)+ E(X_2)+ ... + E(X_n)}{n} \\\\ &amp;=&amp; \\frac{\\mu + \\mu + ... +\\mu}{n} \\\\ &amp;= &amp; \\mu \\end{eqnarray*}\\] Dit geeft aan dat het verwachte steekproefgemiddelde in een eenvoudige lukrake steekproef gelijk is aan het beoogde populatiegemiddelde \\(\\mu\\). Men zegt dan dat \\(\\bar X\\) een onvertekende schatter is voor \\(\\mu\\). We kunnen in dat geval verwachten dat de waarde \\(\\bar x\\) die we schatten voor \\(\\mu\\) op basis van de steekproef, niet systematisch hoger of lager dan de gezochte waarde \\(\\mu\\) zal zijn. Het spreekt voor zich dat dit een zeer wenselijke eigenschap is. Definitie 5.1 (Onvertekende schatter) Een statistiek of schatter \\(S\\) voor een parameter \\(\\theta\\) wordt onvertekend genoemd als haar theoretische verwachtingswaarde gelijk is aan die parameter, d.w.z. \\(E(S)= \\theta\\). Einde definitie 5.3.2 Imprecisie/standard error Het feit dat het steekproefgemiddelde (over een groot aantal vergelijkbare studies) gemiddeld gezien niet afwijkt van de gezochte waarde \\(\\mu\\), impliceert niet dat ze niet rond die waarde varieert. Om inzicht te krijgen hoe dicht we het steekproefgemiddelde bij \\(\\mu\\) mogen verwachten, wensen we bijgevolg ook haar variabiliteit te kennen. Om dit te bepalen, zullen we ervan uitgaan dat de metingen \\(X_1, X_2, ..., X_n\\) werden gemaakt bij \\(n\\) onafhankelijke observationele eenheden. In woorden betekent onafhankelijkheid dat elk subject een volledig nieuw stukje informatie bijdraagt tot het geheel. Een voorbeeld van afhankelijkheid tussen studie-objecten komt klassiek uit de studie van kankerverwekkende stoffen. Bij testen op zwangere ratten, worden metingen gedaan op hun levende foetussen of boorlingen. Foetussen van eenzelfde moeder delen dezelfde genetische achtergrond en zijn daarom waarschijnlijk meer aan elkaar gelijk dan foetussen van verschillende moeders. Zelfs al zijn de moeders die opgenomen worden in zo’n studie onafhankelijk van elkaar gekozen, de verschillende kleine ratjes leveren niet langer onafhankelijke stukjes informatie: via de gedeelde moeders is een afhankelijkheid ingebouwd. Afhankelijke gegevens worden ondermeer ook verzameld in pre-test/post-test designs en cross-over studies. De volgende eigenschap illustreert de noodzaak om over onafhankelijke gegevens te beschikken, wil men gemakkelijk de variabiliteit van het steekproefgemiddelde kunnen bepalen. Eigenschap Als \\(X\\) en \\(Y\\) onafhankelijke toevalsveranderlijken zijn, dan geldt27: \\[\\begin{equation*} \\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y) \\end{equation*}\\] Algemeen (d.i. voor mogelijks afhankelijke toevalsveranderlijken \\(X\\) en \\(Y\\)) geldt voor constanten \\(a\\) en \\(b\\): \\[\\begin{eqnarray*} \\text{Var}(aX+bY) &amp;=&amp; a^2 \\text{Var}(X) + b^2 \\text{Var}(Y) + 2 ab {% \\text{Cor}}(X,Y)\\sqrt{\\text{Var}(X)}\\sqrt{\\text{Var}(Y)} \\end{eqnarray*}\\] Einde Eigenschap Een veelgemaakte fout is dat men beweert dat \\(\\text{Var}(X-Y)=\\text{Var}(X)-\\text{Var}(Y)\\). Niets is minder waar! Stel bijvoorbeeld dat de lengte \\(X\\) van moeders en de lengte \\(Y\\) van vaders evenveel variëren zodat \\(\\text{Var}(X)=\\text{Var}(Y)\\). Dan impliceert dat nog niet dat als je het verschil \\(X-Y\\) neemt tussen de lengte van een moeder en haar partner, dat dit verschil variantie nul heeft; d.w.z. dat het niet varieert en bijgevolg voor alle moeder-vader paren exact dezelfde waarde aanneemt! Bovenstaande formules geven inderdaad integendeel aan dat: \\[\\begin{equation*} \\text{Var}(X-Y) = \\text{Var}(X) + \\text{Var}(Y) -2{\\text{Cor}}(X,Y)\\sqrt{\\text{Var}(X)}\\sqrt{\\text{Var}(Y)}. \\end{equation*}\\] Gebruik makend van deze rekenregels en steunend op de onafhankelijkheid van de observaties (waarvan we gebruik maken in de derde overgang, *) kunnen we nu verder berekenen dat: \\[\\begin{eqnarray*} \\text{Var}(\\bar X)&amp;=&amp;\\text{Var} \\left(\\frac{X_1+ X_2+ ... + X_n}{n}\\right) \\\\ &amp;= &amp; \\frac{\\text{Var} (X_1+ X_2+ ... + X_n)}{n^2} \\\\ &amp;\\overset{*}{=} &amp; \\frac{\\text{Var}(X_1)+ \\text{Var}(X_2)+ ... + \\text{Var}(X_n)}{n^2} \\\\ &amp;=&amp; \\frac{\\sigma^2 + \\sigma^2 + ... \\sigma^2}{n^2} \\\\ &amp;= &amp; \\frac{\\sigma^2}{n}. \\end{eqnarray*}\\] Het steekproefgemiddelde heeft dus een spreiding (standaarddeviatie) rond haar gemiddelde \\(\\mu\\) die \\(\\sqrt{n}\\) keer kleiner is dan de deviatie op de oorspronkelijke observaties. Vandaar dat we meer over \\(\\mu\\) kunnen leren door het steekproefgemiddelde \\(\\bar X\\) te observeren dan door een individuele waarde \\(X\\) te observeren. Definitie 5.2 (Standaard error) De standaarddeviatie van \\(\\bar{X}\\) is \\(\\sigma/\\sqrt{n}\\) en krijgt in de literatuur de speciale naam {standard error} van het gemiddelde. Algemeen noemt men de standaarddeviatie van een schatter voor een bepaalde parameter \\(\\theta\\), de standard error van die schatter. Men noteert dit als \\(SE\\). Einde definitie Voorbeeld 5.2 (Gemiddelde bloeddrukverandering) Stel dat we \\(n = 15\\) systolische bloeddrukobservaties zullen meten en dat de standaarddeviatie van de bloeddrukverschillen in de populatie \\(\\sigma = 9.0\\) mmHg bedraagt, dan is standard error (SE) van de systolische bloeddrukveranderingen \\(\\bar X\\): \\[ SE= \\frac{9.0}{\\sqrt{15}}=2.32\\text{mmHg.} \\] Meestal is \\(\\sigma\\), en bijgevolg de standard error van het steekproefgemiddelde, ongekend. Men moet dan de standard error schatten. Een voor de hand liggende schatter met goede eigenschappen is \\(S/\\sqrt{n},\\) waarbij \\(S^2\\) de steekproefvariantie van de reeks observaties \\(X_1,...,X_n\\) is en \\(S\\) de steekproef standaarddeviatie wordt genoemd. Voor het captopril voorbeeld kunnen we de standard error op het steekproefgemiddelde van de bloeddrukveranderingen schatten in R als n=length(delta) se=sd(delta)/sqrt(n) se ## [1] 2.330883 5.3.2.1 Standaarddeviatie vs standard error Er is vaak nogal wat verwarring over het onderscheid tussen standard error en standaarddeviatie. De standard error verwijst steeds naar de spreiding op een geschatte parameter zoals het steekproefgemiddelde. Omdat een schatting steeds precieser wordt naarmate de steekproef groter wordt, daalt de standard error met stijgende steekproefgrootte \\(n\\). Als de term standaarddeviatie verwijst naar het steekproefgemiddelde (m.a.w. als men spreekt over de standaarddeviatie van het steekproefgemiddelde), dan is deze standaarddeviatie identiek gelijk aan de standard error. Als ze verwijst naar de individuele observaties, dan niet. Dit kun je ondermeer zien aan het feit dat de individuele observaties niet minder variabel zijn in grote steekproeven dan in kleine steekproeven; m.a.w. de standaarddeviatie van de individuele observaties neemt niet af naarmate de steekproef groter wordt, het is immers een karakteristiek van de populatie. De standaarddeviatie op de observaties is een maat voor de variabiliteit tussen individuen met betrekking tot een bepaalde meetwaarde. De standaard error van een schatter meet de onzekerheid in die schatter voor een bepaalde parameter. Beide statistieken worden ook anders beïnvloed door de steekproefgrootte. De variabiliteit in de populatie verandert niet. Buiten het feit dat we de standaarddeviatie meer nauwkeurig kunnen schatten in een grotere steekproef zal ze dus steeds in dezelfde grootteorde liggen. Ze heeft als verwachte waarde immers de theoretische standaarddeviatie \\(\\sigma\\) in de populatie. De standard error van een schatter wordt echter sterk beïnvloed door de steekproefgrootte: hoe groter de steekproef hoe nauwkeuriger de schatter voor een bepaalde parameter en hoe kleiner zijn standard error! 5.3.2.2 Geclusterde metingen De data in studies zijn niet altijd onafhankelijk. Dat heeft zijn consequenties voor het schatten van de standaard errors. Beschouw een studiedesign waarbij voor \\(n\\) planten, tijdens een bepaalde fase in de groei, de expressie van een bepaald gen 2 maal wordt gemeten om meetfouten te drukken. Men is geïnteresseerd in de gemiddelde genexpressie. Als we met \\(Y_{i1}\\) en \\(Y_{i2}\\) de eerste en tweede meting, respectievelijk, voorstellen voor plant \\(i=1,...,n\\), dan kunnen we dit schatten als \\[\\begin{equation*} \\bar Y = \\sum_{i=1}^n \\frac{Y_{i1}+Y_{i2}}{2n} \\end{equation*}\\] In de onderstelling dat de \\(n\\) planten onafhankelijk van elkaar gekozen werden en de eerste en tweede metingen even variabel zijn (d.w.z. \\(\\text{Var}(Y_{i1})=\\text{Var}(Y_{i2})=\\sigma^2\\)), bedraagt de variantie op dit steekproefgemiddelde \\[\\begin{eqnarray*} \\text{Var}(\\bar Y)&amp;=&amp;\\sum_{i=1}^n \\frac{\\text{Var}(Y_{i1}+Y_{i2})}{4n^2} \\\\ &amp;=&amp;\\sum_{i=1}^n \\frac{\\sigma^2+\\sigma^2+2\\text{Cor}(Y_{i1},Y_{i2})\\sigma^2}{% 4n^2} \\\\ &amp;=&amp;\\frac{\\sigma^2}{2n}\\{1+\\text{Cor}(Y_{1},Y_{2})\\} \\end{eqnarray*}\\] Vermits verschillende metingen afkomstig van eenzelfde plant doorgaans positief met elkaar gecorreleerd zijn, is de standard error op \\(\\bar Y\\) dus groter dan wanneer de \\(2n\\) metingen van \\(2n\\) verschillende, onafhankelijke planten afkomstig zouden zijn. Dat is omdat, gegeven de eerste meting \\(Y_{i1}\\), de tweede meting \\(Y_{i2}\\) geen volledig nieuwe informatie toevoegt en er bijgevolg minder informatie beschikbaar is om het gemiddelde te schatten dan wanneer alle gegevens van verschillende planten afkomstig waren. In het bijzonder, wanneer \\(\\text{Cor}(Y_{1},Y_{2})=1\\), dan levert de tweede meting geen nieuwe informatie en bekomt men eenzelfde nauwkeurigheid als wanneer men slechts 1 meting per plant had bekomen. Wanneer \\(\\text{Cor}(Y_{1},Y_{2})=0\\), dan levert de tweede meting volledig nieuwe informatie en bekomt men eenzelfde nauwkeurigheid als wanneer men 1 meting had bekomen voor \\(2n\\) i.p.v. \\(n\\) verschillende planten. Vermits \\[\\frac{\\sigma^2}{2n}\\{1+\\text{Cor}(Y_{1},Y_{2})\\}\\geq \\frac{\\sigma^2}{2n}\\] Wanneer de correlatie tussen herhaalde genexpressie metingen positief is (hetgeen we verwachten), zal men in de praktijk meer preciese resultaten bekomen door 1 meting te bepalen voor \\(2n\\) verschillende planten dan door 2 metingen te bepalen voor \\(n\\) verschillende planten. De metingen in de captopril voorbeeld zijn eveneens geclusterd. We hebben immers twee systolische bloeddrukmetingen per patiënt. 1 meting voor en 1 meting na het toedienen van captopril. We beogen om de gemiddelde bloeddrukverandering \\(\\mu\\) te schatten a.d.h.v. de gegevens \\[(Y_{i1} , Y_{i2}),\\] voor subjecten \\(i = 1, ..., n\\). En we bekomen de volgende schatting: \\[\\bar X = \\sum_{i=1}^n \\frac{Y_{i2}-Y_{i1}}{n}\\] Uit de rekenregels voor de variantie weten we dat \\[\\begin{eqnarray*} \\text{Var}\\left[\\bar X\\right]&amp;=&amp;\\sum_{i=1}^n \\frac{\\text{Var}\\left[Y_{i1}-Y_{i2}\\right]}{n^2}\\\\ &amp;=&amp;\\sum_{i=1}^n \\frac{\\sigma^2_1+\\sigma^2_2-2\\text{Cor}\\left[Y_{i1},Y_{i2}\\right]\\sigma_1\\sigma_2}{n^2}\\\\ &amp;=&amp;\\frac{\\sigma^2_1+\\sigma^2_2-2\\text{Cor}\\left[Y_{i1},Y_{i2}\\right]\\sigma_1\\sigma_2}{n},\\\\ \\end{eqnarray*}\\] In R kunnen we dit als volgt berekenen: #functie var op een matrix berekent varianties sigma_1^2, sigma_2^2 #covariantie sigma_{12} vars=var(captopril[,c(&quot;SBPb&quot;,&quot;SBPa&quot;)]) vars ## SBPb SBPa ## SBPb 422.9238 370.7857 ## SBPa 370.7857 400.1429 cor(captopril$SBPa,captopril$SBPb) ## [1] 0.9013312 varXbarDelta=(vars[1,1]+vars[2,2]-2*vars[1,2])/15 sqrt(varXbarDelta) ## [1] 2.330883 We zien dat de metingen heel sterk gecorreleerd zijn, waardoor de variantie op het verschil veel lager zal liggen dan op de originele metingen. Gezien we voor elke patiënt twee metingen hebben bestaat een alternatieve methode om de standard error te bepalen erin om alle gecorreleerde metingen tot 1 meting te reduceren. Merk op dat we dit enkel kunnen doen voor gepaarde metingen. Alle resulterende metingen zijn dan onafhankelijk. Concreet kunnen we voor elke patiënt \\(i\\) in de steekproef het bloeddrukverschil berekenen: \\[X_{i}=Y_{ai}-Y_{bi}\\] en vervolgens standard error op \\(\\bar X\\). In het captopril voorbeeld wordt de schatting sd(delta)/sqrt(15) ## [1] 2.330883 We zien dat we exact dezelfde schatting voor de standard error bekomen. Verder zien we ook dat het design een groot voordeel heeft: Aangezien de bloeddrukmetingen voor en na het toedienen van captopril sterk positief gecorreleerd zijn is de variantie van het verschil veel lager dan deze op de originele bloeddrukmetingen. Iedere patiënt in de studie dient immers als zijn eigen controle en op die manier kunnen we de variabiliteit in de bloeddrukmetingen tussen patiënten uit de analyse verwijderen! 5.3.2.3 Normaal verdeelde gegevens Als de gegevens Normaal verdeeld zijn, dan zijn er meerdere onvertekende schatters voor het populatiegemiddelde \\(\\mu\\), bvb. het steekproefgemiddelde en de mediaan. Men kan echter aantonen dat in dat geval het steekproefgemiddelde \\(\\bar{X}\\) de onvertekende schatter is voor \\(\\mu\\) met de kleinste standard error. Dat betekent dat ze gemiddeld minder afwijkt van de echte parameterwaarde dan de mediaan, die veel meer varieert van steekproef tot steekproef. Het steekproefgemiddelde is bijgevolg een schatter die accuraat is (want onvertekend) en meest precies (kleinste standaarddeviatie). 5.3.3 Verdeling van het steekproefgemiddelde Om ondermeer goed de betekenis van de standard error te kunnen vatten, moeten we van \\(\\bar X\\) niet alleen het gemiddelde en de standaarddeviatie, maar ook de exacte verdeling kennen. De standard error is immers een standaardeviatie (bvb. van het steekproefgemiddelde), waarvan de betekenis het meest duidelijk is wanneer de metingen (in dit geval, het steekproefgemiddelde) Normaal verdeeld zijn. In het bijzonder geval dat de individuele observaties \\(X_i\\) een Normale verdeling hebben met gemiddelde \\(\\mu\\) en variantie \\(\\sigma^2\\), kan men aantonen dat ook \\(\\bar X\\) Normaal verdeeld is met gemiddelde \\(\\mu\\) en variantie \\(\\sigma^2/n.\\) Dit fenomeen wordt geïllustreerd in Figuur 5.7. De linkse figuur illustreert een lukrake trekking of steekproef van observaties uit een Normale verdeling. Als men dit blijft herhalen en voor alle bekomen steekproeven het steekproefgemiddelde berekent en en vervolgens deze gemiddeldes uitzet in een histogram, dan krijgt men het histogram uit rechtse figuur. De steekproefgemiddeldes in deze figuur lijken inderdaad een Normale verdeling te volgen. Figuur 5.7: Simulaties van steekproeven met n=15 observaties uit een normale verdeling met gemiddelde systolische bloeddrukdaling 19 mmHg en standaard deviate van 9 mmHg. (links één steekproef, rechts een histogram van steekproefgemiddelden voor 1000 steekproeven. Het gemiddelde in de populatie is weergegeven d.m.v. rode lijn). In het captopril voorbeeld zagen we dat de systolische bloeddrukverandering approximatief normaal verdeeld is. De standard error op de bloeddrukverandering bedroeg 2.32 mm Hg. Dus op 100 studies met n = 15 subjecten, verwachten we dat de geschatte gemiddelde systolische bloeddrukafwijking (\\(\\bar X\\)) op minder dan 2 × 2.32 = 4.64mm Hg van het werkelijke populatiegemiddelde (\\(\\mu\\)) ligt in 95 studies. In het algemeen, wanneer de individuele observaties \\(X_i\\) geen Normale verdeling hebben, is \\(\\bar X\\) toch nog Normaal verdeeld zodra het aantal observaties groot genoeg is. Hoe groot de steekproef hiervoor moet zijn, hangt hierbij af van hoe scheef de verdeling van de oorspronkelijke observaties is. Dat is het gevolg van de volgende fundamentele en veel toegepaste wiskundestelling. De Centrale Limietstelling (CLT) Stel dat \\(X_1, X_2, \\dots, X_n, \\; n\\) onafhankelijke lukrake trekkingen van de toevalsveranderlijke \\(X\\) voorstellen, met allen dezelfde theoretische verdeling. Laat \\(X\\) gemiddelde \\(\\mu\\) en variantie \\(\\sigma^2\\) hebben maar verder een ongespecifieerde verdeling, dan wordt de verdeling van het steekproefgemiddelde \\(\\bar{X}_n = {\\sum_{i=1}^{n} X_i}/{n}\\) naarmate \\(n\\) groter wordt steeds beter benaderd door de Normale verdeling met gemiddelde \\(\\mu\\) en variantie \\(\\sigma^2/n.\\) Einde Stelling Deze belangrijke eigenschap zal ons toelaten om de meeste technieken die in deze cursus aan bod komen toe te passen op een zeer uitgebreid spectrum van experimenten. We illustreren deze stelling in Figuur 5.8. We simuleren data uit een experiment waarbij we een munt opwerpen. De data zijn dan Bernouilli verdeeld en kunnen de waarde \\(X=0\\) (munt) of \\(X=1\\) (kop) aannemen met een kans van 50% en zijn duidelijk niet-Normaal verdeeld. We simuleren steekproeven met een steekproefgrootte van 10 observaties en 100 observaties en onderzoeken de verdeling van het steekproefgemiddelde voor elke steekproefgrootte. We zien duidelijk dat CLT niet van toepassing is bij een steekproefgrootte van 10. Voor steekproeven met 100 observaties zien we dat de verdeling van het steekproefgemiddelde al beter benaderd kan worden door een Normale verdeling. Figuur 5.8: Illustratie van de Centrale Limietstelling d.m.v. Bernouilli verdeelde gegevens (opwerpen van een muntstuk) Steekproefgroottes (n=10, links, en n=100, rechts). Densiteit van de normale verdeling worden weergegeven in rood. We zien duidelijk dat CLT niet van toepassing is bij een steekproefgrootte van 10. Voor steekproeven met 100 observaties zien we dat de verdeling van het steekproefgemiddelde al beter benaderd kan worden door een Normale verdeling. 5.4 Intervalschatters In de vorige sectie hebben we vastgesteld dat het steekproefgemiddelde van steekproef tot steekproef varieert rond het populatiegemiddelde dat we willen schatten. Om die reden wensen we in deze sectie een interval rond het steekproefgemiddelde te bepalen waarbinnen we het populatiegemiddelde met gegeven kans (bvb. 95% kans) kunnen verwachten. In Sectie 5.4.1 zullen we dit uitwerken voor het geval waar de populatievariantie \\(\\sigma^2\\) op de metingen gekend is. Deze onderstelling is meestal onredelijk28, maar wordt hier gemaakt om redenen van eenvoud. In Sectie 5.4.2 zullen we van deze onderstelling afstappen. 5.4.1 Gekende variantie op de metingen Wanneer de individuele observaties \\(X\\) Normaal verdeeld zijn met gemiddelde \\(\\mu\\) en gekende variantie \\(\\sigma^2\\), noteren we dat als volgt: \\(X\\sim N(\\mu,\\sigma^2)\\). Uit vorige sectie volgt dan dat het steekproefgemiddelde \\(\\bar{X}\\) eveneens Normaal verdeeld is volgens \\(N(\\mu,\\sigma^2/n)\\). Een 95% referentie-interval voor het steekproefgemiddelde ziet er bijgevolg uit als \\[\\begin{equation*} \\left[\\mu - 1.96 \\frac{\\sigma}{\\sqrt{n}},\\mu + 1.96 \\frac{\\sigma}{\\sqrt{n}}% \\right] \\end{equation*}\\] Het bevat met 95% kans het steekproefgemiddelde van een lukrake steekproef. Dit interval kunnen we niet expliciet berekenen op basis van de geobserveerde gegevens, omdat \\(\\mu\\) ongekend is (we gaan er hier voorlopig van uit dat \\(\\sigma\\) wel gekend is). Het kan wel geschat worden als \\[\\begin{equation*} \\left[\\bar X - 1.96 \\frac{\\sigma}{\\sqrt{n}},\\bar X + 1.96 \\frac{\\sigma}{\\sqrt{n}}\\right] \\end{equation*}\\] Hoewel dit laatste interval nog steeds kan geïnterpreteerd worden als een referentie-interval voor het steekproefgemiddelde, kunnen we er een veel nuttigere interpretatie aan geven. Immers, de ongelijkheid \\(\\mu - 1.96 \\ \\sigma/\\sqrt{n} &lt; \\bar{X}\\) kan equivalent worden herschreven als \\(\\mu &lt; \\bar{X} + 1.96 \\ \\sigma/\\sqrt{n}\\). Hieruit volgt: \\[\\begin{eqnarray*} 95\\% &amp;=&amp; P( \\mu - 1.96 \\ \\sigma/\\sqrt{n} &lt; \\bar{X} &lt; \\mu + 1.96 \\ \\sigma/\\sqrt{n} ) \\\\ &amp;=&amp;P( \\bar{X} - 1.96 \\ \\sigma/\\sqrt{n} &lt; \\mu &lt; \\bar{X} + 1.96 \\ \\sigma/\\sqrt{n} ) \\end{eqnarray*}\\] Dit leidt tot volgende definitie. Definitie 5.3 (95\\(\\%\\) betrouwbaarheidsinterval voor populatiegemiddelde) Het interval \\[\\begin{equation} [\\bar{X} - 1.96 \\ \\sigma/\\sqrt{n} , \\bar{X} + 1.96 \\ \\sigma/\\sqrt{n} ], \\tag{5.1} \\end{equation}\\] bevat met 95% kans het populatiegemiddelde \\(\\mu\\). Het wordt een 95% betrouwbaarheidsinterval (in het Engels: 95% confidence interval) voor het populatiegemiddelde \\(\\mu\\) genoemd. De kans dat het de populatieparameter \\(\\mu\\) bevat, d.i. 95%, wordt het betrouwbaarheidsniveau genoemd. Einde definitie Een 95% betrouwbaarheidsinterval bepaalt met andere woorden een reeks waarden waarbinnen de gezochte populatieparameter waarschijnlijk (namelijk met 95% kans) valt. Stel dat we in een steekproef een bloeddrukdaling van -18.93mmHg observeren en dat we weten dat de standaarddeviatie van de bloeddrukmetingen 9mmHg bedraagt. Dan vinden we een betrouwbaarheidsinterval voor de gemiddelde bloeddrukdaling van \\(\\left[-18.93-1.96\\times 9/\\sqrt{15},-18.9+1.95\\times 9/\\sqrt{15}\\right]=\\)[-23.48,-14.38]mmHg. De reden waarom over “95% kans” gesproken wordt, is omdat de eindpunten van het 95% betrouwbaarheidsinterval toevalsveranderlijken zijn die variëren van steekproef tot steekproef. Met andere woorden, verschillende steekproeven leveren telkens andere betrouwbaarheidsintervallen op, vermits die intervallen berekend zijn op basis van de gegevens in de steekproef. Men noemt het om die reden stochastische intervallen. Voor 95% van alle steekproeven zal het berekende 95% betrouwbaarheidsinterval de gezochte waarde van de populatieparameter bevatten, en voor de overige 5% niet. Dat wordt geïllustreerd a.d.h.v. een simulatiestudie in Sectie 5.4.3 (nadat we de intervallen hebben uitgebreid voor de meer realistische setting waarbij de variantie in de populatie ongekend is). Uiteraard kunnen de onderzoekers o.b.v. een gegeven betrouwbaarheidsinterval niet besluiten of het de gezochte parameterwaarde bevat of niet, vermits ze precies op zoek zijn naar die onbekende waarde. Maar ze gebruiken een procedure die in 95% van de gevallen werkt; m.a.w. die in 95% van de gevallen de gezochte waarde bevat. Of nog, als men dagelijks gegevens zou verzamelen en telkens een 95% betrouwbaarheidsinterval zou berekenen voor een nieuwe parameter \\(\\theta\\) (bvb. een odds ratio), dan zou men op lange termijn in 95% van de gevallen de gezochte waarde omvat hebben. Tot nog toe zijn we ervan uitgegaan dat de individuele observaties Normaal verdeeld zijn en dat hun variantie gekend is (want als de variantie \\(\\sigma^2\\) niet gekend is, kan men de grenzen van het interval niet berekenen). Wegens de Centrale Limietstelling bevat Vergelijking (5.1) het gemiddelde \\(\\mu\\) bij benadering met 95% kans wanneer de steekproef groot is en de variantie van de individuele observaties gekend, maar hun verdeling ongekend is. Wanneer bovendien de variantie ongekend is, kan me ze schatten door gebruik te maken van de steekproefvariantie \\(S^2\\) van de reeks observaties \\(X_1,...,X_n\\). Men kan aantonen dat het interval \\([\\bar{X} - 1.96 \\ s/\\sqrt{n} , \\bar{X} + 1.96 \\ s/\\sqrt{n} ]\\) dan het populatiegemiddelde met bij benadering 95% kans bevat, op voorwaarde dat de steekproef groot is. In de volgende sectie gaan we na hoe een betrouwbaarheidsinterval voor het populatiegemiddelde geconstrueerd kan worden wanneer de variantie ongekend is en de steekproef relatief klein. Om een betrouwbaarheidsinterval met een ander betrouwbaarheidsniveau, \\((1- \\alpha)100\\%\\) te construeren, vervangt men 1.96 door het relevante kwantiel \\(z_{\\alpha/2}.\\) De breedte van een \\(100\\%(1-\\alpha)\\) betrouwbaarheidsinterval voor een populatiegemiddelde \\(\\mu\\) is \\(2 z_{\\alpha/2} \\ \\sigma/\\sqrt{n}\\). Ze wordt dus bepaald door 3 factoren: de standaarddeviatie op de individuele observaties, \\(\\sigma\\), de grootte van de steekproef, \\(n\\), en het betrouwbaarheidsniveau, \\(1-\\alpha\\): \\(n\\): naarmate de steekproefgrootte toeneemt, krimpt het betrouwbaarheidsinterval. In grote steekproeven beschikken we immers over veel informatie en kunnen we de gezochte populatieparameter bijgevolg relatief nauwkeurig afschatten. \\(\\sigma\\): naarmate de standaarddeviatie van de oorspronkelijke observaties toeneemt, neemt de lengte van het betrouwbaarheidsinterval toe. Indien er immers veel ruis op de gegevens zit, dan is het moeilijker om populatieparameters of -kenmerken te identificeren. \\(1-\\alpha\\): naarmate het betrouwbaarheidsniveau toeneemt, wordt het betrouwbaarheidsinterval breder. Indien we immers eisen dat het interval met 99.9% kans de populatiewaarde bevat i.p.v. met 80% kans, dan zullen we duidelijk een breder interval nodig hebben. Betrouwbaarheidsintervallen worden niet enkel gebruikt voor het populatiegemiddelde, maar kunnen in principe voor om het even welke populatieparameter worden gedefinieerd. Zo kunnen ze bijvoorbeeld gedefinieerd worden voor een verschil tussen 2 gemiddelden, voor een odds ratio, voor een variantie, … De manier om die intervallen te berekenen is vaak complex en sterk afhankelijk van de gebruikte schatter voor de populatieparameter. Er wordt daarom niet van u verwacht dat u voor alle populatieparameters die we in deze cursus ontmoeten, een betrouwbaarheidsinterval kunt berekenen, maar wel dat u het kunt interpreteren. Definitie 5.4 (Betrouwbaarheidsinterval) Een \\((1-\\alpha)100\\)% betrouwbaarheidsinterval voor een populatieparameter \\(\\theta\\) is een geschat (en bijgevolg stochastisch) interval dat met \\((1-\\alpha)100\\)% kans de echte waarde van die populatieparameter \\(\\theta\\) bevat. Einde Definitie 5.4.2 Ongekende variantie op de metingen Tot nog toe werd verondersteld dat de populatievariantie \\(\\sigma^2\\) gekend is bij het berekenen van een betrouwbaarheidsinterval voor \\(\\mu\\). Betrouwbaarheidsintervallen voor \\(\\mu\\) werden dan opgebouwd door op te merken dat de gestandaardiseerde waarde \\((\\bar{X} - \\mu)/(\\sigma/\\sqrt{n})\\) standaardnormaal verdeeld is en bijgevolg \\[\\begin{equation*} \\left[\\mu - 1.96 \\frac{\\sigma}{\\sqrt{n}},\\mu + 1.96 \\frac{\\sigma}{\\sqrt{n}}% \\right] \\end{equation*}\\] een 95% referentie-interval voor het steekproefgemiddelde voorstelt. In de praktijk komt het quasi nooit voor dat men de populatievariantie \\(\\sigma^2\\) exact kent. In de praktijk wordt deze geschat als \\(S^2\\) op basis van de voorhanden zijnde steekproef. Als gevolg hiervan zullen de betrouwbaarheidsintervallen uit voorgaande sectie doorgaans iets te smal zijn (omdat ze er geen rekening mee houden dat ook de variantie werd geschat) en is het noodzakelijk om bij de berekening \\((\\bar{X} - \\mu)/(S/\\sqrt{n})\\) te gebruiken als gestandaardiseerde waarde i.p.v. \\((\\bar{X} - \\mu)/(\\sigma/\\sqrt{n})\\). Wanneer de steekproef voldoende groot is, ligt de vierkantswortel van variantie \\(S^2\\) voldoende dicht bij \\(\\sigma\\) zodat \\({(\\bar{X} - \\mu)}/{(S/\\sqrt{n}) }\\) bij benadering een standaardnormale verdeling volgt en, bijgevolg, \\[\\begin{equation*} \\left[\\bar{X} - z_{\\alpha/2} \\ \\frac{S}{\\sqrt{n}} , \\bar{X} + z_{\\alpha/2} \\ \\frac{S}{\\sqrt{n}}\\right] \\end{equation*}\\] een benaderd \\((1- \\alpha)100\\%\\) betrouwbaarheidsinterval is voor \\(\\mu\\). Voor kleine steekproeven is dit niet langer het geval. Daardoor introduceert men een extra onnauwkeurigheid in de gestandaardiseerde waarde \\({(\\bar{X} - \\mu)}/{(S/\\sqrt{n})}\\). Deze is nog wel gecentreerd rond nul en symmetrisch, maar niet langer Normaal verdeeld. De echte verdeling voor eindige steekproefgrootte \\(n\\) heeft zwaardere staarten dan de Normale. Hoeveel zwaarder de staarten zijn, hangt van de steekproefgrootte \\(n\\) af. Als \\(n\\) oneindig groot wordt, komt \\(S\\) zodanig dicht bij \\(\\sigma\\) te liggen dat de extra onnauwkeurigheid in de gestandaardiseerde waarde verwaarloosbaar is en bijgevolg ook het verschil met de Normale verdeling. Maar voor relatief kleine steekproeven hangt de verdeling van \\({(\\bar{X} - \\mu)}/({S/\\sqrt{n}})\\) af van de grootte \\(n\\) van de steekproef. Ze krijgt de naam (Student) \\(t\\)-verdeling met \\(n-1\\) vrijheidsgraden (in het Engels: degrees of freedom). Deze verdeling wordt voor een aantal verschillende vrijheidsgraden geïllustreerd in Figuur 5.9. De t-verdelingen in de figuur hebben duidelijk bredere staarten dan de normaalverdeling, waardoor ze ook een grotere percentielwaarden hebben voor een vooropgesteld betrouwbaarheidsniveau. Dat zal leiden tot bredere intervallen, wat logisch is aangezien we de extra onzekerheid inbouwen die gerelateerd is aan het schatten van de standaarddeviatie. Definitie 5.5 (t-verdeling) Als \\(X_1, X_2, ..., X_n\\) een steekproef vormen uit de Normale verdeling \\(N(\\mu, \\sigma^2)\\), dan is \\((\\bar{X} - \\mu)/(S/\\sqrt{n})\\) verdeeld als een \\(t\\)-verdeling met \\(n-1\\) vrijheidsgraden. **Einde Definitie grid=seq(-5,5,.1) plot(grid,dnorm(grid),ylab=&quot;densiteit&quot;,xlab=&quot;X&quot;,type=&quot;l&quot;,lwd=2) dfs=c(2,5,14) for (i in 1:length(dfs)) lines(grid,dt(grid,dfs[i]),col=i+1,lwd=2) legend(&quot;topright&quot;,lty=1,col=1:4,legend=c(&quot;N(X,mean=0,sd=1)&quot;,paste0(&quot;t(X,df=&quot;,dfs,&quot;)&quot;))) Figuur 5.9: Normale verdeling en t-verdeling met verschillende vrijheidsgraden. Percentielen van de \\(t\\)-verdeling kunnen niet met de hand berekend worden, maar kan men voor de verschillende waarden van \\(n\\) aflezen in Tabellen of berekenen in R. In de onderstaande code wordt het 95%, 97.5%, 99.5% percentiel berekend voor een t-verdeling met 14 vrijheidsgraden, die gebruik kunnen worden voor de berekening van 90%, 95% en 99% betrouwbaarheidsintervallen. qt(.975,df=14) ## [1] 2.144787 qt(c(.95,.975,.995),df=14) ## [1] 1.761310 2.144787 2.976843 We zien dat het 97.5% percentiel 2.14 voor een t-verdeling met \\(n-1=14\\) vrijheidsgraden inderdaad groter is dan het kwantiel uit de normaal verdeling 1.96. Een gelijkaardige logica als voor de Normale verdeling met gekende variantie, geeft dan aan dat een \\(100\\% (1-\\alpha)\\) betrouwbaarheidsinterval voor het gemiddelde \\(\\mu\\) van een Normaal verdeelde veranderlijke \\(X\\) met onbekende variantie kan berekend worden als \\[\\begin{equation*} \\left[\\bar{X} - t_{n-1, \\alpha/2} \\frac{s}{\\sqrt{n}} , \\bar{X} + t_{n-1, \\alpha/2} \\frac{s}{\\sqrt{n}}\\right] \\end{equation*}\\] Deze uitdrukking verschilt van deze in de vorige sectie doordat het \\((1-\\alpha/2)100\\%\\) percentiel van de Normale verdeling wordt vervangen door het \\((1-\\alpha/2)100\\%\\) percentiel van de t-verdeling met \\(n-1\\) vrijheidsgraden. Voor het captopril voorbeeld kunnen we dus een 95% betrouwbaarheidsinterval bekomen door mean(delta) - qt(.975,df=14)*sd(delta)/sqrt(n) ## [1] -23.93258 mean(delta) + qt(.975,df=14)*sd(delta)/sqrt(n) ## [1] -13.93409 Een 99% betrouwbaarheidsinterval voor gemiddelde bloeddrukverandering wordt als volgt bekomen: mean(delta) - qt(.995,df=14)*sd(delta)/sqrt(n) ## [1] -25.87201 mean(delta) + qt(.995,df=14)*sd(delta)/sqrt(n) ## [1] -11.99466 5.4.3 Interpretatie van betrouwbaarheidsintervallen We zullen de interpretatie van betrouwbaarheidsintervallen weergegeven a.d.h.v. een simulatie studie waarbij we 1000 herhaalde steekproeven simuleren met 15 observaties uit een normaal verdeling. De gemiddelde bloeddrukdaling in de populatie bedraagt -18.9 mmHg en de standaarddeviate 9.0 mmHg. We houden voor elke steekproef volgende gegevens bij: het gemiddelde, de ondergrens en bovengrens van het BI en of het BI het werkelijke gemiddelde. set.seed(115) mu &lt;- -18.9 sigma &lt;- 9.0 nSim &lt;- 1000 alpha &lt;- 0.05 n &lt;- 15 muHat &lt;- sigmaHat &lt;- BI.ondergrens &lt;- BI.bovengrens &lt;- omvat &lt;- array(dim=nSim) cnt&lt;-0 for(i in 1:nSim) { y&lt;-rnorm(n,mean=mu,sd=sigma) muHat[i]&lt;-mean(y) sigmaHat[i]&lt;-sd(y)/sqrt(n) BI.ondergrens[i]&lt;-muHat[i]-qt(1-alpha/2,df=n-1)*sigmaHat[i] BI.bovengrens[i]&lt;-muHat[i]+qt(1-alpha/2,df=n-1)*sigmaHat[i] omvat[i]&lt;-(mu&lt;BI.bovengrens[i])&amp;(BI.ondergrens[i]&lt;mu) cnt&lt;-cnt+as.numeric(omvat[i]) } cnt/nSim ## [1] 0.951 Op basis van de 1000 herhaalde steekproeven van de simulatiestudie zien we dat voor 95.1% van de steekproeven de intervallen het werkelijke populatiegemiddelde bevat29. De simulatiestudie toont dus op een empirische wijze aan dat de constructie correct is. Het demonstreert bovendien de interpretatie van probabiliteit via herhaalde steekproefname. In Figuur 5.10 wordt de interpretatie ook grafisch weergegeven voor de eerste 100 gesimuleerde steekproeven. De figuur toont duidelijk aan dat het werkelijke populatiegemiddelde vast is maar ongekend. Het wordt geschat aan de hand van het steekproefgemiddelde dat at random varieert van steekproef tot steekproef rond het werkelijk gemiddelde. We zien ook dat de grenzen van de betrouwbaarheidsintervallen variëren van steekproef tot steekproef. Daarnaast varieert de breedte van de betrouwbaarheidsintervallen eveneens omdat de steekproefstandaarddeviatie eveneens varieert van steekproef tot steekproef30. In de praktijk zullen we op basis van 1 steekproef besluiten dat het betrouwbaarheidsinterval het populatiegemiddelde bevat en we weten dat dergelijke uitspraken met een kans van \\(1-\\alpha\\) (hier 95%) correct zijn. Figuur 5.10: Interpretatie van 95\\(\\%\\) betrouwbaarheidintervallen. Resultaten op basis van 100 gesimuleerde steekproeven. We zien in de figuur duidelijk dat het populatiegemiddelde vast is maar ongekend (blauwe lijn) en dat de bovengrens en ondergrens van betrouwbaarheidsintervallen voor het populatiegemiddelde varieert van steekproef tot steekproef. Van de 100 betrouwbaarheidsintervallen die worden geplot bevatten 95 intervallen het werkelijke steekproef gemiddelde (zwarte BIs). Voor 5 intervallen is dat niet het geval (rode BIs). We zullen nu de simulatie herhalen, maar zullen het aantal observaties in de steekproef verdubbelen. mu &lt;- -18.9 sigma &lt;- 9.0 nSim &lt;- 1000 alpha &lt;- 0.05 n &lt;- 30 muHat &lt;- sigmaHat &lt;- BI.ondergrens &lt;- BI.bovengrens &lt;- omvat &lt;- array(dim=nSim) cnt&lt;-0 for(i in 1:nSim) { y&lt;-rnorm(n,mean=mu,sd=sigma) muHat[i]&lt;-mean(y) sigmaHat[i]&lt;-sd(y)/sqrt(n) BI.ondergrens[i]&lt;-muHat[i]-qt(1-alpha/2,df=n-1)*sigmaHat[i] BI.bovengrens[i]&lt;-muHat[i]+qt(1-alpha/2,df=n-1)*sigmaHat[i] omvat[i]&lt;-(mu&lt;BI.bovengrens[i])&amp;(BI.ondergrens[i]&lt;mu) cnt&lt;-cnt+as.numeric(omvat[i]) } cnt/nSim ## [1] 0.949 We zien een coverage van 94.9% wat opnieuw dicht ligt bij de nominale coverage van 95%. Wanneer we opnieuw de eerste 100 betrouwbaarheidsintervallen plotten (Figuur 5.11) merken we op dat de intervallen smaller zijn dan in Figuur 5.10 (waarom is dat het geval, ga zelf na met welke factor de intervallen ongeveer versmallen?) Figuur 5.11: Interpretatie van 95\\(\\%\\) betrouwbaarheidintervallen. Resultaten op basis van 100 gesimuleerde steekproeven. We zien in de figuur duidelijk dat het populatiegemiddelde vast is maar ongekend (blauwe lijn) en dat de bovengrens en ondergrens van betrouwbaarheidsintervallen voor het populatiegemiddelde varieert van steekproef tot steekproef. Van de 100 betrouwbaarheidsintervallen die worden geplot bevatten 95 intervallen het werkelijke steekproef gemiddelde (zwarte BIs). Voor 5 intervallen is dat niet het geval (rode BIs). 5.4.4 Wat rapporteren? Rapporteer dus zeker steeds de onzekerheid op de resultaten! Conclusies trekken op basis van 1 schatting kan zeer misleidend zijn! In statistische analyses rapporteert men daarom systematisch betrouwbaarheidsintervallen. Betrouwbaarheidsintervallen vormen een goed compromis: ze zijn smal genoeg om informatief te zijn, maar haast nooit zeer misleidend. We besluiten dat de parameter die ons interesseert in het 95% betrouwbaarheidsinterval zit, en weten dat die uitspraak met 95% kans correct is. In de statistiek trekt men dus nooit absolute conclusies. Op basis van de data-analyse voor het captopril voorbeeld kunnen we dus besluiten dat de gemiddelde bloeddrukdaling 18.9mmHg bedraagt na het toedienen van captopril. Met een 95% betrouwbaarheidsinterval op het gemiddelde van [-22.3,-15.6]mmHg. Op basis van het betrouwbaarheidsinterval is het duidelijk dat het toedienen van captopril resulteert in een sterke bloeddrukdaling bij patiënten met hypertensie. 5.5 Principe van Hypothesetoetsen (via one sample t-test) We wensen een uitspraak te kunnen doen of er al dan niet een effect is van het toedienen van Captopril op de systolische bloeddruk? Beslissen op basis van gegevens is niet evident. Er is immers onzekerheid of de bevindingen uit de steekproef generaliseerbaar zijn naar de populatie. We stellen ons dus de vraag of het schijnbaar gunstig effect systematisch of toevallig is? Een natuurlijke beslissingsbasis is het gemiddeld verschil \\(X\\) in de systolische bloeddruk: \\(\\bar x=\\) -18.93mmHg (\\(s =\\) 9.03, \\(SE =\\) 2.33). Dat \\(\\bar{x}&lt; 0\\) volstaat niet om te beslissen dat de gemiddelde systolische bloeddruk lager is na het toedienen van captopril op het niveau van de volledige populatie. Om het effect die we in de steekproef observeren te kunnen veralgemenen naar de populatie moet de bloeddrukverlaging voldoende groot zijn. Maar hoe groot moet dit effect nu zijn? Hiervoor hebben statistici zogenaamde toetsen ontwikkeld om met dit soort vragen om te gaan. Deze leveren een ja/nee antwoord op de vraag of een geobserveerde associatie systematisch is (d.w.z. opgaat voor de studiepopulatie) of als er integendeel onvoldoende informatie in de steekproef voorhanden is om te besluiten dat de geobserveerde associatie ook aanwezig is in de volledige studiepopulatie. Tegenwoordig is het haast onmogelijk om een wetenschappelijk onderzoeksartikel te lezen zonder de resultaten van dergelijke toetsen te ontmoeten. Om die reden wensen we in dit hoofdstuk in te gaan op de betekenis van statistische toetsen en hun nomenclatuur. We weten dat we volgens het falcificatieprincipe van Popper nooit een hypothese kunnen bewijzen op basis van data (zie Sectie 1.1). Daarom zullen we twee hypotheses introduceren: een nulhypothese en een alternatieve hypothese. We zullen dan later a.d.h.v. de toets de nulhypothese trachten te ontkrachten. 5.5.1 Hypotheses Algemeen starten we met het vertalen van de wetenschappelijke vraagstelling naar een nulhypothese (\\(H_0\\)) en een alternatieve hypothese (\\(H_1\\)). Dit kan pas nadat de probleemstelling vertaald is naar een geparametriseerd statistisch model. Uit de beschrijving van de proefopzet volgt dat \\(X_1,...,X_n\\) i.i.d.31 \\(f(X)\\) met \\(f(X)\\) de dichtheidsfunctie van de bloeddrukverschillen. Vereenvoudiging: veronderstel dat \\(f(X)\\) gekend is op een eindig-dimensionale set van parameters \\(\\mathbf{\\theta}\\) na (parametrisch statistisch model). Voor het captopril voorbeeld veronderstellen we dat \\(f(X)\\) een normale distributie \\(N(\\mu,\\sigma^2)\\) volgt met parameters \\(\\mathbf{\\theta}=(\\mu,\\sigma^2)\\), het gemiddelde \\(\\mu\\) en variantie \\(\\sigma^2\\). De vraagstelling is geformuleerd in termen van de gemiddelde bloeddrukdaling: \\(\\mu=E_f[X]\\). De alternatieve hypothese wordt geformuleerd in termen van een parameter van \\(f(X)\\) en dient uit te drukken wat de onderzoekers wensen te bewijzen aan de hand van de studie. Hier: \\[H_1: \\mu&lt;0.\\] Gemiddeld gezien daalt de bloeddruk bij patiënten met hypertensie na toediening van captopril. De nulhypothese is meestal een uitdrukking van de nultoestand, i.e. de omstandigheden waarin niets bijzonders aan de hand is. De onderzoekers wensen meestal te bewijzen via empirisch onderzoek dat de nulhypothese niet waar is: Falsificatie principe. De nulhypothese wordt veelal uitgedrukt door gebruik te maken van dezelfde parameter als deze die in \\(H_1\\) gebruikt is. Hier: \\[H_0 : \\mu=0\\] m.a.w. gemiddeld gezien blijft de systolische bloeddruk na toediening van captopril onveranderd. 5.5.2 Test-statistiek Eens de populatie, de parameters en de nulhypothese en alternatieve hypothese bepaald zijn, kan de basisgedachte van een hypothesetest als volgt bondig beschreven worden. Construeer een teststatistiek zodanig dat deze de evidentie meet die aanwezig is in de steekproef, tegen de gestelde nulhypothese, ten voordele van de alternatieve hypothese. Een teststatistiek is dus noodzakelijk een functie van de steekproefobservaties. Voor het captopril voorbeeld drukt de statistiek \\[T=\\bar X - \\mu_0\\] uit hoever het steekproefgemiddelde van de bloeddrukdaling ligt van het gemiddelde \\(\\mu_0=0\\) in de populatie onder de nulhypothese32. Als \\(H_0\\) waar is en er dus geen effect is van captopril in de populatie, dan verwachten we dat de teststatistiek T dicht ligt bij \\(T=0\\) Als \\(H_1\\) waar is, dan verwachten we dat \\(T&lt;0\\). In de praktijk gebruiken we echter meestal teststatistieken die niet alleen de grootte van het effect in rekening brengen maar ook de onzekerheid op het effect. We doen dit door de effectgrootte te balanceren t.o.v. de standard error. \\[T=\\frac{\\bar{X}-0}{\\text{SE}_{\\bar X}}\\] Waarbij \\(\\mu_0=0\\) voor het captopril voorbeeld. Opnieuw geldt dat Als \\(H_0\\) waar is en er dus geen effect is van captopril in de populatie, dan verwachten we dat de teststatistiek T dicht ligt bij \\(T=0\\) Als \\(H_1\\) waar is, dan verwachten we dat \\(T&lt;0\\). Voor het captopril voorbeeld vinden we \\(t=(-18.93-0)/2.33=-8.12\\). Is \\(t = -8.12\\) groot genoeg in absolute waarde om te kunnen besluiten dat \\(\\mu &lt; 0\\) en met welke zekerheid kunnen we dit besluiten? Om daar een uitspraak over te doen zullen we de teststatistiek T verder bestuderen. T is een toevalsveranderlijke en de verdeling van T hangt af van de verdeling van de steekproefobservaties, maar die verdeling is ongekend! We hebben normaliteit verondersteld, maar dit laat nog steeds het gemiddelde en de variantie onbepaald. Bovendien wordt de hypothesetest net geconstrueerd om een uitspraak te kunnen doen over het gemiddelde \\(\\mu\\)! De oplossing zit in de nulhypothese die we kunnen veronderstellen als er geen effect is van captopril. De \\(H_0\\) stelt dat \\(\\mu=0\\). Als we aannemen dat \\(H_0\\) waar is, dan is het gemiddelde van de normale distributie gekend! Als de bloeddrukverschillen \\(X_1, \\ldots X_{15}\\) onafhankelijk en identiek normaal verdeeld (i.i.d.) zijn, dan weten we dat \\[\\bar X \\stackrel{H_0}{\\sim} N(0, \\sigma^2/n)\\] Gezien we \\(\\sigma^2\\) niet kennen kunnen we deze vervangen door de steekproef variantie. Dan weten we dat \\[T=\\frac{\\bar{X}-0}{\\text{SE}_{\\bar X}}\\stackrel{H_0}{\\sim} t(n-1) \\] een t-verdeling volgt met n-1 vrijheidsgraden onder de nulhypothese. We weten dat indien de alternatieve hypothese waar zou zijn, we mogen verwachten dat er meer kans is op het observeren van een kleine waarde voor de teststatistiek dan wat verwacht wordt onder de nulhypothese. We zullen de verdeling van de teststatistiek onder de nulhypothese gebruiken om na te gaan of de geobserveerde test-statistiek \\(t = -8.12\\) klein genoeg is om te kunnen besluiten dat \\(\\mu &lt; 0\\). Is de geobserveerde teststatistiekwaarde (\\(t=-8.12\\)) een waarde die we verwachten als \\(H_0\\) waar is, of is het een waarde die onwaarschijnlijk klein is als \\(H_0\\) waar is? In het laatste geval deduceren we dat we niet langer kunnen aannemen dat \\(H_0\\) waar is, en dienen we dus \\(H_1\\) te concluderen. De vraag blijft: (a) hoe groot moet de geobserveerde teststatistiek \\(t\\) zijn opdat we \\(H_0\\) verwerpen zodat (b) we bereid zijn om \\(H_1\\) te besluiten en (c) hoe zeker zijn we van deze beslissing? Het antwoord hangt samen met de interpretatie van de kansen die berekend kunnen worden op basis van de nuldistributie33 en de geobserveerde teststatistiek \\(t\\). 5.5.3 De p-waarde De kans waarop de keuze tussen \\(H_0\\) en \\(H_1\\) gebaseerd wordt, wordt de \\(p\\)-waarde genoemd. De berekeningswijze is context-afhankelijk, maar voor het huidige voorbeeld wordt de \\(p\\)-waarde gegeven door \\[ p = P\\left[T \\leq t \\mid H_0\\right] = \\text{P}_0\\left[T\\leq t\\right], \\] waar de index “0” in \\(\\text{P}_0\\left[.\\right]\\) aangeeft dat de kans onder de nulhypothese berekend wordt. Het is met andere woorden de kans om in een willekeurige steekproef onder de nulhypothese een waarde voor de teststatistiek T te bekomen die lager of gelijk is aan34 de waarde die in de huidige steekproef werd geobserveerd. De \\(p\\)-waarde voor het captopril voorbeeld wordt berekend als \\[p= \\text{P}_0\\left[T\\leq -8.12\\right]=F_t(-8.12;14) = 0.6\\ 10^{-6}.\\] waarbij \\(F_t(;14)\\) de cumulatieve distributie functie is van een t-verdeling met 14 vrijheidsgraden, \\[F_t(x;14)=\\int\\limits_{-\\infty}^{x} f_t(x;14).\\] Waarbij \\(f_t(.;14)\\) de densiteitsfunctie is van de t-verdeling. De oppervlakte onder de densiteitsfunctie is opnieuw een kans. Deze kans kan berekend worden in R m.b.v. de functie pt(x,df) die twee argumenten heeft, de waarde van de test-statistiek x en het aantal vrijheidsgraden van de t-verdeling df. pt(x,df) berekent de kans om een waarde te observeren die kleiner of gelijk is aan x wanneer men een willekeurige observatie trekt uit een t-verdeling met df vrijheidsgraden. n &lt;- length(delta) stat&lt;-(mean(delta)-0)/(sd(delta)/sqrt(n)) stat ## [1] -8.122816 pt(stat,n-1) ## [1] 5.731936e-07 Definitie 5.6 (\\(p\\)-waarde) De p-waarde (ook wel geobserveerd significantieniveau genoemd) is de kans om onder de nulhypothese een even of meer “extreme” toetsinggrootheid waar te nemen (in de richting van het alternatief) dan de waarde \\(t\\) die geobserveerd werd o.b.v. de steekproef. Hoe kleiner die kans is, hoe sterker het bewijs tegen de nulhypothese. Merk op dat de p-waarde de kans niet uitdrukt dat de nulhypothese waar is!35. Einde Definitie Het woord “extreem” duidt op de richting waarvoor de teststatistiek onder de alternatieve hypothese meer waarschijnlijk is. In het voorbeeld is \\(H_1: \\mu &lt; 0\\) en verwachten we dus kleinere waarden van \\(t\\) onder \\(H_1\\). Vandaar de kans op \\(T\\leq t\\). Uit de definitie van de \\(p\\)-waarde volgt dat een kleine \\(p\\)-waarde betekent dat de geobserveerde teststatistiek eerder onwaarschijnlijk is als aangenomen wordt dat \\(H_0\\) correct is. Dus een voldoende kleine \\(p\\)-waarde noopt ons tot het verwerpen van \\(H_0\\) ten voordele van \\(H_1\\). De drempelwaarde waarmee de \\(p\\)-waarde vergeleken wordt, wordt het significanctieniveau genoemd en wordt voorgesteld door \\(\\alpha\\). Definitie 5.7 (significantieniveau) De drempelwaarde \\(\\alpha\\) staat gekend als het significantieniveau van de statistische test. Een statistische test uitgevoerd op het \\(\\alpha\\) significantieniveau wordt een niveau-\\(\\alpha\\) test genoemd (Engels: level-\\(\\alpha\\) test). Einde definitie Een toetsingsresultaat wordt statistisch significant genoemd wanneer de bijhorende p-waarde kleiner is dan \\(\\alpha\\), waarbij \\(\\alpha\\) meestal gelijk aan 5% wordt genomen. Hoe kleiner de p-waarde hoe meer `significant’ het testresultaat afwijkt van de verwachting onder de nulhypothese. Het aangeven van een p-waarde voor een toets geeft bijgevolg meer informatie over het resultaat dan een eenvoudig ja/nee antwoord of de nulhypothese wordt verworpen op een vast gekozen \\(\\alpha\\)-niveau. Het geeft immers niet alleen aan of de nulhypothese verworpen wordt op een gegeven significantieniveau, maar ook op welke significantieniveaus de nulhypothese verworpen wordt. Ze vat dus de bewijskracht tegen de nulhypothese samen \\[\\begin{array}{cl}&gt;0.10 &amp; \\text{ niet significant (zwak bewijs)}\\\\0.05-0.10 &amp; \\text{ marginaal significant, suggestief}\\\\0.01-0.05 &amp; \\text{ significant}\\\\0.001-0.01 &amp; \\text{ sterk significant}\\\\&lt;0.001 &amp; \\text{ extreem significant}\\end{array}\\] 5.5.4 Kritieke waarde Een alternatieve wijze voor de formulering van de beslissingsregel kan worden bekomen door gebruik te maken van een kritieke waarde. In plaats van \\(p\\)-waarden, kan de beslissingsregel geschreven worden in termen van de teststatistiek. Bij gebruik van \\(p\\)-waarden bepaalt \\(p=\\alpha\\) de grens. Een \\(p\\)-waarde van \\(\\alpha\\) schrijven we als \\[p=\\text{P}_0 \\left[ T \\leq t \\right]=\\alpha.\\] Dat is exact de definitie van het het \\(\\alpha\\)-percentiel van de distributie van \\(T\\). In het voorbeeld is de nuldistributie \\(t_{n-1}\\). Dus,\\[\\text{P}_0\\left[T\\leq -t_{n-1;\\alpha}\\right]=\\alpha.\\] De beslissingsregel mag dus ook geschreven worden als \\[\\begin{eqnarray*} \\text{als } &amp; t&lt; -t_{n-1;\\alpha} &amp; \\text{ dan verwerp }H_0\\text{ en besluit }H_1 \\\\ \\text{als } &amp; t\\geq -t_{n-1;\\alpha} &amp; \\text{ dan aanvaard }H_0. \\end{eqnarray*}\\] Het percentiel \\(t_{n-1;\\alpha}\\) dat de drempelwaarde vormt in de beslissingsregel wordt in deze context de kritieke waarde op het \\(5\\%\\) significantieniveau genoemd. De beslissingsregel waarbij de geobserveerde \\(t\\) vergeleken wordt met een kritieke waarde is minder algemeen geformuleerd dan deze gebruik makend van de \\(p\\)-waarde omdat het expliciet gebruik maakt van de nuldistributie die van teststatistiek tot teststatistiek, of zelfs van dataset tot dataset kan variëren. De begrippen p-waarde, kritieke waarde, significantie-niveau, verwerpings- en aanvaardingsregio worden weergegeven in Figuur 5.12. Figuur 5.12: Interpretatie van p-waarde, kritieke waarde, verwerpingsgebied, aanvaardingsgebied voor het captopril voorbeeld. 5.5.5 Beslissingsfouten Aangezien de beslissing over het al dan niet verwerpen van de nulhypothese bepaald wordt door slechts een steekproef te observeren, kunnen volgende beslissing genomen worden: Werkelijkheid Besluit H0 H1 Aanvaard H0 OK Type II (β) Verwerp H0 Type I (α) OK Het schema geeft de vier mogelijke situaties: \\(H_0\\) is in werkelijkheid waar, en dit wordt ook besloten aan de hand van de statistische test (dus geen beslissingsfout) \\(H_1\\) is in werkelijkheid waar, en dit wordt ook besloten aan de hand van de statistische test (dus geen beslissingsfout) \\(H_0\\) is in werkelijkheid waar, maar aan de hand van de statistische test wordt besloten om \\(H_0\\) te verwerpen en \\(H_1\\) te concluderen. Dus \\(H_1\\) wordt foutief besloten. Dit is een zogenaamde type I fout. \\(H_1\\) is in werkelijkheid waar, maar aan de hand van de statistische test wordt besloten om \\(H_0\\) te aanvaarden. Dit is een zogenaamde type II fout. Dus \\(H_0\\) wordt foutief aanvaard. De beslissing is gebaseerd op een teststatistiek \\(T\\) die een toevalsveranderlijke is. De beslissing is dus ook stochastisch en aan de vier mogelijke situaties uit bovenstaand schema kunnen dus probabiliteiten toegekend worden. Net zoals voor het afleiden van de steekproefdistributie van de teststatistiek, moeten we de distributie van de steekproefobservaties kennen alvorens het stochastisch gedrag van de beslissingen te kunnen beschrijven. Indien we aannemen dat \\(H_0\\) waar is, dan is de distributie van \\(T\\) gekend en kunnen ook de kansen op de beslissingen bepaald worden voor de eerste kolom van de tabel. We starten met de kans op een type I fout (hier uitgewerkt voor het captopril voor beeld): \\[\\text{P}\\left[\\text{type I fout}\\right]=\\text{P}\\left[\\text{verwerp }H_0 \\mid H_0\\right] = \\text{P}_0\\left[T&lt;t_{n-1;1-\\alpha}\\right]=\\alpha.\\] Dit geeft ons meteen een interpretatie van het significantieniveau \\(\\alpha\\): het is de kans op het maken van een type I fout. De constructie van de statistische test garandeert dus dat de kans op het maken van een type I fout gecontroleerd wordt op het significantieniveau \\(\\alpha\\). De kans op het correct aanvaarden van \\(H_0\\) is dus \\(1-\\alpha\\). Verder kan aangetoond worden dat de p-waarde onder \\(H_0\\) uniform verdeeld is. Het leidt dus tot een uniforme beslissingsstrategie. Het bepalen van de kans op een type II fout is minder evident omdat de alternatieve hypothese minder éénduidig is als de nulhypothese. In het captopril voorbeeld is \\(H_1: \\mu&lt;0\\); met deze informatie wordt de distributie van de steekproefobservaties niet volledig gespecifieerd en dus ook niet de distributie van de teststatistiek. Dit impliceert dat we eigenlijk de kans op een type II fout niet kunnen berekenen. De klassieke work-around bestaat erin om één specifieke distributie te kiezen die voldoet aan \\(H_1\\). \\[H_1(\\delta): \\mu=0-\\delta \\text{ voor een }\\delta&gt;0.\\] De parameter \\(\\delta\\) kwantificeert de afwijking van de nulhypothese. De kracht van een test (Engels: power) is een kans die meer frequent gebruikt wordt dan de kans op een type II fout \\(\\beta\\). De kracht wordt gedefinieerd als \\[\\pi(\\delta) = 1-\\beta(\\delta) = \\text{P}_\\delta\\left[T&gt;t_{n-1;1-\\alpha}\\right]=\\text{P}_\\delta\\left[P&lt;\\alpha\\right].\\] De kracht van een niveau-\\(\\alpha\\) test voor het detecteren van een afwijking \\(\\delta\\) van het gemiddelde onder de nulhypothese \\(\\mu_0=0\\) is dus de kans dat de niveau-\\(\\alpha\\) test dit detecteert wanneer de afwijking in werkelijkheid \\(\\delta\\) is. Merk op dat \\(\\pi(0)=\\alpha\\) en de kracht van een test toeneemt als de afwijking van de nulhypothese toeneemt. De kracht van de test (d.i. de kans om Type II fouten te vermijden) wordt typisch niet gecontroleerd, tenzij d.m.v. studiedesign en steekproefgrootte. Interpretatie Stel dat we voor een gegeven dataset bekomen dat \\(p&lt;\\alpha\\), m.a.w. \\(H_0\\) wordt verworpen. Volgens het schema van de beslissingsfouten zijn er dan slechts twee mogelijkheden (zie onderste rij van schema): ofwel is de beslissing correct, ofwel hebben we een type I fout gemaakt. Over de type I fout weten we echter dat ze slechts voorkomt met een kleine kans. Anderzijds, indien \\(p\\geq \\alpha\\) en we \\(H_0\\) niet verwerpen, dan zijn er ook twee mogelijkheden: ofwel is de beslissing correct, ofwel hebben we een type II fout gemaakt. De kans op een type II fout (\\(\\beta\\)) is echter niet gecontroleerd op een gespecifieerde waarde. De statistische test is zodanig geconstrueerd dat ze enkel de kans op een type I fout controleert (op \\(\\alpha\\)). Om wetenschappelijk eerlijk te zijn, moeten we een pessimistische houding aannemen en er rekening mee houden dat \\(\\beta\\) groot zou kunnen zijn (i.e. een kleine kracht). Bij \\(p &lt; \\alpha\\) wordt de nulhypothese verworpen en we mogen hieruit concluderen dat \\(H_1\\) waarschijnlijk juist is. Dit noemen we een sterke conclusie. Bij \\(p\\geq \\alpha\\) wordt de nulhypothese aanvaard, maar dat impliceert niet dat we concluderen dat \\(H_0\\) juist is. We kunnen enkel besluiten dat de data onvoldoende bewijskracht tegen \\(H_0\\) ten gunste van \\(H_1\\) bevatten. Dit noemen we een daarom zwakke conclusie. 5.5.6 Conclusies Captopril voorbeeld. De test die we hebben uitgevoerd is in de literatuur ook bekend als de one sample t-test op het verschil of als een gepaarde t-test, we beschikken immers over gepaarde gegevens per patiënt. De test is eenzijdig uitgevoerd. We testen tegen het alternatief dat er een bloeddrukdaling is. Beide testen (one sample t-test op het verschil en de gepaarde t-test) geven ons inderdaad dezelfde resultaten: t.test(delta,alternative=&quot;less&quot;) ## ## One Sample t-test ## ## data: delta ## t = -8.1228, df = 14, p-value = 5.732e-07 ## alternative hypothesis: true mean is less than 0 ## 95 percent confidence interval: ## -Inf -14.82793 ## sample estimates: ## mean of x ## -18.93333 with(captopril, t.test(SBPa,SBPb,paired=TRUE,alternative=&quot;less&quot;)) ## ## Paired t-test ## ## data: SBPa and SBPb ## t = -8.1228, df = 14, p-value = 5.732e-07 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -14.82793 ## sample estimates: ## mean of the differences ## -18.93333 We kunnen op basis van de test het volgende concluderen: Na toediening van captopril is er een extreem significante verlaging van de systolische bloeddruk bij patiënten met hypertensie (\\(p &lt;&lt; 0.001\\)). De systolische bloeddruk neemt gemiddeld met 18.9 mm kwik af na de behandeling met captopril (95% BI [\\(-\\infty,-14.82\\)] mm Hg). Merk op dat we Een eenzijdig interval rapporteren gezien we enkel geïnteresseerd zijn om aan te tonen dat er een bloeddrukdaling is. Door het pre-test/post-test design geen uitsluitsel kunnen geven of dit te wijten is aan de werking van het middel of aan een placebo effect. Er was geen goeie controle! Het gebrek van een goeie controle is veelal een probleem bij pre-test/post-test designs. 5.5.7 Eenzijdig of tweezijdig toetsen? De test in het captopril voorbeeld was een eenzijdige test. We wensen immers enkel te detecteren of de captopril behandeling de bloeddruk gemiddeld gezien doet dalen. In andere gevallen of een andere context wenst men enkel een stijging te detecteren. Stel dat men het bloeddrukverschil had gedefineerd als \\(X_{i}^\\prime=Y_{i}^\\text{voor}-Y_{i}^\\text{na}\\) dan zouden positieve waarden aangeven dat er een bloeddrukdaling was na de behandeling van captopril: de bloeddruk bij aanvang is dan immers groter dan na de behandeling. De gemiddelde bloeddrukverandering in de populatie noteren we nu als \\(\\mu^\\prime=\\text{E}[X^*]\\). In dat geval hadden we een eenzijdige test uit moeten voeren om \\(H_0: \\mu^\\prime=0\\) te testen tegen \\(H_1: \\mu^\\prime&gt;0\\). Voor deze test kunnen we de p-waarde als volgt berekenen: \\[p=\\text{P}_0\\left[T\\geq t\\right].\\] We voeren nu de analyse uit in R op basis van de toevallige veranderlijke \\(X^\\prime\\). We zullen nu het argument alternative=&quot;greater&quot; gebruiken in de t.test functie zodat we de nulhypothese toetsen tegen het alternatief \\(H_1: \\mu^\\prime&gt;0\\): delta2 &lt;- captopril$SBPb-captopril$SBPa t.test(delta2,alternative=&quot;greater&quot;) ## ## One Sample t-test ## ## data: delta2 ## t = 8.1228, df = 14, p-value = 5.732e-07 ## alternative hypothesis: true mean is greater than 0 ## 95 percent confidence interval: ## 14.82793 Inf ## sample estimates: ## mean of x ## 18.93333 Uiteraard bekomen we met deze analyse exact dezelfde p-waarde en hetzelfde betrouwbaarheidsinterval. Enkel het teken is omgewisseld. Naast eenzijdige testen kunnen eveneens tweezijdige testen worden uitgevoerd. Het had gekund dat de onderzoekers de werking van het nieuwe medicijn captopril wensten te testen, maar het werkingsmechanisme nog niet kenden in de ontwerpfase. In dat geval zou het eveneens interessant geweest zijn om zowel een stijging als een daling van de bloeddruk te kunnen detecteren. Hiervoor zou men een tweezijdige toetsstrategie moeten gebruiken waarbij men de nulhypothese \\[H_0: \\mu=0\\] gaat testen versus het alternatieve hypothese \\[H_1: \\mu\\neq0,\\] zodat het gemiddelde onder de alternatieve hypothese verschillend is van 0. Het kan zowel een positieve of negatieve afwijking zijn en men weet niet bij aanvang van de studie in welke richting het werkelijk gemiddelde zal afwijken onder de alternatieve hypothese. We kunnen tweezijdig testen op het \\(\\alpha=5\\%\\) significantieniveau door een kritieke waarde af te leiden: Bij een tweezijdige test kan het effect onder de alternatieve hypothese zowel positief of negatief zijn. Hierdoor zullen we onder de nulhypothese de kans berekenen om onder de nulhypothese een effect te observeren dat meer extreem is dan het resultaat dat werd geobserveerd in de steekproef. In deze context betekent “meer extreem” dat de statistiek groter is in absolute waarde dan het geobserveerde resultaat, want zowel grote (sterk positieve) als kleine (sterk negatieve) waarden zijn een indicatie van een afwijking van de nulhypothese. Om een kritieke waarde af te leiden,zullen we het significatie-niveau \\(\\alpha\\) daarom verdelen over de linker en rechter staart van de verdeling onder \\(H_0\\). Gezien de t-verdeling symmetrisch is, volgt dat we een kritieke waarde \\(c\\) kiezen zodat er een kans is van \\(\\alpha/2=2.5\\%\\) dat \\(T\\geq c\\) en er \\(\\alpha/2=2.5\\%\\) kans is dat \\(T\\leq -c\\). We kunnen dit ook nog als volgt formuleren: Er is onder \\(H_0\\) \\(\\alpha=5\\%\\) kans dat \\(\\vert T\\vert\\geq c\\) (zie Figuur 5.13). We kunnen ook gebruik maken van een tweezijdige p-waarde: \\[\\begin{eqnarray*} p&amp;=&amp;\\text{P}_0\\left[T\\leq -|t|\\right] + \\text{P}_0\\left[T\\geq |t|\\right]\\\\ &amp;=&amp;\\text{P}_0\\left[\\vert T\\vert \\geq \\vert t \\vert\\right]\\\\ &amp;=&amp;\\text{P}_0\\left[T \\geq \\vert t \\vert\\right]\\times 2. \\end{eqnarray*}\\] We berekenen dus de kans dat de t-statistiek onder \\(H_0\\) meer extreem is dan de geobserveerde teststatistiek \\(t\\) in de steekproef. Waarbij meer extreem tweezijdig moet geïnterpreteerd worden. De teststatistiek onder \\(H_0\\) is meer extreem als hij groter is in absolute waarde dan \\(\\vert t \\vert\\), de geobserveerde test statistiek. Gezien de verdeling symmetrisch is, kunnen we ook eerst de kans in de rechter staart van de verdeling berekenen en deze kans vervolgens vermenigvuldigen met 2 zodoende een tweezijdige p-waarde te bekomen. Als de onderzoekers niet vooraf gedefineerd hadden dat ze enkel een bloeddrukdaling wensten te detecteren, dan hadden ze dus een twee-zijdige test uitgevoerd. Merk op dat het argument alternative van de t.test functie een default waarde heeft alternative=&quot;two.sided&quot; zodat er standaard tweezijdig wordt getoetst. t.test(delta) ## ## One Sample t-test ## ## data: delta ## t = -8.1228, df = 14, p-value = 1.146e-06 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -23.93258 -13.93409 ## sample estimates: ## mean of x ## -18.93333 We bekomen nog steeds een exteem significant resultaat. De p-waarde is echter dubbel zo groot omdat we tweezijdig testen. We verkrijgen eveneens een tweezijdig betrouwbaarheidsinterval. De tweezijdige toetsstrategie wordt weergegeven in Figuur 5.13. Figuur 5.13: Interpretatie van p-waarde, kritieke waarde, verwerpingsgebied, aanvaardingsgebied voor het captopril voorbeeld wanneer we een tweezijdige toets uitvoeren. We kunnen ons nu de vraag stellen wanneer we eenzijdig of tweezijdig toetsen. Met een eenzijdige toets kan men gemakkelijker een alternatieve hypothese aantonen (op voorwaarde dat ze waar is) dan met een tweezijdige toets. Dit komt essentieel omdat bij zo’n toets alle informatie kan worden aangewend om in 1 enkele richting te zoeken. Precies daarom vergt de eenzijdige toets een extra beschouwing vóór de aanvang van de studie. Ook al hebben we sterke a priori vermoedens, vaak kunnen we niet zeker zijn dat dat zo is. Anders was er immers geen reden om dit te willen toetsen. Als men een eenzijdige test voorstelt, maar men vindt een resultaat in de andere richting dat formeel statistisch significant is, dan is het niet geschikt om dit te zien als bewijs voor een werkelijk effect in die richting. Dat is omdat de onderzoekers die mogelijkheid uitgesloten hebben bij de planning van de studie en het resultaat daarom zó onverwacht is dat het als een vals positief resultaat kan gezien worden. Een eenzijdige test is om die reden niet aanbevolen. Een tweezijdige toets is altijd verdedigbaar omdat ze in principe toelaat om elke afwijking van de nulhypothese te detecteren. Ze worden daarom het meest gebruikt en ten zeerste aangeraden. Het is nooit toegelaten om een tweezijdige toets in een eenzijdige toets om te zetten op basis van wat men observeert in de gegevens! Anders wordt de type I fout van de toetsingsstrategie niet correct gecontroleerd. Dat wordt geïllustreerd in de onderstaande simulatie. We evalueren twee strategieën, de correcte tweezijdige test en een test waar we eenzijdig toetsen op basis van het teken van het geobserveerde effect. set.seed(115) mu &lt;- 0 sigma &lt;- 9.0 nSim &lt;- 1000 alpha &lt;- 0.05 n &lt;- 15 pvalsCor &lt;- pvalsInCor&lt;-array(0,nSim) for (i in 1:nSim) { x &lt;- rnorm(n,mean=mu,sd=sigma) pvalsCor[i] &lt;- t.test(x)$p.value if (mean(x)&lt;0) pvalsInCor[i] &lt;- t.test(x,alternative=&quot;less&quot;)$p.value else pvalsInCor[i] &lt;- t.test(x,alternative=&quot;greater&quot;)$p.value } mean(pvalsCor&lt;0.05) ## [1] 0.049 mean(pvalsInCor&lt;0.05) ## [1] 0.106 We zien inderdaad dat de type I fout correct gecontroleerd wordt op het nominaal significantie-niveau \\(\\alpha\\) wanneer we tweezijdig testen en dat dit helemaal niet het geval is wanneer we eenzijdige toetsen op basis van het teken van het geobserveerde effect. 5.6 Two-sample t-test Een two-sample t-test is een statistische toets die werd ontwikkeld om verschillen in gemiddelde te detecteren tussen twee onafhankelijke groepen. We introduceren eerst een motiverende dataset. Men vermoedt dat hinderlijke geur onder de oksels (bromhidrosis) wordt veroorzaakt door specifieke microorganismen die behoren tot de groep van de Corynebacterium spp.. Het is immers niet het zweet dat de geur veroorzaakt, maar de geur is het resultaat van specifieke bacteriën die het zweet metaboliseren. Een andere sterk abundante groep wordt gevormd door de Staphylococcus spp.. In de CMET onderzoeksgroep van de Universiteit Gent wordt onderzoek verricht naar de mogelijkheid van microbiële transplanties in de oksels om mensen van de hinderlijke okselgeur te verlossen. Deze therapie bestaat erin om eerst het oksel-microbioom te verwijderen door een lokale antibiotica behandeling, en vervolgens via een microbiële transplantie de populatie te beïnvloeden. (zie: https://youtu.be/9RIFyqLXdVw ) De primaire onderzoeksvraag: leidt de microbiële transplantatie na zes weken tot een verandering in de relatieve abundantie van Staphylococcus spp. in het oksel microbioom in vergelijking met een placebo behandeling die enkel bestaat uit een antibiotica behandeling? Twintig personen met een hinderlijke okselgeur worden willekeurig toegekend aan twee behandelingsgroepen: placebo (enkel antibiotica) en transplantie (antibiotica, gevolgd door microbiële transplantatie). Zes weken na de start van de behandeling wordt een staal van de huid uit de okselholte genomen en worden de relatieve abundanties van Staphylococcus spp. en Corynebacterium spp. in het microbioom gemeten via DGGE (Denaturing Gradient Gel Electrophoresis). De dataset bevat de variabelen Staph en Cor die de relatieve abundanties (%) weergeven van Staphylococcus spp. en Corynebacterium spp. De variabele Rel werd berekend als \\[ \\text{Rel}=\\frac{\\text{Staph}}{\\text{Staph}+\\text{Cor}}. \\] Deze variabele is het relatief aandeel van Staphylococcus spp. op het totaal aantal Staphylococcus spp. en Corynebacterium spp.. In de folder dataset staat de file oksel.rda, een dump van het R object oksel, een data frame voor het oksel voorbeeld. R objecten die zijn opgeslagen kunnen via de load(.) functie worden ingelezen. De resultaten worden weergegeven in Figuur 5.14. load(&quot;dataset/oksel.rda&quot;) head(oksel) ## trt Staph Cor Rel ## 1 trt 2: placebo 34.7 28.4 54.99208 ## 2 trt 2: placebo 16.4 35.1 31.84466 ## 3 trt 2: placebo 31.4 45.0 41.09948 ## 4 trt 2: placebo 44.7 30.4 59.52064 ## 5 trt 2: placebo 45.9 26.3 63.57341 ## 6 trt 2: placebo 30.7 43.3 41.48649 #outline = FALSE, geen outliers #alle datapunten worden toegevoegd via stripchart #dus ook outliers zijn zichtbaar boxplot(Rel~trt,data=oksel,xlab=&quot;behandeling&quot;,ylab=&quot;Relatieve abundantie&quot;,outline=FALSE) set.seed(394) stripchart(Rel~trt, data=oksel,vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;,&quot;coral&quot;), add = TRUE) set.seed(394) stripchart(Rel~trt, data=oksel,vertical = TRUE, method = &quot;jitter&quot;, pch = 1, add = TRUE) Figuur 5.14: Boxplot van de relatieve Staphylococcus spp. abundantie t.o.v. het totaal van Staphylococcus spp. en Corynebacterium spp., voor beide behandelingsgroepen. par(mfrow=c(1,2)) oksel$trt=as.factor(oksel$trt)#zet charactervector om in factor for (i in levels(oksel$trt)) with(subset(oksel,trt==i), { qqPlot(Rel,main=i) }) Figuur 5.15: QQ-plots van relatieve Staphylococcus spp. abundantie t.o.v. het totaal van Staphylococcus spp. en Corynebacterium spp. Normaliteit van de data in beide groepen wordt ook nagegaan d.m.v. QQ-plots (zie Figuur 5.15). De QQ-plots geven geen te grote afwijkingen weer van normaliteit. We introduceren eerst de notatie. Stel \\(Y_{ij}\\) de uitkomst van observatie \\(i=1,\\ldots, n_j\\) uit populatie \\(j=1,2\\). We zullen dikwijls de term behandeling of groep gebruiken in plaats van populatie, zelfs wanneer de twee populaties niet geïnterpreteerd kunnen worden als behandelingen. Beschouw het als een (misgroeide) conventie. In de context van het voorbeeld is behandeling \\(j=1\\) de microbiële transplantatie en behandeling \\(j=2\\) de placebo behandeling. We veronderstellen \\[Y_{ij}\\text{ i.i.d. } N(\\mu_j,\\sigma^2)\\;\\;\\;i=1,\\ldots,n_i\\;j=1,2.\\] Merk op dat dit inhoudt dat gelijke varianties verondersteld worden. De eigenschap van gelijke varianties wordt ook aangeduid met de term homoskedasticiteit, en ongelijke varianties met heteroskedasticiteit. We zijn geïnteresseerd in het testen van de nulhypothese \\[ H_0: \\mu_1 = \\mu_2 \\] tegenover de alternatieve hypothese \\[ H_1: \\mu_1 \\neq \\mu_2 .\\] De alternatieve hypothese drukt dus de onderzoeksvraag uit: een verschil in relatieve abundantie van Staphylococcus spp. na microbiële transplantatie t.o.v. de placebo behandeling. De nul en alternatieve hypothese kunnen ook worden uitgedrukt in termen van de effectgrootte tussen behandeling en placebo groep \\(\\mu_1-\\mu_2\\): \\[H_0: \\mu_1-\\mu_2 = 0,\\] \\[H_1: \\mu_1-\\mu_2 \\neq 0.\\] We kunnen de effectgrootte in het experiment schatten a.d.h.v. de steekproefgemiddeldes: \\[\\hat \\mu_1-\\hat \\mu_2=\\bar Y_1 -\\bar Y_2.\\] Gezien de experimentele eenheden onafhankelijk zijn, zijn de steekproefgemiddeldes dat ook en is de variantie op het verschil: \\[\\text{Var}_{\\bar Y_1 -\\bar Y_2}=\\frac{\\sigma^2}{n_1}+\\frac{\\sigma^2}{n_2}=\\sigma^2 \\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right).\\] De standard error is bijgevolg: \\[\\sigma_{\\bar Y_1 -\\bar Y_2}=\\sigma\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}.\\] We zouden de variantie apart kunnen schatten in elke groep aan de hand van de steekproefvariatie, maar als we gelijkheid van variantie kunnen veronderstellen kan de variantie meer precies worden geschat door gebruik te maken van alle gegevens in beide groepen. Deze variatieschatter wordt ook de gepoolde variantieschatter genoemd: \\(S^2_p\\). Op basis van de observaties uit de eerste groep kan \\(\\sigma^2_1\\) geschat worden als \\[S_1^2 = \\frac{1}{n_1-1}\\sum_{i=1}^{n_1} (Y_{i1}-\\bar{Y}_1)^2.\\] Analoog: op basis van de observaties uit de tweede groep kan \\(\\sigma^2_2\\) geschat worden als \\[S_2^2 = \\frac{1}{n_2-1}\\sum_{i=1}^{n_2} (Y_{i2}-\\bar{Y}_2)^2.\\] Merk op dat we homoscedasticiteit veronderstellen, \\(\\sigma_1^2=\\sigma_2^2=\\sigma^2\\). Dus \\(S_1^2\\) en \\(S_2^2\\) zijn schatters zijn voor dezelfde parameter \\(\\sigma^2\\). Daarom kunnen ze gezamenlijk gebruikt worden om tot één schatter te komen die alle \\(n_1+n_2\\) observaties gebruikt: \\[ S_p^2 = \\frac{n_1-1}{n_1+n_2-2} S_1^2 + \\frac{n_2-1}{n_1+n_2-2} S_2^2 = \\frac{1}{n_1+n_2-2}\\sum_{j=1}^2\\sum_{i=1}^{n_j} (Y_{ij} - \\bar{Y}_j)^2.\\] De gepoolde variantieschatter wordt dus geschat door gebruik te maken van de kwadratische afwijkingen tussen de observaties en hun groepsgemiddelde en dat te delen door het aantal vrijheidsgraden \\(n_1+n_2-2\\)36. Nu we de effectgrootte en de standard error op de effectgrootte hebben kunnen schatten, kunnen we opnieuw een t-statistiek definiëren (two-sample \\(t\\)-teststatistiek): \\[T = \\frac{\\bar{Y}_1-\\bar{Y}_2}{\\sqrt{\\frac{S_p^2}{n_1}+\\frac{S_p^2}{n_2}}} = \\frac{\\bar{Y}_1 - \\bar{Y}_2}{S_p\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}.\\] Als de data onafhankelijk zijn, de steekproefgemiddelden normaal verdeeld zijn en de variantie in beide groepen gelijk zijn, dan kan men aantonen de teststatistiek T opnieuw een t-verdeling volgt met \\(n_1+n_2-2\\) vrijheidsgraden onder de nulhypothese. Aangezien de alternatieve hypothese \\(H_1: \\mu_1 \\neq \\mu_2\\) impliceert dat de probabiliteitsmassa van de distributie van \\(T\\) onder \\(H_1\\) verschuift naar hogere of lagere waarden, zullen we \\(H_0\\) wensen te verwerpen ten gunste van \\(H_1\\) voor grote absolute waarde van de teststatistiek. De \\(p\\)-waarde wordt dus \\[\\begin{eqnarray*} p&amp;=&amp;\\text{P}_0\\left[T\\leq -|t|\\right] + \\text{P}_0\\left[T\\geq |t|\\right]\\\\ &amp;=&amp;\\text{P}_0\\left[\\vert T\\vert \\geq \\vert t \\vert\\right]\\\\ &amp;=&amp;\\text{P}_0\\left[T \\geq \\vert t \\vert\\right]\\times 2\\\\ &amp;=&amp; 2\\times(1-F_T(\\vert t\\vert;n_1+n_2-2)), \\end{eqnarray*}\\] met \\(F_T(\\cdot;n_1+n_2-2)\\) de cumulatieve distributiefunctie van \\(t_{n_1+n_2-2}\\). 5.6.1 Oksel-voorbeeld De onderzoeksvraag van het oksels-voorbeeld kan vertaald worden in een nulhypothese en een alternatieve hypothese. De nulhypothese verwoordt de stelling dat de behandeling geen effect heeft op de gemiddelde relatieve abundantie van Staphylococcus spp.. Indien \\(\\mu_1\\) en \\(\\mu_2\\) de gemiddelde abundanties voorstellen in respectievelijk de transplantatie groep en de placebo groep, dan schrijven we \\[ H_0: \\mu_1=\\mu_2.\\] De alternatieve hypothese correspondeert met wat we wensen te bewijzen aan de hand van de experimentele data: een verschil in gemiddelde abundantie van Staphylococcus spp. in de transplantatie groep i.v.m. de placebo groep. Dus \\[H_1: \\mu_1\\neq \\mu_2.\\] De berekeningen kunnen als volgt in R worden uitgevoerd: ybar1&lt;-mean(oksel$Staph[oksel$trt==&quot;trt 1: transplant&quot;]) ybar1 ## [1] 49.79 ybar2&lt;-mean(oksel$Staph[oksel$trt==&quot;trt 2: placebo&quot;]) ybar2 ## [1] 31.9 var1&lt;-var(oksel$Staph[oksel$trt==&quot;trt 1: transplant&quot;]) var1 ## [1] 64.95656 var2&lt;-var(oksel$Staph[oksel$trt==&quot;trt 2: placebo&quot;]) var2 ## [1] 76.78222 n1&lt;-sum(oksel$trt==&quot;trt 1: transplant&quot;) n1 ## [1] 10 n2&lt;-sum(oksel$trt==&quot;trt 2: placebo&quot;) n2 ## [1] 10 #gepoolde variantieschatting sp2&lt;-((n1-1)*var1+(n2-1)*var2)/(n1+n2-2) sp2 ## [1] 70.86939 #geobserveerde t-statistiek t.obs&lt;-(ybar1-ybar2)/sqrt(sp2/n1+sp2/n2) t.obs ## [1] 4.751886 #p-waarde p&lt;-(1-pt(abs(t.obs),df=n1+n2-2))*2 p ## [1] 0.0001592919 #De p-waarde kon ook worden berekend door #gebruik te maken van de probabiliteit in de linker staart #dat is vaak stabieler in R p&lt;-pt(-abs(t.obs),df=n1+n2-2)*2 p ## [1] 0.0001592919 De R software heeft ook een specifieke functie voor het uitvoeren van deze \\(t\\)-test. t.test(Staph~trt,data=oksel,var.equal=TRUE) ## ## Two Sample t-test ## ## data: Staph by trt ## t = 4.7519, df = 18, p-value = 0.0001593 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 9.980404 25.799596 ## sample estimates: ## mean in group trt 1: transplant mean in group trt 2: placebo ## 49.79 31.90 Uit deze analyse lezen we \\(p\\approx 0.16 \\times 10^{-3}&lt;&lt;0.05\\). Dus op het \\(5\\%\\) significantieniveau verwerpen we de nulhypothese ten voordele van de alternatieve en besluiten we dat de gemiddelde abundantie van Staphylococcus spp. extreem significant hoger is in de transplantatie groep dan in de placebo groep37. Indien de transplantatie geen effect heeft op de gemiddelde abundantie van Staphylococcus spp., dan is er slechts een kans van 16 in de \\(100000\\) om een teststatistiek te bekomen in een willekeurige steekproef die minstens zo extreem is als deze die wij geobserveerd hebben. Dit is uiterst zeldzaam onder de hypothese dat \\(H_0\\) waar is, en het is kleiner dan \\(5\\%\\) (het significantieniveau). Indien \\(H_1\\) waar zou zijn, dan verwachten we grotere absolute waarden van de teststatistiek en verwachten we dus ook kleine \\(p\\)-waarden. Om deze reden wensen we niet verder te geloven dat \\(H_0\\) waar is, en besluiten we dat er veel evidentie in de steekproefdata zit om te besluiten dat \\(H_1\\) waar is op het \\(5\\%\\) significantieniveau. Good statistical practice houdt ook in dat niet enkel de \\(p\\)-waarde van de hypothesetest wordt gerapporteerd, maar dat ook de gemiddelden en een maat voor de betrouwbaarheid van de schattingen (bv. BI) worden gerapporteerd. Conclusie Gemiddeld is de relatieve abundantie van Staphylococcus spp. in het microbioom van de oksel in de transplantatie groep extreem significant verschillend van dat in de controle groep (\\(p&lt;&lt;0.001\\)). De relatieve abundantie van Staphylococcus spp. is gemiddeld 17.9% hoger in de transplantie groep dan in de controle groep (95% BI [10.0,25.8]%). 5.7 Aannames In de voorgaande secties hebben we t-testen geïntroduceerd en de geldigheid ervan hangt af van enkele distributionele veronderstellingen: Onafhankelijke gegevens (design) One-sample t-test: normaliteit van de steekproefobservaties Paired t-test: normaliteit van de verschillen tussen de gepaarde observaties Two-sample t-test: normaliteit van de steekproefobservaties in beide groepen, en gelijkheid van varianties. Indien niet voldaan is aan de veronderstellingen, is de t-distributie niet noodzakelijk de correcte nuldistributie, en bijgevolg is er geen garantie dat de p-waarde en kritieke waarden correct zijn. Ook voor de constructie van het betrouwbaarheidsinterval van het gemiddelde hebben we beroep gedaan op de veronderstelling van normaliteit. De normaliteitsveronderstelling was nodig om kwantielen uit de t-verdeling te kunnen gebruiken bij het opstellen van de boven- en ondergrens, en de correcte probabiliteitsinterpretatie van het betrouwbaarheidsinterval hangt hiervan af. 5.7.1 Nagaan van de veronderstelling van Normaliteit Normaliteit kan via de volgende methoden nagegaan worden. Boxplots en histogrammen Beide figuren laten toe om een idee te vormen over de vorm van de distributie: symmetrie, outliers. QQ-plots Deze plots laten toe om op een grafische wijze na te gaan in welke mate steekproefobservaties zich gedragen als een vooropgestelde distributie. Hypothesetesten (goodness-of-fit test) Goodness-of-fit testen zijn statistische hypothesetesten die ontwikkeld zijn voor het testen van de nulhypothese dat de steekproefobservaties uit een vooropgestelde distributie getrokken zijn (hier: normale distributie). De alternatieve hypothese is meestal de negatie van de nulhypothese (hier: geen normaliteit). Bekende testen zijn: Kolmogorov-Smirnov, Shapiro-Wilk en Anderson-Darling. Op het eerste zicht lijkt een goodness-of-fit test een gemakkelijke en zinvolle oplossing. De methode geeft een \\(p\\)-waarde en deze laat onmiddellijk toe om te besluiten of de data normaal verdeeld zijn. Er is echter kritiek te leveren op deze aanpak: indien \\(p\\geq \\alpha\\), dan is normaliteit niet bewezen! Het zegt enkel dat er onvoldoende evidentie is tegen de veronderstelling van normaliteit. In een kleine steekproef is de kracht van een test meestal klein. indien \\(p&lt;\\alpha\\), dan mag wel besloten worden om de nulhypothese te verwerpen en mag dus besloten worden dat de data niet normaal verdeeld zijn, maar soms is een afwijking van normaliteit niet zo erg. Algemeen advies: Start met een grafische exploratie van de data (boxplots, histogrammen en QQ-plots) en houdt hierbij steeds de steekproefgrootte in het achterhoofd om te vermijden dat je de figuren zou overinterpreteren. Als je twijfelt kan je gebruik maken van simulaties waarbij je nieuwe steekproeven simuleert met eenzelfde steekproefgrootte en data die uit de Normaal verdeling komt met eenzelfde gemiddelde en variantie als wat in de steekproef werd geobserveerd. Indien een afwijking van normaliteit wordt vastgesteld, tracht dan na te gaan (bv. via literatuur) of de statistische methode die je wenst toe te passen, gevoelig is voor dergelijke afwijkingen (een t-test is bijvoorbeeld vrij ongevoelig voor afwijkingen van Normaliteit als de afwijkingen symetrisch zijn). Eventueel kan je ook beroep doen op de centrale limietstelling. 5.7.2 Nagaan van homoscedasticiteit Dat kan opnieuw via boxplots. De grootte van de box is de interkwartiel range (IQR), een robuuste schatter voor de variantie (zie Sectie 4.3.2). Als de verschillen tussen de IQR range van beide groepen niet te groot is, kan men besluiten dat de data homoscedastisch zijn. Opnieuw kan inzicht gekregen worden in dergelijke plots door gebruik te maken van simulaties (zie Oefeningen). Men kan eveneens een formele F-test gebruiken om de varianties te vergelijken (zie oefeningen), maar hiervoor geldt dezelfde kritiek als voor het testen van normaliteit (zie vorige sectie). Als er bij het vergelijken van gemiddelden tussen twee groepen niet aan homoscedasticiteit is voldaan, kan je gebruik maken van de Welch two-sample T-test. Hierbij wordt de gepoolde variantieschatter niet langer gebruikt. \\[T = \\frac{\\bar{Y}_1 - \\bar{Y}_2}{\\sqrt{\\frac{S^2_1}{n_1}+\\frac{S^2_2}{n_2}}}\\] waarbij \\(S^2_1\\) en \\(S^2_2\\) de steekproefvarianties zijn in beide groepen. Deze statistiek volgt bij benadering een t-verdeling met een aantal vrijheidsgraden dat ligt tussen het kleinste aantal observaties \\(\\text{min}(n_1-1,n_2-1)\\) en \\(n_1+n_2-2\\). De vrijheidsgraden worden in R berekend via de Welch–Satterthwaite benadering. Dat kan door in de t.test functie het argument var.equal=FALSE te zetten. t.test(Staph~trt,data=oksel,var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: Staph by trt ## t = 4.7519, df = 17.876, p-value = 0.0001622 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 9.976456 25.803544 ## sample estimates: ## mean in group trt 1: transplant mean in group trt 2: placebo ## 49.79 31.90 Merk op dat we in de output zien dat een Welch T-test is uitgevoerd aan de titel boven de analyse. Verder zien we dat voor dit voorbeeld de aangepaste vrijheidsgraden \\(df = 17.876\\) bijna gelijk zijn aan de vrijheidsgraden van de klassieke T-test, omdat de varianties ongeveer gelijk zijn. 5.8 Wat rapporteren? In de wetenschappelijke literatuur is er een overdreven aandacht voor p-waarden. Nochtans is het interessanter om een schatting te rapporteren samen met een betrouwbaarheidsinterval (dan met een p-waarde). Vuistregel: Rapporteer een schatting steeds samen met een betrouwbaarheidsinterval (en een p-waarde), want Het resultaat van een toets kan veelal uit een betrouwbaarheidsinterval worden afgeleid; Dit laat toe om te oordelen of het resultaat ook wetenschappelijk van belang is. 5.8.1 Reden 1: Relatie toetsen en betrouwbaarheidsintervallen Stel dat we voor een zekere parameter \\(\\theta\\) (bvb. een populatiegemiddelde, verschil in populatiegemiddelden, odds ratio, regressieparameter) de nulhypothese wensen te toetsen dat \\(H_0 : \\theta= \\theta_0\\) versus het alternatief \\(H_A : \\theta \\neq \\theta_0\\) voor een zeker getal \\(\\theta_0\\). Dan kan men aantonen dat men deze tweezijdige toetsingsprocedure kan uitvoeren op het \\(\\alpha 100\\%\\) significantieniveau door de nulhypothese te verwerpen als en slechts als het \\((1-\\alpha)100\\%\\) betrouwbaarheidsinterval voor \\(\\theta\\) het getal \\(\\theta_0\\) niet omvat. Met andere woorden, het \\((1-\\alpha)100\\%\\) betrouwbaarheidsinterval voor \\(\\theta\\) bevat alle getallen \\(\\theta_0\\) zodat de tweezijdige toets van \\(H_0 : \\theta= \\theta_0\\) versus \\(H_1 : \\theta \\neq \\theta_0\\) de nulhypothese niet verwerpt. 5.8.2 Reden 2: Statistische significantie versus wetenschappelijke relevantie Een betrouwbaarheidsinterval laat toe om zowel statistische significantie als wetenschappelijk belang van een resultaat te interpreteren. Stel dat experimentele behandeling significant betere respons oplevert dan standaard/placebo. Een associatie is statistisch significant als P \\(&lt; \\alpha\\), de data dragen m.a.w. voldoende bewijskracht om te besluiten dat er een associatie is. Dan blijft het mogelijk dat het effect wetenschappelijk irrelevant is. Met betrouwbaarheidsintervallen kunnen we dit wel evalueren. Maar, dat laat echter nog veel subjectiviteit en manipulatie toe. Onderzoekers hopen in de praktijk immers wetenschappelijk belangrijke vondsten te maken en kunnen daarom geneigd zijn om hun oordeel over wat wetenschappelijk belangrijk is, wijzigen in functie van het bekomen betrouwbaarheidsinterval. Om dit te vermijden is het wenselijk dat wetenschappers a priori, d.i. vooraleer de gegevens verzameld werden, hun oordeel over wetenschappelijke relevantie uitdrukken. 5.9 Equivalentie-intervallen Betrouwbaarheidsintervallen kunnen ook worden gebruikt om na te gaan of twee interventies wetenschappelijk equivalent zijn. Twee interventies worden wetenschappelijk equivalent genoemd als het verschil tussen de populatiegemiddelden \\(\\mu_1\\) en \\(\\mu_2\\) van hun uitkomsten \\(X_1\\) en \\(X_2\\) in een equivalentie-interval ligt (dat 0 zal omvatten), bijvoorbeeld: \\[\\begin{equation*} (\\mu_1 - \\mu_2) \\in [E_1, E_2] \\end{equation*}\\] In de meeste gevallen worden \\(E_1\\) en \\(E_2\\) symmetrisch rond nul gekozen, in welk geval \\(E_1=-\\Delta\\) en \\(E_2=\\Delta\\) voor gegeven \\(\\Delta\\). Het (wetenschappelijk) equivalentie-interval wordt dan gegeven door alle koppels \\((\\mu_1,\\mu_2)\\) waarvoor \\[\\begin{equation*} |\\mu_1 - \\mu_2| &lt; \\Delta \\end{equation*}\\] Twee interventies zijn met andere woorden klinisch equivalent wanneer hun verschil in effect verwaarloosbaar klein is vanuit wetenschappelijk oogpunt. In het vervolg van deze sectie zullen we nagaan of de gemiddelden van 2 onafhankelijke populaties wetenschappelijk equivalent zijn (of wetenschappelijk niet significant van elkaar verschillen). Een eerste stap in dit proces is om op basis van louter wetenschappelijk overwegingen een interval op te stellen waarbinnen het verschil \\(\\mu_1-\\mu_2\\) verwaarloosbaar klein kan worden genoemd. Dit gebeurt met hulp van een deskundige die kan oordelen over het belang van een gegeven effectgrootte. Vervolgens wordt het gemiddeld verschil in uitkomst onder beide interventies geschat op basis van de gegevens. Nagaan of dit verschil in het equivalentie-interval gelegen is, volstaat op zich niet om wetenschappelijke equivalentie te kunnen besluiten vermits een klein/groot verschil louter het gevolg kan zijn van biologische variatie. Een logische stap is daarom een bijhorend 95% betrouwbaarheidsinterval voor \\(\\mu_1 - \\mu_2\\) te berekenen op basis van de beschikbare gegevens (gepaard, ongepaard, …). De wetenschappelijke equivalentie zal nu bepaald worden door de ligging van het betrouwbaarheidsinterval te vergelijken met het interval van wetenschappelijke equivalentie. Het zou verkeerd zijn om wetenschappelijke equivalentie te besluiten zodra het equivalentie-interval volledig omsloten is door het 95% betrouwbaarheidsinterval. Inderdaad, kleine steekproeven produceren brede betrouwbaarheidsintervallen zodat men op die manier in kleine steekproeven gemakkelijk equivalentie zou besluiten louter wegens gebrek aan informatie. We volgen daarom de volgende strategie. Noem \\(O\\) de ondergrens en \\(B\\) de bovengrens van het 95% betrouwbaarheidsinterval voor \\(\\mu_1-\\mu_2\\). Als \\(E_1 &lt; O &lt; B &lt; E_2\\), dan is het verschil tussen de populatiegemiddelden met minstens 95% kans binnen de grenzen van wetenschappelijke equivalentie gelegen. Men kan dan met minstens 95% zekerheid besluiten dat de 2 interventies inderdaad wetenschappelijk equivalent zijn. Als \\(E_2 &lt; O\\) dan kan men met minstens 95% zekerheid besluiten dat \\(\\mu_1\\) wetenschappelijk significant groter is dan \\(\\mu_2\\). (In dit geval is \\(\\mu_1\\) automatisch ook statistisch significant groter dan \\(\\mu_2\\) op het 2-zijdig significantieniveau 5%). Als \\(B &lt; E_1\\) dan kan men met minstens 95% zekerheid besluiten dat \\(\\mu_1\\) wetenschappelijk significant kleiner is dan \\(\\mu_2.\\) Het resultaat kan ook minder duidelijk zijn. Als \\(O &lt; E_1 &lt; E_2 &lt; B\\) dan is er te weinig informatie om ook maar iets betekenisvol te kunnen besluiten: meer gegevens zijn nodig. Als $O &lt; E_1 &lt; B &lt; E_2 $ dan kan men op het 5% significantieniveau besluiten dat \\(\\mu_1\\) niet wetenschappelijk groter is dan \\(\\mu_2\\). In dat geval zijn zowel de opties wetenschappelijk equivalent met \\(\\mu_2\\) als wetenschappelijk significant kleiner dan \\(\\mu_2\\) niet uit te sluiten met 95% zekerheid. Analoog voor de symmetrische situatie waarbij \\(E_1 &lt; O &lt; E_2 &lt; B.\\) In asthmastudies legt men bijvoorbeeld op voorhand vast dat een verschil in Peak Expiratory Flow (PEF) van 15 l/min klinisch onbelangrijk is. Men bepaald m.a.w. een equivalentie-interval: [-15,15] l/min. Een 95% BI van [-10,-5] l/min voor gemiddeld verschil in PEF tussen twee geneesmiddelen Formoterol en Salbutamol wijst op een onbelangrijk effect, equivalentie. Het betrouwbaarheidsinterval geeft weer hoe groot het verschil kan zijn. Als men een BI van [-25,-16] l/min had bekomen dan kon men besluiten dat het geneesmiddel Formoterol minder efficient is gezien het gemiddeld gezien PEF waarden oplevert die wetenschappelijk significant lager zijn dan wanneer Salbutamol wordt toegediend. Als het [-20,-5] l/min zou zijn, dan is er ambiguïteit. Ook wel Statistische Inferentie genoemd↩ Om die reden duiden we ze aan met een hoofdletter.↩ Zo is het met 1 observatie voor \\(\\bar X\\) niet mogelijk om een histogram voor \\(\\bar X\\) uit te zetten.↩ In principe is een meer theoretische, mathematische ontwikkeling nodig omdit aan te tonen, maar voor het bestek van deze cursus volstaat het om het meer intuïtieve argument aan te nemen.↩ Merk op dat de vierkantswortel van een som niet gelijk is aan de som van de vierkantswortels. Bijgevolg is de standaarddeviatie van de som van \\(X\\) en \\(Y\\) niet de som van de corresponderende standaarddeviaties!↩ Denk zelf maar eens na of je gevallen kunt bedenken waar je al op voorhand, zonder ook maar observaties te zien, de variantie op een bepaalde karakteristiek kent…↩ 95.1% is niet exact gelijk aan het nominale 95% omdat er ‘slechts’ 1000 simulaties gelopen zijn↩ De steekproefstandaarddeviatie is eveneens een toevallig veranderlijke die van steekproef tot steekproef varieert rond werkelijke standaarddeviatie. Hierdoor zal de breedte van de intervallen eveneens variëren↩ independent and identically distributed, onafhankelijk en gelijk verdeeld↩ vandaar de index 0 bij \\(\\mu_0\\)↩ distributie van de teststatistiek onder de nulhypothese↩ meer extreem in de richting van \\(H_1\\)↩ In de frequentistische theorie die we hier volgen, is de nulhypothese immers ofwel altijd waar, ofwel altijd vals, en is het dus zelfs niet mogelijk om de kans te definiëren dat de nulhypothese waar is. Teminste, die kans is ofwel 1 ofwel 0.!↩ We hebben \\(n_1+n_2\\) observaties (vrijheidsgraden) in het experiment, om de gepoolde variantie te schatten hebben we echter 2 vrijheidsgraden verloren aangezien we eerst het gemiddelde in elke groep dienden te bepalen om de variantie te kunnen schatten.↩ Merk op dat we de richting “significant hoger is in de transplantatie groep” afleiden uit de groepsgemiddelden in de output en/of het BI↩ "],
["chap-linReg.html", "Hoofdstuk 6 Enkelvoudige lineaire regressie 6.1 Inleiding 6.2 Lineaire regressie 6.3 Parameterschatting 6.4 Statistische besluitvorming 6.5 Nagaan van modelveronderstellingen 6.6 Afwijkingen van Modelveronderstellingen 6.7 Besluitvorming over gemiddelde uitkomst 6.8 Predictie-intervallen 6.9 Kwadratensommen en Anova-tabel 6.10 Dummy variabelen", " Hoofdstuk 6 Enkelvoudige lineaire regressie 6.1 Inleiding 6.1.1 Borstkanker dataset Sotiriou et al. (2006) publiceerden onderzoek naar de moleculaire basis van borstkanker. In de studie hebben de onderzoekers voor een groot aantal borstkanker patiënten klinische variabelen geregistreerd alsook de genexpressie in tumor weefsel gemeten voor duizenden genen m.b.v. microarray technologie. De genexpressie werd gemeten op de tumor biopsie die werd genomen voordat de behandeling werd gestart. De studie is een retrospectieve studie in de zin dat niet werd geëxperimenteerd en dat de genexpressie werd geëvalueerd als gevolg van de blootstelling die de individuen hebben ondergaan in het verleden. In dit hoofdstuk zullen we een subset van de data gebruiken om de associatie te bestuderen tussen de genexpressie van twee sleutelgenen bij borstkanker: de estrogeen receptor 1 (ESR1) gen, een belangrijke biomerker voor de prognose van de patiënt, en het S100A8 gen dat een prominente rol speelt in de regulatie van inflammatie en immuun respons. De data is opgeslagen in een tekst bestand met naam borstkanker.txt in de folder dataset. # we lezen de data in en slaan die op in het object # met de naam borstkanker # Het argument header=TRUE wordt gebruikt omdat de eerste # lijn van het bestand de namen van de variabelen bevat borstkanker &lt;- read.table(&quot;dataset/borstkanker.txt&quot;,header=TRUE) knitr::kable(head(borstkanker),caption=&quot;Overzicht van de variabelen in de borstkanker dataset.&quot;,booktabs = TRUE) 6.1.2 Data exploratie In Sectie 4.6.3 werd de associatie tussen beide genen uitgebreid verkend. Daarin hebben we de genexpressie data eerst log-getransformeerd. In dit hoofdstuk zullen we om didactische redenen eerst werken met de expressiemetingen op de originele schaal. De expressie van het S100A8 gen wordt weergegeven in Figuur 6.1. Op de originele schaal zien we drie heel grote outliers. Omwille van didactische redenen worden deze eerst verwijderd uit de dataset. In principe mogen outliers enkel worden verwijderd uit een studie als daar een goede reden voor is. We kunnen op basis van de informatie over de studie echter niet argumenteren waarom de outliers niet representatief zijn, zoals bijvoorbeeld wel het geval zou zijn wanneer zich meetfouten of problemen voordeden m.b.t. deze observaties in de studie. Later in het hoofdstuk zullen we zien hoe we op een correcte wijze alle data kunnen modelleren. boxplot(borstkanker$S100A8,ylab=&quot;S100A8 expressie&quot;) Figuur 6.1: Expressie van het S100A8 gen. Om meerdere variabelen in de borstkanker dataset te bestuderen, kunnen we gebruik maken van de grafische scatterplot matrix voorstelling (zie Figuur 6.2). Hierbij wordt een matrix met paarsgewijze dotplots voor alle variabelen geproduceerd. plot(subset(borstkanker,S100A8&lt;2000)[,-(1:4)]) Figuur 6.2: Scatterplot matrix voor de observaties in de borstkanker dataset na verwijdering van outliers in de S100A8 expressie (merk op dat we deze outliers in principe niet mochten verwijderen uit de dataset). In de scatterplot matrix zien we bijvoorbeeld dat er een positieve associatie lijkt te zijn tussen de leeftijd (age) en de lymfeknoop status (node; geeft aan of de lymfeknopen al dan niet aangetast zijn en chirurgisch werden verwijderd, node 0: niet aangetast, 1: aangetast). Daarnaast observeren we ook een indicatie voor een negatieve associatie (dalende trend) tussen de ESR1 en S100A8 gen expressie. In dit hoofdstuk zullen we ons in het bijzonder focussen op de relatie tussen de ESR1 en de S100A8 gen expressie. Een individuele scatterplot met smoother (zie Figuur 6.3) geeft de associatie tussen beide genen nog beter weer. Smoothers kunnen trends visualiseren tussen variabelen zonder vooraf veronderstellingen te doen over de vorm van het verband en zijn daarom heel erg nuttig bij data exploratie. We zien dat de genexpressie van S100A8 gemiddeld gezien daalt voor patiënten met een hogere expressie van ESR1. with(subset(borstkanker,S100A8&lt;2000), scatter.smooth(ESR1,S100A8)) Figuur 6.3: Scatterplot voor S100A8 expressie in functie van de ESR1 expressie met smoother die het verband tussen beide genen samenvat (na verwijdering van outliers in de S100A8 expressie, merk op dat we deze outliers in principe niet mochten verwijderen uit de dataset). 6.1.3 Model Op basis van Figuur 6.3 zien we dat er een relatie is tussen de S100A8 (Y) en ESR1 (X) expressie. De expressiemetingen voor het S100A8 gen zijn echter onderhevig aan ruis onder andere door biologische variabiliteit en technische variabiliteit. Voor een gegeven waarde \\(X=x\\) neemt de genexpressie \\(Y\\) dus niet steeds dezelfde waarde aan. Generiek kunnen we de S100A8 gen expressie dus beschrijven als \\[\\text{observatie = signaal + ruis.}\\] Wiskundig kunnen we dat modelleren als \\[Y_i=g(X_i)+\\epsilon_i\\] waarbij we de toevallige veranderlijke S100A8 genexpressie voor subject \\(i\\) (\\(Y_i\\)) modelleren in functie van de genexpressie van het ESR1 gen (\\(X_i\\)). Uiteraard is dit verband niet perfect. Dat wordt aangegeven door de foutterm \\(\\epsilon_i\\) die uitdrukt dat observaties \\(Y_i\\) variëren rond dit verband, m.a.w. het verband modelleert een conditioneel gemiddelde: \\[E[Y_i|X_i=x]=g(x),\\] het is de verwachte uitkomst38 (\\(E[Y]\\)) bij subjecten met een expressieniveau \\(X_i=x\\) voor het ESR1 gen. Zo geeft \\(E(Y|X=2400)\\) de gemiddelde genexpressie aan van het S100A8 gen voor subjecten die een expressie hebben van 2400 voor het ESR1 gen. Men zou dit gemiddelde bekomen door van alle patiënten in de studiepopulatie, die een ESR1 expressie hebben van 2400, de S100A8 expressie te meten en hier vervolgens het gemiddelde van te nemen. Het gemiddelde \\(E(Y|X=x)\\) wordt een conditioneel gemiddelde genoemd omdat het een gemiddelde uitkomst beschrijft, conditioneel op het feit dat \\(X=x\\). Gezien \\[E[Y_i|X_i=x]=g(x)\\] het gemiddelde beschrijft voor subjecten met een ESR1 expressieniveau van \\(x\\) is de foutterm \\(\\epsilon_i\\) gemiddeld 0 voor deze subjecten: \\[E[\\epsilon_i\\vert X_i=x]=0.\\] 6.2 Lineaire regressie Om accurate en interpreteerbare resultaten te bekomen gaat men vaak bepaalde veronderstellingen doen over de structuur van \\(g(x)\\). Zo modelleert men \\(g(x)\\) vaak als een lineaire functie van ongekende parameters. Dat wordt geïllustreerd in Figuur 6.4. plot(S100A8~ESR1,data=subset(borstkanker,S100A8&lt;2000)) #lm functie fit een linear model #abline functie voegt een lijn toe aan een plot abline(lm(S100A8~ESR1,data=subset(borstkanker,S100A8&lt;2000))) Figuur 6.4: Scatterplot voor S100A8 expressie in functie van de ESR1 expressie met lineair model dat het verband tussen beide genen samenvat (na verwijdering van outliers in de S100A8 expressie, merk op dat we deze outliers in principe niet mochten verwijderen uit de dataset zoals we verder in dit hoofdstuk zullen zien). Men veronderstelt dan het onderstaande lineaire regressiemodel \\[\\begin{equation} E(Y|X =x)=\\beta_0 + \\beta_1 x \\tag{6.1} \\end{equation}\\] waarbij \\(\\beta_0\\) en \\(\\beta_1\\) onbekende modelparameters zijn. In deze uitdrukking stelt \\(E(Y|X=x)\\) de waarde op de \\(Y\\)-as voor, \\(x\\) de waarde op de \\(X\\)-as, het intercept \\(\\beta_0\\) stelt het snijpunt met de \\(Y\\)-as voor en de helling \\(\\beta_1\\) geeft de richtingscoëfficiënt van de rechte weer. Uitdrukking (6.1) wordt een statistisch model genoemd. Merk op dat dit model enkel een onderstelling maakt over het gemiddelde van de S100A8 expressie. Deze naamgeving suggereert dat het bepaalde onderstellingen legt op de verdeling van de geobserveerde gegevens. In het bijzonder onderstelt het dat de gemiddelde uitkomst lineair varieert in functie van één verklarende variabele \\(X\\). Om die reden wordt Model (6.1) ook een enkelvoudig lineair regressiemodel genoemd. Onder dit model kan elke meting \\(Y\\) op een foutterm \\(\\epsilon\\) na beschreven worden als een lineaire functie van de verklarende variabele \\(X\\), verder in deze cursus ook de predictor genoemd: \\[Y=E(Y|X=x)+\\epsilon=\\beta_0+\\beta_1 x+\\epsilon\\] waarbij \\(\\epsilon\\) de afwijking tussen de uitkomst en haar (conditioneel) gemiddelde waarde voorstelt, dit is de onzekerheid in de responsvariabele. Gezien het lineair regressiemodel onderstellingen doet over de verdeling van X en Y , kunnen deze onderstellingen ook vals zijn. Later in dit hoofdstuk zullen we zien hoe deze onderstellingen geëvalueerd kunnen worden. Als echter voldaan is aan de onderstellingen, laat dit een efficiënte data-analyse toe: alle observaties worden benut om te leren over verwachte uitkomst bij X = x. Het lineair regressiemodel kan worden gebruikt voor - predictie (voorspellingen): als \\(Y\\) ongekend is, maar \\(X\\) wel gekend is, kunnen we \\(Y\\) voorspellen op basis van \\(X\\) \\[\\text{E}\\left[Y|X =x\\right]=\\beta_0 + \\beta_1 x.\\] - associatie: beschrijven van de biologische relatie tussen variabele \\(X\\) en continue meting \\(Y\\): \\[\\text{E}\\left[Y|X=x+\\delta\\right]-\\text{E}\\left[Y|X=x\\right]= \\left[\\beta_0+\\beta_1(x+\\delta)\\right]-(\\beta_0+\\beta_1x)=\\beta_1\\delta\\] waarbij \\(\\beta_1\\) het verschil is in gemiddelde uitkomst tussen subjecten die 1 eenheid verschillen in de genexpressie van het ESR1 gen. 6.3 Parameterschatting De parameters \\(\\beta_0\\) en \\(\\beta_1\\) zijn onbekenden. Indien de volledige studiepopulatie geobserveerd werd, dan zouden beide parameters exact bepaald kunnen worden (door bijvoorbeeld in 2 x-waarden de gemiddelde uitkomst te berekenen en vervolgens het resulterende stelsel van 2 vergelijkingen, bepaald door Model (6.1), op te lossen). In de praktijk observeert men slechts een beperkte steekproef uit de studiepopulatie en is de taak om die parameters te schatten op basis van de beschikbare observaties. Deze schatting gebeurt door naar de lijn te zoeken die “het best past” bij de gegevens. Daarbij wil men dat bij een gegeven waarde \\(x_i\\) voor het \\(i\\)-de subject het punt op de regressielijn, \\((x_i, \\beta_0 + \\beta_1 x_i)\\), zo weinig mogelijk afwijkt van de overeenkomstige observatie \\((x_i, y_i)\\). Dit realiseert men door deze waarden voor \\(\\beta_0\\) en \\(\\beta_1\\) te kiezen die de som van die kwadratische afstanden tussen de voorspelde en geobserveerde punten, \\[\\sum_{i=1}^n (y_i-\\beta_0-\\beta_1 x_i)^2=\\sum_{i=1}^n e_i^2\\] zo klein mogelijk maakt. Waarbij \\(e_i\\) de verticale afstanden van de observaties tot de gefitte regressierechte, ook wel residuen genoemd (zie Figuur 6.5). borstkankerSubset&lt;-subset(borstkanker,S100A8&lt;2000) plot(S100A8~ESR1,borstkankerSubset) lm1 &lt;- lm(S100A8~ESR1,borstkankerSubset) abline(lm1,col=2) points(borstkankerSubset$ESR1,lm1$fitted,col=2,pch=2) for (i in 1:length(borstkankerSubset$S100A8)) lines(rep(borstkankerSubset$ESR1[i],2),c(lm1$fitted[i],borstkankerSubset$S100A8[i]),lty=2,col=1) legend(&quot;topright&quot;,lty=c(0,2,0,1),col=c(1,1,2,2),pch=c(1,26,2,26),legend=c(&quot;observatie&quot;,&quot;residu&quot;,&quot;predictie&quot;,&quot;regressielijn&quot;)) Figuur 6.5: Scatterplot voor S100A8 expressie in functie van de ESR1 expressie met lineair model en residuen. De rechte die men aldus bekomt, noemt men de kleinste kwadratenlijn en is de best passende rechte door de puntenwolk. De overeenkomstige waarden of schattingen \\(\\hat{\\beta}_0\\) voor \\(\\beta_0\\) en \\(\\hat{\\beta}_1\\) voor \\(\\beta_1\\), noemt men kleinste kwadratenschattingen. Men kan eenvoudig aantonen dat \\[\\hat{\\beta_1}= \\frac{\\sum\\limits_{i=1}^n (y_i-\\bar y)(x_i-\\bar x)}{\\sum\\limits_{i=1}^n (x_i-\\bar x_i)^2}=\\frac{\\mbox{cor}(x,y)s_y}{s_x} \\] en dat \\[\\hat{\\beta_0}=\\bar y - \\hat{\\beta}_1 \\bar x \\] Merk op dat de helling van de kleinste kwadratenlijn evenredig is met de correlatie tussen de uitkomst en de verklarende variabele. Voor gegeven schattingen \\(\\hat{\\beta}_0\\) voor \\(\\beta_0\\) en \\(\\hat{\\beta}_1\\) voor \\(\\beta_1\\) laat het lineaire regressiemodel (6.1) toe om: de verwachte uitkomst te voorspellen voor subjecten met een gegeven waarde \\(x\\) voor de verklarende variabele. Deze kan geschat worden als \\(\\hat{\\beta}_0+\\hat{\\beta}_1x\\). na te gaan hoeveel de uitkomst gemiddeld verschilt tussen 2 groepen subjecten met een verschil van \\(\\delta\\) eenheden in de verklarende variabele. Namelijk: \\[\\text{E}\\left[Y|X=x+\\delta\\right]-\\text{E}\\left[Y|X=x\\right]= \\hat{\\beta}_1\\delta\\] Voor de borstkanker dataset levert een analyse van de gegevens in R de volgende resultaten op. lm1 &lt;- lm(S100A8~ESR1,borstkankerSubset) summary(lm1) ## ## Call: ## lm(formula = S100A8 ~ ESR1, data = borstkankerSubset) ## ## Residuals: ## Min 1Q Median 3Q Max ## -95.43 -34.81 -6.79 34.23 145.21 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 208.47145 28.57207 7.296 7.56e-08 *** ## ESR1 -0.05926 0.01212 -4.891 4.08e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 59.91 on 27 degrees of freedom ## Multiple R-squared: 0.4698, Adjusted R-squared: 0.4502 ## F-statistic: 23.93 on 1 and 27 DF, p-value: 4.078e-05 De software rapporteert \\(\\hat{\\beta}_0=\\) 208.47 en \\(\\hat{\\beta}_1=\\)-0.059. We besluiten dat, de verwachte S100A8 expressie gemiddeld -59 eenheden lager ligt bij patiënten met een ESR1 expressieniveau die 1000 eenheden hoger ligt. Bovendien kunnen we de S100A8 expressie voorspellen die men mag verwachten bij een gegeven ESR1 expressieniveau. Bijvoorbeeld, bij een ESR1 expressieniveau van 1300 verwachten we een S100A8 expressieniveau van 208.47 \\(-\\) 0.059 \\(\\times\\) 1300= 131.43. Merk op in Figuur 6.4 dat er in de dataset geen patiënt is geobserveerd die een ESR1 expressieniveau had van 1300. Op basis van de dataset zou het bijgevolg niet mogelijk zijn om, zonder gebruik te maken van een statistisch model, een schatting te bekomen voor de S100A8 expressie bij deze ESR1 expressiewaarde. Onder de veronderstelling dat de gemiddelde S100A8 expressie lineair varieert in functie van de ESR1 expressie, kunnen we alle observaties gebruiken om dit gemiddelde te schatten. Bijgevolg bekomen we een zinvol en precies resultaat, op voorwaarde dat aan de veronderstelling van lineariteit is voldaan. Het zal bijgevolg belangrijk zijn om de veronderstelling van lineariteit na te gaan (zie verder). Gezien de lineariteit van het model enkel kan worden nagegaan over het geobserveerde bereik van de verklarende variabele (bijvoorbeeld, over het interval 396.1,3967.2), is het belangrijk om te begrijpen dat de resultaten van een lineair regressiemodel niet zomaar kunnen geëxtrapoleerd worden voorbij de kleinste of grootste geobserveerde \\(X\\)-waarde. Met het model kunnen we de verwachte S100A8 intensiteit voor patiënten met een ESR1 expressie-niveau van 4500 schatten, maar de geobserveerde data laten niet toe om na te gaan of dit een betrouwbare schatting is. Het zou immers kunnen dat de regressielijn bij hoge waarden van de predictorvariabele afbuigt of opklimt waardoor een lineaire extrapolatie misleidend zou zijn. Merk zo bijvoorbeeld op dat predictie bij een ESR1 intensiteit van 4500 bijzonder misleidend is vermits ze een negatief resultaat oplevert wat onmogelijk is voor een intensiteitsmeting (208.47 \\(+\\) -0.059 \\(\\times\\) 4500= -58.22). 6.4 Statistische besluitvorming Als de gegevens representatief zijn voor de populatie kan men in de regressiecontext eveneens aantonen dat de kleinste kwadraten schatters voor het intercept en de helling onvertekend zijn, m.a.w \\[E[\\hat \\beta_0]=\\beta_0 \\text{ en } E[\\hat \\beta_1]=\\beta_1\\] Het feit dat de schatters gemiddeld (over een groot aantal vergelijkbare studies) niet afwijken van de waarden in de populatie, impliceert niet dat ze niet rond die waarde variëren. Om inzicht te krijgen hoe dicht we de parameterschatters bij het werkelijke intercept \\(\\beta_0\\) en de werkelijke helling \\(\\beta_1\\) mogen verwachten, wensen we bijgevolg ook haar variabiliteit te kennen. In de borstkanker dataset hebben we een negatieve associatie geobserveerd tussen de S100A8 en ESR1 gen expressie. Net zoals in Hoofdstuk 5 is het op basis van de puntschatters voor de helling niet duidelijk of dat verband werkelijk voorkomt in de populatie of indien we het verband door toeval hebben geobserveerd in de dataset. De schatting van de helling is immers onnauwkeurig en zal variëren van steekproef tot steekproef. Het resultaat van een data-analyse is dus niet interpreteerbaar zonder die variabiliteit in kaart te brengen. Om de resultaten uit de steekproef te kunnen veralgemenen naar de populatie zullen we in deze context eveneens inzicht nodig hebben op de verdeling van de parameterschatters. Om te kunnen voorspellen hoe de parameterschatters variëren van steekproef tot steekproef enkel en alleen op basis van slechts één steekproef zullen we naast de onderstelling van Lineariteit bijkomende aannames moeten maken over de verdeling van de gegevens, met name Onafhankelijkheid: de metingen \\((X_1,Y_1), ..., (X_n,Y_n)\\) werden gemaakt bij n onafhankelijke subjecten/observationele eenheden Homoscedasticiteit of gelijkheid van variantie: de observaties variëren met een gelijke variantie rond de regressierechte. De residuen \\(\\epsilon_i\\) hebben dus een gelijke variantie \\(\\sigma^2\\) voor elke \\(X_i=x\\). Dat impliceert ook dat de conditionele variantie van Y gegeven X39, \\(\\text{var}(Y\\vert X=x)\\) dus gelijk is, met name \\(\\text{var}(Y\\vert X=x) = \\sigma^2\\) voor elke waarde \\(X=x\\). De constante \\(\\sigma\\) wordt ook de residuele standaarddeviatie genoemd. Normaliteit: de residuen \\(\\epsilon_i\\) zijn normaal verdeeld. Uit 2, 3 en 4 volgt dus dat de residuen \\(\\epsilon_i\\) onafhankelijk zijn en dat ze allen eenzelfde Normale verdeling volgen \\[\\epsilon_i \\sim N(0,\\sigma^2).\\] Als we ook steunen op de veronderstelling van lineariteit weten we dat de originele observaties conditioneel op \\(X\\) eveneens Normaal verdeeld zijn \\[Y_i\\sim N(\\beta_0+\\beta_1 X_i,\\sigma^2),\\] met een gemiddelde dat varieert in functie van de waarde van de onafhankelijke variabele \\(X_i\\). Verder kan men aantonen dat onder deze aannames \\[\\sigma^2_{\\hat{\\beta}_0}=\\frac{\\sum\\limits_{i=1}^n X^2_i}{\\sum\\limits_{i=1}^n (X_i-\\bar X)^2} \\times\\frac{\\sigma^2}{n} \\text{ en } \\sigma^2_{\\hat{\\beta}_1}=\\frac{\\sigma^2}{\\sum\\limits_{i=1}^n (X_i-\\bar X)^2}\\] en dat de parameterschatters eveneens normaal verdeeld zijn \\[\\hat\\beta_0 \\sim N\\left(\\beta_0,\\sigma^2_{\\hat \\beta_0}\\right) \\text{ en } \\hat\\beta_1 \\sim N\\left(\\beta_1,\\sigma^2_{\\hat \\beta_1}\\right)\\] Merk op dat de onzekerheid op de helling af zal nemen wanneer er meer observaties zijn en/of wanneer de observaties meer gespreid zijn. Voor het opzetten van een experiment kan dit belangrijke informatie zijn. Uiteraard wordt de precisie ook beïnvloed door de grootte van de variabiliteit van de observaties rond de rechte, \\(\\sigma^2\\), maar dat heeft een onderzoeker meestal niet in de hand. De conditionele variantie (\\(\\sigma^2\\)) is echter niet gekend en is noodzakelijk voor de berekening van de variantie op de parameterschatters. We kunnen \\(\\sigma^2\\) echter ook schatten op basis van de observaties. Zoals beschreven in Hoofdstuk 4 kunnen we de variatie van de uitkomsten rond hun conditionele gemiddelde beschrijven d.m.v. de afwijkingen tussen de observaties \\(y_i\\) en hun (geschatte) gemiddelde \\(\\hat{g}(x)=\\hat{\\beta}_0+\\hat{\\beta}_1x_i\\), de residu’s. Het gemiddelde van die residu’s is echter altijd 0 omdat positieve en negatieve residu’s mekaar opheffen. Bijgevolg levert het gemiddelde residu geen goede maat op voor de variatie en is het beter om naar kwadratische afwijkingen \\(e_i^2\\) te kijken. Net zoals de steekproefvariantie een goede schatter was voor de variantie (Sectie 4.3.2), zal in de regressiecontext het gemiddelde van die kwadratische afwijkingen rond de regressierechte opnieuw een goede schatter zijn voor \\(\\sigma^2\\). Deze schatter wordt in de literatuur ook wel de mean squared error (MSE) genoemd. \\[\\hat\\sigma^2=MSE=\\frac{\\sum\\limits_{i=1}^n \\left(y_i-\\hat\\beta_0-\\hat\\beta_1\\times x_i\\right)^2}{n-2}=\\frac{\\sum\\limits_{i=1}^n e^2_i}{n-2}.\\] Voor het bekomen van deze schatter steunen we op onafhankelijkheid (aanname 2) en homoscedasticiteit (aanname 3). Merk op dat we bij deze schatter niet delen door het aantal observaties \\(n\\), maar door \\(n-2\\). Hierbij corrigeren we voor het feit dat voor de berekening van MSE 2 vrijheidsgraden worden gespendeerd aan het schatten van het intercept en de helling. Na het schatten van MSE kunnen we \\(\\sigma^2\\) door MSE vervangen zodat schatters worden bekomen voor de variantie en standard error op de schatters van model parameters, \\[\\text{SE}_{\\hat{\\beta}_0}=\\hat\\sigma_{\\hat{\\beta}_0}=\\sqrt{\\frac{\\sum\\limits_{i=1}^n X^2_i}{\\sum\\limits_{i=1}^n (X_i-\\bar X)^2} \\times\\frac{\\text{MSE}}{n}} \\text{ en } \\text{SE}_{\\hat{\\beta}_1}=\\hat\\sigma_{\\hat{\\beta}_1}=\\sqrt{\\frac{\\text{MSE}}{\\sum\\limits_{i=1}^n (X_i-\\bar X)^2}}\\] Analoog als in Hoofdstuk 5 kunnen we opnieuw toetsen en betrouwbaarheidsintervallen construeren op basis van de teststatistieken \\[T=\\frac{\\hat{\\beta}_k-\\beta_k}{SE(\\hat{\\beta}_k)} \\text{ met } k=1,2.\\] Als aan alle aannames is voldaan dan volgen deze statistieken \\(T\\) een t-verdeling met n-2 vrijheidsgraden. Wanneer niet is voldaan aan de veronderstelling van normaliteit maar wel aan lineariteit, onafhankelijkheid en homoscedasticiteit dan kunnen we voor inferentie opnieuw beroep doen op de centrale limietstelling die zegt dat de statistiek T bij benadering een standaard Normaal verdeling zal volgen wanneer het aantal observaties voldoende groot is. In de borstkanker dataset hebben we een negatieve associatie geobserveerd tussen de S100A8 en ESR1 gen expressie. We kunnen het effect in de steekproef nu veralgemenen naar de populatie toe door een betrouwbaarheidsinterval te bouwen voor de helling: \\[[\\hat\\beta_1 - t_{n-2,\\alpha/2} \\text{SE}_{\\hat\\beta_1},\\hat\\beta_1 + t_{n-2,\\alpha/2} \\text{SE}_{\\hat\\beta_1}]\\]. confint(lm1) ## 2.5 % 97.5 % ## (Intercept) 149.84639096 267.09649989 ## ESR1 -0.08412397 -0.03440378 Op basis van de R-output bekomen we een 95% betrouwbaarheidsinterval voor de helling [-0.084,-0.034]. Gezien nul niet in het interval ligt weten we eveneens dat de negatieve associatie statistisch significant is op het 5% significantieniveau. Anderzijds kunnen we ook een formele hypothesetoets uitvoeren. Onder de nulhypothese veronderstellen we dat er geen associatie is tussen de expressie van beide genen: \\[H_0: \\beta_1=0\\] en onder de alternatieve hypothese is er een associatie tussen beide genen: \\[H_1: \\beta_1\\neq0\\] Met de test statistiek \\[T=\\frac{\\hat{\\beta}_1-0}{SE(\\hat{\\beta}_k)}\\] kunnen we de nulhypothese falsifiëren. Onder \\(H_0\\) volgt de statistiek een t-verdeling met n-2 vrijheidsgraden. Deze tweezijdige test is geïmplementeerd in de standaard output van R. summary(lm1) ## ## Call: ## lm(formula = S100A8 ~ ESR1, data = borstkankerSubset) ## ## Residuals: ## Min 1Q Median 3Q Max ## -95.43 -34.81 -6.79 34.23 145.21 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 208.47145 28.57207 7.296 7.56e-08 *** ## ESR1 -0.05926 0.01212 -4.891 4.08e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 59.91 on 27 degrees of freedom ## Multiple R-squared: 0.4698, Adjusted R-squared: 0.4502 ## F-statistic: 23.93 on 1 and 27 DF, p-value: 4.078e-05 De test geeft weer dat de associatie tussen de S100A8 en ESR1 genexpressie extreem significant is (p&lt;&lt;0.001). Als de nulhypothese waar is en als aan alle voorwaarden is voldaan dan is er een kans van 4 op 100000 om een helling te vinden die minstens even extreem is door toeval. Het is bijgevolg heel onwaarschijnlijk om dergelijke associatie te observeren in een steekproef wanneer de nulhypothese waar is. Vooraleer we een conclusie trekken is het echter belangrijk dat we alle aannames verifiëren omdat de statistische test en de betrouwbaarheidsintervallen anders incorrect zijn. 6.5 Nagaan van modelveronderstellingen Voor de statistische besluitvorming hebben we volgende aannames gedaan Lineariteit Onafhankelijkheid Homoscedasticiteit Normaliteit Onafhankelijkheid is moeilijk te verifiëren op basis van de data, dat zou gegarandeerd moeten zijn door het design van de studie. Als we afwijkingen zien van lineariteit dan heeft besluitvorming geen zin gezien het de primaire veronderstelling is. In dat geval moeten we het conditioneel gemiddeld eerst beter modelleren. In geval van lineariteit maar schendingen van homoscedasticiteit of normaliteit dan weten we dat de besluitvorming mogelijks incorrect is omdat de teststatistiek dan niet langer een t-verdeling volgt. 6.5.1 Lineariteit De primaire veronderstelling in lineaire regressie-analyse is de aanname dat de uitkomst (afhankelijke variabele) lineair varieert ten opzichte van de verklarende variabele. Deze veronderstelling kan men gemakkelijk grafisch verifiëren op basis van een scatterplot waarbij men de uitkomst uitzet in functie van de verklarende variabele. Vervolgens gaat men na of het verband een lineair patroon volgt. In Figuur 6.4 zien we systematische afwijkingen bij kleine en grote waarden voor de ESR1 expressie. De observaties liggen dan steeds systematisch boven de regressierechte wat aangeeft dat het gemiddelde in deze regio’s systematisch wordt onderschat. Afwijkingen van lineariteit worden vaak echter makkelijker opgespoord d.m.v. een residuplot. Dit is een scatterplot met de verklarende variabele op de \\(X\\)-as en de residuen op de \\(Y\\)-as \\[e_i=y_i-\\hat{g}(x_i)=y_i-\\hat\\beta_0-\\hat\\beta_1\\times x_i,\\] deze werden weergegeven in Figuur 6.5. Als de veronderstelling van lineariteit opgaat, krijgt men in een residuplot geen patroon te zien. De residuen zijn immers gemiddeld nul voor elke waarde van de predictor en zouden dus mooi rond nul moeten variëren. Wanneer de residu’s echter een niet-lineair patroon onthullen, dan geeft dit aan dat extra termen in het model moeten worden opgenomen om de gemiddelde uitkomst correct te voorspellen. Bijvoorbeeld, wanneer de residu’s een kwadratisch patroon onthullen, dan kunnen we schrijven dat bij benadering \\(e_i\\approx \\delta_0+\\delta_1 x_i+\\delta_2 x_i^2\\) voor zekere getallen \\(\\delta_0,\\delta_1,\\delta_2\\), en bijgevolg dat de uitkomst \\(y_i=\\hat{\\alpha}+\\hat{\\beta}x_i+e_i\\approx (\\hat{\\alpha}+\\delta_0)+(\\hat{\\beta}+\\delta_1)x_i+\\delta_2 x_i^2\\) (op een foutterm na) een kwadratische functie is van \\(x_i\\). In dat geval is het aangewezen om op een kwadratisch regressiemodel over te stappen (zie Hoofdstuk 10). Residuplots worden standaard gegenereerd door de R-software. Hier worden de residuen echter geplot ten opzichte van de gefitte waarden wat eenvoudiger is wanneer meerdere predictoren in het model worden opgenomen (zie Hoofdstuk 10). par(mfrow=c(2,2)) plot(lm1) Figuur 6.6: Diagnostische plots voor het nagaan van de veronderstellingen van het lineair regressiemodel waarbij de S100A8 expressie wordt gemodelleerd i.f.v de ESR1 expressie (na verwijdering van 3 outliers). De residu plot voor het borstkanker voorbeeld wordt weergegeven in Figuur 6.6 boven links. De residuen zijn niet overal mooi gespreid rond nul. Bij lage en hoge voorspelde waarden voor het model (dus bij hoge en lage waarden voor de predictor, negatieve helling) zijn de residuen overwegend positief wat opnieuw aangeeft dat het model de data in deze regio’s systematisch onderschat. Dat was ergens te verwachten gezien de smoother in Figuur 6.3 immers eerder een exponentiëel verband suggereerde. Bovendien voorspelde het regressiemodel eveneens negatieve waarden voor de S100A8 expressie wat onmogelijk is voor intensiteitsmetingen die immers steeds positief zijn. 6.5.2 Veronderstelling van homoscedasticiteit (gelijkheid van variantie) Residuen en kwadratische residu’s dragen informatie in zich over residuele variabiliteit. Als er homoscedasiticiteit is dan verwachten we dat de residuen eenzelfde spreiding hebben voor elke waarde van de predictor en voor elke predictie. Als de spreiding in de residuen geassocieerd zijn met de verklarende variabelen, dan is er indicatie van heteroscedasticiteit. De diagnostische plots van het software pakket R geven een residu-plot weer en een plot van de vierkantswortel van de absolute waarde van de gestandardiseerde error \\(\\sqrt{|e_i|/\\sqrt{MSE}}\\) in functie van de predicties. De residu-plot voor het borstkanker voorbeeld Figuur 6.6 boven links geeft afwijkingen weer van homoscedasiticiteit. De spreiding in de residuen lijkt toe te nemen met een toenemende waarde van de predictor. De plot beneden links is specifiek om de voorwaarde van gelijkheid van variantie na te gaan en geeft eveneens aan dat de variantie toeneemt met het conditioneel gemiddelde. Een dergelijke trend komt dikwijls voor bij concentratiemetingen en intensiteitsmetingen, die vaak een multiplicatieve errorstructuur vertonen i.p.v. een additieve error. Voor bepaalde types uitkomsten bestaan er variantie-stabiliserende transformaties voor de afhankelijke variabele die erop gericht zijn om de onderstelling van homoscedasticiteit te doen opgaan. Voor proporties of percentages, gebruikt men bijvoorbeeld vaak de arcsin-transformatie die de uitkomst \\(Y\\) omzet in \\(\\arcsin\\sqrt{Y}\\), omdat men kan aantonen dat percentages (onder bepaalde onderstellingen) een constante variantie hebben na deze transformatie. Voor concentraties en intensiteitsmetingen gebruikt men dan weer vaak een logaritmische transformatie gezien deze (a) positief zijn, (b) vaak gekenmerkt worden door een variantie die toeneemt met het gemiddelde en (c) veelal een scheve verdeling vertonen maar rechts. Indien transformatie van de uitkomst niet helpt of niet wenselijk is (bijvoorbeeld, omdat het de interpretatie van het model niet ten goede komt) en er is een consistent patroon van ongelijke variantie (bijvoorbeeld, toenemende variantie in uitkomst bij toenemende predictorwaarden), dan kan men ook gewogen kleinste kwadratenschatters (in het Engels: weighted least squares) bepalen. Een verder alternatief is om veralgemeende lineaire modellen (in het Engels: generalized linear models) te schatten die tevens andere verdelingen voor de uitkomst dan de Normale verdeling toelaten. Beide klassen van oplossingen (d.i. gewogen kleinste kwadratenschatters en veralgemeende lineaire modellen) vallen echter buiten het bestek van deze cursus. 6.5.3 Veronderstelling van normaliteit Opnieuw kunnen we de veronderstelling van normaliteit nagaan door gebruik te maken van QQ-plots. Een QQ-plot van de afhankelijke variabele is misleidend omdat deze nagaat of de metingen voor alle subjecten samen Normaal verdeeld zijn. Dat is echter niet het geval gezien de normale verdeling per subject varieert. Elk subject kan immers andere waarde hebben voor de predictor \\(X\\) (ESR1 expressie) en bijgevolg hebben ze een verschillend conditioneel gemiddelde. Normaal verdeelde uitkomsten bij gegeven \\(x\\)-waarde impliceert echter dat de residu’s bij benadering Normaal verdeeld zijn. Afwijkingen van Normaliteit in een QQ-plot van de residu’s levert dus een indicatie dat de uitkomsten niet Normaal verdeeld zijn bij vaste \\(x\\). Figuur 6.6 rechts boven geeft de QQ-plot weer van de residuen voor het borstkanker voorbeeld. We zien wat afwijkingen in de rechterstaart die wijzen op meerdere outliers of op observaties die systematisch hoger liggen dan wat verwacht kan worden op basis van de normaalverdeling. Dit is niet verrassend omdat heterogeniteit van de variantie vaak samengaat met niet-Normaliteit, i.h.b. scheefheid, van de gegevens. Dat komt vaak voor bij concentratie- en intensiteitsmetingen. 6.6 Afwijkingen van Modelveronderstellingen De primaire onderstelling in lineaire regressie-analyse is de aanname dat de uitkomst lineair varieert in de predictor. Wanneer residuplots suggereren dat aan deze onderstelling niet is voldaan, dan kan men overwegen om de verklarende variabele te transformeren. In genexpressie studies waarbij expressie als een covariaat wordt gebruikt om een andere variabele te verklaren, is het bijvoorbeeld vaak zo dat de (gemiddelde) uitkomst niet lineair varieert in functie van de predictor, maar wel in functie van het logaritme van de genexpressie. In dat geval kan men ervoor kiezen om de log-transformatie van de verklarende variabele als predictor in het model op te nemen. Vaak wordt in expressie studies een \\(\\log_2\\) transformatie gebruikt. In andere voorbeelden kan een andere transformatie dan de log-transformatie beter geschikt zijn, zoals de vierkantswortel (\\(\\sqrt{x}\\)) of inverse (\\(1/x\\)) transformatie. Een transformatie van de verklarende variabele is vaak makkelijk uit te voeren, maar bemoeilijkt wel vaak de interpretatie van de parameters in het model. Dit laatste is echter niet het geval wanneer de log-transformatie wordt gebruikt, een stijging in \\(log_2\\)-expressie met bijvoorbeeld 1 eenheid is immers equivalent met een wijziging in genexpressie met een factor \\(2^1=2\\). Kenmerkend aan transformatie van de verklarende variabele is dat ze geen rechtstreekse invloed heeft op de homogeniteit van de variantie en de Normaliteit van de uitkomst (bij vaste waarden van de predictorvariabele), tenzij door het verbeteren van de lineariteit van het model. Om die reden is deze optie vaak minder geschikt wanneer er sterke afwijkingen van Normaliteit zijn. Een alternatieve mogelijkheid om de lineariteit van het model te verbeteren, is hogere orde regressie (in het Engels: higher order regression. Hierbij modelleert men rechtstreeks niet-lineaire relaties door hogere orde termen in het model op te nemen. Zo kan men bijvoorbeeld een tweede orde model beschouwen: \\[E(Y|X)=\\beta_0+\\beta_1X+\\beta_2X^2\\] zodat de regressiekromme eruit ziet als een parabool, of een derde orde model: \\[E(Y|X)=\\beta_0+\\beta_1X+\\beta_2X^2+\\beta_3X^3\\] zodat de regressiekromme een derdegraadspolynoom is. Deze methode kan gezien worden als een vorm van transformatie van de verklarende variabele en bezit wezenlijk dezelfde eigenschappen en voor- en nadelen. Een bijkomend voordeel is echter dat het hier niet nodig is om zelf een transformatie te zoeken, maar dat de methode zelf impliciet een goede polynoom als transformatie schat. Tenslotte kan men ook overwegen om, in plaats van de verklarende variabele, de uitkomst te transformeren. Bijvoorbeeld, wanneer de uitkomsten scheef verdeeld zijn naar rechts is het vaak aangewezen om een log-transformatie van de uitkomst uit te voeren en deze nieuwe variabele als uitkomst in het model op te nemen. Doorgaans verbetert dit niet alleen de lineariteit van het model, maar maakt het ook de residu’s beter Normaal verdeeld met een meer constante variabiliteit. Deze methode heeft dezelfde voor- en nadelen als transformatie van de verklarende variabele. Een groot verschil dat de keuze tussen beide methoden beïnvloedt is dat transformaties van de onafhankelijke variabele weinig of geen invloed hebben op de verdeling van de residu’s (tenzij via wijzigingen in hun gemiddelde) in tegenstelling tot transformaties van de afhankelijke variabele. In het bijzonder blijven Normaal verdeelde residu’s vrij Normaal verdeeld na transformatie van de verklarende variabele, terwijl ze mogelijks niet langer Normaal verdeeld zijn na transformatie van de uitkomst, en vice versa. In het borstkanker voorbeeld wordt de S100A8 genexpressie gemodelleerd in functie van de ESR1 genexpressie. Er waren problemen m.b.t. heteroscedasticiteit, mogelijkse afwijking van normaliteit (scheefheid naar rechts), negatieve concentratievoorspellingen die theoretisch niet mogelijk zijn en niet-lineairiteit. Dergelijke problemen treden veelal op bij concentratie en intensiteitsmetingen. Deze zijn vaak log-normaal verdeeld (normale verdeling na log-transformatie) en worden daarom vaak log-getransformeerd. Bovendien zagen we in Figuur 6.3 eveneens een soort exponentiële trend. In de genexpressie literatuur wordt veelal gebruik gemaak van \\(\\log_2\\) transformatie gezien een verschil van 1 op log-schaal een verdubbeling impliceert in de expressie op de originele schaal. Wanneer men gen-expressie op log-schaal modelleert, modellert men dus in feite proportionele verschillen op de originele schaal wat ook meer relevant is vanuit een biologisch standpunt. In deze sectie zullen we beide genexpressies \\(\\log_2\\) transformeren en een log-lineaire regressie uitvoeren. Zoals we zullen zien vormen de outliers in de S100A8 expressie na log-transformatie ook geen problemen meer. borstkanker$log2S100A8 &lt;- log2(borstkanker$S100A8) borstkanker$log2ESR1 &lt;- log2(borstkanker$ESR1) lm2 &lt;- lm(log2S100A8~log2ESR1,borstkanker) with(borstkanker, scatter.smooth(log2ESR1,log2S100A8,lpars=list(lty=2))) abline(lm2) legend(&quot;topright&quot;,lty=1:2,legend=c(&quot;Lineair model&quot;,&quot;Smoother&quot;)) Figuur 6.7: Scatterplot voor log2-S100A8 expressie in functie van de log2-ESR1 expressie met smoother en lineair model die het verband tussen beide genen samenvatten (outliers worden niet langer verwijderd uit de dataset). In Figuur 6.7 zien we duidelijk een dalende lineaire trend van de S100A8 expressie i.f.v. de ESR1 expressie na log-transformatie. De smoother toont ook niet langer een afwijking aan van lineariteit. Daarnaast kunnen we alle data meenemen in de analyse en kan het model geen negatieve expressiewaarden meer voorspellen na terugtransformatie. In Figuur 6.8 zien we tevens dat er niet langer afwijkingen zijn van lineariteit, normaliteit en gelijkheid van variantie. De residuen in de residu-plot liggen mooi rond nul en hebben een constante spreiding. De QQ-plot toont geen systematische afwijkingen van normaliteit en de plot links beneden toont ook geen trend in de variantie van de residuen. par(mfrow=c(2,2)) plot(lm2) Figuur 6.8: Diagnostische plots voor het lineair model voor log2-S100A8 expressie in functie van de log2-ESR1. Na log-transformatie zijn alle voorwaarden voldaan en kunnen we overgaan tot statistische besluitvorming en interpretatie van de modelparameters. summary(lm2) ## ## Call: ## lm(formula = log2S100A8 ~ log2ESR1, data = borstkanker) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.94279 -0.66537 0.08124 0.68468 1.92714 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 23.401 1.603 14.60 3.57e-15 *** ## log2ESR1 -1.615 0.150 -10.76 8.07e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.026 on 30 degrees of freedom ## Multiple R-squared: 0.7942, Adjusted R-squared: 0.7874 ## F-statistic: 115.8 on 1 and 30 DF, p-value: 8.07e-12 confint(lm2) ## 2.5 % 97.5 % ## (Intercept) 20.128645 26.674023 ## log2ESR1 -1.921047 -1.308185 Er is een extreem significante negatieve associatie tussen de S100A8 en ESR1 genexpressie (\\(p&lt;&lt;0.001\\)). Interpretatie 1 Een groep patiënten met een ESR1 expressie die 1 eenheid op de \\(\\log_2\\) schaal hoger ligt dan dat van een andere groep patiënten heeft gemiddeld gezien een expressie-niveau van het S100A8 gen dat 1.61 eenheden lager ligt (95% BI [-1.92,-1.31]). \\[\\log_2 \\hat\\mu_1=23.401 -1.615 \\times \\text{logESR}_1,\\text{ } \\log_2 \\hat\\mu_2=23.401 -1.615 \\times \\text{logESR}_2 \\] \\[\\log_2 \\hat\\mu_2-\\log_2 \\hat\\mu_1= -1.615 (\\log_2 \\text{ESR}_2-\\log_2 \\text{ESR}_1) = -1.615 \\times 1 = -1.615\\] Interpretatie 2 Wanneer de data op log-schaal wordt gemodelleerd, worden na terugtransformatie geometrische gemiddelden bekomen. Ter illustratie herschrijven we bijvoorbeeld het rekenkundig gemiddelde op de log schaal: \\[\\begin{eqnarray*} \\sum\\limits_{i=1}^n \\frac{\\log x_i}{n}&amp;=&amp;\\frac{\\log x_1 + \\ldots + \\log x_n}{n}\\\\\\\\ &amp;\\stackrel{(1)}{=}&amp;\\frac{\\log(x_1 \\times \\ldots \\times x_n)}{n}=\\frac{\\log\\left(\\prod\\limits_{i=1}^n x_i\\right)}{n}\\\\\\\\ &amp;\\stackrel{(2)}{=}&amp;\\log \\left(\\sqrt[\\leftroot{-1}\\uproot{2}\\scriptstyle n]{\\prod\\limits_{i=1}^n x_i}\\right) \\end{eqnarray*}\\] waarbij in overgang (1) en (2) wordt gesteund op de eigenschappen van logaritmen en \\(\\prod\\) de product operator is. Na terug transformatie wordt dus een geometrisch gemiddelde \\(\\sqrt[\\leftroot{-1}\\uproot{2}\\scriptstyle n]{\\prod\\limits_{i=1}^n x_i}\\) bekomen. In de onderstaande notatie worden de populatiegemiddelden \\(\\mu\\) dus geschat a.d.h.v. geometrisch gemiddelden. Omdat de logaritmische transformatie een monotone transformatie is, kunnen we ook betrouwbaarheidsintervallen berekend op log-schaal terugtransformeren! 2^lm2$coef[2] ## log2ESR1 ## 0.3265519 2^-lm2$coef[2] ## log2ESR1 ## 3.0623 2^-confint(lm2)[2,] ## 2.5 % 97.5 % ## 3.786977 2.476298 Een groep patiënten met een dubbel zo hoge ESR1 expressie hebben gemiddeld een S100A8 expressie die 3.06 keer lager ligt (95% BI [2.48,3.79]). \\[\\log_2 \\hat\\mu_1=23.401 -1.615 \\times \\text{logESR}_1,\\text{ } \\log_2 \\hat\\mu_2=23.401 -1.615 \\times \\text{logESR}_2 \\] \\[\\log_2 \\hat\\mu_2-\\log_2 \\hat\\mu_1= -1.615 (\\log_2 \\text{ESR}_2-\\log_2 \\text{ESR}_1) \\] \\[\\log_2 \\left[\\frac{\\hat\\mu_2}{\\hat\\mu_1}\\right]= -1.615 \\log_2\\left[\\frac{ \\text{ESR}_2}{\\text{ESR}_1}\\right] \\] \\[\\frac{\\hat\\mu_2}{\\hat\\mu_1}=\\left[\\frac{ \\text{ESR}_2}{\\text{ESR}_1}\\right]^{-1.615}=2^ {-1.615} =0.326\\] of \\[\\frac{\\hat\\mu_1}{\\hat\\mu_2}=2^{1.615} =3.06\\] Interpretatie 3 Een groep patiënten met een ESR1 expressie die 1% hoger ligt dan dat van een andere groep patiënten heeft gemiddeld gezien een expressie-niveau van het S100A8 gen dat ongeveer -1.61% lager ligt (95% BI [-1.92,-1.31])%. \\[\\log_2 \\hat\\mu_1=23.401 -1.615 \\times \\text{logESR}_1,\\text{ } \\log_2 \\hat\\mu_2=23.401 -1.615 \\times \\text{logESR}_2 \\] \\[\\log_2 \\hat\\mu_2-\\hat\\log_2 \\mu_1= -1.615 (\\log_2 \\text{ESR}_2-\\log_2 \\text{ESR}_1) \\] \\[\\log_2 \\left[\\frac{\\hat\\mu_2}{\\hat\\mu_1}\\right]= -1.615 \\log_2\\left[\\frac{ \\text{ESR}_2}{\\text{ESR}_1}\\right] \\] \\[\\frac{\\hat\\mu_2}{\\hat\\mu_1}=\\left[\\frac{ \\text{ESR}_2}{\\text{ESR}_1}\\right]^{-1.615}=1.01^ {-1.615} =0.984 \\approx -1.6\\%\\] Merk op dat voor waarden van \\[−10&lt; \\beta_1&lt;10 \\rightarrow 1.01 ^{\\beta_1}−1 \\approx \\frac{\\beta_1}{100}.\\] Dus voor log-getransformeerde predictoren met kleine tot gematigde waarden voor \\(\\beta_1\\) kan de helling \\(\\beta_1\\) als volgt geïnterpreteerd worden: een 1% toename in de predictor resulteert gemiddelde in een \\(\\beta_1\\)% verschil in de uitkomst. 6.7 Besluitvorming over gemiddelde uitkomst In de sectie 6.4 toonden we dat de parameterschatters van het linear regressie model normaal verdeeld zijn onder de voorwaarden van onafhankelijkheid, lineariteit, homoscedasticiteit en (conditionele) normaliteit van de gegevens. Het regressie model wordt niet enkel gebruikt om de associatie tussen twee variabelen te bestuderen, maar ook om voorspellingen te doen van de response gegeven een gekende waarde voor de predictor. In dat geval wenst men vaak besluitvorming te doen over de gemiddelde uitkomst geschat met het model bij een gegeven waarde \\(x\\), m.a.w. \\[\\hat{g}(x)= \\hat{\\beta}_0 + \\hat{\\beta}_1 x\\] Hierbij is de gemiddelde uitkomst \\(\\hat{g}(x)\\) een schatter van het conditionele gemiddelde \\(E[Y\\vert X=x]\\). Wanneer de parameterschatters een Normale verdeling volgen zal de schatter voor de gemiddelde uitkomst ook Normaal verdeeld zijn gezien het een lineaire combinatie is van de parameterschatters. Gezien de parameterschatters onvertekend zijn, is de schatter van de gemiddelde uitkomst dat ook. Men kan aantonen dat de standard error op de schatter voor de gemiddelde uitkomst \\[\\text{SE}_{\\hat{g}(x)}=\\sqrt{MSE\\left\\{\\frac{1}{n}+\\frac{(x-\\bar X)^2}{\\sum\\limits_{i=1}^n (X_i-\\bar X)^2}\\right\\}}.\\] Dit geeft aan dat de schatter voor de gemiddelde uitkomst het meest precies is voor \\(x=\\bar x\\) en in dit punt zelfs even precies zijn dan wanneer alle observaties \\(x_1,\\ldots, x_n\\) in de steekproef gelijk zouden zijn aan \\(x\\). Opnieuw kan men aantonen dat de statistiek \\[T=\\frac{\\hat{g}(x)-g(x)}{SE_{\\hat{g}(x)}}\\sim t_{n-2}\\] een t-verdeling volgt met \\(n-2\\) vrijheidsgraden. Deze statistiek kan opnieuw gebruikt worden voor besluitvorming d.m.v. hypothese testen of door de constructie van betrouwbaarheidsintervallen. De gemiddelde uitkomst en betrouwbaarheidsintervallen op de gemiddelde uitkomst kunnen eenvoudig worden verkregen in R via de predict(.) functie. De predictorwaarden (x-waarden) voor het berekenen van gemiddelde uitkomsten kunnen worden meegegeven via het newdata argument. Betrouwbaarheidsintervallen op de geschatte gemiddelde uitkomsten kunnen worden verkregen d.m.v. het argument interval=&quot;confidence&quot;. Zonder het newdata argument wordt de gemiddelde uitkomsten berekend voor alle predictorwaarden van de dataset. grid=log2(140:4000) g &lt;- predict(lm2,newdata=data.frame(log2ESR1=grid), interval=&quot;confidence&quot;) head(g) ## fit lwr upr ## 1 11.89028 10.76082 13.01974 ## 2 11.87370 10.74721 13.00019 ## 3 11.85724 10.73370 12.98078 ## 4 11.84089 10.72028 12.96151 ## 5 11.82466 10.70696 12.94237 ## 6 11.80854 10.69372 12.92336 De gemiddelde uitkomst en hun 95% puntgewijze betrouwbaarheidsintervallen kunnen eveneens grafisch worden weergegeven (Figuur 6.9) plot(log2S100A8~log2ESR1,borstkanker,ylab=&quot;S100A8 (log2)&quot;,xlab=&quot;ESR1 (log2)&quot;) lines(grid,g[,1]) lines(grid,g[,2],lty=2) lines(grid,g[,3],lty=2) legend(&quot;topright&quot;,lty=1:2,legend=c(&quot;Lineair model&quot;,&quot;95% puntgewijze BI&quot;)) Figuur 6.9: Scatterplot voor log2-S100A8 expressie in functie van de log2-ESR1 expressie met model schattingen en 95\\(\\%\\) betrouwbaarheidsintervallen. De gemiddelde uitkomst en hun 95% betrouwbaarheidsintervallen kunnen makkelijk worden teruggetransformeerd naar de originele schaal, zodat een geometrisch gemiddelde wordt bekomen met 95% betrouwbaarheidsintervallen op het geometrische gemiddelde. Deze kunnen dan grafisch worden weergegeven op de originele schaal in een gewone scatterplot (Figuur 6.10 links) of in een scatterplot met logaritmische assen (Figuur 6.10 rechts). In Figuur 6.10 (links) is het duidelijk dat we met het model na log-transformatie een exponentieel verband kunnen modelleren op de originele schaal. par(mfrow=c(1,2)) gOrig &lt;- 2^g plot(S100A8~ESR1,borstkanker) lines(2^grid,gOrig[,1]) lines(2^grid,gOrig[,2],lty=2) lines(2^grid,gOrig[,3],lty=2) legend(&quot;topright&quot;,lty=1:2,legend=c(&quot;Geometrisch gemiddelde&quot;,&quot;95% puntgewijze BI&quot;),cex=.5) #cex=.5 wordt gebruikt voor kleiner lettertype #standaard staat cex=1 plot(S100A8~ESR1,borstkanker,log=&quot;xy&quot;) lines(2^grid,gOrig[,1]) lines(2^grid,gOrig[,2],lty=2) lines(2^grid,gOrig[,3],lty=2) legend(&quot;topright&quot;,lty=1:2,legend=c(&quot;Geometrisch gemiddelde&quot;,&quot;95% puntgewijze BI&quot;),cex=.5) Figuur 6.10: Scatterplot voor S100A8 expressie in functie van de ESR1 expressie met model schattingen (geometrische gemiddeldes) een 95\\(\\%\\) betrouwbaarheidsintervallen (links: originele schaal, rechts: originele schaal met logaritmische assen). 6.8 Predictie-intervallen Het geschatte regressiemodel kan ook worden gebruikt om een predictie te maken voor één uitkomst van één experiment waarbij een nieuwe uitkomst \\(Y^*\\) bij een gegeven \\(x\\) zal geobserveerd worden. Het is belangrijk in te zien dat dit experiment nog moet worden uitgevoerd. We wensen dus een nog niet-geobserveerde individuele uitkomst te voorspellen. Aangezien \\(Y^*\\) een nieuwe, onafhankelijke observatie voorstelt, weten we dat \\[ Y^* = g(x) + \\epsilon^* \\] met \\(\\epsilon^*\\sim N(0,\\sigma^2)\\) en \\(\\epsilon^*\\) onafhankelijk van de steekproefobservaties \\(Y_1,\\ldots, Y_n\\). We weten dat \\(\\hat{g}(x)\\) een schatting is van de gemiddelde log-S100A8 expressie bij de log-ESR1 expressie \\(x\\), met name een schatting van het conditioneel gemiddelde \\(\\text{E}[Y\\vert x]\\). We argumenteren nu dat \\(\\hat{g}(x)\\) ook een goede predictie is van een nieuwe log-S100A8 expressiewaarde \\(Y^*\\) bij een gegeven log-ESR1 expressieniveau \\(x\\). We weten reeds dat \\(\\hat{g}(x)\\) een schatting is van \\(\\text{E}[Y\\vert x]\\), wat het punt op de regressierechte bij \\(x\\) voorstelt. Het regressiemodel stelt dat bij een gegeven \\(x\\), de individuele uitkomsten \\(Y\\) Normaal verdeeld zijn rond dit punt op de regressierechte. Aangezien een Normale verdeling symmetrisch is, is het even waarschijnlijk om een uitkomst groter dan \\(\\text{E}[Y\\vert x]\\) te observeren, als een uitkomst kleiner dan \\(\\text{E}[Y\\vert x]\\) te observeren. We beschikken echter niet over meer informatie dat ons zou toelaten om te vermoeden dat een uitkomst eerder groter, dan wel kleiner dan \\(\\text{E}[Y\\vert x]\\) zou zijn. Om die reden is het punt op de (geschatte) regressierechte de beste predictie van een individuele uitkomst bij een gegeven \\(x\\). We voorspellen dus een nieuwe log-S100A8 meting bij een gekend log2-ESR1 expressieniveau x door \\[ \\hat{y}(x)=\\hat{\\beta}_0+\\hat{\\beta}_1 \\times x \\] Merk op dat \\(\\hat{y}(x)\\) eigenlijk numeriek gelijk is aan \\(\\hat{g}(x)\\). Gezien het verschil in interpretatie tussen een predictie en een schatting van een conditioneel gemiddelde, gebruiken we een andere notatie. Hoewel de geschatte gemiddelde uitkomst en de predictie voor een nieuwe uitkomst gelijk zijn, zullen hun steekproefdistributies echter verschillend zijn: de onzekerheid op de geschatte gemiddelde uitkomst wordt gedreven door de onzekerheid op de parameterschatters \\(\\hat\\beta_0\\) en \\(\\hat\\beta_1\\). De onzekerheid op de ligging van een nieuwe observatie, daarentegen, wordt gedreven door de onzekerheid op het geschatte gemiddelde en de bijkomende onzekerheid ten gevolge van het feit dat nieuwe observaties at random variëren rond de het conditionele gemiddelde (de regressie rechte) met een variantie \\(\\sigma^2\\). De nieuwe observatie is eveneens onafhankelijk van de observaties in de steekproef zodat de error \\(\\epsilon\\) onafhankelijk zal zijn van de schatter van de gemiddelde uitkomst \\(\\hat{g}(x)\\). De standard error op een predictie voor een nieuwe observatie wordt dus \\[\\text{SE}_{\\hat{Y}(x)}=\\sqrt{\\hat\\sigma^2+\\hat\\sigma^2_{\\hat{g}(x)}}=\\sqrt{MSE\\left\\{1+\\frac{1}{n}+\\frac{(x-\\bar X)^2}{\\sum\\limits_{i=1}^n (X_i-\\bar X)^2}\\right\\}}.\\] Opnieuw kan worden aangetoond dat de statistiek \\[\\frac{\\hat{Y}(x)-Y}{\\text{SE}_{\\hat{Y}(x)}}\\sim t_{n-2}\\] een t-verdeling volgt met n-2 vrijheidsgraden. Deze statistiek kan gebruikt worden om een betrouwbaarheidsinterval op de predictie te construeren, ook wel een predictie-interval (PI) genoemd. Merk op dat dit predictie-interval een verbeterde versie is van een referentie-interval wanneer de modelparameters niet gekend zijn. Het PI houdt immers rekening met de onzekerheid op het geschatte gemiddelde (gebruik van standard error op predictie i.p.v. standaard deviatie) en deze op de geschatte standaard deviatie (gebruik van t-verdeling i.p.v Normale verdeling). Predicties en predictie-intervallen (PIs) kunnen opnieuw eenvoudig worden verkregen in R via de predict(.) functie. De predictorwaarden (x-waarden) voor het berekenen van de predicties40 worden opnieuw meegegeven via het newdata argument. PIs op de predicties kunnen worden verkregen d.m.v. het argument interval=&quot;prediction&quot;. grid=log2(140:4000) p &lt;- predict(lm2,newdata=data.frame(log2ESR1=grid), interval=&quot;prediction&quot;) head(p) ## fit lwr upr ## 1 11.89028 9.510524 14.27004 ## 2 11.87370 9.495354 14.25205 ## 3 11.85724 9.480288 14.23419 ## 4 11.84089 9.465324 14.21646 ## 5 11.82466 9.450461 14.19886 ## 6 11.80854 9.435698 14.18138 De predicties en hun 95% puntgewijze predictie-intervallen kunnen eveneens grafisch worden weergegeven (Figuur 6.11). Merk op dat de intervallen veel breder zijn dan de betrouwbaarheidsintervallen. Merk ook op dat de meeste observaties binnen de predictie-intervallen liggen. We verwachten inderdaad gemiddeld 95% van de observaties binnen de predictie-intervallen. Dat is niet zo voor de betrouwbaarheidsintervallen, die immers geen informatie geven over de verwachte locatie van een nieuwe observatie, maar wel over waar men het conditioneel gemiddelde verwacht op basis van de steekproef! plot(log2S100A8~log2ESR1,borstkanker,ylab=&quot;S100A8 (log2)&quot;,xlab=&quot;ESR1 (log2)&quot;,ylim=range(p)) lines(grid,p[,1]) lines(grid,g[,2],lty=2) lines(grid,g[,3],lty=2) lines(grid,p[,2],lty=3,col=2) lines(grid,p[,3],lty=3,col=2) legend(&quot;topright&quot;,lty=1:3,legend=c(&quot;Lineair model&quot;,&quot;95% puntsgewijze BI&quot;,&quot;95% puntsgewijs PI&quot;),col=c(1,1,2)) Figuur 6.11: Scatterplot voor log2-S100A8 expressie in functie van de log2-ESR1 expressie met model voorspellingen en 95\\(\\%\\) betrouwbaarheidsintervallen en 95\\(\\%\\) predictie-intervallen. NHANES voorbeeld Aangezien een predictie-interval een verbeterde versie is van een referentie-interval bij ongekend populatie gemiddelde en de standaardafwijking, kunnen we a.d.h.v. de lm(.) functie het referentie-interval voor de normale bloeddruk in Sectie 4.4.1 vervangen door een predictie-interval. Het PI zal eveneens de onzekerheid meenemen op de parameterschattingen (gemiddelde en standard error). Het referentie-interval in Sectie 4.4.1 bedroeg [91.9, 147]mmHg. Een predictie-interval kan als volgt worden bekomen in de R software. lmBpNorm &lt;- lm(bpSys~1,data=nhanesSubHealthy) predInt &lt;- predict(lmBpNorm,interval=&quot;prediction&quot;,newdata=data.frame(geenpredictor=1)) round(predInt,1) ## fit lwr upr ## 1 119.5 91.7 147.2 De formule bpSys~1 drukt uit dat we enkel een intercept hebben in het model. We modelleren de bloeddruk dus als \\[Y_i=\\beta_0 + \\epsilon_i,\\] waarbij de parameter \\(\\beta_0\\) de interpretatie heeft van de gemiddelde bloeddruk. Merk op dat het predictie-interval voor de bloeddruk van “gezonde personen tussen 40 en 65 jaar” in de NHANES studie maar een klein beetje breder is dan het referentie-interval. De subset van “gezonde personen tussen 40 en 65 jaar” in de NHANES studie bevat immers 275 subjecten. Hierdoor kan het gemiddelde heel nauwkeurig worden geschat en heeft de t-verdeling voor de constructie van het predictie-interval 274 vrijheidsgraden waardoor het 2.5% kwantiel van de t-verdeling, \\(t_{0.025,n-1}=\\) 1.97, bijna overeenkomt met het 2.5% kwantiel van de normaal verdeling \\(z_{0.025}=\\) 1.96. 6.9 Kwadratensommen en Anova-tabel In deze sectie bespreken we de constructie van kwadratensommen die typisch in een tabel worden gegeven en die behoren tot de klassieke presentatiewijze van een regressie-analyse. De tabel wordt de variantie-analyse tabel of anova tabel genoemd. De totale kwadratensom is gelijk aan \\[\\text{SSTot} = \\sum_{i=1}^n (Y_i-\\bar{Y})^2.\\] Het is de som van de kwadratische afwijkingen van de observaties rond het steekproefgemiddelde \\(\\bar Y\\). Deze kwadratensom kan worden gebruikt om de variantie te schatten van de marginale distributie van de uitkomsten. In dit hoofdstuk wordt de focus hoofdzakelijk gelegd op de conditionele distributie van \\(Y\\vert X=x\\). We weten reeds dat MSE een schatter is van de variantie van de conditionele distributie van \\(Y\\vert X=x\\). De marginale distributie van \\(Y\\) is de verdeling van \\(Y\\) wanneer we geen rekening houden met de waarde voor de predictor \\(X\\). Het heeft als gemiddelde \\(E[Y]\\) wat geschat wordt door het steekproefgemiddelde \\(\\bar{Y}\\) en een variantie \\(\\text{var}[Y]\\) die geschat kan worden aan de hand van \\(\\frac{\\text{SSTot}}{n-1}\\), de steekproefvariantie van \\(Y\\) (zie Sectie 4.3.2). Een grafische interpretatie van SSTot wordt weergegeven in Figuur 6.13. plot(log2S100A8~log2ESR1,data=borstkanker,xlab=&quot;ESR1 expressie (log2)&quot;,ylab=&quot;S100A8 expressie (log2)&quot;,cex.axis=1.5,cex.main=1.5,cex.lab=1.5,col=4) abline(h=mean(borstkanker$log2S100A8)) for (i in 1:length(borstkanker$log2S100A8)) lines(rep(borstkanker$log2ESR1[i],2),c(mean(borstkanker$log2S100A8),borstkanker$log2S100A8[i]),lty=2,col=4) Figuur 6.12: Interpretatie van de totale kwadratensom (SSTot): de som van de kwadratische afwijkingen rond het steekproefgemiddelde. Daarnaast kunnen we eveneens een tweede kwadratensom definiëren: de kwadratensom van de regressie, SSR, die een maat is voor de variabiliteit die verklaard kan worden door de regressie. Het is de som van de kwadratische afwijkingen van de voorspelde response \\(\\hat{Y}_i\\)41 rond het steekproefgemiddelde \\(\\bar Y\\). De kwadratensom van de regressie is gelijk aan \\[\\text{SSR} = \\sum_{i=1}^n (\\hat{Y}_i - \\bar{Y})^2 = \\sum_{i=1}^n (\\hat{g}(x_i) - \\bar{Y})^2.\\] SSR is een maat voor de afwijking tussen de predicties op de geschatte regressierechte en het steekproefgemiddelde van de uitkomsten. Het kan ook geïnterpreteerd worden als een maat voor de afwijking tussen de geschatte regressierechte \\(\\hat{g}(x)=\\hat\\beta_0+\\hat\\beta_1x\\) en een “geschatte regressierechte” waarbij de regressor geen effect heeft op de gemiddelde uitkomst. Deze laatste is dus eigenlijk een schatting van de regressierechte \\(g(x)=\\beta_0\\), waarin \\(\\beta_0\\) geschat wordt door \\(\\bar{Y}\\). Anders geformuleerd: SSR meet de grootte van het regressie-effect zodat \\(\\text{SSR} \\approx 0\\) duidt op geen effect van de regressor en \\(\\text{SSR}&gt;0\\) duidt op een effect van de regressor. We voelen reeds aan dat \\(\\text{SSR}\\) zal kunnen worden gebruikt voor het ontwikkelen van een statistische test die de associatie tussen \\(X\\) en \\(Y\\) evalueert. Een grafische interpretatie van SSR wordt weergegeven in Figuur 6.13. plot(log2S100A8~log2ESR1,borstkanker,xlab=&quot;ESR1 expressie (log2)&quot;,ylab=&quot;S100A8 expressie (log2)&quot;,cex.axis=1.5,cex.main=1.5,cex.lab=1.5) abline(h=mean(borstkanker$log2S100A8)) abline(lm2,col=2) points(borstkanker$log2ESR1,lm2$fitted,pch=2,col=2) for (i in 1:length(borstkanker$log2S100A8)) lines(rep(borstkanker$log2ESR1[i],2),c(mean(borstkanker$log2S100A8),lm2$fitted[i]),lty=2,col=2) Figuur 6.13: Interpretatie van de kwadratensom van de regressie (SSR): de som van de kwadratische afwijkingen tussen de geschatte regressierechte en het steekproefgemiddelde van de uitkomsten. Tenslotte herhalen we de kwadratensom van de fout: \\[ \\text{SSE} = \\sum_{i=1}^n (Y_i-\\hat{Y}_i )^2 = \\sum_{i=1}^n \\left\\{Y_i-\\hat{g}\\left(x_i\\right)\\right\\}^2.\\] Van SSE weten we reeds dat het een maat is voor de afwijking tussen de observaties en de predicties bij de geobserveerde \\(x_i\\) uit de steekproef. Hoe kleiner SSE, hoe beter de fit (schatting) van de regressierechte voor predictiedoeleinden. We hebben deze immers geminimaliseerd om tot de kleinste kwadratenschatters te komen. Een interpretatie van SSE voor het log-log model wordt weergegeven in Figuur 6.14. plot(log2S100A8~log2ESR1,borstkanker,xlab=&quot;ESR1 expressie (log2)&quot;,ylab=&quot;S100A8 expressie (log2)&quot;,cex.axis=1.5,cex.main=1.5,cex.lab=1.5) abline(lm2,col=2) points(borstkanker$log2ESR1,lm2$fitted,pch=2,col=2) for (i in 1:length(borstkanker$log2S100A8)) lines(rep(borstkanker$log2ESR1[i],2),c(borstkanker$log2S100A8[i],lm2$fitted[i]),lty=2) Figuur 6.14: Interpretatie van de kwadratensom van de error (SSE): de som van de kwadratische afwijkingen tussen uitkomsten en de predicties op de geschatte regressierechte. Verder kan worden aangetoond dat de totale kwadratensom als volgt kan ontbonden worden \\[\\begin{eqnarray*} \\text{SSTot} &amp;=&amp; \\sum_{i=1}^n (Y_i-\\bar{Y})^2 \\\\ &amp;=&amp; \\sum_{i=1}^n (Y_i-\\hat{Y}_i+\\hat{Y}_i-\\bar{Y})^2 \\\\ &amp;=&amp; \\sum_{i=1}^n (Y_i-\\hat{Y}_i)^2+\\sum_{i=1}^n(\\hat{Y}_i-\\bar{Y})^2 \\\\ &amp;=&amp; \\text{SSE }+\\text{SSR} \\end{eqnarray*}\\] De ontbinding van de totale kwadratensom kan als volgt worden geïnterpreteerd: De totale variabiliteit in de data (SSTot) wordt gedeeltelijk verklaard door het regressieverband (SSR). De variabiliteit die niet door het regressieverband verklaard wordt, is de residuele variabiliteit (SSE). 6.9.1 Determinatie-coëfficiënt De determinatiecoëfficiënt wordt gedefinieerd door \\[ R^2 = 1-\\frac{\\text{SSE}}{\\text{SSTot}}=\\frac{\\text{SSR}}{\\text{SSTot}}.\\] Het is dus de fractie van de totale variabiliteit in de steekproef-uitkomsten die verklaard wordt door het geschatte regressieverband. Een grote \\(R^2\\) is meestal een indicatie dat het model potentieel tot goede predicties kan leiden (kleine SSE), maar de waarde van \\(R^2\\) is slechts in beperkte mate indicatief voor de p-waarde van de test \\(H_0:\\beta_1=0\\) vs \\(H_1:\\beta_1\\neq0\\). De p-waarde wordt immers sterk beïnvloed door SSE, maar niet door SSTot. Ook de steekproefgrootte n heeft een grote invloed op de p-waarde. De determinatiecoëfficiënt \\(R^2\\) wordt door SSE en SSTot bepaald, maar niet door de steekproefgrootte n. \\(R^2\\) vormt een maat voor de predictieve waarde van de verklarende variabele. Dat wil zeggen dat ze uitdrukt hoe goed de verklarende variabele de uitkomst voorspelt. \\(R^2\\) is steeds gelegen tussen 0 en 1. Een waarde gelijk aan 1 geeft aan dat er geen residuele variatie is rond de regressielijn en dat de uitkomst dus een perfect lineaire relatie met de predictor vertoont. Analoog impliceert een \\(R^2\\) waarde van 0 dat er geen associatie is tussen de uitkomst en de predictor. Vaak wordt er verkeerdelijk beweerd dat een lineair regressiemodel slecht is wanneer de determinatiecoëfficiënt klein is (bvb. \\(R^2=0.2\\)). Wanneer het doel van de studie erin bestaat om de uitkomst te voorspellen o.b.v. verklarende variabele, dan is een hoge \\(R^2\\) inderdaad vereist omdat er bij een lage waarde veel variabiliteit op de uitkomsten overblijft, die niet wordt opgevangen door de verklarende variabele. Wanneer het doel van de studie er echter in bestaat om het effect van een blootstelling op de uitkomst te bepalen, dan is een lineair regressiemodel goed zodra het correct de associatie beschrijft tussen de uitkomst enerzijds en de blootstelling anderzijds. Wanneer blootstelling zwak geassocieerd zijn met de uitkomst, dan wordt een kleine \\(R^2\\)-waarde verwacht, zelfs wanneer een correct regressiemodel wordt gebruikt. summary(lm2) ## ## Call: ## lm(formula = log2S100A8 ~ log2ESR1, data = borstkanker) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.94279 -0.66537 0.08124 0.68468 1.92714 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 23.401 1.603 14.60 3.57e-15 *** ## log2ESR1 -1.615 0.150 -10.76 8.07e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.026 on 30 degrees of freedom ## Multiple R-squared: 0.7942, Adjusted R-squared: 0.7874 ## F-statistic: 115.8 on 1 and 30 DF, p-value: 8.07e-12 In de output voor het borstkankervoorbeeld zien we een \\(R^2\\)=0.79 en kunnen we besluiten dat 79% van de variabiliteit in de \\(\\log_2\\)-S100A8 expressie kan worden verklaard door de \\(\\log_2\\)-ESR1 expressie-waarden. 6.9.2 F-Testen in het enkelvoudig lineair regressiemodel De kwadratensommen vormen de basis van een belangrijke klasse van hypothesetesten. De \\(F\\)-teststatistiek wordt gedefinieerd als \\[ F = \\frac{\\text{MSR}}{\\text{MSE}}\\] met \\[\\text{MSR} = \\frac{\\text{SSR}}{1} \\text{ en } \\text{MSE} = \\frac{\\text{SSE}}{n-2}.\\] MSR wordt de gemiddelde kwadratensom van de regressie genoemd. De noemers 1 en \\(n-2\\) zijn de vrijheidsgraden van SSR en SSE. Ze kan worden gebruikt om de nulhypothese \\(H_0: \\beta_1=0\\), dat er geen associatie is tussen de uitkomst (response) en de blootstelling (predictor) te evalueren t.o.v de alternatieve hypothese \\(H_1: \\beta_1\\neq0\\). Onder \\(H_0: \\beta_1=0\\) volgt de teststatistiek \\[H_0:F = \\frac{\\text{MSR}}{\\text{MSE}} \\sim F_{1,n-2},\\] een F-verdeling met 1 vrijheidsgraad in de teller en n-2 vrijheidsgraden in de noemer. De teststatistiek kan enkel gebruikt worden voor het testen tegenover \\(H_1:\\beta_1\\neq 0\\) (tweezijdig alternatief), waarvoor de \\(p\\)-waarde gegeven wordt door \\[ p = P_0\\left[F\\geq f\\right]=1-F_F(f;1,n-2),\\] de kans onder de nulhypothese42 om een test statistiek F te bekomen die ten minste zo extreem is43 als de waarde f die werd geobserveerd in de steekproef, \\(F_F(.;1,n-2)\\) de cumulatieve distributie is van een F-verdeling met 1 vrijheidsgraad in de teller en n-2 vrijheidsgraden in de noemer. De kritieke waarde op het \\(\\alpha\\) significantieniveau is \\(F_{1,n-2;1-\\alpha}\\). 6.9.3 Anova Tabel De kwadratensommen en de F-test worden meestal in een zogenaamde variantie-analyse tabel of een anova tabel gerapporteerd. Df Sum Sq Mean Sq F value Pr(&gt;F) Regressie vrijheidsgraden SSR SSR MSR f-statistiek p-waarde Error vrijheidsgraden SSE SSE MSE De anovatabel voor het borstkanker voorbeeld kan als volgt in de R-software worden bekomen anova(lm2) ## Analysis of Variance Table ## ## Response: log2S100A8 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## log2ESR1 1 121.814 121.814 115.8 8.07e-12 *** ## Residuals 30 31.559 1.052 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We besluiten dus dat er een extreem significant lineair verband is tussen de \\(\\log_2\\) ESR1 expressie en de \\(\\log_2\\) S100A8 expressie. De \\(F\\)-test is tweezijdig. Door te kijken naar het teken van \\(\\hat\\beta_1\\) (\\(\\hat\\beta_1=-1.615\\)) kunnen we tevens besluiten dat er een negatieve associatie is tussen beiden. Merk op dat de \\(p\\)-waarde van de \\(F\\)-test en de \\(p\\)-waarde van de tweezijdige \\(t\\)-test exact gelijk zijn. Voor het enkelvoudig lineair regressie-model zijn beide testen equivalent! 6.10 Dummy variabelen Het lineaire regressiemodel kan ook gebruikt worden voor het vergelijken van twee gemiddelden. In het Borstkanker voorbeeld kunnen we bijvoorbeeld nagaan of er een verschil is in de gemiddelde leeftijd van de patiënten met onaangetaste lymfeknopen en patiënten waarvan de lymfeknopen werden verwijderd. Hiervoor definiëren we eerst een \\(dummy\\) variabele \\[x_i = \\left\\{ \\begin{array}{ll} 1 &amp; \\text{aangetaste lymfeknopen} \\\\ 0 &amp; \\text{onaangetaste lymfeknopen} \\end{array}\\right.\\] De groep met \\(x_i=0\\) wordt de referentiegroep genoemd. Het regressiemodel blijft ongewijzigd, \\[Y_i = \\beta_0 + \\beta_1 x_i +\\epsilon_i\\] met \\(\\epsilon_i \\text{ iid } N(0,\\sigma^2)\\)44. Gezien \\(x_i\\) slechts twee waarden kan aannemen, is het eenvoudig om het regressiemodel voor beide waarden van \\(x_i\\) afzonderlijk te bekijken: \\[ \\begin{array}{lcll} Y_i &amp;=&amp; \\beta_0 +\\epsilon_i &amp;\\text{onaangetaste lymfeknopen} (x_i=0) \\\\ Y_i &amp;=&amp; \\beta_0 + \\beta_1 +\\epsilon_i &amp;\\text{ aangetaste lymfeknopen} (x_i=1) . \\end{array}\\] Dus \\[\\begin{eqnarray*} E\\left[Y_i\\mid x_i=0\\right] &amp;=&amp; \\beta_0 \\\\ E\\left[Y_i\\mid x_i=1\\right] &amp;=&amp; \\beta_0 + \\beta_1, \\end{eqnarray*}\\] waaruit direct de interpretatie van \\(\\beta_1\\) volgt: \\[ \\beta_1 = E\\left[Y_i\\mid x_i=1\\right]-E\\left[Y_i\\mid x_i=0\\right]\\] \\(\\beta_1\\) is dus het gemiddelde verschil in leeftijd tussen patiënten met aangetaste lymfeknopen en patiënten met onaangetaste lymfeknopen (referentiegroep). Met de notatie \\(\\mu_1= E\\left[Y_i\\mid x_i=0\\right]\\) en \\(\\mu_2= E\\left[Y_i\\mid x_i=1\\right]\\) wordt dit \\[\\beta_1 = \\mu_2-\\mu_1.\\]45 Er kan aangetoond worden dat \\[\\begin{array}{ccll} \\hat\\beta_0 &amp;=&amp; \\bar{Y}_1&amp;\\text{ (steekproefgemiddelde in referentiegroep)} \\\\ \\hat\\beta_1 &amp;=&amp; \\bar{Y}_2-\\bar{Y}_1&amp;\\text{(schatter van effectgrootte)} \\\\ \\text{MSE} &amp;=&amp; S_p^2 . \\end{array}\\] De testen voor \\(H_0:\\beta_1=0\\) vs. \\(H_1:\\beta_1\\neq0\\) kunnen gebruikt worden voor het testen van de nulhypothese van de two-sample \\(t\\)-test, \\(H_0:\\mu_1=\\mu_2\\) t.o.v. \\(H_1:\\mu_1\\neq\\mu_2\\). borstkanker$node=as.factor(borstkanker$node) lm3 &lt;- lm(age~node,borstkanker) t.test(age~node,borstkanker,var.equal=TRUE) ## ## Two Sample t-test ## ## data: age by node ## t = -2.7988, df = 30, p-value = 0.008879 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -15.791307 -2.467802 ## sample estimates: ## mean in group 0 mean in group 1 ## 59.94737 69.07692 summary(lm3) ## ## Call: ## lm(formula = age ~ node, data = borstkanker) ## ## Residuals: ## Min 1Q Median 3Q Max ## -19.9474 -5.3269 0.0526 5.3026 18.0526 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 59.947 2.079 28.834 &lt; 2e-16 *** ## node1 9.130 3.262 2.799 0.00888 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.063 on 30 degrees of freedom ## Multiple R-squared: 0.207, Adjusted R-squared: 0.1806 ## F-statistic: 7.833 on 1 and 30 DF, p-value: 0.008879 par(mfrow=c(2,2)) plot(lm3) Figuur 6.15: Diagnostische plot voor het model waarbij leeftijd wordt gemodelleerd a.d.h.v. een dummy variabele voor factor lymfe knoop status. We zien in de R output dat de output van de t-test en het lineaire model met 1 dummy variabele identieke resultaten geeft voor de test statistiek en de p-waarde. We zien eveneens een heel significante associatie tussen de leeftijd en de lymfe node status (p=0.009). De leeftijd van personen met aangetaste lymfeknopen is gemiddeld 9.1 jaar hoger dan die van patiënten zonder aantasting van de lymfeknopen. Let op: We kunnen echter niet besluiten dat oudere personen een hoger risico hebben op aantasting van de lymfeknopen ten gevolge van hun leeftijd. Aangezien de studie een observationele studie is, kunnen de groepen patiënten met aangetaste lymfeknopen en niet-aangetaste lymfeknopen nog in andere karateristieken van elkaar verschillen. We kunnen dus enkel besluiten dat er een associatie is tussen de lymfeknoop status en de leeftijd. Het is dus niet noodzakelijkerwijs een causaal verband! Het is immers steeds moeilijk om causale verbanden te trekken op basis van observationele studies gezien confounding kan optreden. We hebben de patiënten immers niet kunnen randomiseren over de twee groepen, de lymfeknoopstatus werd niet geïnduceerd door de onderzoekers maar enkel geobserveerd en we kunnen daarom niet garanderen dat de patiënten enkel verschillen in de lymfeknoopstatus! Hetzelfde geldt voor het lineair model voor de \\(\\log_2\\)-S100A8-expressie. Aangezien we de ESR1-expressie niet experimenteel vast hebben kunnen leggen, kunnen we niet besluiten dat een hogere ESR1-expressie de S100A8-expressie doet verlagen. We hebben beide genexpressies enkel geobserveerd dus kunnen we alleen besluiten dat ze negatief geassocieerd zijn met elkaar. Om te evalueren of de expressie van een bepaald gen de expressie van ander genen beïnvloedt, gaat men vaak knockout constructen generenen in het labo, dat zijn mutanten die een bepaald gen niet tot expressie kunnen brengen. Wanneer de wild type (normale genotype) en de knockout dan onder identieke condities worden opgegroeid in het lab, weten onderzoekers dat verschillen in genexpressie worden geïnduceerd door de afwezigheid van de expressie van het knockout gen. Experimentele studies zijn immers essentieel om causale verbanden te kunnen trekken. Veronderstellingen: We moeten echter ook nog de veronderstellingen van het model voor de leeftijd nagaan! In Figuur 6.15 zien we geen afwijkingen van normaliteit in de QQ-plot. Er lijkt echter wel een aanwijzing dat de variantie in beide groepen verschillend is. De residuen lijken meer gespreid in de groep met lagere gemiddelde leeftijd (node=0) dan in de groep met een hogere gemiddelde leeftijd (node=1). Merk echter ook op dat er een verschil is in het aantal observaties in beide groepen. Wanneer we een boxplot maken, zoals we ook deden in het hoofdstuk 5 om gelijkheid van variantie na te gaan bij het uitvoeren van een t-test, zien we dat het verschil in interkwartiel afstand (IRQ, boxgrootes) niet zo groot is (Figuur 6.16). Als we data simuleren die \\(iid\\) normaal verdeeld zijn en deze at random opslitsen in twee groepen die gelijk zijn in grootte als die voor de lymfeknoop status (19 vs 13 patiënten) zien we dat een dergelijk verschil in IQR gerust kan voorkomen door toeval (Figuur 6.17). We kunnen dus besluiten dat aan alle aannames is voldaan voor de statistische besluitvorming en dat we de R-output van het statistisch model voor de response age i.f.v de dummy variabele voor de node-status mogen gebruiken om conclusies te formuleren over de associatie tussen leeftijd en node status (zie hoger). plot(age~node,borstkanker) Figuur 6.16: boxplot van de leeftijd vs lymfeknoop status in de borstkanker dataset. par(mfrow=c(3,3)) set.seed(354) for(i in 1:9) plot(rnorm(32)~node,borstkanker,ylab=&quot;iid N(0,1)&quot;) Figuur 6.17: Simulatie van normaal verdeelde gegevens met gelijk gemiddelde en variantie. Zoals in de borstkanker dataset zijn er 19 observaties in ene groep en 13 observaties in de andere groep. We zien dat er door puur toeval een behoorlijk verschil kan optreden in de IQR tussen beide groepen in de steekproef. Zoals we illustreerden is het steeds nuttig om simulaties te gebruiken om in te leren schatten wanneer de diagnostische plots duiden op een afwijking van de voorwaarden. References "],
["chap-anova.html", "Hoofdstuk 7 Variantie analyse 7.1 Inleiding 7.2 Variantie-analyse 7.3 Post hoc analyse: Meervoudig Vergelijken van Gemiddelden 7.4 Conclusies: Prostacycline Voorbeeld", " Hoofdstuk 7 Variantie analyse 7.1 Inleiding 7.1.1 Prostacycline voorbeeld Prostacycline is een lipide die een belangrijke rol speelt in vasodilatatie (bloedvatverwijding) en bloedstolling. Het inhibeert de activatie van bloedplaatjes en vermijdt de vorming van bloedklonters. Arachidonzuur speelt een belangrijke rol in de productieweg van prostacycline. Onderzoekers willen daarom bestuderen of het toedienen van arachidonzuur een effect heeft op het prostacycline niveau in het bloedplasma. Ze zetten hiervoor een proef op waarbij ze het effect van arachidonzuur zullen nagaan op het prostacycline niveau van ratten. Arachidonzuur wordt hierbij toegediend in drie verschillende concentraties (verklarende variabele met drie behandelingen): laag (L, 10 eenheden), gemiddeld (M, 25 eenheden) en een hoge dosis (H, 50 eenheden). Het prostacycline niveau in het bloedplasma wordt gemeten a.d.h.v. een gecalibreerde elisa fluorescentie meting (responsvariabele). Het experiment is een volledige gerandomiseerd proefopzet, “completely randomized design” CRD. In totaal worden 12 ratten (experimentele eenheden) at random toegekend aan elke behandelingsgroep. De data is opgeslagen in een tekst bestand met naam prostacyclin.txt in de folder dataset. Een boxplot en QQ-plots voor de data in elke groep worden weergegeven in Figuur 7.1. prostacyclin &lt;- read.table(&quot;dataset/prostacyclin.txt&quot;,header=TRUE,sep=&quot;\\t&quot;) #dosis wordt als continue covariaat ingelezen #zet om naar een factor. prostacyclin$dose &lt;- as.factor(prostacyclin$dose) par(mfrow=c(2,2)) #boxplot plot(prostac~dose,data=prostacyclin,xlab=&quot;Arachidonzuurdosis &quot;,ylab=&quot;Prostacycline (ng/ml)&quot;) #toevoegen van originele datapunten op de plot #jitter zal de punten random verspreiden #set seed om gekleurde volle bol pch=19 te zetten set.seed(10) stripchart(prostac~dose,data=prostacyclin, vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;), add = TRUE) #zelfde seed gebruiken zodat we op zelfde plek een #ronde open cirkel kunnen zetten zodat punt duidelijker is #pch =1, col=1 (kleur is zwart) set.seed(10) stripchart(prostac~dose,data=prostacyclin, vertical = TRUE, method = &quot;jitter&quot;, pch = 1, col =1, add = TRUE) #3 QQ plot via for loop, we lopen over de niveaus voor de prostacycline dosis for (i in levels(prostacyclin$dose)) with(subset(prostacyclin,dose==i),{qqnorm(prostac,ylim=c(0,max(prostacyclin$prostac)),main=paste(&quot;Dosis&quot;,i));qqline(prostac)}) Figuur 7.1: Data-exploratie van het prostacycline niveau bij 36 ratten die behandeld werden met drie verschillende arachidonzuurconcentraties (12 ratten per behandeling). Links boven: boxplots van prostacycline niveau in functie van de dosis, QQ-plot van prostacycline voor lage, matige en hoge dosisgroep worden respectievelijk rechtsboven, linksonder en rechtsonder weergegeven Figuur 7.1 geeft weer dat er een effect lijkt te zijn van de arachidonzuurdosis op de hoogte van het prostacycline niveau. In het bijzonder de hoge dosis lijkt het prostacycline niveau in het bloedplasma te laten toenemen. 7.1.2 Model Op basis van de boxplots in Figuur 7.1 zien we dat de variantie gelijk lijkt te zijn tussen de verschillende behandelingsgroepen. Er is een indicatie dat het gemiddeld prostacycline niveau verschilt tussen de behandelingsgroepen. In het bijzonder voor de hoge dosisgroep H (50 eenheden). Er zijn geen grote verschillen in de interkwartiel range (box-groottes). De QQ-plots in Figuur 7.1 tonen geen grote afwijkingen aan van Normaliteit. De QQ-plot geeft een indicatie dat mogelijks een outlier voorkomt in groep L. Deze wordt echter niet door de boxplots gesignaleerd. We kunnen dus volgend statistisch model voorop stellen: \\[Y_i \\vert \\text{groep j} \\sim N(\\mu_j,\\sigma^2),\\] met \\(j= \\text{1, 2, 3}\\), respectievelijk de lage, matige en hoge dosisgroep. Hierbij veronderstellen we dus dat de data Normaal verdeeld zijn met een gelijke variantie binnen elk van de \\(g=3\\) groepen, \\(\\sigma^2\\), maar met een verschillend groepsgemiddelde \\(\\mu_j\\). De onderzoeksvraag kan nu vertaald worden in termen van het model. De onderzoekers wensen aan te tonen dat het arachidonzuur niveau een effect heeft op de gemiddelde prostacycline concentratie in het bloed. Dat vertaalt zich in volgende nulhypothese, de arachidonzuurconcentratie heeft geen effect op het gemiddelde prostacycline niveau bij ratten, \\[H_0:\\mu_1=\\mu_2 = \\mu_3\\] en de alternatieve hypothese dat er een effect is van de arachidonzuurconcentratie op het gemiddelde prostacycline niveau bij ratten. Dat betekent dat minstens twee gemiddelden verschillend zijn \\[H_1: \\exists\\ j,k \\in \\{1,\\ldots,g\\} : \\mu_j\\neq\\mu_k.\\] Of letterlijk: er bestaat minstens één koppel behandelingsgroepen (j en k) waarvoor het gemiddelde prostacycline niveau \\(\\mu_j\\) verschillend is van dat in groep \\(k\\), \\(\\mu_k\\). Een naïeve benadering zou zijn om de nulhypothese op splitsen in partiële hypothesen \\[ H_{0jk}: \\mu_j=\\mu_k \\text{ versus } H_{1jk}: \\mu_j \\neq \\mu_k\\] Waarbij de gemiddelden tussen de groepen twee aan twee worden vergeleken. Met deze procedure zouden we elk van deze partiële hypothesen kunnen testen met een two-sample \\(t\\)-test. Dat zou echter leiden tot een probleem van meervoudig toetsen en een verlies aan power (zie verder). Voor dit voorbeeld zouden we met deze aanpak immers 3 t-testen moeten uitvoeren om de onderzoeksvraag te evalueren. In dit hoofdstuk zullen we methoden introduceren om \\(H_0:\\mu_1=\\mu_2=\\mu_3\\) vs \\(H_1: \\exists j,k \\in \\{1,\\ldots,g\\} : \\mu_j\\neq\\mu_k\\) te testen met één enkele test. De correcte oplossing voor het testprobleem waarbij we een continue response meten en wensen te detecteren of er een verschil is in gemiddelde response tussen meerdere groepen wordt een variantie-analyse of ANOVA (ANalysis Of VAriance) genoemd. 7.2 Variantie-analyse We leiden de methode af voor de meest eenvoudige uitbreiding met 3 groepen (prostacycline voorbeeld), maar de veralgemening naar g groepen met \\(g&gt;3\\) is triviaal. 7.2.1 Model Zoals bij de t-test kunnen we het probleem ook modelleren a.d.h.v een lineair model door gebruik te maken van dummy variabelen (Sectie 6.10). We zullen hierbij steeds 1 dummy variable minder nodig hebben dan er groepen zijn. Voor het prostacycline voorbeeld zijn dus twee dummy variabelen nodig en kunnen we de data dus modelleren met onderstaand lineair regressiemodel: Stel dat \\(Y_i\\) de uitkomst voorstelt van observatie \\(i\\) (\\(i=1,\\ldots, n\\)), dan beschouwen we \\[\\begin{eqnarray} Y_i &amp;=&amp; g(x_{i1},x_{i2}) + \\epsilon_i\\\\ Y_i &amp;=&amp; \\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2} +\\epsilon_i \\tag{7.1} \\end{eqnarray}\\] waarbij de error term opnieuw i.i.d.46 normaal verdeeld wordt verondersteld met een constante variantie, \\(\\epsilon_i\\sim N(0,\\sigma^2)\\), en waarbij de predictoren dummy-variabelen zijn: \\[x_{i1} = \\left\\{ \\begin{array}{ll} 1 &amp; \\text{ als observatie $i$ behoort tot middelste dosisgroep (M)} \\\\ 0 &amp; \\text{ als observatie $i$ behoort tot een andere dosisgroep} \\end{array}\\right. .\\] en \\[x_{i2} = \\left\\{ \\begin{array}{ll} 1 &amp; \\text{ als observatie $i$ behoort tot de hoogste dosisgroep (H)} \\\\ 0 &amp; \\text{ als observatie $i$ behoort tot een andere dosisgroep} \\end{array}\\right. .\\] De lage dosisgroep (L) met \\(x_{i1}=x_{i2}=0\\) wordt in deze context de referentiegroep genoemd. Zoals in Sectie 6.10 kunnen we het regressie-model opnieuw herschrijven als een model voor elke groep: Voor observaties in dosisgroep L wordt het Model (7.1) \\[Y_i = \\beta_0+\\epsilon_i,\\] met \\(\\epsilon_i \\sim N(0,\\sigma^2)\\). Voor observaties in dosisgroep M wordt het Model (7.1) \\[Y_i = \\beta_0+\\beta_1 + \\epsilon_i,\\] met \\(\\epsilon_i \\sim N(0,\\sigma^2)\\). Voor observaties in dosisgroep H wordt het Model (7.1) \\[Y_i = \\beta_0+\\beta_2 + \\epsilon_i\\] met \\(\\epsilon_i \\sim N(0,\\sigma^2)\\). Hieruit volgt direct de interpretatie van de modelparameters: \\[\\begin{eqnarray*} \\beta_0 &amp;=&amp; \\text{E}\\left[Y_i \\mid \\text{behandeling met lage dosisgroep L}\\right] \\\\ \\beta_1 &amp;=&amp; (\\beta_0+\\beta_1)-\\beta_0 = \\text{E}\\left[Y_i \\mid \\text{behandeling M}\\right] - \\text{E}\\left[Y_i \\mid \\text{behandeling L}\\right] \\\\ \\beta_2 &amp;=&amp; (\\beta_0+\\beta_2)-\\beta_0 = \\text{E}\\left[Y_i \\mid \\text{behandeling H}\\right]-\\text{E}\\left[Y_i \\mid \\text{behandeling L}\\right]. \\end{eqnarray*}\\] of anders geformuleerd: parameter \\(\\beta_0\\) is de gemiddelde uitkomst in de lage dosis groep L. Parameter \\(\\beta_1\\) is het effect (verschil in gemiddelde concentratie) van groep M t.o.v. groep L. Parameter \\(\\beta_2\\) is het effect van hoge dosis groep H t.o.v. groep L. We herformuleren de modellen gebruik makend van de \\(\\mu\\)-notaties: \\[\\begin{eqnarray*} Y_{i\\vert \\text{dose=L}} &amp;=&amp; \\beta_0+\\epsilon_i = \\mu_1+\\epsilon_i \\\\ Y_{i\\vert \\text{dose=M}} &amp;=&amp; \\beta_0+\\beta_1+ \\epsilon_i = \\mu_2+\\epsilon_i \\\\ Y_{i\\vert \\text{dose=H}} &amp;=&amp; \\beta_0+\\beta_2 + \\epsilon_i = \\mu_3+\\epsilon_i . \\end{eqnarray*}\\] met \\(\\epsilon_i \\sim N(0,\\sigma^2)\\) en met \\[ \\mu_j = \\text{E}\\left[Y_i \\mid \\text{behandelingsgroep } j\\right].\\] De oorspronkelijk nulhypothese \\(H_0:\\mu_1=\\mu_2=\\mu_3\\) kan equivalent geformuleerd worden als \\[H_0: \\beta_1=\\beta_2=0.\\] Gezien Model (7.1) een lineair regressiemodel is, kunnen de methoden van lineaire regressie gebruikt worden voor het schatten van de parameters en hun varianties, het opstellen van hypothesetesten en betrouwbaarheidsintervallen. Het testen van \\(H_0: \\beta_1=\\beta_2=0\\) gebeurt d.m.v. een \\(F\\)-test. Hiermee is bijna de volledige oplossing bekomen. Voor het prostacycline voorbeeld bekomen we het volgende model in het software pakket R: model1=lm(prostac~dose,data=prostacyclin) summary(model1) ## ## Call: ## lm(formula = prostac ~ dose, data = prostacyclin) ## ## Residuals: ## Min 1Q Median 3Q Max ## -35.167 -17.117 -4.958 17.927 41.133 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 40.108 6.150 6.521 2.10e-07 *** ## dose25 8.258 8.698 0.949 0.349 ## dose50 43.258 8.698 4.974 1.99e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.3 on 33 degrees of freedom ## Multiple R-squared: 0.458, Adjusted R-squared: 0.4252 ## F-statistic: 13.94 on 2 and 33 DF, p-value: 4.081e-05 We zien dat R eveneens de lage klasse (dose10) kiest als referentie-klasse aangezien er enkel een intercept voorkomt en parameters voor dose25 (M) en dose50 (H). De output laat dus onmiddellijk toe om het effect te vergelijken tussen de middelste en laagste dosisgroep en de hoogste en laagste dosisgroep a.d.h.v. twee t-testen. De volledige nulhypothese \\(H_0: \\beta_1=\\beta_2=0\\) kan worden geëvalueerd op basis van de F-test onderaan in de output. De p-waarde van de test geeft aan dat er een extreem significant effect is van de arachidonzuurconcentratie op het gemiddelde prostacycline niveau (\\(p&lt;&lt;0.001\\)). In de volgende Sectie tonen we dat de F-test opnieuw opgebouwd wordt d.m.v. kwadratensommen. 7.2.2 Kwadratensommen en Anova Net zoals bij enkelvoudige regressie (Sectie 6.9) kunnen we opnieuw de kwadratensom van de regressie gebruiken bij het opstellen van de F-test. De kwadratensom van de regressie \\[\\begin{eqnarray*} \\text{SSR}&amp;=&amp;\\sum\\limits_{i=1}^n (\\hat Y_{i} -\\bar Y)^2 \\end{eqnarray*}\\] kan nu worden herschreven als \\[\\begin{eqnarray*} \\text{SSR}&amp;=&amp;\\sum\\limits_{i=1}^n (\\hat Y_i -\\bar Y)^2\\\\ &amp;=&amp; \\sum\\limits_{i=1}^n (\\hat{g} (x_{i1},x_{i2}) - \\bar Y)^2\\\\ &amp;=&amp; \\sum\\limits_{i=1}^n (\\hat\\beta_0+\\hat\\beta_1x_{i1}+\\hat\\beta_2x_{i2}) - \\bar Y)^2\\\\ &amp;=&amp; \\sum\\limits_{i=1}^{n_1} (\\hat\\beta_0 - \\bar Y)^2 +\\sum\\limits_{i=1}^{n_2} (\\hat\\beta_0 + \\hat\\beta_1 - \\bar Y)^2+\\sum\\limits_{i=1}^{n_3} (\\hat\\beta_0 + \\hat\\beta_2 - \\bar Y)^2\\\\ &amp;=&amp; \\sum\\limits_{i=1}^{n_1} (\\bar Y_1- \\bar Y)^2 +\\sum\\limits_{i=1}^{n_2} (\\bar Y_2- \\bar Y)^2+\\sum\\limits_{i=1}^{n_3} (\\bar Y_3 - \\bar Y)^2\\\\ \\end{eqnarray*}\\] met \\(n_1\\), \\(n_2\\) en \\(n_3\\) het aantal observaties in elke groep (\\(n-1=n_2=n_3=12\\)). Net als in Sectie 6.9 is SSR een maat voor de afwijking tussen de predicties van het anova model (groepsgemiddelden) en het steekproefgemiddelde van de uitkomsten. Het kan opnieuw geïnterpreteerd worden als een maat voor de afwijking tussen het geschatte Model (7.1) en een gereduceerd model met enkel een intercept. Deze laatste is dus eigenlijk een schatting van het model \\(g(x_1,x_2)=\\beta_0\\), waarin \\(\\beta_0\\) geschat wordt door \\(\\bar{Y}\\). Anders geformuleerd: SSR meet de grootte van het behandelingseffect zodat \\(\\text{SSR} \\approx 0\\) duidt op de afwezigheid van het effect van de dummy variabelen en \\(\\text{SSR}&gt;0\\) duidt op een effect van de dummy variabelen. We voelen opnieuw aan dat \\(\\text{SSR}\\) zal kunnen worden gebruikt voor het ontwikkelen van een statistische test voor de evaluatie van het behandelingseffect. In de anova context heeft SSR \\(g-1=3-1=2\\) vrijheidsgraden: de kwadratensom is opgebouwd op basis van \\(g=3\\) groepsgemiddelden \\(\\bar Y_j\\) en we verliezen 1 vrijheidsgraad door de schatting van het algemeen steekproefgemiddelde \\(\\bar Y\\). Wanneer we SSR interpreteren als een verschil tussen twee modellen, bekomen we eveneens een verschil van \\(g-1=2\\) vrijheidsgraden: \\(g=3\\) model parameters in het volledige model (intercept voor referentie klasse en g-1 parameters voor elk van de dummies) en 1 parameter voor het gereduceerde model (enkel intercept). In een ANOVA setting is het gebruikelijk om de kwadratensom van de regressie te noteren als \\(\\text{SST}\\), de kwadratensom van de behandeling (treatment) of als SSBetween. De kwadratensom van de behandeling geeft inderdaad de variabiliteit weer tussen de groepen. Het meet immers de afwijkingen tussen de groepsgemiddelden \\(\\bar Y_j\\) en het steekproefgemiddelde \\(\\bar Y\\) (Zie Figuur 7.2). We kunnen eveneens opnieuw een overeenkomstige gemiddelde kwadratensom bekomen als \\[\\text{MST}=\\text{SST}/(g-1).\\] met het aantal groepen \\(g=3\\). #attach dataframe dan kunnen we variabele namen rechtstreeks gebruiken #zonder dataframe naam en $-teken attach(prostacyclin) #maak jitter zelf (variatie rond 1,2 en 3 jitIk=runif(36,-.2,.2)+rep(1:3,each=12) plot(prostac~dose,data=prostacyclin,xlab=&quot;Arachidonzuurdosis &quot;,ylab=&quot;Prostacycline (ng/ml)&quot;) cols=dose levels(cols)=c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;) points(jitIk,prostac,col=cols,pch=19) points(jitIk,prostac,col=4) points(1:3,predict(model1,data.frame(dose=factor(c(10,25,50)))),pch=17,col=c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;),cex=1.5) points(1:3,predict(model1,data.frame(dose=factor(c(10,25,50)))),pch=2,col=2,cex=1.5) abline(h=mean(prostac),lty=1) for (i in 1:3) lines(c(i-.2,i+.2),rep(predict(model1,data.frame(dose=levels(dose)[i])),2),col=c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;)[i],lwd=3) for (i in 1:36) lines(rep(jitIk[i],2),c(mean(prostac),model1$fitted[i]),col=2,lty=2) Figuur 7.2: Interpretatie van de kwadratensom van de behandeling (SST): de som van de kwadratische afwijkingen tussen de groepsgemiddelden (\\(\\bar Y_j\\)) en het steekproefgemiddelde van de uitkomsten (\\(\\bar Y\\)) detach(prostacyclin) Opnieuw kunnen we de totale kwadratensom SSTot ontbinden in \\[\\text{SSTot} = \\text{SST} + \\text{SSE}.\\] Waarbij SSTot opnieuw de totale variabiliteit voorstelt, met name de som van de kwadratische afwijking van de uitkomsten \\(Y_{i}\\) t.o.v. het algemeen gemiddelde prostacycline niveau \\(\\bar{Y}\\) en SSE de residuele variabiliteit of de som van de kwadratische afwijkingen tussen de observaties \\(Y_{i}\\) en de modelvoorspellingen (hier groepsgemiddelden) \\(\\hat{g}(x_{i1},x_{i2})=\\hat \\mu_j=\\bar Y_j\\). De interpretatie van de deze kwadratensommen worden weergegeven in Figuur 7.3. #attach dataframe dan kunnen we variabele namen rechtstreeks gebruiken #zonder dataframe naam en $-teken par(mfrow=c(1,2)) attach(prostacyclin) #maak jitter zelf (variatie rond 1,2 en 3 plot(prostac~dose,data=prostacyclin,xlab=&quot;Arachidonzuurdosis &quot;,ylab=&quot;Prostacycline (ng/ml)&quot;,main=&quot;SStot&quot;) points(jitIk,prostac,col=cols,pch=19) points(jitIk,prostac,col=4) points(1:3,predict(model1,data.frame(dose=factor(c(10,25,50)))),pch=17,col=c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;),cex=1.5) points(1:3,predict(model1,data.frame(dose=factor(c(10,25,50)))),pch=2,col=1,cex=1.5) abline(h=mean(prostac),lty=1) for (i in 1:36) lines(rep(jitIk[i],2),c(mean(prostac),prostac[i]),col=4,lty=2) plot(prostac~dose,data=prostacyclin,xlab=&quot;Arachidonzuurdosis &quot;,ylab=&quot;Prostacycline (ng/ml)&quot;,main=&quot;SSE&quot;) points(jitIk,prostac,col=cols,pch=19) points(jitIk,prostac,col=1) points(1:3,predict(model1,data.frame(dose=factor(c(10,25,50)))),pch=17,col=c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;),cex=1.5) points(1:3,predict(model1,data.frame(dose=factor(c(10,25,50)))),pch=2,col=2,cex=1.5) for (i in 1:3) lines(c(i-.2,i+.2),rep(predict(model1,data.frame(dose=levels(dose)[i])),2),col=c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;)[i],lwd=3) abline(h=mean(prostac),lty=1) for (i in 1:36) lines(rep(jitIk[i],2),c(prostac[i],model1$fitted[i]),col=1,lty=2) Figuur 7.3: Interpretatie van de totale kwadratensom (SSTot, som van de kwadratische afwijkingen tussen de uitkomsten \\(Y_{i}\\) en het steekproefgemiddelde van de uitkomsten \\(\\bar Y\\), links) en van residuele kwadratensom (SSE, som van de kwadratische afwijkingen tussen de uitkomsten \\(Y_{i}\\) en de groepsgemiddelden \\(\\bar Y_j\\), rechts) detach(prostacyclin) 7.2.3 Anova-test Het testen van \\(H_0: \\beta_1=\\ldots=\\beta_{g-1}=0\\) vs \\(H_1: \\exists k \\in\\{1,\\ldots,g-1\\} : \\beta_k \\neq0\\)47 kan d.m.v. onderstaande \\(F\\)-test. \\[F = \\frac{\\text{MST}}{\\text{MSE}}\\] met \\(\\text{MST}\\) de gemiddelde kwadratensom van de behandeling met \\(g-1\\) vrijheidsgraden en \\(\\text{MSE}\\) de gemiddelde residuele kwadratensom uit het niet-gereduceerde model (7.1), deze heeft \\(n-g\\) vrijheidsgraden (met het aantal groepen \\(g=3\\)). De teststatistiek vergelijkt dus variabiliteit verklaard door het model (MST) met de residuele variabiliteit (MSE) of met andere woorden vergelijkt het de variabiliteit tussen groepen (MST) met de variabiliteit binnen groepen (MSE). Grotere waarden voor de test-statistiek zijn minder waarschijnlijk onder de nulhypothese. Wanneer aan alle modelvoorwaarden is voldaan, dan volgt de statistiek onder de nulhypothese opnieuw een F-verdeling, \\(F \\sim F_{g-1,n-g}\\), met \\(g-1\\) vrijheidsgraden in de teller en \\(n-g\\) vrijheidsgraden in de noemer. 7.2.4 Anova Tabel De kwadratensommen en de F-test worden meestal in een zogenaamde variantie-analyse tabel of een anova tabel gerapporteerd. Df Sum Sq Mean Sq F value Pr(&gt;F) Treatment vrijheidsgraden SST SST MST F-statistiek p-waarde Error vrijheidsgraden SSE SSE MSE De anovatabel voor het prostacycline voorbeeld kan als volgt in de R-software worden bekomen anova(model1) ## Analysis of Variance Table ## ## Response: prostac ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dose 2 12658 6329.0 13.944 4.081e-05 *** ## Residuals 33 14979 453.9 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We kunnen dus opnieuw besluiten dat er een extreem significant effect is van de dosering van arachidonzuur op de gemiddelde prostacycline concentratie in het bloed bij ratten (\\(p&lt;&lt;0.001\\)). In Figuur 7.4 wordt de F-verdeling weergegeven samen met de kritische waarde op het 5% significantie niveau en de geobserveerde F-statistiek voor het prostacycline voorbeeld. grid &lt;- seq(0,17,.01) df1=anova(model1)[1,1] df2=anova(model1)[2,1] fval=anova(model1)[1,4] crit=qf(0.95,df1,df2) reject=c(crit,grid[which(grid&gt;crit)]) accept=c(grid[which(grid&lt;crit)],crit) plot(grid,df(grid,df1,df2),type=&quot;l&quot;,xlab=&quot;Density&quot;,ylab=&quot;F-statistic&quot;) polygon(c(0,accept,crit,0),c(0,df(accept,df1,df2),0,0),col=&quot;blue&quot;,border=&quot;blue&quot;) text(crit/2,.97,labels=&quot;aanvaard\\n95%&quot;,col=&quot;blue&quot;) polygon(c(crit,reject,15,crit),c(0,df(reject,df1,df2),0,0),col=&quot;red&quot;,border=&quot;red&quot;) abline(v=crit,col=&quot;red&quot;,lwd=2) text(crit+(fval-crit)/2,.97,labels=&quot;verwerp\\n5%&quot;,col=&quot;red&quot;) text(pos=4,crit,df(crit,2,33),labels=paste0(&quot;F(0.05,&quot;,df1,&quot;,&quot;,df2,&quot;)&quot;),col=&quot;red&quot;) text(pos=4,fval,df(crit,df1,df2),labels=paste0(&quot;f=&quot;,round(fval,1)),col=&quot;darkorange&quot;) abline(v=fval,col=&quot;darkorange&quot;,lwd=2,lty=2) text(15.5,.97,labels=paste0(&quot;p-value\\n&quot;,format(anova(model1)[1,5],digits=2)),col=&quot;darkorange&quot;) arrows(x0=17.5,x1=fval,y0=.9,y1=.9,col=&quot;darkorange&quot;) Figuur 7.4: Een F-verdeling met 2 vrijheidsgraden in de teller en 33 in de noemer. Het aanvaardingsgebied wordt weergegeven in blauw, de kritische waarde en de verwerpingsregio bij het \\(\\alpha=5\\%\\) niveau in rood, en, de geobserveerde f-waarde en de p-waarde worden in oranje. Voorbeelden van meerdere F-verdelingen met een verschillend aantal vrijheidsgraden in teller en noemer worden weergegeven in Figuur 7.5. plot(grid,df(grid,1,5),type=&quot;l&quot;,xlab=&quot;Density&quot;,ylab=&quot;F-statistic&quot;,xlim=c(0,5),ylim=c(0,1.5),lwd=2) lines(grid,df(grid,5,5),type=&quot;l&quot;,col=2,lwd=2) lines(grid,df(grid,10,30),type=&quot;l&quot;,col=3,lwd=2) lines(grid,df(grid,20,30),type=&quot;l&quot;,col=4,lwd=2) lines(grid,df(grid,50,50),type=&quot;l&quot;,col=5,lwd=2) legend(&quot;topright&quot;,lty=1,col=c(1,2,3,4,5),legend=c(&quot;F(1,5)&quot;,&quot;F(5,5)&quot;,&quot;F(10,30)&quot;,&quot;F(20,30)&quot;,&quot;F(50,50)&quot;),lwd=2) Figuur 7.5: Meerdere F-verdelingen met een verschillend aantal vrijheidsgraden in de teller en de noemer. 7.3 Post hoc analyse: Meervoudig Vergelijken van Gemiddelden 7.3.1 Naïeve methode In het eerste deel van dit hoofdstuk hebben we een \\(F\\)-test besproken die gebruikt kan worden voor het testen van \\[ H_0: \\mu_1=\\cdots = \\mu_g \\text{ versus } H_1: \\text{niet } H_0.\\] Dus als de nulhypothese verworpen wordt, dan wordt besloten dat er minstens twee gemiddelden verschillen van elkaar. De methode stelt ons echter niet in staat om te identificeren welke gemiddelden van elkaar verschillen. Een eerste, maar naïeve benadering van het probleem bestaat erin om de nulhypothese op te splitsen in partiële hypotheses \\[H_{0jk}: \\mu_j=\\mu_k \\text{ versus } H_{1jk}: \\mu_j \\neq \\mu_k\\] en deze partiële hypotheses te testen met two-sample \\(t\\)-testen. Voor het vergelijken van groep \\(j\\) met groep \\(k\\) wordt de klassieke two-sample \\(t\\)-test onder de veronderstelling van homoscedasticiteit gegeven door \\[T_{jk} = \\frac{\\bar{Y}_j-\\bar{Y}_k}{S_p\\sqrt{\\frac{1}{n_j}+\\frac{1}{n_k}}} \\sim t_{n-2}\\] waarin \\(S_p^2\\) de gepoolde variantieschatter is, \\[S_p^2 = \\frac{(n_j-1)S_j^2 + (n_k-1)S_k^2}{n_j+n_k-2}\\] met \\(S_j^2\\) en \\(S_k^2\\) de steekproefvarianties van respectievelijk de uitkomsten uit groep \\(j\\) en \\(k\\). In een ANOVA context wordt echter verondersteld dat in alle \\(g\\) groepen de variantie van de uitkomsten dezelfde is (de residuele variantie \\(\\sigma^2\\)). Indien we dus \\(S_p^2\\) gebruiken, dan is dit niet de meest efficiënte schatter omdat deze niet van alle data gebruik maakt48. We kunnen dus efficiëntie winnen door MSE te gebruiken. Ter herinnering, MSE kan geschreven worden als \\[\\text{MSE}= \\sum_{j=1}^g \\frac{(n_j-1)S_j^2}{n-g}.\\] De \\(t\\)-testen voor het twee-aan-twee vergelijken van alle gemiddelden worden dus best gebaseerd op \\[T_{jk} = \\frac{\\bar{Y}_j-\\bar{Y}_k}{\\text{MSE}\\sqrt{\\frac{1}{n_j}+\\frac{1}{n_k}}} \\sim t_{n-g}.\\] We zullen hier eerst demonstreren dat het werken met \\(m\\)-testen op het \\(\\alpha\\) significantieniveau een foute aanpak is die de kans op een type I fout niet onder controle kan houden. Dit zal aanleiding geven tot een meer algemene definitie van de type I fout. Alvorens de denkfout in de naïeve aanpak te demonsteren via simulaties, tonen we hoe de naïeve benadering in zijn werk zou gaan voor het prostacycline voorbeeld. with(prostacyclin,pairwise.t.test(prostac,dose,&quot;none&quot;)) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: prostac and dose ## ## 10 25 ## 25 0.34927 - ## 50 2e-05 0.00031 ## ## P value adjustment method: none Deze output toont de tweezijdige \\(p\\)-waarden voor het testen van alle partiële hypotheses. We zouden hier kunnen besluiten dat het gemiddelde prostacycline niveau extreem significant verschillend is tussen de hoge en de lage dosis groep en tussen de hoge en de matige dosis groep (beide \\(p&lt;&lt;0.001\\)). Verder is het gemiddelde prostacycline niveau niet significant verschillend is tussen de matige en de lage dosis groep. In onderstaande R code wordt een simulatiestudie opgezet (herhaalde steekproefname). We simuleren uit een ANOVA model met \\(g=3\\) groepen. De gemiddelden in het ANOVA model zijn gelijk aan elkaar, zodat de nulhypothese \\[H_0: \\mu_1=\\mu_2=\\mu_3\\] opgaat. Voor iedere gesimuleerde dataset zijn er \\(m=3\\) paarsgewijze two-sample \\(t\\)-testen Zodra minstens één van de \\(p\\)-waarden kleiner is dan het significantieniveau \\(\\alpha=5\\%\\), wordt de nulhypothese \\(H_0: \\mu_1=\\mu_2=\\mu_3\\) verworpen omdat er minstens twee gemiddelden verschillend zijn volgens de \\(t\\)-testen. We rapporteren de relatieve frequentie van het verwerpen van de globale nulhypothese, meer bepaald de kans op een type I fout van de test voor \\(H_0: \\mu_1=\\mu_2=\\mu_3\\). g&lt;-3 # aantal behandelingen (g=3) ni&lt;-12 # aantal herhalingen in iedere groep n&lt;-g*ni # totaal aantal observaties alpha&lt;-0.05 # significantieniveau van een individuele test N=10000 #aantal simulaties set.seed(302) #seed zodat resultaten exact geproduceerd kunnen worden trt=factor(rep(1:g,ni)) #factor cnt&lt;-0 #teller voor aantal foutieve verwerpingen for(i in 1:N) { if (i%%1000==0) cat(i,&quot;/&quot;,N,&quot;\\n&quot;) y &lt;- rnorm(n) tests&lt;-pairwise.t.test(y,trt,&quot;none&quot;) verwerp&lt;-min(tests$p.value,na.rm=T)&lt;alpha if(verwerp) cnt&lt;-cnt+1 } ## 1000 / 10000 ## 2000 / 10000 ## 3000 / 10000 ## 4000 / 10000 ## 5000 / 10000 ## 6000 / 10000 ## 7000 / 10000 ## 8000 / 10000 ## 9000 / 10000 ## 10000 / 10000 cnt/N ## [1] 0.1209 De simulatiestudie toont aan dat de kans op een type I fout gelijk is aan 12.1%, wat meer dan dubbel zo groot is dan de vooropgestelde \\(\\alpha=5\\%\\). Als we de simulatiestudie herhalen met \\(g=5\\) groepen (i.e. m=g(g-1)/2=10 paarsgewijze \\(t\\)-testen) dan vinden we \\(28.0\\%\\) in plaats van de gewenste \\(5\\%\\). Deze simulaties illustreren het probleem van multipliciteit (Engels: multiplicity): de klassieke \\(p\\)-waarden mogen enkel met het significantieniveau \\(\\alpha\\) vergeleken worden, indien het besluit op exact één \\(p\\)-waarde gebaseerd is. Hier wordt het finale besluit (aldanniet verwerpen van \\(H_0: \\mu_1=\\cdots =\\mu_g\\)) gebaseerd op \\(m=g\\times(g-1)/2\\) \\(p\\)-waarden, met \\(g\\) het aantal groepen. In de volgende sectie breiden we het begrip van type I fout uit en introduceren we enkele oplossingen om met multipliciteit om te gaan. 7.3.2 Family-wise error rate Wanneer \\(m&gt;1\\) toetsen worden aangewend om 1 beslissing te vormen, is het noodzakelijk te corrigeren voor het risico op vals positieve resultaten49. Meeste procedures voor meervoudig toetsen gaan ervan uit dat alle \\(m\\) nulhypotheses waar zijn. Er wordt dan geprobeerd om het risico op minstens 1 vals positief resultaat te controleren op experimentgewijs significantieniveau \\(\\alpha_E\\), typisch \\(\\alpha_E=0.05\\). In de engelstalige literatuur wordt het experimentgewijs significantieniveau family-wise error rate (FWER) genoemd. 7.3.2.1 Bonferroni correctie Bij het uitvoeren van \\(m\\) onafhankelijke toetsen met elk significantieniveau \\(\\alpha\\), is \\[\\begin{eqnarray*} \\alpha_E&amp;=&amp;\\text{P}[\\text{minstens 1 Type I fout}]\\\\ &amp;=&amp;1-(1-\\alpha)^m \\leq m\\alpha \\end{eqnarray*}\\] Als we 5 toetsen uitvoeren op het 5% significantieniveau is FWER \\(\\approx 25\\%\\). Door ze op het 1% significantieniveau uit te voeren, bekomen we FWER \\(\\approx 5\\%\\). De Bonferroni correctie houdt de FWER begrensd op \\(\\alpha_E\\) door \\[\\alpha=\\alpha_E/m\\] te kiezen voor het uitvoeren van de \\(m\\) paarsgewijze vergelijkingen. Als alternatieve methode kunnen we ook aangepaste p-waarden rapporteren zodat we deze met het experimentgewijze \\(\\alpha_E\\) niveau kunnen vergelijken: \\[\\tilde{p}=min(m\\times p,1)\\] \\((1-\\alpha_E/m)100\\%\\) betrouwbaarheidsintervallen rapporteren. Het gebruik van aangepaste p-waarden heeft als voordeel dat de lezer deze zelf kan interpreteren en hij/zij een maat kan geven voor de significantie op het experimentsgewijs significantie niveau. Merk op dat we de aangepaste p-waarden begrenzen op \\(\\tilde{p}=1\\) omdat p-waarden kansen zijn en steeds tussen 0 en 1 dienen te liggen. Onderstaande R code geeft de resultaten (gecorrigeerde \\(p\\)-waarden) na correctie met de methode van Bonferroni. with(prostacyclin,pairwise.t.test(prostac,dose, data = prostacyclin, p.adjust.method=&quot;bonferroni&quot;)) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: prostac and dose ## ## 10 25 ## 25 1.00000 - ## 50 6e-05 0.00094 ## ## P value adjustment method: bonferroni De conclusies blijven hetzelfde behalve dat de FWER nu gecontroleerd is \\(\\alpha=5\\%\\) en de \\(\\tilde{p}\\)-waarden een factor 3 groter zijn. Dezelfde analyse kan uitgevoerd worden met het multcomp R package dat speciaal werd ontwikkeld voor multipliciteit in lineaire modellen. library(multcomp) model1.mcp&lt;-glht(model1,linfct=mcp(dose=&quot;Tukey&quot;)) summary(model1.mcp,test=adjusted(&quot;bonferroni&quot;)) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = prostac ~ dose, data = prostacyclin) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 25 - 10 == 0 8.258 8.698 0.949 1.000000 ## 50 - 10 == 0 43.258 8.698 4.974 5.98e-05 *** ## 50 - 25 == 0 35.000 8.698 4.024 0.000943 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- bonferroni method) Om Bonferroni aangepaste betrouwbaarheidsintervallen te verkrijgen moeten we eerst zelf functie definiëren in R om bonferroni kritische waarde te bepalen. We noemen deze functie calpha_bon_t. calpha_bon_t&lt;-function(object,level) abs(qt((1-level)/2/nrow(object$linfct), object$df)) confint(model1.mcp,calpha=calpha_bon_t) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = prostac ~ dose, data = prostacyclin) ## ## Quantile = 2.5222 ## 95% confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## 25 - 10 == 0 8.2583 -13.6790 30.1957 ## 50 - 10 == 0 43.2583 21.3210 65.1957 ## 50 - 25 == 0 35.0000 13.0626 56.9374 We zullen nu het effect van de Bonferroni correctie opnieuw nagaan via simulaties. g&lt;-3 # aantal behandelingen (g=3) ni&lt;-12 # aantal herhalingen in iedere groep n&lt;-g*ni # totaal aantal observaties alpha&lt;-0.05 # significantieniveau van een individuele test N=10000 #aantal simulaties set.seed(302) #seed zodat resultaten exact geproduceerd kunnen worden trt=factor(rep(1:g,ni)) #factor cnt&lt;-0 #teller voor aantal foutieve verwerpingen for(i in 1:N) { if (i%%1000==0) cat(i,&quot;/&quot;,N,&quot;\\n&quot;) y &lt;- rnorm(n) tests&lt;-pairwise.t.test(y,trt,&quot;bonferroni&quot;) verwerp&lt;-min(tests$p.value,na.rm=T)&lt;alpha if(verwerp) cnt&lt;-cnt+1 } ## 1000 / 10000 ## 2000 / 10000 ## 3000 / 10000 ## 4000 / 10000 ## 5000 / 10000 ## 6000 / 10000 ## 7000 / 10000 ## 8000 / 10000 ## 9000 / 10000 ## 10000 / 10000 cnt/N ## [1] 0.0457 We vinden dus een FWER van 4.6% (een beetje conservatief). Wanneer we de simulaties doen voor \\(g=5\\) groepen, vinden we een FWER van \\(4.1\\%\\) (conservatiever). Door de Bonferroni correctie is de kans op minstens één vals positief resultaat \\(&lt; \\alpha_E\\). Hoewel de FWER wordt gecontroleerd door de Bonferroni methode, kan een verlies aan power worden verwacht aangezien het werkelijke niveau lager is dan het vooropgestelde 5% experimentsgewijs significantieniveau. 7.3.2.2 Methode van Tukey De methode van Tukey is een minder conservatieve methode voor het uitvoeren van post hoc testen. De implementatie benadert de nuldistributie van de posthoc test d.m.v. simulaties. De resultaten kunnen daarom lichtjes verschillen wanneer je de posthoc analyse opnieuw uitvoert. De details van de methode vallen buiten het bestek van deze cursus. Via de implementatie in het multcomp package kunnen we opnieuw aangepaste p-waarden verkrijgen en aangepaste betrouwbaarheidsintervallen voor alle \\(m\\) paarsgewijze testen. We hoeven zelf geen functies te definiëren voor het verkrijgen van Tukey gecorrigeerde BIs. model1.mcp&lt;-glht(model1,linfct=mcp(dose=&quot;Tukey&quot;)) summary(model1.mcp) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = prostac ~ dose, data = prostacyclin) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 25 - 10 == 0 8.258 8.698 0.949 0.613390 ## 50 - 10 == 0 43.258 8.698 4.974 &lt; 1e-04 *** ## 50 - 25 == 0 35.000 8.698 4.024 0.000835 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) confint(model1.mcp) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = prostac ~ dose, data = prostacyclin) ## ## Quantile = 2.4539 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## 25 - 10 == 0 8.2583 -13.0849 29.6016 ## 50 - 10 == 0 43.2583 21.9151 64.6016 ## 50 - 25 == 0 35.0000 13.6567 56.3433 Merk op dat de Tukey methode smallere BIs en kleinere aangepaste p-waarden teruggeeft dan Bonferroni en dus minder conservatief is. De betrouwbaarheidsintervallen kunnen ook grafisch worden weergegeven wat handig is als er veel vergelijkingen worden uitgevoerd (zie Figuur 7.6). plot(confint(model1.mcp)) Figuur 7.6: \\(95\\%\\) experimentsgewijze betrouwbaarheidsintervallen voor de paarsgewijze verschillen in gemiddeld prostacycline niveau tussen alle arachidonzuur dosisgroepen. De BIs zijn gecorrigeerd voor multipliciteit via de Tukey methode. Hierop zien we onmiddellijk dat het effect van de hoogste dosisgroep verschillend is van de laagste en middelste dosisgroep en dat er geen significant verschil is tussen de laagste en de middelste dosisgroep op het 5% experimentsgewijze significantieniveau. Tenslotte gaan we ook via simulatie na of de Tukey methode de FWER correct kan controleren. g&lt;-3 # aantal behandelingen (g=3) ni&lt;-12 # aantal herhalingen in iedere groep n&lt;-g*ni # totaal aantal observaties alpha&lt;-0.05 # significantieniveau van een individuele test N=10000 #aantal simulaties set.seed(302) #seed zodat resultaten exact geproduceerd kunnen worden trt=factor(rep(1:g,ni)) #factor cnt&lt;-0 #teller voor aantal foutieve verwerpingen for(i in 1:N) { if (i%%1000==0) cat(i,&quot;/&quot;,N,&quot;\\n&quot;) y &lt;- rnorm(n) m&lt;-lm(y~trt) m.mcp&lt;-glht(m,linfct=mcp(trt=&quot;Tukey&quot;)) tests&lt;-summary(m.mcp)$test verwerp&lt;-min(as.numeric(tests$pvalues),na.rm=T)&lt;alpha if(verwerp) cnt&lt;-cnt+1 } ## 1000 / 10000 ## 2000 / 10000 ## 3000 / 10000 ## 4000 / 10000 ## 5000 / 10000 ## 6000 / 10000 ## 7000 / 10000 ## 8000 / 10000 ## 9000 / 10000 ## 10000 / 10000 cnt/N ## [1] 0.0503 We vinden dus een FWER van \\(5.03\\%\\) wat heel dicht hij het nominale FWER\\(=5\\%\\) ligt. Voor \\(g=5\\) groepen, vinden we een FWER van \\(5.2\\%\\), wat ook vrij goed is.50 7.4 Conclusies: Prostacycline Voorbeeld We overlopen nog eens de volledige analyse voor het prostacycline voorbeeld. Merk op dat we steeds eerst een anova analyse doen voor posthoc testen worden uitgevoerd. De F-test heeft immers een hogere power voor het vinden van een effect van de behandelingen dan paarsgewijze t-testen omdat de F-test alle data gebruikt en voor deze test geen correctie voor multipliciteit nodig is om de algemene nulhypothese te evalueren. anova(model1) ## Analysis of Variance Table ## ## Response: prostac ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dose 2 12658 6329.0 13.944 4.081e-05 *** ## Residuals 33 14979 453.9 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(model1.mcp) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = prostac ~ dose, data = prostacyclin) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 25 - 10 == 0 8.258 8.698 0.949 0.613433 ## 50 - 10 == 0 43.258 8.698 4.974 &lt; 1e-04 *** ## 50 - 25 == 0 35.000 8.698 4.024 0.000922 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) confint(model1.mcp) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = prostac ~ dose, data = prostacyclin) ## ## Quantile = 2.4526 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## 25 - 10 == 0 8.2583 -13.0736 29.5902 ## 50 - 10 == 0 43.2583 21.9264 64.5902 ## 50 - 25 == 0 35.0000 13.6681 56.3319 We kunnen dus concluderen dan er een extreem significant effect is van de arachidonzuurdosering op de gemiddelde prostacycline concentratie in het bloed bij ratten (\\(p&lt;0.001\\)). De gemiddelde prostacycline concentratie is hoger bij de hoge arachidinezuur dosisgroep dan bij de lage en matige dosisgroep (beide \\(p&lt;0.001\\)). De gemiddelde prostacycline concentratie in de hoge dosis groep is respectievelijk 43.3ng/ml (95% BI [21.9,64.6]ng/ml) en 35ng/ml (95% BI [13.6,56.4]ng/ml) hoger dan in de lage en matige dosis groep. Het verschil in gemiddelde prostacycline concentratie tussen de matige en lage dosisgroep is niet significant (p=0.61, 95% BI op gemiddelde verschil [-13.1,29.6]ng/ml). (De p-waarden en betrouwbaarheidsintervallen van de post-hoc tests werden gecorrigeerd voor multipliciteit d.m.v. de Tukey methode). Merk op dat we eveneens niet significante resultaten vermelden. Het is namelijk belangrijk om eveneens negatieve resultaten te rapporteren! onafhankelijk en identiek verdeeld (i.i.d., independent and identically distributed)↩ Onder \\(H_1\\) bestaat er dus minimum 1 dummy-variabele in het model waarvoor de overeenkomstige parameter \\(\\beta_k\\) verschillend is van nul onder de alternatieve hypothese↩ maar enkel van de data in de twee groepen die getest worden↩ De nulhypothese onterecht verwerpen↩ theoretisch moet dit \\(5\\%\\) zijn, maar we tonen “slechts” het resultaat gebaseerd op 10000 simulaties↩ "],
["niet-parametrische-statistiek.html", "Hoofdstuk 8 Niet-parametrische statistiek 8.1 Inleiding 8.2 Vergelijken van twee groepen 8.3 Vergelijken van \\(g\\) Behandelingen", " Hoofdstuk 8 Niet-parametrische statistiek 8.1 Inleiding Alle methoden die in de vorige hoofdstukken behandeld werden, zijn zogenaamde parametrische methoden. Deze term duidt erop dat de geldigheid van de inferentie enkel correct is als er voldaan is aan parametrische veronderstellingen. Dit zijn voornamelijk de distributionele veronderstellingen, zoals dat de observaties normaal verdeeld zijn. Andere voorbeelden van een parametrische veronderstelling zijn de gelijkheid van varianties bij de two-sample \\(t\\)-test en ANOVA en de lineariteit van een regressiemodel. Wanneer we over statistische besluitvorming spreken, is bijvoorbeeld de \\(p\\)-waarde van een statistische test, of de probabilistische interpretatie van een betrouwbaarheidsinterval enkel correct interpreteerbaar onder bepaalde veronderstellingen: De \\(p\\)-waarde is de kans dat de teststatistiek \\(T\\) onder de nulhypothese meer extreem is dan de waargenomen waarde \\(t\\) (gegeven dat \\(H_0\\) waar is). Die kans wordt berekend op basis van de nuldistributie van \\(T\\). Deze distributie wordt bij parametrische testen afgeleid door te steunen op veronderstellingen over de verdeling van de observaties. Indien er niet voldaan is aan deze veronderstellingen, is de berekende \\(p\\)-waarde fout. Dit betekent dat de conclusies die op \\(p\\) gebaseerd worden, eveneens mogelijks fout kunnen zijn. De berekening van bv. een \\(95\\%\\) betrouwbaarheidsinterval steunt eveneens op distributionele veronderstellingen. Als er niet voldaan is aan de veronderstellingen, is er geen garantie meer dat de berekende intervallen de (correcte) interpretatie hebben dat dergelijke intervallen de juiste parameterwaarde omvatten met \\(95\\%\\) kans. Asymptotische theorie is misschien moeilijker te plaatsen onder parametrisch of niet-parametrisch. Je zou kunnen stellen dat bv. een \\(t\\)-test asymptotisch niet-parametrisch is, omdat bij erg grote steekproefgroottes de distributionele veronderstelling van normaliteit niet meer belangrijk is. De reden waarom we in deze cursus een focus hebben op parametrische methoden is omdat ze efficiënter en meer flexibel zijn wanneer er aan de voorwaarden voldaan is. Efficiëntie betekent dat bij een constante steekproefgrootte de testen een grotere power hebben en dat de betrouwbaarheidsintervallen smaller zijn. Met meer flexibel bedoelen we dat het eenvoudiger is om de methoden in te zetten voor experimenten met meer complexe designs. Als er niet voldaan is aan de veronderstellingen van de parameterische methoden kunnen we voor bepaalde designs overschakelen naar niet-parametrische methoden die in deze situatie nog steeds formeel geldig zijn. 8.2 Vergelijken van twee groepen 8.2.1 Cholestorol voorbeeld In een studie werd de cholestorolconcentratie in het bloed gemeten bij 5 patiënten (groep=1) die twee dagen geleden een hartaanval hadden en bij 5 gezonde personen (groep=2). De onderzoekers wensen na te gaan of de cholestorolconcentratie verschillend is bij hartpatiënten en gezonde personen. Boxplots van de data worden weergegeven in Figuur 8.1. chol &lt;- read.table(&quot;dataset/chol.txt&quot;,header=TRUE) chol$group &lt;- as.factor(chol$group) head(chol) ## group cholest ## 1 1 244 ## 2 1 206 ## 3 1 242 ## 4 1 278 ## 5 1 236 ## 6 2 188 boxplot(cholest~group,data=chol,ylab=&quot;cholestorol (mg/dl)&quot;,outline=FALSE,ylim=range(chol$cholest)) set.seed(10) stripchart(cholest~group,data=chol, vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;,&quot;coral&quot;), add = TRUE) set.seed(10) stripchart(cholest~group,data=chol, vertical = TRUE, method = &quot;jitter&quot;, pch = 1, add = TRUE) Figuur 8.1: Boxplot van de cholesterol concentratie in het bloed bij hartpatiënten (groep 1) en gezonde individuen (groep 2). nGroups=table(chol$group) n=sum(nGroups) De boxplots geven aan dat er mogelijks outliers in de data voorkomen. Het is moeilijk om inzicht te krijgen in de verdeling van de data gezien we maar 5 observaties hebben per groep. 8.2.2 Permutatietesten De vraagstelling van het cholestorol voorbeeld is geformuleerd in erg ruime bewoordingen en dit laat vrijheid in de vertaling ervan naar een nulhypothese. Laten we starten met een nulhypothese in termen van gemiddelden. Stel dat \\(\\mu_1\\) en \\(\\mu_2\\) de gemiddelde uitkomsten in behandelingsgroep 1 (hartpatiënten) en 2 (gezonde personen) voorstellen, dan zouden de hypotheses kunnen zijn: \\[H_0: \\mu_1=\\mu_2 \\text{ versus } H_1: \\mu_1\\neq \\mu_2.\\] Voor het testen van deze hypotheses kunnen we bijvoorbeeld gebruik maken van de two-sample \\(t\\)-test. We gaan de voorwaarden na: Normaliteit van de uitkomsten in de twee behandelingsgroepen. Met slechts 5 observaties in iedere groep, kan de veronderstelling niet nagegaan worden. Gelijkheid van varianties. Met slechts 5 observaties in iedere groep, kan de veronderstelling niet nagegaan worden. We kunnen dus de veronderstellingen van de two-sample \\(t\\)-test niet nagaan. We kunnen ook geen beroep doen op de asymptotische benadering omdat 5 observaties per groep te weinig is. Samengevat: de veronderstellingen van de \\(t\\)-test kunnen niet worden nagegaan en er zijn te weinig observaties om gebruik te kunnen maken van de asymptotische benadering. Aangezien het erg gevaarlijk is een statistische methode te gebruiken waarvan de voorwaarden niet nagegaan kunnen worden, is de klassieke \\(t\\)-test niet de geschikte methode. De oplossing die in dit hoofdstuk besproken wordt, zijn permutatietesten. Om deze te kunnen beschrijven, zullen we eerst de nulhypothese anders formuleren. 8.2.2.1 Hypothesen De oplossing die in deze sectie besproken wordt, zijn de permutatietesten. Om deze te kunnen beschrijven, zullen we eerst de nulhypothese anders formuleren. De veronderstelling voor de two-sample \\(t\\)-test kunnen we als volgt schrijven, met \\(Y_{1j}\\) en \\(Y_{2j}\\) de notatie voor de uitkomsten uit respectievelijk groep 1 en 2: \\[Y_{1j} \\text{ iid } N(\\mu_1,\\sigma^2) \\;\\;\\;\\text{ en }\\;\\;\\; Y_{2j} \\text{ iid } N(\\mu_2,\\sigma^2).\\] Onder \\(H_0:\\mu_1=\\mu_2\\), wordt dit (stel \\(\\mu=\\mu_1=\\mu_2\\) onder \\(H_0\\)) \\[ Y_{ij} \\text{ iid } N(\\mu,\\sigma^2),\\] wat uitdrukt dat alle \\(n=n_1+n_2\\) uitkomsten uit dezelfde normale distributie komen en onafhankelijk verdeeld zijn. Dit laat ons dus toe om de oorspronkelijke nulhypothese van de two-sample \\(t\\)-test anders te schrijven: \\[\\begin{equation} H_0: F_1(y) = F_2(y) \\text{ voor alle } y \\;\\;\\;\\text{ of }\\;\\;\\; H_0: f_1(y) = f_2(y) \\text{ voor alle } y \\tag{8.1} \\end{equation}\\] met \\(F_1\\) en \\(F_2\\) de distributiefuncties en \\(f_1\\) en \\(f_2\\) de densiteitfuncties van de verdeling van de uitkomsten in respectievelijk behandelingsgroep 1 en 2, en met de bijkomende veronderstelling dat \\(f_1\\) en \\(f_2\\) de distributiefuncties van Normale verdelingen zijn. Onder de alternatieve hypothese wordt een locatie-shift verondersteld: \\[H_1: f_1(y)=f_2(y-\\Delta) \\;\\;\\;\\text{ voor alle } y\\] met \\(\\Delta=\\mu_1-\\mu_2\\), verder hebben de Normale verdelingen dezelfde variantie. We illustreren dit in R voor \\(f_1\\sim N(0,1)\\) en \\(f_2\\sim N(1,1)\\) en \\(\\Delta=-1\\). mu1 &lt;- 0 sigma1 &lt;- 1 mu2 &lt;- 1 sigma2 &lt;- 1 y &lt;- -2:2 delta &lt;- mu1-mu2 delta ## [1] -1 dnorm(y,mu1,sigma1) ## [1] 0.05399097 0.24197072 0.39894228 0.24197072 0.05399097 dnorm(y-delta,mu2,sigma2) ## [1] 0.05399097 0.24197072 0.39894228 0.24197072 0.05399097 De permutatietesten die in de volgende sectie ontwikkeld worden, kunnen gebruikt worden voor het testen van de hypothese (8.1), maar dan zonder de Normaliteitsveronderstelling. We schrijven hypothese (8.1) verkort als \\[ H_0: F_1=F_2 \\;\\;\\;\\text{ of }\\;\\;\\; H_0:f_1=f_2. \\] Als de nulhypothese waar is, met name dat de verdelingen van de cholestorolconcentraties gelijk zijn voor hartpatiënten en gezonde personen, dan zijn de groep-labels van de 10 personen niet informatief. Gezien er geen verschil is in de verdeling tussen beide groepen is elke groepering immers irrelevant. We kunnen bijgevolg de verdeling van de test-statistiek onder de nulhypothese bekomen door de groepslabels \\(G\\) te permuteren. 8.2.2.2 Verdeling van de statistiek onder \\(H_0\\) In praktijk zijn er \\(m=\\binom{n_1+n_2}{n_1}=\\binom{n}{n_1}=\\binom{n}{n_2}\\) mogelijke unieke permutaties \\(\\cal{G}\\) van de groepslabels. Voor ons voorbeeld zijn dat er \\(m=\\) 252. Als \\(m\\) niet te groot is dan kunnen alle unieke permutaties van de groepslabels berekend worden. Voor iedere unique permutatie \\(g \\in \\cal{G}\\) wordt de teststatistiek \\(t^*_g\\) berekend51. We kunnen alle m=252 permutaties in R genereren a.d.h.v. de functie combn(n,n_1). Dit wordt geïllustreerd in de onderstaande R code: G=combn(n,nGroups[1]) dim(G) ## [1] 5 252 G[,1:10] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 1 1 1 1 1 1 1 1 1 ## [2,] 2 2 2 2 2 2 2 2 2 2 ## [3,] 3 3 3 3 3 3 3 3 3 3 ## [4,] 4 4 4 4 4 4 5 5 5 5 ## [5,] 5 6 7 8 9 10 6 7 8 9 De matrix G bevat voor elke permutatie de volgnummers van de observaties die tot de eerste groep zullen behoren. We tonen enkel de eerste 10 permutaties. We kunnen nu de teststatistiek berekenen voor de originele steekproef en voor elke permutatie #Originele test statistiek tOrig=t.test(cholest~group,chol)$statistic #bereken alle permutatiecombinaties en voer voor #elke combinantie een functie uit die de t-test statistiek #berekent voor de gepermuteerde groepslabels tStar=combn(n,nGroups[1], function(g,y=chol$cholest) t.test(y[g],y[-g])$statistic) head(tStar) ## [1] 3.6644253 1.6397911 2.3973923 1.5876250 1.9217173 0.9967105 length(tStar) ## [1] 252 Merk op dat y[g] de data selecteert met volgnummers g uit de vector y en y[-g] de data waarvoor de volgnummers niet tot g behoren. De vector tStar bevat de waarden van de teststatistiek \\(t^*_g\\) voor alle \\(g \\in {\\cal{G}}\\). We kunnen een frequentietabel van de teststatistiek verkrijgen en de unieke resultaten uitzetten in een plot of er een histogram van maken. tab=table(tStar) head(tab) ## tStar ## -4.17457930205164 -3.66442526456221 -3.14250320139171 -2.64368173056088 ## 1 1 1 1 ## -2.55798397117996 -2.39739232497298 ## 1 1 par(mfrow=c(2,1)) plot(table(tStar),xaxt=&quot;n&quot;,ylab=&quot;Frequency&quot;, xlab=expression(&quot;permutatiestatistiek t&quot;^&quot;*&quot;)) axis(1,at=seq(-4,4,1)) abline(v=tOrig,col=2,lwd=2) hist(tStar,ylab=&quot;Frequency&quot;, xlab=expression(&quot;permutatiestatistiek t&quot;^&quot;*&quot;)) abline(v=tOrig,col=2,lwd=2) Figuur 8.2: Exacte permutatie nuldistributie van de Welch t-test voor het cholestorol voorbeeld. Bovenaan histogram van elke mogelijke waarde voor de test-statistiek. Onderaan een gewoon histogram met balkbreedtes gelijk aan 1. De geobserveerde waarde voor de test-statistiek is aangeduid met een rode verticale lijn. De frequentietabel of het histogram (Figuur 8.2) bevat alle informatie voor de permutatienuldistributie van de two-sample \\(t\\)-teststatistiek voor de geobserveerde uitkomsten; merk op dat er 110 unieke waarden van de teststatistiek berekend zijn. Het histogram in Figuur 8.2 is de verdeling van de teststatistiek onder de nulhypothese. We zien eveneens dat de geobserveerde teststatistiek vrij extreem is. 8.2.2.3 p-waarde Nu we in staat zijn de permutatienuldistributie te berekenen, kunnen we hypothesetesten uitvoeren net als in de parametrische statistiek. Voor een permutatietest is de \\(p\\)-waarde voor de tweezijdige test (immers \\(H_1: \\mu_1 \\neq \\mu_2\\)) \\[p=\\text{P}_0\\left[\\vert T\\vert \\geq \\vert t\\vert \\mid \\mathbf{y}\\right].\\] Merk op dat deze p-waarde geconditioneerd is op de geobserveerde cholestorolwaarden die weergegeven worden in de vector \\(\\mathbf{y}=(y_{11},\\ldots,y_{51},y_{12},\\ldots,y_{52})^T\\). Aangezien de permutatienuldistrubutie van \\(T\\) bepaald wordt door \\(t^*_g\\), \\(g \\in{\\cal{G}}\\), berekenen we \\[p = \\text{P}_0\\left[\\left\\vert T\\right\\vert \\geq \\left\\vert t\\right\\vert \\mid \\mathbf{y}\\right] = \\frac{\\#\\{g\\in {\\cal{G}}: \\vert t^*_g\\vert \\geq \\vert t \\vert \\}}{m},\\] m.a.w. als de ratio van het aantal permutaties waarvoor de statistiek minstens even extreem is als de geobserveerde statistiek op het totaal aantal permutaties. In R kunnen we dit als volgt berekenen. pval=mean(abs(tStar)&gt;=abs(tOrig)) pval ## [1] 0.01587302 We vinden dus een \\(p\\)-waarde van 0.0159. Aangezien \\(p&lt;5\\%\\), besluiten we op het \\(5\\%\\) significantieniveau dat de distributies van de cholestorol concentraties niet gelijk zijn bij hartpatiënten en bij gezonde personen. De \\(p\\)-waarde die gevonden wordt via de permutatienuldistributie op basis van alle permutaties wordt een exacte \\(p\\)-waarde genoemd. De permutatienuldistributie wordt een exacte nuldistributie genoemd. De term exact betekent dat de resultaten correct zijn voor iedere steekproefgrootte \\(n\\). 8.2.2.4 Kritieke waarde Ook de kritieke waarde \\(c\\) voor de test op het \\(\\alpha\\) significantieniveau kan eenvoudig bekomen worden. \\[ \\text{P}_0\\left[\\vert T\\vert&gt; c \\mid \\mathbf{y}\\right] =\\alpha. \\] Gezien de discrete natuur van de permutatienuldistributie van \\(T\\), is het onwaarschijnlijk om een kritieke waarde te vinden zodat deze gelijkheid exact opgaat. Daarom zoeken we de kleinste waarde \\(c\\) zodat \\[ \\text{P}_0\\left[\\vert T\\vert&gt; c \\mid \\mathbf{y}\\right] \\leq \\alpha. \\] Dit impliceert dat een permutatietest mogelijks conservatief is, maar meestal is \\(m\\) voldoende groot zodat de kans op een type I fout (\\(\\text{P}_{0}\\left[ \\vert T \\vert &gt; c \\mid \\mathbf{y}\\right]\\)) erg dicht bij het nominale significantieniveau ligt. alpha&lt;-0.05 m &lt;- length(tStar) t.crit&lt;-sort(abs(tStar))[ceiling((1-alpha)*m)] t.crit ## [1] 2.179236 mean(abs(tStar)&gt;t.crit) ## [1] 0.04761905 De kans op een type I fout wordt dus gecontroleerd door een permutatietest, maar wel conditioneel op de geobserveerde uitkomsten data \\(\\mathbf{y}\\). We hebben steeds geconditioneerd op de observaties van de steekproef. We kunnen ons nu afvragen of we de conclusies kunnen veralgemenen naar de populatie toe? Het antwoord is ja, als de subjecten at random getrokken zijn uit de populatie. Het bewijs hiervan valt buiten het bestek van de cursus. Soms treedt er een praktisch probleem op omdat het aantal permutaties \\(m=\\#{\\cal{G}}\\) erg groot is. Enkele voorbeelden: \\(\\binom{20}{10}=\\) 184756, \\(\\binom{30}{15}=\\) 1.55e+08 en \\(\\binom{40}{20}=\\) 1.38e+11. Dus zelfs met slechts 40 observaties en een gebalanceerde proefopzet is het quasi onmogelijk om alle permutaties één voor één door te rekenen. De oplossing bestaat erin om niet alle \\(g \\in {\\cal{G}}\\) te beschouwen, maar slechts een beperkt aantal (bv. 10000 of 100000). We kunnen m.a.w. de nuldistributie benaderen door een groot aantal random permutaties uit te voeren. We illustreren dit principe voor ons voorbeeld waar we in alle permutaties door konden rekenen en de exacte p-waarde kennen. Merk op dat wanneer men een aantal random permutaties genereert de p-waarde lichtjes anders wordt berekend. Als men niet alle permutaties uitvoert, kan het dat de geobserveerde statistiek niet berekend wordt in de permutaties die worden beschouwd. Als de statistiek erg extreem is, dan kan het voorkomen dat de de statistiek groter is dan alle statistieken die in de permutaties werden berekend. Als we de p-waarde dan berekenen zoals voor de exacte p-waarde, dan kan het voorkomen dat de approximatieve p-waarde op basis van het aantal random permutatries gelijk is aan nul. Dat is theoretisch niet mogelijk omdat de geobserveerde waarde voor de teststatistiek ten minste 1 keer dient te worden behaald in de permutatiedistributie. Daarom wordt de p-waarde op basis van B willekeurige permutaties vaak berekend als \\[p=\\frac{\\#\\{\\vert t^*_g\\vert \\geq \\vert t \\vert \\}+1}{B+1},\\] zodat ze nooit nul wordt. set.seed(304) B=10000 tStar2=sapply(X=1:B, FUN=function(b,y,groep) {t.test(y~sample(groep))$statistic},y=chol$cholest,groep=chol$group) #een for lus is niet efficient mbt tot #geheugengebruik in R daarom gebruikt men beter #de sapply functie. # #argument X: een vector of lijst #over de welke men wil itereren. # #argument FUN: een functie die men wil uitvoeren op X. #Het argument die niet bepaald is in de functie wordt #vervangen door een element van X in elke iteratie. #De functie mag extra argumenten hebben. #Deze kunnen worden geinitialiseerd #door gebruik te maken van extra argumenten #in de sapply functie call. # #Argumenten van onze functie: #Hier staat X voor het aantal iteraties, #b: is iteratienummer, #y: extra argument met data, #groep: extra argument met groepsindictator. # #Wat doet onze functies? #Er wordt een t-test uitgevoerd na het permuteren van #de groepslabels sample(groep). #De t-statistic wordt teruggegeven. head(tStar2) ## t t t t t t ## 0.2574372 -0.1540545 -0.9967105 -0.7233167 -1.5876250 0.4322569 pval2=(sum(abs(tStar2)&gt;=mean(tOrig))+1)/(B+1) pval2 ## [1] 0.01409859 par(mfrow=c(2,1)) plot(table(tStar2),type=&quot;h&quot;,xaxt=&quot;n&quot;, xlab=expression(&quot;permutatiestatistiek t&quot;^&quot;*&quot;)) axis(1,at=-4:4) abline(v=tOrig,col=2,lwd=2) hist(tStar2, xlab=expression(&quot;permutatiestatistiek t&quot;^&quot;*&quot;)) abline(v=tOrig,col=2,lwd=2) Figuur 8.3: Approximatieve permutatie nulldistributie van de Welch t-test voor het cholestorol voorbeeld op basis van 10000 permutaties. De geobserveerde waarde voor de test-statistiek is aangeduid met een rode verticale lijn. We vinden een approximatieve \\(p\\)-waarde van 0.0141, wat niet ver verwijderd is van de exacte \\(p\\)-waarde (p=0.0159) die we eerder berekend hadden. Het histogram van de approximatieve permutatiedistributie is weergegeven in Figuur 8.3. 8.2.3 Rank Testen De ontwikkeling van rank testen startte in de eerste helft van de twintigste eeuw, maar ze vormen vandaag nog steeds de belangrijkste groep van niet-parametrische testen. Aanvankelijk hadden ze hun populariteit te danken aan het feit dat ze niet-parametrisch zijn en dat ze exacte \\(p\\)-waarden geven op basis van de permutatienuldistributie. In tegenstelling tot de test besproken in de vorige sectie, hebben rank testen geen nood aan het numeriek opstellen van de permutatienuldistributie voor iedere nieuwe dataset. De permutatienuldistributie van rank testen hangt alleen af van de steekproefgroottes. Bovendien zal blijken dat de testen erg robust zijn tegen uitschieters (Engels: outliers) en dat ze nuttig zijn als het locatie-shift model niet opgaat. Rank testen starten vanuit rank-getransformeerde uitkomsten. Definitie 8.1 (Rank) Beschouw \\(Y_1, \\ldots, Y_n\\). We veronderstellen voorlopig dat er geen twee gelijke observaties voorkomen (i.e. geen ties). De rank van observatie \\(Y_i\\) wordt dan gedefinieerd als \\[\\begin{equation*} R_i=R(Y_i) = \\#\\{Y_j: Y_j\\leq Y_i; j=1,\\ldots, n\\}. \\end{equation*}\\] De kleinste observatie krijgt dus rank 1, de tweede kleinste rank 2, enzovoort, en de grootste observatie, tenslotte, krijgt rank \\(n\\). Einde Definitie De rank transformatie wordt geïllustreerd op basis van het cholestorol voorbeeld. sort(chol$cholest) ## [1] 160 186 188 198 206 212 236 242 244 278 rank(sort(chol$cholest)) ## [1] 1 2 3 4 5 6 7 8 9 10 chol$cholest ## [1] 244 206 242 278 236 188 212 186 198 160 rank(chol$cholest) ## [1] 9 5 8 10 7 3 6 2 4 1 Soms komen ties voor in de data, i.e. minstens twee observaties hebben dezelfde numerieke waarde. Een klein voorbeeld: metTies=c(403,507,507,610,651,651,651,830,900) rank(metTies) ## [1] 1.0 2.5 2.5 4.0 6.0 6.0 6.0 8.0 9.0 De numerieke waarde 507 komt tweemaal voor en de numerieke waarde 651 komt driemaal voor. Dit zijn voorbeelden van ties. Wanneer ties voorkomen, wordt dikwijls de definitie van midranks toegepast voor de rank-transformatie. Definitie 8.2 (Midrank) Beschouw \\(Y_1, \\ldots, Y_n\\). De midrank van observatie \\(Y_i\\) wordt dan gedefinieerd als \\[\\begin{eqnarray*} R_i &amp;=&amp; \\frac{ \\#\\{Y_j: Y_j\\leq Y_i\\} + ( \\#\\{Y_j: Y_j &lt; Y_i\\} +1)}{2}. \\end{eqnarray*}\\] Einde Definitie In wat volgt hebben we dikwijls de ranks van de uitkomsten nodig in de gepoolde steekproef. Bijvoorbeeld: beschouw de uitkomsten \\(Y_{ij}\\), \\(i=1,\\ldots, n_j\\) en \\(j=1,2\\). Deze uitkomsten kunnen ook gerepresenteerd worden door \\(Z_1,\\ldots, Z_n\\) (\\(n=n_1+n_2\\)), de uitkomsten uit de gepoolde steekproef. chol ## group cholest ## 1 1 244 ## 2 1 206 ## 3 1 242 ## 4 1 278 ## 5 1 236 ## 6 2 188 ## 7 2 212 ## 8 2 186 ## 9 2 198 ## 10 2 160 z=chol$cholest z ## [1] 244 206 242 278 236 188 212 186 198 160 rank(z) ## [1] 9 5 8 10 7 3 6 2 4 1 8.2.4 Wilcoxon-Mann-Whitney Test De test werd gelijktijdig ontwikkeld door Wilcoxon en door Mann en Whitney. Om deze reden wordt de test dikwijls de Wilcoxon-Mann-Whitney (WMW) test genoemd. Soms wordt de test ook de Wilcoxon rank sum test of de Mann-Whitney U test genoemd. De test werd ontwikkeld voor het testen van de nulhypothese (8.1) tegenover het alternatief \\(H_1: \\mu_1\\neq \\mu_2\\) (of de eenzijdige versies). Eerst wordt er een distributionele veronderstelling gemaakt: het locatie-shift model, later relaxeren we deze aanname. Stel dat \\(Y_1\\) en \\(Y_2\\) uitkomsten zijn uit respectievelijk de eerste en tweede behandelingsgroep, met respectievelijke verdelingen \\(f_1\\) en \\(f_2\\). Het locatie-shift model geldt als er een \\(\\Delta\\) bestaat waarvoor geldt \\[ f_1(y)=f_2(y-\\Delta) \\;\\;\\;\\text{ voor alle } y. \\] Locatie-shift betekent dat \\(f_1\\) en \\(f_2\\) dezelfde vorm hebben, maar ze mogen over \\(\\Delta\\) verschoven zijn. De \\(\\Delta\\) uit de definitie heeft als interpretatie: \\(\\Delta = \\mu_1-\\mu_2\\). Door locatie-shift aan te nemen, zal het verwerpen van \\(H_0: f_1=f_2\\) de conclusie \\(\\mu_1\\neq \\mu_2\\) impliceren. De klassieke two-sample \\(t\\)-teststatistiek is gebouwd rond het verschil in steekproefgemiddelden \\(\\bar{Y}_1-\\bar{Y}_2\\). We beschouwen nu ook het verschil in steekproefgemiddelden, maar niet op basis van de oorspronkelijke uitkomsten, maar op basis van de rank-getransformeerde uitkomsten. De ranks zijn toegekend op basis van de gepoolde observaties (i.e. na samenvoegen van de uitkomsten uit groep 1 en groep 2); dus \\(R_{ij}=R(Y_{ij})\\) is de rank van uitkomst \\(Y_{ij}\\) in de gepoolde steekproef. Beschouw de teststatistiek \\[ T = \\frac{1}{n_1}\\sum_{i=1}^{n_1} R(Y_{i1}) - \\frac{1}{n_2}\\sum_{i=1}^{n_2} R(Y_{i2}) . \\] De statistiek vergelijkt dus de gemiddelde rank in groep 1 met de gemiddelde rank in groep 2. Dit is een zinvolle teststatistiek, want als \\(H_0\\) waar is, dan verwachten we dat de gemiddelde rank in de eerste groep ongeveer gelijk is aan de gemiddelde rank in de tweede groep en dus verwachten we dat \\(T\\) dicht bij nul ligt. als \\(H_1\\) waar is dan verwachten we dat de gemiddelde ranks zullen verschillen en dus dat \\(T\\) niet dicht bij nul zal liggen. Er kan echter worden aangetoond dat het volstaat het om \\[S_1=\\sum_{i=1}^{n_1} R(Y_{i1})\\] als teststatistiek te beschouwen. \\(S_1\\) is de som van de ranks van de observaties uit de eerste behandelingsgroep; dit verklaart de naam rank sum test. \\(S_1\\) en \\(S_2\\) bevatten immers dezelfde informatie en zijn gerelateerd via \\[ S_1+S_2 = \\text{som van alle ranks} = 1+2+\\cdots + n=\\frac{1}{2}n(n+1). \\] Nu we weten dat \\(S_1\\) (en \\(S_2\\)) een goede teststatistiek is, kan de permutatietestmethode toegepast worden om de exacte permutatienuldistributie op te stellen en de test uit te voeren. Voor een gegeven steekproefgrootte \\(n\\), en veronderstellend dat er geen ties zijn, nemen de rank-getransformeerde uitkomsten altijd de waarden \\(1, 2, \\ldots, n\\) aan. Voor gegeven groepsgroottes \\(n_1\\) en \\(n_2\\), zal de permutatienuldistributie dan ook steeds dezelfde zijn! In de vorige eeuw (tot ongeveer de jaren 1980) werd dit als een groot voordeel beschouwd omdat de nuldistributies voor gegeven \\(n_1\\) en \\(n_2\\) getabuleerd konden worden (belangrijke kwantielen werden als tabellen in boeken gepubliceerd zodat ze konden gebruikt worden voor het bepalen van kritische waarden en \\(p\\)-waarden), waardoor de gebruiker geen nood had aan zware rekencapaciteit. Vandaag de dag speelt dit argument niet meer mee, maar toch blijven de rank testen erg populair, maar dan wel om andere, heel belangrijke redenen. Niettegenstaande \\(S_1\\) en \\(S_2\\) perfect als teststatistieken gebruikt kunnen worden, wordt dikwijls gewerkt met de gestandaardiseerde teststatistiek \\[ T = \\frac{S_1-\\text{E}_{0}\\left[S_1\\right]}{\\sqrt{\\text{Var}_{0}\\left[S_1\\right]}}, \\] met \\(\\text{E}_{0}\\left[S_1\\right]\\) en \\(\\text{Var}_{0}\\left[S_1\\right]\\) de verwachtingswaarde en variantie van \\(S_1\\) onder \\(H_0\\). Dit zijn dus het gemiddelde en variantie van de permutatienuldistributie van \\(S_1\\). Onder \\(H_0\\) geldt \\[ \\text{E}_{0}\\left[S_1\\right]= \\frac{1}{2}n_1(n+1) \\;\\;\\;\\;\\text{ en }\\;\\;\\;\\; \\text{Var}_{0}\\left[S_1\\right]=\\frac{1}{12}n_1n_2(n+1). \\] Verder kan men onder \\(H_0\\) en als \\(\\min(n_1,n_2)\\rightarrow \\infty\\) opgaat aantonen dat, \\[ T = \\frac{S_1-\\text{E}_{0}\\left[S_1\\right]}{\\sqrt{\\text{Var}_{0}\\left[S_1\\right]}} \\rightarrow N(0,1). \\] Asymptotisch volgt de gestandaardiseerde teststatistiek dus een standaardnormaal verdeling. We illustreren de WMW test aan de hand van de R functie wilcox.test. wilcox.test(cholest~group,data=chol) ## ## Wilcoxon rank sum test ## ## data: cholest by group ## W = 24, p-value = 0.01587 ## alternative hypothesis: true location shift is not equal to 0 We zien dat we op basis van de test de nulhypothese kunnen verwerpen op het 5% significantie-niveau. De output geeft de teststatistiek \\(W=\\) 24. In volgende lijnen berekenen we \\(S_1\\) en \\(S_2\\) manueel voor de dataset. attach(chol) S1=sum(rank(cholest)[group==1]) S1 ## [1] 39 S2=sum(rank(cholest)[group==2]) S2 ## [1] 16 detach(chol) Waar komt \\(W=\\) 24 vandaan? Dit wordt zodadelijk toegelicht. De teststatistieken \\(S_1\\) en \\(S_2\\) werden voorgesteld door Wilcoxon, maar tezelfdertijd werd een equivalente test voorgesteld door Mann en Whitney. Hun teststatistiek wordt gegeven door52 \\[ U_1 = \\sum_{i=1}^{n_1}\\sum_{k=1}^{n_2} \\text{I}\\left\\{Y_{i1}\\geq Y_{k2}\\right\\}. \\] waarbij \\(\\text{I}\\left\\{.\\right\\}\\) een indicator is die 1 is als de uitdrukking waar is en 0 als dit niet het geval is. Er wordt voor elke observatie uit de eerste groep geteld hoeveel keer zij groter of gelijk is aan een observatie uit de tweede groep. We berekenen de Mann-Whitney statistiek nu manueel in R. y1=subset(chol,group==1)$cholest y2=subset(chol,group==2)$cholest u1Hlp=sapply(y1,function(y1i,y2) {y1i&gt;=y2},y2=y2) colnames(u1Hlp)=y1 rownames(u1Hlp)=y2 u1Hlp ## 244 206 242 278 236 ## 188 TRUE TRUE TRUE TRUE TRUE ## 212 TRUE FALSE TRUE TRUE TRUE ## 186 TRUE TRUE TRUE TRUE TRUE ## 198 TRUE TRUE TRUE TRUE TRUE ## 160 TRUE TRUE TRUE TRUE TRUE U1=sum(u1Hlp) U1 ## [1] 24 Er kan worden aangetoond dat \\[U_1 = S_1 - \\frac{1}{2}n_1(n_1+1).\\] S1-nGroups[1]*(nGroups[1]+1)/2 ## 1 ## 24 Hieruit concluderen we (1) dat \\(U_1\\) en \\(S_1\\) dezelfde informatie bevatten, (2) dat \\(U_1\\) ook een rankstatistiek is en dat exacte testen gebaseerd op \\(U_1\\) en \\(S_1\\) equivalent zijn. De statistiek \\(U_1\\) heeft als voordeel dat het een informatieve interpretatie heeft. Stel \\(Y_j\\) een willekeurige uitkomst uit behandelingsgroep \\(j\\) (\\(j=1,2\\)). Dan geldt \\[\\begin{eqnarray*} \\frac{1}{n_1n_2}\\text{E}\\left[U_1\\right] &amp;=&amp; \\text{P}\\left[Y_1 \\geq Y_2\\right]. \\end{eqnarray*}\\] Intuïtief voelen we dit aan: Op basis van de steekproef kunnen we die kans schatten door het gemiddelde te berekenen van alle indicator waarden \\(\\text{I}\\left\\{Y_{i1}\\geq Y_{k2}\\right\\}\\). We voerden inderdaad \\(n_1 \\times n_2\\) vergelijkingen uit. mean(u1Hlp) ## [1] 0.96 U1/(nGroups[1]*nGroups[2]) ## 1 ## 0.96 De kans \\(\\text{P}\\left[Y_1 \\geq Y_2\\right]\\) wordt een probabilistische index (Engels: probabilistic index) genoemd. Het is de kans dat een uitkomst uit de eerste groep groter of gelijk is dan een uitkomst uit de tweede groep. Als \\(H_0\\) waar is, dan is \\(\\text{P}\\left[Y_1 \\geq Y_2\\right]=\\frac{1}{2}\\). De gestandaardiseerde Mann-Whitney statistiek is \\[ T = \\frac{U_1 - \\frac{n_1n_2}{2}}{\\sqrt{\\frac{1}{12}n_1n_2(n+1)}}. \\] De R functie wilcox.test geeft niet de Wilcoxon rank sum statistiek, maar wel de Mann-Whitney statistiek \\(U_1\\). We weten echter dat exacte permutatietesten gebaseerd op \\(U_1\\), \\(U_2\\), \\(S_1\\) of \\(S_2\\) dezelfde resultaten geven. We bekijken nogmaals de output wTest=wilcox.test(cholest~group,data=chol) wTest ## ## Wilcoxon rank sum test ## ## data: cholest by group ## W = 24, p-value = 0.01587 ## alternative hypothesis: true location shift is not equal to 0 U1 ## [1] 24 probInd=wTest$statistic/prod(nGroups) probInd ## W ## 0.96 Aangezien \\(p=\\) 0.0159 \\(&lt;0.05\\) besluiten we op het \\(5\\%\\) significantieniveau dat de gemiddelde cholestorolconcentratie groter is bij hartpatiënten kort na een hartaanval dan bij gezonde personen. We nemen aan dat locatie-shift opgaat. Nu we weten hoe \\(U_1\\) berekend wordt, weten we ook meteen dat een cholestorolwaarde van hartpatiënten met een kans van \\(U1/(n_1\\times n_2)=\\) 96% groter is die van gezonde personen. Aangezien we het locatie-shift model veronderstellen, besluiten we ook dat de gemiddelde uitkomst uit de behandelingsgroep groter is dan de gemiddelde uitkomst uit de placebogroep. We zouden de veronderstelling van de locatie-shift moeten nagaan, maar met slechts 5 observaties in elke behandelingsgroep is dit zinloos. Zonder verder theorie hierover te geven, geven we nog mee dat zonder de locatie-shift veronderstelling de conclusie in termen van de probabilistische index correct blijft en de conclusie ook zo zou moeten worden geformuleerd. Dus wanneer we geen locatie-shift veronderstellen en een tweezijdige test uitvoeren testen we eigenlijk \\[H_0: F_1=F_2 \\text{ vs P}(Y_1 \\geq Y_2) \\neq 0.5.\\] 8.2.5 Conclusie Cholestorol Voorbeeld Er is een significant verschil in de distributie van de cholestorolconcentraties bij hartpatiënten 2 dagen na hun hartaanval en gezonde individuen (\\(p=\\) 0.0159). Het is meer waarschijnlijk om hogere cholestorolconcentraties te observeren bij hartpatiënten dan bij gezonde individuen. De puntschatting voor deze kans bedraagt 96%. 8.3 Vergelijken van \\(g\\) Behandelingen In deze sectie veralgemenen we de methoden uit de vorige sectie. De methoden kunnen ook gezien worden als niet-parametrische tegenhangers van de \\(F\\)-test uit een one-way ANOVA. 8.3.1 DMH Voorbeeld Nieuwe (en bestaande) chemische substaties moeten getest worden op genotoxiciteit. De resultaten van genotoxiciteitstesten vormen de basis voor risic0-analyses en de classificatie en labeling van chemische substanties in de EU (Dangerous Substances Directive 67/548/EEC and Regulation (EC) No. 1272/2008). In dat kader werd een studie met 24 ratten opgezet voor het testen van de genotoxiciteit van 1,2-dimethylhydrazine dihydrochloride (DMH). De ratten werden at random verdeeld over vier groepen die een verschillende dagelijkse DMH dosis kregen toegediend (controle, laag, medium, hoog). Na drie weken werden de dieren afgemaakt en werd genotoxiciteit van DMH in de lever bepaald a.d.h.v. een comet assay waarbij DNA strengbreuken worden gevisualiseerd via gel electroforese. De lengte van de comet staart is een proxy voor het aantal strengbreuken. De onderzoekers wensen na te gaan of er verschillen zijn in de DNA schade tengevolge van de DMH dosis. Boxplots van de data worden weergegeven in Figuur 8.4. dna &lt;- read.table(&quot;dataset/dna.txt&quot;,header=TRUE) dna$dose &lt;- as.factor(dna$dose) par(mfrow=c(1,2)) boxplot(length~dose,data=dna,ylab=&quot;lengte&quot;,xlab=&quot;dosis&quot;,outline=FALSE,ylim=range(dna$length)) set.seed(10) stripchart(length~dose,data=dna, vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;,&quot;purple&quot;), add = TRUE) set.seed(10) stripchart(length~dose,data=dna, vertical = TRUE, method = &quot;jitter&quot;, pch = 1, add = TRUE) boxplot(log(length)~dose,data=dna,ylab=&quot;log-lengte&quot;,xlab=&quot;dosis&quot;,outline=FALSE,ylim=range(log(dna$length))) set.seed(10) stripchart(log(length)~dose,data=dna, vertical = TRUE, method = &quot;jitter&quot;, pch = 19, col =c(&quot;bisque&quot;,&quot;coral&quot;,&quot;darkcyan&quot;,&quot;purple&quot;), add = TRUE) set.seed(10) stripchart(log(length)~dose,data=dna, vertical = TRUE, method = &quot;jitter&quot;, pch = 1, add = TRUE) Figuur 8.4: Boxplot van de comet staart lengte in functie van de DMH dosis. De boxplots lijken een indicatie te geven dat de controle groep een andere variabiliteit heeft. Merk wel op dat er slechts 6 observaties zijn per groep wat eigenlijk te weinig is om de aannames na te gaan. 8.3.2 Permutatietest Merk eerst op dat het one-way ANOVA model ook een locatie-shift impliceert. De distributies hebben opnieuw dezelfde vorm (normale verdeling met zelfde variantie) maar met een verschillend gemiddeld. Onder de veronderstellingen van het one-way ANOVA model kunnen we de nulhypothese net zoals bij de permutatie t-test algemener formuleren: \\[\\begin{equation*} H_0: f_1(y)=f_2(y) = \\ldots = f_t(y) \\text{ voor alle } y. \\end{equation*}\\] Nu veronderstellen we echter niet dat de densiteitsfuncties \\(f(y)\\) normale distributies zijn. Als we een locatie-shift model kunnen veronderstellen dan is de alternatieve hypothese analoog als bij de ANOVA test nl. \\[H_1: \\exists\\ j,k \\in \\{1,\\ldots,g\\} : \\mu_j\\neq\\mu_k.\\] We kunnen nu opnieuw de groepslabels permuteren om de nuldistributie van de test-statistiek te bekomen. Men kan aantonen dat er \\[m=\\frac{n!}{n_1!\\ldots n_g!}\\] unieke permutaties \\(\\cal{G}\\) bestaan. Voor ons voorbeeld zijn dat er \\(m=(24!)/(6!)^4=\\) 2.31e+12. De permutatienuldistributie wordt opnieuw opgesteld door de F-teststatistiek te berekenen voor iedere \\(g\\in \\cal{G}\\) of voor een willekeurige steekproef van permutaties uit \\(\\cal{G}\\). Hieronder wordt de R code gegeven voor het benaderen van de \\(p\\)-waarde op basis van 10000 willekeurige permutaties. set.seed(165) B=10000 fOrig=anova(lm(log(length)~dose,data=dna))$F[1] fStar=sapply(X=1:B, FUN=function(b,y,groep) {anova(lm(y~sample(groep)))$F[1]},y=log(dna$length),groep=dna$dose) pval=(sum(fStar&gt;=fOrig)+1)/(B+1) pval ## [1] 9.999e-05 hist(fStar,breaks=100) Figuur 8.5: Approximatieve permutatie nulldistributie van de F-statistiek voor het DMH voorbeeld op basis van 10000 permutaties. De geobserveerde waarde voor de F-statistiek is 367.76. De benaderde \\(p\\)-waarde is \\(p&lt;0.001\\), dus we besluiten dat het effect van de dosis van DMH op DNA beschadiging in levercellen van ratten extreem significant is. Via een posthoc analyse zouden we de groepen paarsgewijs met elkaar kunnen vergelijken. Merk op, dat als het locatie-shift model niet opgaat, het moeilijk is om inzicht te krijgen in de precieze alternatieve hypothese van de toets. De verdelingen hebben dan een andere vorm. Vandaar dat we geen formele conclusie formuleren voor dit voorbeeld. 8.3.3 Kruskal-Wallis Rank Test De Kruskal-Wallis Rank Test (KW-test) is een niet-parameterisch alternatief voor de ANOVA F-test. De klassieke \\(F\\)-teststatistiek kan geschreven worden als \\[ F = \\frac{\\text{SST}/(g-1)}{\\text{SSE}/(n-g)} = \\frac{\\text{SST}/(g-1)}{(\\text{SSTot}-\\text{SST})/(n-g)} , \\] met \\(g\\) het aantal groepen. Merk op dat SSTot enkel afhangt van de uitkomsten \\(\\mathbf{y}\\) en niet zal variëren bij permutaties. Het is dus eigenlijk voldoende om SST als teststatistiek te gebruiken. Ter herinnering: \\(\\text{SST}=\\sum_{j=1}^t n_j(\\bar{Y}_j-\\bar{Y})^2\\). De KW teststatistiek maakt gebruik van SST maar dan gebaseerd op de rank-getransformeerde uitkomsten53, \\[ \\text{SST} = \\sum_{j=1}^g n_j \\left(\\bar{R}_j - \\bar{R}\\right)^2 = \\sum_{j=1}^g n_j \\left(\\bar{R}_j - \\frac{n+1}{2}\\right)^2 , \\] met \\(\\bar{R}_j\\) het gemiddelde van de ranks in behandelingsgroep \\(j\\), en \\(\\bar{R}\\) het gemiddelde van alle ranks, \\[ \\bar{R} = \\frac{1}{n}(1+2+\\cdots + n) = \\frac{1}{n}\\frac{1}{2}n(n+1) = \\frac{n+1}{2}. \\] De KW teststatistiek wordt gegeven door \\[ KW = \\frac{12}{n(n+1)} \\sum_{j=1}^g n_j \\left(\\bar{R}_j - \\frac{n+1}{2}\\right)^2. \\] De factor \\(\\frac{12}{n(n+1)}\\) zorgt ervoor dat \\(KW\\) een eenvoudige asymptotische nuldistributie heeft. In het bijzonder, onder \\(H_0\\), als \\(\\min(n_1,\\ldots, n_g)\\rightarrow \\infty\\), \\[ KW \\rightarrow \\chi^2_{t-1}. \\] De exacte KW-test kan uitgevoerd worden via de berekening van de permutatienuldistributie (die enkel afhangt van \\(n_1, \\ldots, n_g\\)) voor het testen van \\[H_0: f_1=\\ldots=f_g \\text{ vs } H_1: \\text{ minstens twee gemiddelden verschillend}.\\] Om toe te laten dat \\(H_1\\) geformuleerd is in termen van gemiddelden, moet locatie-shift verondersteld worden. Indien locatie-shift niet opgaat, zou \\(H_1\\) eigenlijk geformuleerd moeten worden in termen van probabilistische indexen: \\[H_0: f_1=\\ldots=f_g \\text{ vs } H_1: \\exists\\ j,k \\in \\{1,\\ldots,g\\} : \\text{P}\\left[Y_j\\geq Y_k\\right]\\neq 0.5\\] 8.3.3.1 DNA Schade Voorbeeld Eerst analyseren we de data met de R functie kruskal.test kruskal.test(length~dose,data=dna) ## ## Kruskal-Wallis rank sum test ## ## data: length by dose ## Kruskal-Wallis chi-squared = 14, df = 3, p-value = 0.002905 De waarde van de KW teststatistiek is 14, met een \\(p\\)-waarde van 0.00291. Dus op het \\(5\\%\\) significantieniveau kan de nulhypothese worden verworpen. Het is belangrijk om op te merken dat de R-functie kruskal.test steeds de asymptotische benadering gebruikt voor de berekening van de \\(p\\)-waarden. Met slechts 6 observaties per groep, is dit geen optimale benadering van de exacte \\(p\\)-waarde! Met de coin R package kunnen we de exacte \\(p\\)-waarde wel berekenen via het argument distribution='exact'of benaderen a.d.h.v. simulaties distribution=approximate(B=100000), waarbij B het aantal permutaties is. library(coin) kwPerm &lt;- kruskal_test(length~dose,data=dna, distribution=approximate(B=100000)) kwPerm ## ## Approximative Kruskal-Wallis Test ## ## data: length by dose (0, 1.25, 2.5, 5) ## chi-squared = 14, p-value = 0.00036 We kunnen besluiten dat er een extreem significant verschil is in distributie van de DNA schade ten gevolge van de dosis. We voeren nu verdere posthoc testen uit voor alle paarsgewijse verschillen a.d.h.v WMW testen. pairWilcox &lt;- pairwise.wilcox.test(dna$length,dna$dose) pairWilcox ## ## Pairwise comparisons using Wilcoxon rank sum test ## ## data: dna$length and dna$dose ## ## 0 1.25 2.5 ## 1.25 0.013 - - ## 2.5 0.013 0.818 - ## 5 0.013 0.721 0.788 ## ## P value adjustment method: holm De output geeft pairsgewijze p-waarden weer voor elke vergelijking. De output wordt in een matrix geordend. De p-waarde voor elk element van de matrix behoort tot de paarsgewijze vergelijking van de groep in de kolom en de groep in de rij. Standaard wordt de Holm multiple testing methode gebruikt. Dat is een variant van Bonferroni die minder conservatief is. We zien dat alle DMH behandelingen significant verschillen van de controle. Maar er is geen significant verschil in de distributie van de DNA schade tussen de verschillende dosisgroepen waarbij DMH werd toegediend. Om een puntschatter op de kans op hogere DNA-schade te berekenen voor de vergelijkingen tussen de behandelingen met DMH en de controle zouden we ook de statistieken U1 nodig hebben. Dit kunnen we niet bekomen uit de pairwise.wilcox.test output. Hiervoor zullen we de individuele wilcoxon testen aan moeten roepen. nGroep &lt;- table(dna$dose) probInd &lt;- combn(levels(dna$dose),2,function(x) wilcox.test(length~dose,subset(dna,dose%in%x))$statistic/prod(nGroep[x])) names(probInd) &lt;- combn(levels(dna$dose),2,paste,collapse=&quot;vs&quot;) probInd ## 0vs1.25 0vs2.5 0vs5 1.25vs2.5 1.25vs5 2.5vs5 ## 0.0000000 0.0000000 0.0000000 0.4444444 0.2777778 0.3333333 Omdat er twijfels zijn of het locatie-shift model geldig is, doen we enkel uitspraken in termen van de probabilistische index. We besluiten dat er extreem significant verschil is in de distributie van de DNA-schade metingen tengevolge van de DMH behandeling (\\(p&lt;0.001\\) KW-test). DNA-schade is meer waarschijnlijk na behandeling met DMH dan in de controle behandeling (alle p=0.013, WMW-testen). De kansen op hogere DNA-schade na blootstelling aan DMH bedraagt 100%54. Er zijn geen significante verschillen in de distributies van de comit-lengtes tussen de DMH behandelingen onderling (\\(p=\\) 0.72-0.82). DMH vertoont dus al bij de lage dosis genotoxische effecten. (Alle paarsgewijze testen werden gecorrigeerd voor multiple testing d.m.v. Holm’s methode). in ons geval de t-test statistiek door de originele reponses te gebruiken die nu gekoppeld worden aan de gepermuteerde groepslabels \\(G_g^*\\)↩ in de afwezigheid van ties↩ we veronderstellen afwezigheid van ties↩ Het berekenen van een BI op deze kansen valt buiten het bestek van de cursus↩ "],
["chap-categorisch.html", "Hoofdstuk 9 Categorische data analyse 9.1 Inleiding 9.2 Toetsen voor een proportie 9.3 Toets voor associatie tussen 2 kwalitatieve variabelen 9.4 Logistische regressie", " Hoofdstuk 9 Categorische data analyse 9.1 Inleiding Tot nog toe zijn we hoofdzakelijk ingegaan op het modelleren van een continue uitkomst a.d.h.v. een categorische of continue predictor. In dit hoofdstuk onderzoeken we hoe we tot besluitvorming kunnen komen voor een categorische uitkomst. We zullen hierbij focussen op de associatie tussen een categorische uitkomst en een categorische predictor. Zoals we in Sectie 4.6.1 hebben gezien zijn kruistabellen aangewezen om hun associatie voor te stellen. 9.2 Toetsen voor een proportie In Saksen werd een studie opgezet binnen een vrij gesloten populatie mensen (weinig immigratie en emigratie) om te bepalen hoe waarschijnlijk het was dat een ongeboren kind mannelijk is. boys &lt;- 3175 n &lt;- 6155 Op 6155 ongeboren kinderen werden 3175 jongens geobserveerd. We wensen na te gaan of er een verschil is in de kans dat het ongeboren kind een jongen is of een meisje. In het vervolg van deze sectie vatten we deze gegevens op als uitkomsten van een numerieke toevalsveranderlijke \\(X\\) met uitkomst 1 voor jongens en 0 voor meisjes. Merk op dat we hier met een zogenaamd telprobleem te maken hebben omdat de uitkomst een telling (nl. het aantal jongens) voorstelt. Formeel hebben we nu een populatie van ongeboren kinderen beschouwd waarin elk individu gekenmerkt wordt door een 0 of een 1. De uitkomst variabele is dus binair. Binaire data kan worden gemodelleerd a.d.h.v. een Bernoulli verdeling: \\[X_i \\sim B(\\pi) \\text{ met}\\] \\[B(\\pi)=\\pi^{X_i}(1-\\pi)^{(1-X_i)},\\] een distributie met 1 model parameter \\(\\pi\\). \\(\\pi\\) is de verwachte waarde van \\(X_i\\): \\[\\text{E}[X_i]=\\pi,\\] de proportie van ongeboren jongens (d.i. kinderen met een 1) in de populatie. Bijgevolg is \\(\\pi\\) ook de kans dat een lukraak getrokken individu een jongen is (een observatie die 1 oplevert). De variantie van Bernoulli data is eveneens gerelateerd aan de kans \\(\\pi\\). \\[\\text{Var}[X_i]=\\pi (1-\\pi).\\] Een grafische weergave van enkele Bernoulli kansverdelingen wordt weergegeven in Figuur 9.1. par(mfrow=c(1,3)) probs=c(0.25,.5,.75) for (i in 1:length(probs)) { plot(c(0,1),c(1-probs[i],probs[i]),ylim=c(0,1),type=&quot;h&quot;,xaxt=&quot;n&quot;,xlab=&quot;X&quot;,ylab=&quot;Kans (Dichtheid)&quot;,main= as.expression(substitute(pi == val,list(val=probs[i]))),lwd=3) axis(1,at=c(0,1)) } Figuur 9.1: Bernoulli verdelingen. In het voorbeeld werden lukraak 6155 observaties getrokken uit de populatie. We kunnen \\(\\pi\\) schatten op basis van de data d.m.v. het steekproefgemiddelde van de binaire data: \\[\\hat \\pi = \\bar X = \\frac{\\sum\\limits_{i=1}^n X_i}{n},\\] pi=boys/n pi ## [1] 0.5158408 In ons voorbeeld is \\(\\bar x =\\) 3175 / 6155 = 51.6%. 9.2.1 Binomiale test De vraag stelt zich nu of het feit dat 51.6% van de kinderen in de studie mannelijk zijn, voldoende overtuigingskracht draagt om te beweren dat er meer kans is dat een ongeboren kind een jongen is dan een meisje. Met andere woorden, we wensen op basis van deze observaties statistisch te toetsen of de kans \\(\\pi\\) al dan niet gelijk is aan 50%. Om een toets te kunnen construeren van de nulhypothese dat \\[H_0: \\pi=1/2 \\text{ versus } H_1: \\pi\\neq 1/2,\\] moeten we de verdeling van de gegevens \\(X\\) en van de proportie \\(\\bar X\\) (of equivalent de som \\(S=n\\bar X\\)) kennen. Stel dat het voorkomen van jongens en meisjes in de populatie even waarschijnlijk zijn; m.a.w. stel dat de nulhypothese waar is. Bij lukrake trekking van één individu uit de populatie is de kans dat men een jongen observeert dan gelijk aan \\(P(X=1) = \\pi = 1/2.\\) Als twee kinderen onafhankelijk van elkaar getrokken worden (en de populatie is bij benadering oneindig groot) dan heeft zowel het eerste als het tweede kind kans 1/2 om mannelijk te zijn (onafhankelijk van elkaar). De uitkomsten \\((x_1, x_2)\\) voor beide kinderen hebben dan 4 mogelijke waarden: \\((0,0), (0,1),(1,0)\\) en \\((1,1).\\) Deze komen elk voor met kans \\(1/4 = 1/2 \\times 1/2\\). Bijgevolg kan de toevalsveranderlijke \\(S\\) die de som van de uitkomsten weergeeft, de volgende waarden aannemen: \\((x_1,x_2)\\) \\(s\\) \\(P(S = s)\\) (0,0) 0 1/4 (0,1), (1,0) 1 1/2 (1,1) 2 1/4 In het algemeen, als men \\(n\\) onafhankelijke observaties trekt telkens met kans \\(\\pi\\) op “succes” (uitkomst 1), dan kan het totaal aantal successen \\(S\\) (of de som van alle 1-en), \\(n+1\\) mogelijke waarden hebben. Men kan aantonen dat elke waarde \\(k\\) tussen 0 en \\(n\\) dan de volgende kans op voorkomen heeft: \\[\\begin{equation} P(S=k) = \\left ( \\begin{array}{c} n \\\\ k \\\\ \\end{array} \\right ) \\pi^k (1-\\pi)^{n-k} \\tag{9.1} \\end{equation}\\] waarbij \\(1-\\pi\\) de kans is op mislukking in 1 enkele trekking (uitkomst met 0 genoteerd) en \\(\\left(\\begin{array}{c} n \\\\ k \\\\ \\end{array}\\right)\\) de binomiaalcoëfficient55 \\[\\begin{equation*} \\left ( \\begin{array}{c} n \\\\ k \\\\ \\end{array} \\right ) = \\frac{n \\times (n-1) \\times ...\\times (n-k+1) }{ k!} = \\frac{ n!}{ k!(n-k)! } \\end{equation*}\\] is, waarbij \\(0!=1!=1\\). In R kan je die kansen opvragen met behulp van het commando dbinom(k,n,p). Een toevalsveranderlijke \\(S\\) met een kansverdeling zoals in Model (9.1) noemt men een Binomiaal verdeelde toevalsveranderlijke. De bijhorende kansverdeling is de Binomiale kansverdeling met parameters \\(n\\) (d.i. het aantal trekkingen of, equivalent, de maximale uitkomstwaarde) en \\(\\pi\\) (de kans op een `succes’ bij elke trekking). Ze kan gebruikt worden om te berekenen wat de kans is dat er zich op een vast totaal van \\(n\\) onafhankelijke experimenten \\(k\\) gebeurtenissen van een bepaald type voordoen, als je weet dat de kans dat zich 1 zo’n gebeurtenis voordoet op 1 experiment, \\(\\pi\\) bedraagt. De Binomiale kansverdeling wordt vooral gebruikt voor de analyse van gegevens die slechts 2 mogelijke waarden kunnen aannemen. Dergelijke gegevens komen vaak voor in wetenschappelijk onderzoek (bijvoorbeeld: al dan niet besmet met HIV, wild type van een gen vs een mutant,…). Kennis van de Binomiale verdeling kan dan helpen om proporties of risico’s op een gebeurtenis van een bepaald type te vergelijken tussen verschillende groepen. Een grafische weergave van enkele Binomiale kansverdelingen is gegeven in Figuur 9.2. par(mfrow=c(2,2)) probs=c(0.25,.5,.75) for (i in 1:length(probs)) { plot(0:10,dbinom(0:10,prob=probs[i],size=10),ylim=c(0,1),type=&quot;h&quot;,xlab=&quot;X&quot;,ylab=&quot;Kans (Dichtheid)&quot;,main= as.expression(substitute(pi == val,list(val=paste(probs[i],&quot;, nobs=10&quot;)))),lwd=3) } plot(2925:3225,dbinom(2925:3225,prob=.5,size=n),type=&quot;h&quot;,xlab=&quot;X&quot;,ylab=&quot;Kans (Dichtheid)&quot;,main= as.expression(substitute(pi == val,list(val=paste0(&quot;0.5, nobs=&quot;,n))))) Figuur 9.2: Binomiale verdelingen. Om nu te toetsen of \\(\\pi=1/2\\) versus het alternatief dat \\(\\pi\\neq 1/2\\), is een voor de hand liggende toetsstatistiek \\(\\bar X-1/2\\) of, equivalent, \\(\\Delta=n(\\bar X-\\pi_0)=S-s_0\\). De verdeling van deze laatste toetsstatistiek volgt rechtstreeks uit de Binomiale verdeling. We observeren \\(s=\\) 3175 en dus \\(\\delta=s-s_0=\\) 3175 \\(-\\) 6155 \\(\\times 0.5=\\) 97.5. In de onderstelling dat jongens en meisjes even waarschijnlijk zijn (d.i. onder de nulhypothese \\(H_0:\\pi=1/2\\)), kunnen we de bijhorende tweezijdige p-waarde berekenen als de kans dat de uitkomst \\[p=\\text{P}_0\\left[S-s_0\\geq \\vert \\delta\\vert \\right] + \\text{P}_0\\left[S-s_0\\leq - \\vert \\delta\\vert \\right].\\] Merk op dat we dit kunnen herschrijven in termen van S. \\[p=\\text{P}_0\\left[S\\geq s_0+ \\vert \\delta\\vert \\right] + \\text{P}_0\\left[S \\leq s_0 - \\vert \\delta\\vert \\right].\\] Voor ons voorbeeld kunnen we deze kansen als volgt berekenen: \\[\\begin{eqnarray*} \\text{P}_0\\left[S\\geq s_0+ \\vert \\delta\\vert \\right] &amp;=&amp; P(S \\geq 6155 \\times 0.5 + \\vert 3175 - 6155 \\times 0.5\\vert ) = P(S \\geq 3175)\\\\ &amp;= &amp;P(S= 3175) + P(S=3176) + ... + P(S=6155)\\\\ &amp; =&amp; 0.0067\\\\\\\\ \\text{P}_0\\left[S \\leq s_0 - \\vert \\delta\\vert \\right] &amp;=&amp; P(S \\leq 6155 \\times 0.5 - \\vert 3175- 6155 \\times 0.5\\vert) = P(S \\leq 2980)\\\\ &amp;= &amp;P(S=0) + ... + P(S=2980) \\\\ &amp;=&amp;0.0067 \\end{eqnarray*}\\] Gezien \\(\\pi=0.5\\) zijn deze kansen gelijk omdat de binomiale distributie dan symmetrisch is. Dat is niet langer het geval wanneer \\(\\pi\\) afwijkt van 0.5. In R kan men de kansen berekenen via de commando’s: pi0 &lt;- 0.5 s0 &lt;- pi0 *n delta &lt;- abs(boys- s0) delta ## [1] 97.5 sUp &lt;- s0 + delta sDown &lt;- s0 -delta c(sDown,sUp) ## [1] 2980 3175 #Merk op dat we voor de berekening naar rechts #pbinom(sUp-1,n,pi) gebruiken omdat we met #pbinom de kans berekenen in de linkse staart #anders wordt s=3175 er niet bij geteld! pUp &lt;- 1-pbinom(sUp-1,n,pi0) pUp ## [1] 0.006699883 pDown &lt;- pbinom(sDown,n,pi0) pDown ## [1] 0.006699883 p &lt;- pUp+pDown p ## [1] 0.01339977 waarbij pbinom(sUp-1,n,pi0) de kans op een resultaat kleiner of gelijk aan \\(s_0+\\vert \\delta\\vert -1 =\\) 3174 berekent. Als \\(\\pi= 1/2\\), dan zou de kans om door toeval minstens \\(\\delta=\\) 97.5 jongens meer of minder te observeren dan het gemiddelde onder \\(H_0: s_0=\\) 3077.5 , slechts 1.34% is, de \\(p\\)-waarde van de binomiale test. Dit geeft aan dat het heel onwaarschijnlijk is om een dergelijk groot aantal jongens te observeren als in realiteit jongens en meisjes even waarschijnlijk zijn. Het drukt met andere woorden uit dat de onderstelling dat jongens en meisjes even waarschijnlijk zijn, weinig gesteund wordt door de data. Dit blijkt ook uit Figuur 9.3. plot(s0+seq(-150.5,150.5,1),dbinom(s0+seq(-150.5,150.5,1),prob=.5,size=n),type=&quot;h&quot;,xlab=&quot;X&quot;,ylab=&quot;Kans (Dichtheid)&quot;,main= as.expression(substitute(pi == val,list(val=paste0(&quot;0.5, nobs=&quot;,n)))),ylim=c(-.0009,0.011)) abline(v=s0,lwd=2,col=4) abline(v=boys,lwd=2,col=2) abline(v=sDown,lwd=1,col=2,lty=2) text(c(sDown,s0,boys,boys),c(rep(0.011,3),0.01),labels=c(expression(paste(s[0]-delta)),expression(s[0]),expression(s==s[0]+delta),as.expression(substitute(s==val,list(val=boys)))),pos=4,col=c(2,4,2)) text(sDown-50,-.0005,label=&quot;p-waarde&quot;,col=2,pos=4) text(sUp,-.0005,label=&quot;p-waarde&quot;,col=2,pos=4) arrows(s0+1500.5,-.0009,sUp,-.0009,col=2,lwd=2,angle=20,length=.1) arrows(s0-1500.5,-.0009,sDown,-.0009,col=2,lwd=2,angle=20,length=.1) Figuur 9.3: Binomiale verdeling van het aantal jongens S onder \\(H_0: \\pi=0.5 (n=6155)\\). De test kan eveneens worden uitgevoerd a.d.h.v. de binomial.test functie in R. binom.test(x=boys,n=n,p=pi0) ## ## Exact binomial test ## ## data: boys and n ## number of successes = 3175, number of trials = 6155, p-value = ## 0.0134 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.5032696 0.5283969 ## sample estimates: ## probability of success ## 0.5158408 Op het 5% significantie-niveau besluiten we dat er gemiddeld meer kans is dat een ongeboren kind mannelijk dan vrouwelijk is. 9.2.2 Betrouwbaarheidsinterval op een proportie De schatter van de proportie van jongens in de populatie, is het steekproefgemiddelde \\(\\hat \\pi=\\bar x=\\) 0.516 en de standaard error is \\[SE_{\\bar x}=\\sqrt{\\frac{\\text{Var}[X]}{n}}=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\] We kunnen dit schatten o.b.v. de steekproef: \\(SE_{\\bar x}=\\sqrt{\\frac{\\hat\\pi(1-\\hat\\pi)}{n}}=\\) 0.0064. Op basis van de centrale limietstelling (CLT, Sectie 5.3.3) kunnen we nu eveneens een 95% betrouwbaarheidsinterval bouwen: \\[\\hat\\pi \\pm 1.96 SE_{\\hat\\pi}.\\] We kunnen dit in R bekomen: se=sqrt(pi*(1-pi)/n) pi+c(-1,1)*qnorm(0.975)*se ## [1] 0.5033559 0.5283257 Een alternatief dat geen grote dataset vereist, is het inverteren van de one-sample test voor proporties. Stop daartoe in het 95% betrouwbaarheidsinterval alle waarden \\(\\pi_0\\) die niet verworpen worden door deze test op het 5% significantieniveau. Dit is geïmplementeerd in de binom.test functie. BI &lt;- binom.test(x=boys,n=n,p=pi0)$conf.int BI ## [1] 0.5032696 0.5283969 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 We verfiëren dit nu: binom.test(x=boys,n=n,p=BI[1],alternative=&quot;greater&quot;) ## ## Exact binomial test ## ## data: boys and n ## number of successes = 3175, number of trials = 6155, p-value = ## 0.025 ## alternative hypothesis: true probability of success is greater than 0.5032696 ## 95 percent confidence interval: ## 0.5052779 1.0000000 ## sample estimates: ## probability of success ## 0.5158408 binom.test(x=boys,n=n,p=BI[2],alternative=&quot;less&quot;) ## ## Exact binomial test ## ## data: boys and n ## number of successes = 3175, number of trials = 6155, p-value = ## 0.025 ## alternative hypothesis: true probability of success is less than 0.5283969 ## 95 percent confidence interval: ## 0.0000000 0.5263925 ## sample estimates: ## probability of success ## 0.5158408 De p-waardes van de exacte eenzijdige testen waarbij \\(\\pi_0\\) gelijk gesteld wordt aan de onder- en bovengrens van het 95% BI zijn inderdaad beiden gelijk aan 0.025. Het exacte BI is te verkiezen boven het BI dat gebaseerd is op de CLT. Voor de Saksen-studie ligt het BI op basis van de CLT heel dicht bij het exacte BI omdat de studie is gebaseerd op een grote steekproef (\\(n=\\) 6155). 9.2.3 Conclusie Merk op dat het testen voor een proportie kan gezien worden als het equivalent van een one-sample t-test voor binaire data. Voor de Saksen populatie besluiten we op het 5% significantieniveau dat er meer kans is dat een ongeboren kind mannelijk dan vrouwelijk is (\\(p=\\) 0.013). De kans dat een ongeboren kind mannelijk is, bedraagt 51.6% (95% BI [50.3,52.8]%). 9.3 Toets voor associatie tussen 2 kwalitatieve variabelen 9.3.1 Gepaarde gegevens Net zoals bij het vergelijken van gemiddelden (uitkomsten op 2 continue veranderlijken) is het ook hier in principe mogelijk dezelfde individuen 2 keer te meten (bijvoorbeeld, vóór en na blootstelling aan de experimentele stof) en telkens de uitkomst te observeren. In dat geval hebben we te maken met gepaarde binaire uitkomsten en moeten we in de statistische analyse rekening houden met de paring. 9.3.1.1 Voorbeeld Rogovin et al. (2017) onderzochten de partnerkeuze van seksueel mature vrouwelijke Campbelli dwerghamster. Hiervoor bekeken ze verschillende karakteristieken van de mannetjes, waaronder seksgerelateerde morfologische kenmerken (lichaamsmassa, externe testikel diameter), testosteron niveau, immunocompetentie kenmerken (de concentratie aan T-cel en B-cel immuuncellen in het bloed), maar ook gedragskenmerken zoals agressiviteit en seksuele dominantie van het mannetje. De experimentele set-up betreft een rechthoekige doos van plexiglas met drie compartimenten, waarin het vrouwtje zich in het middenste gedeelte bevindt (zie Figuur 9.4). Figuur 9.4: Experimentele opstelling voor het bepalen van de partnerkeuze bij dwerghamsters De mannetjes, die overigens broers zijn, hangen vast aan de doos waardoor ze zich slechts over drie vierden van de ruimte van hun compartiment vrij kunnen bewegen. Na alle dieren enkele minuten te laten acclimatiseren worden niet-doorzichtige wanden die de compartimenten scheidden, opgetrokken waardoor het vrouwtje zich via de aangegeven deurtjes naar de mannetjes kan begeven. Aangezien de mannetjes zich niet buiten hun compartiment kunnen begeven, ligt de keuze volledig in de handen van het vrouwtje. Het wordt aangenomen dat het vrouwtje een partnerkeuze maakt indien ze meer dan twee derden van de tijd met één mannetje doorbrengt, relatief ten opzichte van de totale tijd die ze met mannetjes doorbrengt. Elk vrouwtje onderging tweemaal de test, waarbij ze telkens kon kiezen tussen één agressief en één niet-agressief mannetje. Om te onderzoeken of de partnerkeuze van het vrouwtje beïnvloed wordt door de omgeving, kwam het vrouwtje in één van de testen uit een vijandige omgeving (hoge populatie, weinig voedsel, veel concurrentie) en in een andere test uit een vriendelijkere omgeving. De resultaten van de studie zijn samengevat in de onderstaande kruistabel (Tabel 9.1). hamster &lt;- matrix(c(3,17,1,13),ncol=2,byrow=TRUE) rownames(hamster) &lt;- c(&quot;vijandig-agressief&quot;, &quot;vijandig-niet-agressief&quot;) colnames(hamster) &lt;- c(&quot;vriendelijk-agressief&quot;,&quot;vriendelijk-niet-agressief&quot;) Tabel 9.1: Kruistabel van partnerkeuze bij dwerghamster. vriendelijk-agressief vriendelijk-niet-agressief totaal vijandig-agressief 3 (e) 17 (f) 20 vijandig-niet-agressief 1 (g) 13 (h) 14 totaal 4 30 34 De kans op de keuze voor een agressief mannetje na verblijf in een vijandige omgeving noteren we als \\(\\pi_1\\) en kunnen we schatten als \\((e+f)/n\\), waarbij \\(n=e+f+g+h\\). De kans op de keuze voor een agressief mannetje na een vriendelijke omgeving noteren we met \\(\\pi_0\\) en kunnen we schatten als \\((e+g)/n\\). Het verschil tussen beide kansen, het absoluut riscoverschil (ARV), schatten we als \\[\\begin{equation*} \\widehat{\\text{ARV}}=\\hat\\pi_1-\\hat\\pi_0=\\frac{e+f}{n}-\\frac{e+g}{n}=\\frac{f-g}{n} \\end{equation*}\\] en wordt enkel beïnvloed door de aantallen discordante paren \\(f\\) en \\(g\\)56. Men kan aantonen dat de standaard error van dit verschil gelijk is aan \\[\\begin{equation*} \\text{SE}_{\\widehat{\\text{ARV}}}=\\frac{1}{n}\\sqrt{f+g-\\frac{(f-g)^2}{n}} \\end{equation*}\\] Als er voldoende gegevens zijn, kan men een \\((1-\\alpha)100\\%\\) betrouwbaarheidsinterval voor het absolute risicoverschil op de keuze voor een agressief mannetje t.g.v. de omgeving schatten als \\[\\left[\\widehat{\\text{ARV}}-z_{\\alpha/2}\\text{SE}_{\\widehat{\\text{ARV}}},\\widehat{\\text{ARV}}-z_{\\alpha/2}\\text{SE}_{\\widehat{\\text{ARV}}}\\right]\\] of \\[\\left[\\frac{f-g}{n}-\\frac{z_{\\alpha/2}}{n}\\sqrt{f+g-\\frac{(f-g)^2}{n}},\\frac{f-g}{n}+\\frac{z_{\\alpha/2}}{n}\\sqrt{f+g-\\frac{(f-g)^2}{n}}\\right] \\] f=hamster[1,2] g=hamster[2,1] n=sum(hamster) riskdiff=(f-g)/n riskdiff ## [1] 0.4705882 se=sqrt(f+g-(f-g)^2/n)/n se ## [1] 0.09517144 bi=riskdiff+c(-1,1)*qnorm(0.975)*se bi ## [1] 0.2840556 0.6571208 Het absolute risicoverschil op de keuze van een agressief mannetje tussen een verblijf in een vijandige en vriendelijke omgeving bedraagt \\[\\begin{equation*} \\widehat{\\text{ARV}}=\\frac{17-1}{34}=0.471 \\end{equation*}\\] of 47.1%. De standaard error van dit verschil is \\[\\begin{equation*} \\text{SE}_{\\widehat{\\text{ARV}}}=\\frac{1}{34}\\sqrt{17+1-\\frac{(17-1)^2}{34}}=0.0952 \\end{equation*}\\] Een 95% betrouwbaarheidsinterval absolute risicoverschil op de keuze van een agressief mannetje tussen een verblijf in een vijandige en vriendelijke omgeving is bijgevolg \\[\\begin{equation*} \\left[0.471-1.96\\times 0.0952,0.471+1.96\\times 0.0952\\right]=[0.284,0.658] \\end{equation*}\\] We hebben dus geschat dat het absolute risico met 95% kans in het interval [28.4,65.8]% ligt. 9.3.1.2 McNemar test We gaan vervolgens na hoe we kunnen toetsen of de risico’s verschillen tussen de vijandige en vriendelijke omgeving. Indien alle vrouwtjes in zowel de vijandige als vriendelijke omgeving dezelfde partnerkeuze hadden, dan was er geen informatie over de vraag of de omgeving geassocieerd is met de partnerkeuze. Enkel de discordante paren leveren hier informatie over. Als er meer discordante paren zijn waar een vrouwtje een agressief mannetje kiest na verblijf in een vijandige omgeving en een niet-agressief mannetje na een vriendelijke omgeving, dan discordante paren waar het vrouwtje een niet-agressief mannetje kiest na verblijf in een vijandige omgeving en een agressief mannetje kiest na een vriendelijke omgeving, dan is er een indicatie tegen de nulhypothese dat er geen associatie is tussen de partnerkeuze en de omgeving. Men kan daarom toetsen of de partnerkeuze geassocieerd is met de omgeving door de kans te evalueren dat in een lukraak discordant paar, het vrouwtje na verblijf in een vijandige omgeving kiest voor het agressieve mannetje. Deze kans wordt geschat als \\(f/(f+g)\\) en wordt verwacht in de buurt van 0.5 te liggen als de nulhypothese geldt dat er geen associatie is tussen partnerkeuze en omgeving. Meer bepaald volgt het getal \\(f\\) binnen de groep discordante paren onder de nulhypothese een Binomiale verdeling met parameters \\(f+g\\) en 0.5. De standaarddeviatie van \\(f\\) is bijgevolg gelijk aan \\[\\begin{equation*} \\sqrt{(f+g)\\times 0.5\\times 0.5}=\\frac{\\sqrt{f+g}}{2} \\end{equation*}\\] onder de nulhypothese. Op voorwaarde dat er voldoende observaties zijn, kan men nu de one-sample z-test57 gebruiken om te toetsen of de kans dat een lukraak discordant paar in de cel rechtsboven van de tabel gelegen is, 0.5 bedraagt. M.a.w. bekijken we het gestandaardiseerde verschil tussen \\(f\\) en haar verwachtingswaarde onder de nulhypothese: \\[\\begin{equation*} \\frac{f-(f+g)/2}{\\sqrt{f+g}/2}=\\frac{f-g}{\\sqrt{f+g}} \\end{equation*}\\] die bij benadering een Normale verdeling volgt onder de nulhypothese. De Normale benadering is goed als \\[f \\times g/(f+g) \\geq 5\\] De toets gebaseerd op bovenstaande toetsingsgrootheid heet de Mc Nemar toets. In kleine steekproeven is het meer aangewezen om een continuïteitscorrectie te gebruiken d.m.v. de toetsingsgrootheid \\[\\begin{equation*} \\frac{|f-g|-1}{\\sqrt{f+g}} \\end{equation*}\\] De Mc Nemar test wordt gebruikt om te toetsen of er een associatie is tussen 2 kwalitatieve, binaire variabelen, i.h.b. om te toetsen of de kans op succes voor de ene variabele verschilt tussen de 2 strata van de andere kwalitatieve variabele. Ze vereist dat alle metingen voor de ene kwalitatieve variabele (uitkomst) in het ene stratum van de andere kwalitatieve variabele, onafhankelijk zijn, en dat elke meting uit het ene stratum gepaard is met een meting uit het andere stratum in die zin dat ze van verwante subjecten afkomstig zijn. Op die manier vormt ze het analogon van de gepaarde t-test voor binaire, kwalitatieve i.p.v. continue variabelen. We voeren nu de analyse uit voor het hamstervoorbeeld in R: correct=f*g/(f+g) correct ## [1] 0.9444444 #continuiteitscorrectie t= (abs(f-g)-1)/sqrt(f+g) t ## [1] 3.535534 p=(1-pnorm(t))*2 p ## [1] 0.000406952 Voor het dwerghamster voorbeeld observeren we dat \\(f\\times g/(f+g)=\\) 0.944 \\(&lt;5\\). We zullen dus de continuïteitscorrectie uitvoeren. De McNemar toetsingsgrootheid bedraagt \\((\\vert 17-1 \\vert -1)/\\sqrt{17+1}=\\) 3.54. De kans dat een Normaal verdeelde toevalsveranderlijke groter is dan 3.54 of kleiner is dan -3.54 bedraagt 0.0407% en stelt ook de p-waarde van de toets voor. We verwerpen bijgevolg de nulhypothese op het 5% significantieniveau en besluiten dat de parternkeuze extreem significant geassocieerd is met de omgeving. In R kan de analyse ook worden uitgevoerd a.d.h.v. de mcnemar.test functie mcnemar.test(hamster) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: hamster ## McNemar&#39;s chi-squared = 12.5, df = 1, p-value = 0.000407 We zien dat hier eveneens de continuïteitscorrectie werd uitgevoerd en dat we exact dezelfde p-waarde bekomen. Merk echter op dat de Normale benadering van deze toetstatistiek niet ideaal is omdat \\(f \\times g/(f+g)=\\) 0.944 \\(&lt;5\\). Bovenstaande p-waarde is om die reden niet accuraat. Het is hier meer aangewezen om een exacte toets te gebruiken op basis van het principe in Sectie 9.2.1. Dergelijke toetsen maken gebruik van de exacte Binomiale verdeling van de gegevens om te toetsen of de kans dat een lukraak discordant paar in de cel rechtsboven van de tabel gelegen is, 0.5 bedraagt. binom.test(x=f,n=f+g,p=0.5) ## ## Exact binomial test ## ## data: f and f + g ## number of successes = 17, number of trials = 18, p-value = ## 0.000145 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.7270564 0.9985944 ## sample estimates: ## probability of success ## 0.9444444 9.3.1.3 Conclusie Op basis van de exacte test besluiten we eveneens dat de parternkeuze extreem significant geassocieerd is met de omgeving (\\(p&lt;0.001\\)). De kans op de keuze van een agressief mannetje ligt 47.1% hoger als een dwerghamster vrouwtje zich in een vijandige omgeving bevindt dan wanneer ze zich in een vriendelijke omgeving bevindt (95% BI [28.4,65.7]%). 9.3.2 Ongepaarde gegevens We beschouwen hier opnieuw Voorbeeld 3.16. Het is belangrijk om dit voorbeeld eerst grondig door te nemen alsook de Sectie rond data exploratie van categorische variabelen (Sectie 4.5). Deze genetische associatiestudie was erop gericht om na te gaan of polymorfismen in het BRCA1 gen geassocieerd is met borstkanker. Het was een retrospectieve case-controle studie die 800 borstkankercases en 572 controles omvatte. Een R object met de data is opgeslagen in de file brca.rda in de dataset folder. load(&quot;dataset/brca.rda&quot;) head(brca) ## cancer variant variant2 ## 1 control pro/pro andere ## 2 control pro/pro andere ## 3 control pro/pro andere ## 4 control pro/pro andere ## 5 control pro/pro andere ## 6 control pro/pro andere summary(brca) ## cancer variant variant2 ## control:572 pro/pro:608 andere :1227 ## case :800 pro/leu:619 leu/leu: 145 ## leu/leu:145 De dataset bevat 3 categorische variabelen: de ziekte status (factor cancer: controle vs case), brca variant (variant: wild type Pro/Pro, enkele mutatie Pro/Leu, dubbele mutatie Leu/Leu) en een factor of men de dubbele Leu/Leu mutatie bevat of niet (variant2). Een kruistabel kan in R verkregen worden door brcaTab &lt;- table(brca$variant,brca$cancer) brcaTab ## ## control case ## pro/pro 266 342 ## pro/leu 250 369 ## leu/leu 56 89 Informatie omtrent het BRCA1-polymorfisme werd bekomen via DNA-analyse en staat opnieuw getabuleerd in Tabel 9.2. Tabel 9.2: Kruistabel van borstkanker-status versus BRCA1-allel. Genotype Controles Cases Totaal Pro/Pro 266 (a) 342 (d) 608 (a+d) Pro/Leu 250 (b) 369 (e) 619 (b+e) Leu/Leu 56 (c) 89 (f) 145 (c+f) Totaal 572 (a+b+c) 800 (d+e+f) 1372 (n) In Sectie 4.5.2 zagen we reeds dat het relatief risico op de aandoening (d.w.z. op case) in de populatie voor blootgestelden versus niet-blootgestelden niet rechtstreeks kan geschat worden op basis van gegevens uit een case-controle studie. We zagen dat we wel een uitspraak konden doen hierover a.d.h.v. odds ratio’s, gezien het een symmetrische associatie maat is. In voorbeeld 3.16 konden we daarom de odds op borstkanker berekenen voor vrouwen met allel Leu/Leu versus vrouwen zonder de dubbele mutatie als \\(OR=89\\times (266+250)/(56\\times (342+369))=89\\times 512/(56 \\times 711)=1.15\\). De odds op borstkanker is bijgevolg 15% hoger bij vrouwen met die specifieke allelcombinatie. We kunnen ons nu afvragen of dat verschil groot genoeg is zodat we het effect die we in de steekproef zien kunnen veralgemenen naar de populatie toe. Hiertoe zullen we de kruistabel eerst herschrijven tot een 2x2 tabel zodat we de vrouwen met een Leu/Leu variant vergelijken met de vrouwen in de studie die niet homozygoot zijn in de mutatie58 (Tabel 9.3). brcaTab2 &lt;- table(brca$variant2,brca$cancer) brcaTab2 ## ## control case ## andere 516 711 ## leu/leu 56 89 Tabel 9.3: Kruistabel van borstkanker-status versus Leu/Leu-variant. Genotype Controles Cases Totaal andere 516 (a) 711 (c) 1227 (a+c) Leu/Leu 56 (b) 89 (d) 145 (b+d) Totaal 572 (a+b) 800 (c+d) 1372 (n) 9.3.3 De Pearson Chi-kwadraat test voor ongepaarde gegevens We zullen een toets ontwikkelen voor het testen van associatie tussen de categorische blootstelling (bvb. variant, X) en de categorische uitkomst (bvb. ziekte, Y). Concreet zullen we \\[H_0: \\text{Er is geen associatie tussen } X \\text{ en } Y \\text{ vs } H_1: X \\text{ en } Y \\text{ zijn geassocieerd}\\] testen. Beschouw de rijtotalen \\(n_\\text{andere}=a+c\\), \\(n_\\text{leu,leu}=b+d\\) enerzijds en de kolomtotalen \\(n_\\text{contr}=a+b\\) en \\(n_\\text{case}=c+d\\) anderzijds. Zij verstrekken informatie over de marginale verdeling van de blootstelling (bvb. variant, X) en de uitkomst (bvb. ziekte, Y), maar niet over de associatie tussen die veranderlijken. Als de nulhypothese waar is dat \\(X\\) en \\(Y\\) onafhankelijk zijn, dan verwacht men dat een proportie \\((b+d)/n\\) van \\(a+b\\) controles met een Leu/Leu variant, of dat \\((a+b)(b+d)/n\\) een Leu/Leu variant hebben omdat een proportie \\((b+d)/n\\) van alle geobserveerde individuen een Leu/Leu variant heeft. Analoog kan men op basis van de marginale gegevens het verwachte aantal berekenen dat onder de nulhypothese in elke cel van de \\(2\\times 2\\) tabel zou liggen. Dit verwachte aantal onder \\(H_0\\) in de \\((i,j)\\)-de cel (conditioneel op de marges van de tabel) wordt aangeduid met \\(E_{ij}\\) en is het product van het \\(i\\)-de rijtotaal met het \\(j\\)-de kolomtotaal gedeeld door het algemene totaal. In bovenstaand voorbeeld vinden we \\(E_{11}\\) = het verwachte aantal onder \\(H_0\\) in de (1,1)-cel = 1227 \\(\\times\\) 572/1372 = 511.5 ; \\(E_{12}\\) = het verwachte aantal onder \\(H_0\\) in de (1,2)-cel = 1227 \\(\\times\\) 800/1372 = 715.5 ; \\(E_{21}\\) = het verwachte aantal onder \\(H_0\\) in de (2,1)-cel = 145 \\(\\times\\) 572/1372 = 60.45 ; \\(E_{22}\\) = het verwachte aantal onder \\(H_0\\) in de (2,2)-cel = 145 \\(\\times\\) 800/1372 = 84.55 ; Een toets van de nulhypothese gebeurt nu op basis van een vergelijking tussen de geobserveerde aantallen in cellen \\((i,j),\\) genoteerd met \\(O_{ij}\\) en de verwachte aantallen \\(E_{ij}\\). In dat opzicht levert de toetsingsgrootheid \\[\\begin{equation*} X^2 = \\frac{\\left (|O_{11} - E_{11}| - .5 \\right)^2 }{ E_{11}} + \\frac{ \\left ( |O_{12} - E_{12}| - .5 \\right)^2 }{E_{12} }+ \\frac{ \\left ( |O_{21} - E_{21}| - .5 \\right)^2 }{E_{21}}+ \\frac{ \\left ( |O_{22} - E_{22}| - .5 \\right)^2 }{E_{22} } \\end{equation*}\\] een goede discriminatie tussen de nulhypothese en de alternatieve hypothese. Men kan aantonen dat ze onder de nulhypothese bij benadering een zogenaamde \\(\\chi^2\\)-verdeling volgt met 1 vrijheidsgraad. Deze verdeling neemt uiteraard alleen positieve waarden aan en is scheef naar rechts verdeeld, behalve als het aantal vrijheidsgraden groot is (minstens 100), in welk geval ze meer symmetrisch wordt. Figuur 9.5 toont haar algemene vorm. grid=seq(0,10,.1) plot(grid,dchisq(grid,1),type=&quot;l&quot;,lwd=2) dfs=c(1,2,5) for (i in 2:3) lines(grid,dchisq(grid,dfs[i]),col=i,lwd=2) legend(&quot;topright&quot;,lty=1,lwd=2,col=1:3,legend=sapply(dfs, function(d) as.expression(substitute(chi[df==val]^2,list(val=d))))) Figuur 9.5: Dichtheidsfuncties voor enkele Chi-kwadraat verdelingen Een grote waarde van de toetsingsgrootheid geeft een indicatie van een afwijking van de nulhypothese. Concreet zal een toets op het \\(\\alpha 100\\%\\) significantieniveau de nulhypothese verwerpen zodra de geobserveerde waarde van de toetsingsgrootheid het \\(100\\%(1-\\alpha)\\)-percentiel, \\(\\chi^2_{1, \\alpha}\\), van de \\(\\chi^2_1\\)-verdeling overschrijdt. Ze kan niet verwerpen in het andere geval. De p-waarde voor een 2-zijdige toets is in dit geval de kans om een grotere waarde voor de toetsingsgrootheid te observeren dan de geobserveerde waarde \\(x^2\\) als de nulhypothese waar is. Dit is de kans dat een \\(\\chi^2_1\\)-verdeelde toevalsveranderlijke waarden groter dan \\(x^2\\) aanneemt. expected &lt;- matrix(0,nrow=2,ncol=2) for (i in 1:2) for (j in 1:2) expected[i,j] &lt;- sum(brcaTab2[i,])*sum(brcaTab2[,j])/sum(brcaTab2) expected ## [,1] [,2] ## [1,] 511.5481 715.4519 ## [2,] 60.4519 84.5481 x2 &lt;- sum((abs(brcaTab2-expected) - .5)^2/expected) 1-pchisq(x2,1) ## [1] 0.481519 Omdat de observaties \\(O_{ij}\\) in feite discrete getallen zijn, kan de toetsingsgrootheid \\(X^2\\) slechts discrete waarden aannemen en kan een continue verdeling zoals de \\(\\chi^2_1\\)-verdeling slechts een benadering zijn voor haar werkelijke verdeling. Om de discrete verdeling beter bij de continue \\(\\chi^2_1\\)-verdeling te doen aansluiten, heeft men in de uitdrukking van de toetsingsgrootheid voor elke cel telkens 0.5 afgetrokken. Dit wordt een continuïteitscorrectie genoemd. In dit geval gaat het om de correctie van Yates en noemt men deze toets dan ook de Pearson Chi-kwadraat toets met Yates correctie. Wanneer de correctie niet gebruikt wordt (d.w.z. wanneer de getallen `0.5’ in de uitdrukking voor \\(X^2\\) door 0 vervangen worden), dan spreekt men van de Pearson Chi-kwadraat toets. In R kan je deze toetsen uitvoeren door de optie op TRUE of FALSE te zetten: chisq.test(brcaTab2) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: brcaTab2 ## X-squared = 0.49542, df = 1, p-value = 0.4815 chisq.test(brcaTab2,correct=FALSE) ## ## Pearson&#39;s Chi-squared test ## ## data: brcaTab2 ## X-squared = 0.62871, df = 1, p-value = 0.4278 Zelfs wanneer de continuïteitscorrectie wordt gebruikt, zal de \\(\\chi^2_1\\) benadering voor de verdeling van de toetsingsgrootheid slechts verantwoord zijn als in geen enkele van de cellen het verwachte aantal onder \\(H_0\\) kleiner is dan 5. Wanneer de \\(\\chi^2\\)-benadering niet verantwoord is, kan men een exacte toets uitvoeren die rekening houdt met de echte mogelijke verdelingen van de marginale tellingen over de individuele cellen in de tabel. Dergelijke test maakt bijgevolg geen \\(\\chi^2\\)-benadering voor de verdeling van de toetsingsgrootheid onder de nulhypothese. De test die met de exacte verdeling van de marginale tellingen over de individuele cellen rekening houdt, wordt in de literatuur Fisher’s exact test genoemd. De nulhypothese van deze test is eveneens dat \\(X\\) en \\(Y\\) onafhankelijk zijn, en de alternatieve hypothese dat \\(X\\) en \\(Y\\) afhankelijk zijn. Een nadeel van de exacte test, is dat ze conservatief is (d.w.z. dat ze een kleinere kans hebben op een Type I fout dan vooropgesteld, en bijgevolg een grotere kans op Type II fouten). In R bekomt men deze test als volgt: fisher.test(brcaTab2) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: brcaTab2 ## p-value = 0.4764 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.7998798 1.6738449 ## sample estimates: ## odds ratio ## 1.153279 Merk op dat deze functie tevens 95% betrouwbaarheidsintervallen rapporteert voor de bijhorende odds ratio. 9.3.3.1 Uitbreiding naar categorische variabelen met meerdere niveaus Als minstens 1 van de discrete variabelen \\(X\\) en \\(Y\\) meer dan 2 mogelijke waarden aanneemt, kan men nagaan of de kansverdeling van \\(Y\\) afhangt van de \\(X\\)-waarde in de populatie door een veralgemening van de \\(\\chi^2\\)-toets uit vorige sectie. Ook hier toetst men de nulhypothese \\(H_0: X\\) en \\(Y\\) zijn onafhankelijk, ten opzichte van het tweezijdig alternatief \\(H_A: X\\) en \\(Y\\) zijn niet onafhankelijk. Als de variabele voorgesteld op de rijen \\(r\\) mogelijke uitkomsten heeft en die op de kolommen \\(c\\) mogelijke uitkomsten, dan noemt men de kruistabel die \\(X\\) tegenover \\(Y\\) uitzet, een \\(r \\times c\\) tabel. Zoals voorheen vergelijkt men het aantal geobserveerde waarden in cel \\((i,j)\\), \\(O_{ij}\\) genoteerd, met het aantal verwachte waarden onder de nulhypothese in deze cel, \\(E_{ij}\\) genoemd, op basis van de marginale totalen. Net als voorheen is \\(E_{ij}\\) het product van het \\(i\\)-de rijtotaal met het \\(j\\)-de kolomtotaal gedeeld door het algemene totaal. De toetsingsgrootheid is nu \\[\\begin{equation*} X^2 = \\sum_{ij} \\frac{\\left (O_{ij} - E_{ij}\\right)^2 }{ E_{ij}} \\end{equation*}\\] Men kan aantonen dat ze een Chi-kwadraat verdeling volgt met \\((r-1) \\times (c-1)\\) vrijheidsgraden als de nulhypothese waar is. De continuïteitscorrectie wordt meestal niet gebruikt bij meer dan 2 rijen of kolommen. We voeren nu de test uit voor het BRCA voorbeeld waarbij we nu gebruik maken van alle varianten chisq.test(brcaTab) ## ## Pearson&#39;s Chi-squared test ## ## data: brcaTab ## X-squared = 2.0551, df = 2, p-value = 0.3579 Om te onderzoeken of het BRCA1 gen geassocieerd is met borstkanker, berekenen we de Pearson chi-kwadraat toets voor de case-controle studie uit Tabel 9.2. De toetsingsgrootheid bedraagt nu 2.055 en volgt een Chi-kwadraat verdeling met 2 vrijheidsgraden. De kans dat zo’n \\(\\chi^2\\)- verdeelde toevalsveranderlijke extremer is dan 2.055, bedraagt 36%. Op het 5% significantieniveau kunnen we dus niet besluiten dat het BRCA1 gen geassocieerd is met borstkanker. De Pearson \\(\\chi^2\\) test wordt gebruikt om te toetsen of er een associatie is tussen 2 kwalitatieve (mogelijks niet binaire) variabelen, i.h.b. om te toetsen of de verdeling59 van de ene kwalitatieve variabele verschilt alnaargelang de waarde van de andere kwalitatieve variabele. Ze vereist dat de 2 metingen voor de 2 kwalitatieve variabelen telkens bekomen werden van onafhankelijke subjecten, en dat minstens 80% van de cellen in de overeenkomstige kruistabel een verwacht aantal observaties van minstens 5 bezitten. Op die manier vormt ze het analogon van de one-way variantie-analyse voor kwalitatieve i.p.v. continue variabelen. 9.4 Logistische regressie In de statistische literatuur bestaat ook een raamwerk voor het modelleren van binaire data (vb. kanker vs geen kanker): logistische regressie-modellen. Net zoals we bij het regressiemodel voor Normale continue gegevens hebben gezien in Hoofdstuk 6, 7 en 10, laten logistische regressie modellen toe om binaire gegevens te modelleren a.d.h.v. continue en/of dummy variabelen. De modellen veronderstellen dat de observaties voor subject \\(i=1,\\ldots,n\\) onafhankelijk zijn en een Bernoulli verdeling volgen. Het logaritme van de odds wordt dan gemodelleerd d.m.v. een lineair model, ook wel lineaire predictor genoemd: \\[\\begin{equation} \\left\\{ \\begin{array}{ccl} Y_i&amp;\\sim&amp;B(\\pi_i)\\\\\\\\ \\log \\frac{\\pi_i}{1-\\pi_i}&amp;=&amp;\\beta_0 + \\beta_1X_{i1} + \\ldots + \\beta_p X_{ip} \\end{array}\\right. \\end{equation}\\] 9.4.1 Categorische predictor We illustreren logistische regressie aan de hand van het borstkanker voorbeeld waar we bestuderen of de BRCA 1 variant geassocieerd is met het krijgen van borstkanker (zie Sectie 9.3.2). Net zoals in de anova context, kunnen we een factor in het regressieraamwerk introduceren door gebruik te maken van dummy variabelen. We zullen hierbij 1 dummy variable minder nodig hebben dan er groepen zijn. Voor het BRCA 1 voorbeeld zijn dus twee dummy variabelen nodig en kunnen we de data dus modelleren met onderstaande lineaire predictor: \\[\\begin{eqnarray*} \\log \\frac{\\pi_i}{1-\\pi_i} &amp;=&amp; \\beta_0+\\beta_1 x_{i1} +\\beta_2 x_{i2} \\end{eqnarray*}\\] Waarbij de predictoren dummy-variabelen zijn: \\[x_{i1} = \\left\\{ \\begin{array}{ll} 1 &amp; \\text{ als subject $i$ heterozygoot is, Pro/Leu variant} \\\\ 0 &amp; \\text{ als subject $i$ homozygoot is, (Pro/Pro of Leu/Leu variant)} \\end{array}\\right. .\\] en \\[x_{i2} = \\left\\{ \\begin{array}{ll} 1 &amp; \\text{ als subject $i$ homozygoot is in de Leucine mutatie: Leu/Leu variant} \\\\ 0 &amp; \\text{ als subject $i$ niet homozygoot is in de Leu/Leu variant} \\end{array}\\right. .\\] Homozygositeit in het wild type allel Pro/Pro wordt voor dit model de referentiegroep. Het model wordt als volgt in R gefit: brcaLogit &lt;- glm(cancer~variant,data=brca,family=binomial) summary(brcaLogit) ## ## Call: ## glm(formula = cancer ~ variant, family = binomial, data = brca) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.379 -1.286 1.017 1.017 1.073 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.25131 0.08175 3.074 0.00211 ** ## variantpro/leu 0.13802 0.11573 1.193 0.23302 ## variantleu/leu 0.21197 0.18915 1.121 0.26243 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1863.9 on 1371 degrees of freedom ## Residual deviance: 1861.9 on 1369 degrees of freedom ## AIC: 1867.9 ## ## Number of Fisher Scoring iterations: 4 Het intercept is de log-odds op kanker in de referentieklasse (Pro/Pro) en de hellingstermen zijn log odds ratio’s tussen de behandeling en de referentieklasse: \\[\\begin{eqnarray*} \\log \\text{ODDS}_\\text{Pro/Pro}&amp;=&amp;\\beta_0\\\\\\\\ \\log \\text{ODDS}_\\text{Pro/Leu}&amp;=&amp;\\beta_0+\\beta_1\\\\\\\\ \\log \\text{ODDS}_\\text{Leu/Leu}&amp;=&amp;\\beta_0+\\beta_2\\\\\\\\ \\log \\frac{\\text{ODDS}_\\text{Pro/Leu}}{\\text{ODDS}_\\text{Pro/Pro}}&amp;=&amp;\\log \\text{ODDS}_\\text{Pro/Leu}-\\log ODDS_{Pro/Pro}\\\\ &amp;=&amp;\\beta_0+\\beta_1-\\beta_0=\\beta_1\\\\\\\\ \\log \\frac{\\text{ODDS}_\\text{Leu/Leu}}{\\text{ODDS}_\\text{Pro/Pro}}&amp;=&amp;\\beta_2 \\end{eqnarray*}\\] De analyse laat dus toe om de resultaten onmiddellijk te interpreteren in termen van Odds’es en Odds-ratio’s! Net zoals bij een ANOVA analyse bij een continue response, kan de anova functie worden gebruikt voor het testen of er een associatie is tussen het voorkomen van kanker en de genetische variant. anova(brcaLogit,test=&quot;Chisq&quot;) ## Analysis of Deviance Table ## ## Model: binomial, link: logit ## ## Response: cancer ## ## Terms added sequentially (first to last) ## ## ## Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) ## NULL 1371 1863.9 ## variant 2 2.0562 1369 1861.9 0.3577 De \\(\\chi^2\\)-test in het logistische regressiemodel geeft eveneens aan dat er geen significante associatie is tussen de uitkomst (voorkomen van kanker) en de factor ( de genetische variant van het BRCA gen) (\\(p=\\) 0.358). De p-waarde is bijna equivalent aan de p-waarde van de \\(\\chi^2\\)-test uit de vorige sectie. Als er een significante associatie was geweest, dan hadden we post-hoc tests kunnen uitvoeren om te evalueren welke odds ratio’s verschillend zijn. Voor het BRCA1 voorbeeld zouden we uiteraard geen post-hoc testen uitvoeren omdat de globale \\(\\chi^2\\)-test voor het testen van associatie niet significant is. We illustreren de post-hoc analyse toch zodat jullie over de code beschikken voor het uitvoeren van de analyses. library(multcomp) posthoc=glht(brcaLogit,linfct=mcp(variant = &quot;Tukey&quot;)) posthocTests=summary(posthoc) posthocTests ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: glm(formula = cancer ~ variant, family = binomial, data = brca) ## ## Linear Hypotheses: ## Estimate Std. Error z value Pr(&gt;|z|) ## pro/leu - pro/pro == 0 0.13802 0.11573 1.193 0.449 ## leu/leu - pro/pro == 0 0.21197 0.18915 1.121 0.493 ## leu/leu - pro/leu == 0 0.07395 0.18922 0.391 0.917 ## (Adjusted p values reported -- single-step method) posthocBI=confint(posthoc) posthocBI ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: glm(formula = cancer ~ variant, family = binomial, data = brca) ## ## Quantile = 2.3256 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## pro/leu - pro/pro == 0 0.13802 -0.13112 0.40716 ## leu/leu - pro/pro == 0 0.21197 -0.22790 0.65184 ## leu/leu - pro/leu == 0 0.07395 -0.36609 0.51399 Door middel van de confint functie worden BI’s verkregen op de log-odds ratios die gecorrigeerd zijn voor multiple testing. Deze kunnen als volgt worden teruggetransformeerd naar odds ratios: OR=exp(posthocBI$confint) OR ## Estimate lwr upr ## pro/leu - pro/pro 1.148000 0.8771158 1.502543 ## leu/leu - pro/pro 1.236111 0.7962014 1.919075 ## leu/leu - pro/leu 1.076752 0.6934417 1.671942 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 ## attr(,&quot;calpha&quot;) ## [1] 2.325567 De odds ratios die worden bekomen met het logistisch regressiemodel zijn exact gelijk aan de odds ratios die we zouden bekomen op basis van Tabel 9.2: vb. \\(\\text{OR}_\\text{Leu/Leu-Pro/Pro}=89\\times 266/(56\\times 342)=\\) 1.236. Merk op dat de statistische besluitvorming bij logistische modellen beroep doet op asymptotische theorie. Ze is dus enkel correct voor grote steekproeven. 9.4.2 Continue predictor Om het toxicologisch effect van een stof te kwantificeren worden dierproeven uitgevoerd waarbij dieren bij verschillende concentraties van de stof worden blootgesteld voor een bepaalde tijd. In dit voorbeeld wordt koolstofdisulfide (CS\\(_2\\)) bestudeerd in proeven met kevers. De centrale onderzoeksvraag is of de concentratie van CS\\(_2\\) een effect heeft op de mortaliteit (i.e. kans op sterven) van de kevers? Design In 32 onafhankelijk experimenten wordt een kever blootgesteld aan één van 8 concentraties (mg/l) van CS\\(_2\\) voor een gegeven periode. De uitkomst van het experiment is: de kever sterft (\\(y=1\\)) of de kever overleeft (\\(y=0\\)). Een R object met de data is opgeslagen in de file kevers.rda in de dataset folder. load(&quot;dataset/kevers.rda&quot;) head(kevers) ## dosis status ## 1 169.07 1 ## 2 169.07 0 ## 3 169.07 0 ## 4 169.07 0 ## 5 172.42 1 ## 6 172.42 0 table(kevers$dosis,kevers$status) ## ## 0 1 ## 169.07 3 1 ## 172.42 3 1 ## 175.52 3 1 ## 178.42 2 2 ## 181.13 1 3 ## 183.69 0 4 ## 186.1 0 4 ## 188.39 0 4 We bouwen nu een logistisch regressiemodel waarbij we de log odds modelleren in functie van de dosis \\(x_i\\): \\[\\log \\frac{\\pi_i}{1-\\pi_i}=\\beta_0+\\beta_1 \\times x_i.\\] keverModel&lt;-glm(status~dosis,data=kevers,family=binomial) summary(keverModel) ## ## Call: ## glm(formula = status ~ dosis, family = binomial, data = kevers) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.7943 -0.7136 0.2825 0.5177 2.1670 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -53.1928 18.0046 -2.954 0.00313 ** ## dosis 0.3013 0.1014 2.972 0.00296 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 42.340 on 31 degrees of freedom ## Residual deviance: 26.796 on 30 degrees of freedom ## AIC: 30.796 ## ## Number of Fisher Scoring iterations: 5 Het intercept heeft als betekenis de log odds op mortaliteit wanneer er geen \\(\\text{CS}_2\\) gas wordt toegediend. Het duidt op een heel erg lage odds op sterfte (\\(\\pi/(1-\\pi)=\\exp(-53.2)\\)) en dus op een kans die nagenoeg nul is. We verwachten inderdaad dat de kevers niet zullen sterven als we geen gas gebruiken in het experiment. Merk op dat de interpretatie van het intercept echter wel op een heel sterke extrapolatie berust gezien de minimum dosis in de dataset 169.07 mg/l bedroeg. De geschatte odds ratio voor het effect van dosis op de mortaliteitskans is \\(\\exp(0.3013)=1.35\\). Dus bij een toename van de dosis CS\\(_2\\) met 1 mg/l, is de odds ratio voor de mortaliteit \\(1.35\\). We besluiten dat dit effect heel significant is (\\(p=\\) 0.003). Een toename in de CS\\(_2\\) dosis doet de kans op sterven toenemen. Figuur 9.6 toont de geschatte probabiliteit in functie van de dosis die werd gefit a.d.h.v. het regressiemodel. De figuur werd bekomen met onderstaande R code. We kunnen predicties voor nieuwe dosissen berekenen d.m.v. de predict functie. Het argument type=&quot;response&quot; geeft aan dat we de predicties op de probabiliteitsschaal wensen. Wanneer we dat niet specifiëren genereert het model predictie op de log odds schaal. dosisGrid=seq(min(kevers$dosis),max(kevers$dosis),.1) piHat=predict(keverModel,newdata=data.frame(dosis=dosisGrid),type=&quot;response&quot;) plot(dosisGrid, piHat, type=&quot;l&quot;,ylim=c(0,1), xlab=&quot;dosis&quot;, ylab=&quot;Prob(dood)&quot;) #omdat we meerdere observaties hebben voor elke dosis, #zullen we berekenen hoeveel kevers er leefden voor elke dosis #en dat uitzetten in de grafiek #zodat de ruwe gegevens ook worden weergegeven. tabKevers=table(kevers) text(as.double(rownames(tabKevers)),0,labels=tabKevers[,1]) text(as.double(rownames(tabKevers)),1,labels=tabKevers[,2]) Figuur 9.6: Fit van het logistische regressiemodel voor de kevers data. Het aantal kevers die dood/levend was per dosis is weergegeven met een cijfer. References "],
["chap-glm.html", "Hoofdstuk 10 Algemeen lineair model", " Hoofdstuk 10 Algemeen lineair model In dit hoofdstuk worden lineaire modellen gebouwd voor een continue response i.f.v. meerdere continue en/of discrete predictor variabelen. Het is enkel leerstof voor de studenten uit de Bachelor of Science in de Biochemie en de Biotechnologie De Bachelor of Science in de Biomedische Wetenschappen Schakelprogramma tot Master of Science in Bioinformatics afstudeerrichting Systems Biology Schakelprogramma tot Master of Science in Biochemistry and Biotechnology. Het hoofdstuk komt gedurende het academiejaar online "]
]
